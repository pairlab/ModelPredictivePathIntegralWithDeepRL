Model: <class 'src.models.pytorch.agents.ppo.PPOAgent'>, Env: CarRacing-v1, Date: 23/05/2020 00:44:12
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: eae029f6533faf8e9c0a6033f28b9fc11ef56e50
Branch: master

config: 
   TRIAL_AT = 5000
   SAVE_AT = 1
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 32
   PPO_EPOCHS = 2
   ENTROPY_WEIGHT = 0.005
   CLIP_PARAM = 0.05
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = ppo
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fe1a0d41d90> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7fe1a0d41890>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7fe1a0d0e050>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			pos_scale = 1
			vtarget = 20
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7fe1a0cfbf10> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7fe1a0cfbad0> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				cost_map = [[ 214.381  214.299  214.217 ...  112.184  112.264  112.344]
				 [ 214.324  214.242  214.160 ...  112.124  112.204  112.284]
				 [ 214.267  214.185  214.103 ...  112.064  112.144  112.224]
				 ...
				 [  96.764   96.690   96.616 ...  242.661  242.689  242.717]
				 [  96.831   96.757   96.683 ...  242.757  242.785  242.813]
				 [  96.898   96.824   96.750 ...  242.852  242.881  242.909]]
				res = 0.1
				min_point = [-215.266 -178.250    0.000]
				max_point = [ 210.234  262.950    0.000]
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 
					def get_reward(self, state, prevstate=None):
						prevstate = state if prevstate is None else prevstate
						px, pz, py = prevstate[:3]*self.pos_scale
						x, z, y = state[:3]*self.pos_scale
						_, _, vy = state[3:6]
						idle = state[29]
						cost = self.cost_model.get_cost((x,y), transform=True)
						progress = self.cost_model.track.get_progress([px,py,pz], [x,y,z])
						reward = min(progress,0)*np.exp(2*cost) + np.tanh(progress)/np.exp(cost) + (1-np.power(vy-self.vtarget,2)/self.vtarget**2) + np.tanh(vy)-cost
						return reward
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state = self.observation(next_state)
						reward = self.get_reward(next_state, self.state) - (1-self.time/self.max_time)*int(done)
						self.state = next_state
			
			max_time = 500
			time = 0
			idle_timeout = 10
			state = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  2.000e-02 -1.617e-09  3.908e-03  7.273e-09  8.070e-02  4.592e-03  2.580e-01  1.513e-01  5.392e-03  5.773e-01  2.373e-01  6.680e-03  9.128e-01  3.132e-01  8.130e-03  1.261e+00  3.895e-01  1.002e-02  1.642e+00  5.043e-01  1.191e-02  2.129e+00  6.238e-01  3.193e-02  2.720e+00  7.631e-01  1.057e-01  3.366e+00  9.149e-01  1.247e-01  4.101e+00]
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7fe21f97c4d0>
					get_reward = <function CarRacing.get_reward at 0x7fe21f97c440>
					step = <function CarRacing.step at 0x7fe21f987560>
					render = <function CarRacing.render at 0x7fe21f9875f0>
					observation = <function CarRacing.observation at 0x7fe21f987680>
					close = <function CarRacing.close at 0x7fe21f987710>
					id = 1
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(60,) 
			dtype = float32
			shape = (60,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fe1a11265d0> 
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (60,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fe1a0cb31d0> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=203, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49772), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=204, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58440), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=205, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54958), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=206, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55222), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=207, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49262), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=209, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54406), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=210, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33954), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=211, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45574), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=212, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38886), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=213, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 42488), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=214, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 52294), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=215, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33458), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=216, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 52864), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=217, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57856), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=218, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 46646), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=219, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51158), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 5000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fe1a0cb3410> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fe1a0cb3850> 
		state_size = (60,)
	agent = <src.models.pytorch.agents.ppo.PPOAgent object at 0x7fe1a0cb3e50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fe1a0cb3f90> 
			size = (3,)
			dt = 0.2
			action = [-1.000 -0.666  0.066]
			daction_dt = [ 0.654 -0.443 -0.550]
		discrete = False
		action_size = (3,)
		state_size = (60,)
		config = <src.utils.config.Config object at 0x7fe1a955c650> 
			TRIAL_AT = 5000
			SAVE_AT = 1
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 32
			PPO_EPOCHS = 2
			ENTROPY_WEIGHT = 0.005
			CLIP_PARAM = 0.05
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = ppo
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7fe1a0cb34d0> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = PPONetwork(
			  (actor_local): PPOActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): PPOActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): PPOCritic(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=1024, bias=True)
			    (layer3): Linear(in_features=1024, out_features=1024, bias=True)
			    (value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): PPOCritic(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=1024, bias=True)
			    (layer3): Linear(in_features=1024, out_features=1024, bias=True)
			    (value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			training = True
			tau = 0.0004
			name = ppo
			stats = <src.utils.logger.Stats object at 0x7fe1a0cc0110> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fe1a955c650> 
				TRIAL_AT = 5000
				SAVE_AT = 1
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 32
				PPO_EPOCHS = 2
				ENTROPY_WEIGHT = 0.005
				CLIP_PARAM = 0.05
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = ppo
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class PPOActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config, use_discrete=False):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = use_discrete and type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Parameter(torch.zeros(action_size[-1]))\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\t\tself.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)\n\t\t\n\tdef forward(self, state, action_in=None, sample=True):\n\t\tstate = self.layer1(state).relu()\n\t\tstate = self.layer2(state).relu()\n\t\tstate = self.layer3(state).relu()\n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig.exp().expand_as(action_mu)\n\t\tdist = self.dist(action_mu, action_sig)\n\t\taction = dist.sample() if action_in is None else action_in.argmax(-1) if self.discrete else action_in\n\t\taction_out = one_hot_from_indices(action, action_mu.size(-1)) if self.discrete else action\n\t\tlog_prob = dist.log_prob(action)\n\t\tentropy = dist.entropy()\n\t\treturn action_out, log_prob, entropy\n', 'class PPOCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, critic_hidden)\n\t\tself.layer3 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state):\n\t\tstate = self.layer1(state).relu()\n\t\tstate = self.layer2(state).relu()\n\t\tstate = self.layer3(state).relu()\n\t\tvalue = self.value(state)\n\t\treturn value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fe1a0cb3b90> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fe1a0cb3e90> 
		size = (3,)
		dt = 0.2
		action = [ 0.465  1.000 -0.303]
		daction_dt = [ 1.519  0.942 -0.444]
	discrete = False
	action_size = (3,)
	state_size = (60,)
	config = <src.utils.config.Config object at 0x7fe1a955c650> 
		TRIAL_AT = 5000
		SAVE_AT = 1
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 32
		PPO_EPOCHS = 2
		ENTROPY_WEIGHT = 0.005
		CLIP_PARAM = 0.05
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = ppo
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7fe1a0cc0810> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import numpy as np
from .base import PTACNetwork, PTAgent, Conv, one_hot_from_indices
from src.utils.rand import ReplayBuffer, PrioritizedReplayBuffer

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config, use_discrete=False):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = use_discrete and type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Parameter(torch.zeros(action_size[-1]))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)
		
	def forward(self, state, action_in=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = self.dist(action_mu, action_sig)
		action = dist.sample() if action_in is None else action_in.argmax(-1) if self.discrete else action_in
		action_out = one_hot_from_indices(action, action_mu.size(-1)) if self.discrete else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action_out, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, critic_hidden)
		self.layer3 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=PPOActor, critic=PPOCritic, gpu=True, load=None, name="ppo"):
		super().__init__(state_size, action_size, config, actor=actor, critic=critic, gpu=gpu, load=load, name=name)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			action_or_entropy = action if action_in is None else entropy.mean()
			return (x.cpu().numpy() if numpy else x for x in [action_or_entropy, log_prob])

	def get_value(self, state, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device)).cpu().numpy() if numpy else self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, config):
		values = self.get_value(states, grad=True)
		critic_loss = (values - targets).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)

		entropy, new_log_probs = self.get_action_probs(states, actions, grad=True)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-config.CLIP_PARAM, 1.0+config.CLIP_PARAM)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + config.ENTROPY_WEIGHT*entropy).mean()
		self.step(self.actor_optimizer, actor_loss)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)

class PPOAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, PPONetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		self.action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			values = self.network.get_value(states)
			targets, advantages = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states[:-1], actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*self.config.PPO_EPOCHS)//self.config.BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(self.config.BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, config=self.config)
				

Step:       0, Reward:  -142.357 [  94.858], Avg:  -142.357 (1.000) <0-00:00:00> ({'r_t':    -0.4166, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    5000, Reward:   -36.400 [  41.945], Avg:   -89.378 (1.000) <0-00:02:06> ({'r_t': -1424.5183, 'eps':     1.0000, 'critic_loss':    20.9901, 'actor_loss':     2.0207, 'eps_e':     1.0000})
Step:   10000, Reward:    42.176 [  11.112], Avg:   -45.527 (1.000) <0-00:04:04> ({'r_t':   341.5130, 'eps':     1.0000, 'critic_loss':     9.7426, 'actor_loss':    -0.3428, 'eps_e':     1.0000})
Step:   15000, Reward:    69.295 [  12.315], Avg:   -16.822 (1.000) <0-00:06:03> ({'r_t':  1348.4579, 'eps':     1.0000, 'critic_loss':     4.2567, 'actor_loss':    -0.1297, 'eps_e':     1.0000})
Step:   20000, Reward:   101.832 [  13.113], Avg:     6.909 (1.000) <0-00:08:01> ({'r_t':  1969.9837, 'eps':     1.0000, 'critic_loss':     4.8644, 'actor_loss':    -0.3801, 'eps_e':     1.0000})
Step:   25000, Reward:   129.269 [  18.371], Avg:    27.302 (1.000) <0-00:10:01> ({'r_t':  2343.3352, 'eps':     1.0000, 'critic_loss':     4.0580, 'actor_loss':    -0.4961, 'eps_e':     1.0000})
Step:   30000, Reward:   129.607 [  34.564], Avg:    41.917 (1.000) <0-00:12:08> ({'r_t':  2157.6460, 'eps':     1.0000, 'critic_loss':    12.6390, 'actor_loss':    -0.5127, 'eps_e':     1.0000})
Step:   35000, Reward:   144.031 [  33.956], Avg:    54.682 (1.000) <0-00:14:14> ({'r_t':  1867.8260, 'eps':     1.0000, 'critic_loss':    24.2083, 'actor_loss':    -0.8268, 'eps_e':     1.0000})
Step:   40000, Reward:   183.803 [  18.502], Avg:    69.028 (1.000) <0-00:16:18> ({'r_t':  2530.5743, 'eps':     1.0000, 'critic_loss':    17.6196, 'actor_loss':    -1.0554, 'eps_e':     1.0000})
Step:   45000, Reward:   188.398 [  29.926], Avg:    80.965 (1.000) <0-00:18:25> ({'r_t':  2702.0579, 'eps':     1.0000, 'critic_loss':    11.1209, 'actor_loss':     0.1850, 'eps_e':     1.0000})
Step:   50000, Reward:   192.193 [  25.036], Avg:    91.077 (1.000) <0-00:20:31> ({'r_t':  2575.1775, 'eps':     1.0000, 'critic_loss':    12.4200, 'actor_loss':     0.1622, 'eps_e':     1.0000})
Step:   55000, Reward:   169.926 [  46.888], Avg:    97.648 (1.000) <0-00:22:38> ({'r_t':  2542.2546, 'eps':     1.0000, 'critic_loss':    13.1166, 'actor_loss':     0.0202, 'eps_e':     1.0000})
Step:   60000, Reward:   193.038 [  30.500], Avg:   104.985 (1.000) <0-00:24:44> ({'r_t':  1941.3670, 'eps':     1.0000, 'critic_loss':    19.9990, 'actor_loss':     0.0161, 'eps_e':     1.0000})
Step:   65000, Reward:   183.801 [  59.720], Avg:   110.615 (1.000) <0-00:26:51> ({'r_t':  2557.2595, 'eps':     1.0000, 'critic_loss':    10.6774, 'actor_loss':    -0.2030, 'eps_e':     1.0000})
Step:   70000, Reward:   131.760 [  54.517], Avg:   112.025 (1.000) <0-00:28:59> ({'r_t':  2322.9127, 'eps':     1.0000, 'critic_loss':    17.3667, 'actor_loss':     0.2486, 'eps_e':     1.0000})
Step:   75000, Reward:   160.362 [  75.602], Avg:   115.046 (1.000) <0-00:31:07> ({'r_t':  2235.9498, 'eps':     1.0000, 'critic_loss':    23.5254, 'actor_loss':    -0.2112, 'eps_e':     1.0000})
Step:   80000, Reward:   205.245 [  16.851], Avg:   120.352 (1.000) <0-00:33:11> ({'r_t':  2816.7764, 'eps':     1.0000, 'critic_loss':    12.6684, 'actor_loss':     0.2417, 'eps_e':     1.0000})
Step:   85000, Reward:   180.248 [  25.371], Avg:   123.679 (1.000) <0-00:35:17> ({'r_t':  3095.8101, 'eps':     1.0000, 'critic_loss':     8.3112, 'actor_loss':    -0.0260, 'eps_e':     1.0000})
Step:   90000, Reward:   179.795 [  37.255], Avg:   126.633 (1.000) <0-00:37:22> ({'r_t':  3133.6766, 'eps':     1.0000, 'critic_loss':     5.4253, 'actor_loss':    -0.0032, 'eps_e':     1.0000})
Step:   95000, Reward:   183.992 [  35.451], Avg:   129.501 (1.000) <0-00:39:27> ({'r_t':  2711.2151, 'eps':     1.0000, 'critic_loss':    14.6689, 'actor_loss':     0.2618, 'eps_e':     1.0000})
Step:  100000, Reward:   184.188 [  48.622], Avg:   132.105 (1.000) <0-00:41:31> ({'r_t':  2737.4651, 'eps':     1.0000, 'critic_loss':    13.5904, 'actor_loss':     0.1241, 'eps_e':     1.0000})
Step:  105000, Reward:    41.411 [  72.604], Avg:   127.982 (1.000) <0-00:43:37> ({'r_t':  2635.8104, 'eps':     1.0000, 'critic_loss':    15.0489, 'actor_loss':     1.1148, 'eps_e':     1.0000})
Step:  110000, Reward:    91.645 [   6.665], Avg:   126.402 (1.000) <0-00:45:35> ({'r_t':  1709.5867, 'eps':     1.0000, 'critic_loss':    12.8909, 'actor_loss':     0.5327, 'eps_e':     1.0000})
Step:  115000, Reward:   106.151 [  23.191], Avg:   125.559 (1.000) <0-00:47:34> ({'r_t':  2343.2240, 'eps':     1.0000, 'critic_loss':     5.8102, 'actor_loss':    -0.0932, 'eps_e':     1.0000})
Step:  120000, Reward:   110.506 [  54.377], Avg:   124.957 (1.000) <0-00:49:38> ({'r_t':  2511.9460, 'eps':     1.0000, 'critic_loss':     5.9782, 'actor_loss':    -0.1110, 'eps_e':     1.0000})
Step:  125000, Reward:   151.649 [  10.625], Avg:   125.983 (1.000) <0-00:51:45> ({'r_t':  2772.4590, 'eps':     1.0000, 'critic_loss':     4.9680, 'actor_loss':    -0.3182, 'eps_e':     1.0000})
Step:  130000, Reward:   165.311 [   7.391], Avg:   127.440 (1.000) <0-00:56:59> ({'r_t':  2929.5833, 'eps':     1.0000, 'critic_loss':     2.6443, 'actor_loss':    -0.2612, 'eps_e':     1.0000})
Step:  135000, Reward:   164.034 [  16.719], Avg:   128.747 (1.000) <0-01:02:07> ({'r_t':  2832.3749, 'eps':     1.0000, 'critic_loss':     4.5076, 'actor_loss':    -0.0372, 'eps_e':     1.0000})
Step:  140000, Reward:   169.341 [  18.266], Avg:   130.147 (1.000) <0-01:07:20> ({'r_t':  2619.5102, 'eps':     1.0000, 'critic_loss':     8.6274, 'actor_loss':    -0.1698, 'eps_e':     1.0000})
Step:  145000, Reward:   180.280 [  23.100], Avg:   131.818 (1.000) <0-01:12:33> ({'r_t':  2797.3315, 'eps':     1.0000, 'critic_loss':    13.6011, 'actor_loss':    -0.3611, 'eps_e':     1.0000})
Step:  150000, Reward:   197.206 [  26.198], Avg:   133.927 (1.000) <0-01:17:45> ({'r_t':  2967.7160, 'eps':     1.0000, 'critic_loss':    13.0302, 'actor_loss':    -0.4225, 'eps_e':     1.0000})
Step:  155000, Reward:   202.104 [  29.615], Avg:   136.057 (1.000) <0-01:22:58> ({'r_t':  3584.8226, 'eps':     1.0000, 'critic_loss':     5.9777, 'actor_loss':     0.0127, 'eps_e':     1.0000})
Step:  160000, Reward:   193.560 [  32.057], Avg:   137.800 (1.000) <0-01:28:15> ({'r_t':  3690.0809, 'eps':     1.0000, 'critic_loss':     4.5409, 'actor_loss':    -0.0924, 'eps_e':     1.0000})
Step:  165000, Reward:   164.542 [  43.101], Avg:   138.586 (1.000) <0-01:33:34> ({'r_t':  2192.3832, 'eps':     1.0000, 'critic_loss':    10.1708, 'actor_loss':     0.5307, 'eps_e':     1.0000})
Step:  170000, Reward:   189.545 [  11.845], Avg:   140.042 (1.000) <0-01:38:35> ({'r_t':  2374.2187, 'eps':     1.0000, 'critic_loss':     8.5518, 'actor_loss':    -0.4010, 'eps_e':     1.0000})
Step:  175000, Reward:   177.952 [  34.907], Avg:   141.095 (1.000) <0-01:43:48> ({'r_t':  2559.8349, 'eps':     1.0000, 'critic_loss':     9.2542, 'actor_loss':    -0.1030, 'eps_e':     1.0000})
Step:  180000, Reward:   175.255 [  40.502], Avg:   142.019 (1.000) <0-01:49:06> ({'r_t':  2427.9388, 'eps':     1.0000, 'critic_loss':    10.7857, 'actor_loss':    -0.0425, 'eps_e':     1.0000})
Step:  185000, Reward:   198.154 [  24.106], Avg:   143.496 (1.000) <0-01:54:15> ({'r_t':  2531.8924, 'eps':     1.0000, 'critic_loss':     8.7721, 'actor_loss':     0.1066, 'eps_e':     1.0000})
Step:  190000, Reward:    78.459 [  54.180], Avg:   141.828 (1.000) <0-01:59:26> ({'r_t':  1382.5980, 'eps':     1.0000, 'critic_loss':    14.2746, 'actor_loss':     1.2766, 'eps_e':     1.0000})
Step:  195000, Reward:   199.347 [  30.431], Avg:   143.266 (1.000) <0-02:04:48> ({'r_t':  1550.3453, 'eps':     1.0000, 'critic_loss':    26.3104, 'actor_loss':    -0.0736, 'eps_e':     1.0000})
Step:  200000, Reward:   196.272 [  28.531], Avg:   144.559 (1.000) <0-02:09:56> ({'r_t':  2440.8787, 'eps':     1.0000, 'critic_loss':    12.0627, 'actor_loss':    -0.6162, 'eps_e':     1.0000})
Step:  205000, Reward:   203.373 [  27.499], Avg:   145.959 (1.000) <0-02:15:03> ({'r_t':  2633.0664, 'eps':     1.0000, 'critic_loss':     8.7565, 'actor_loss':    -0.0920, 'eps_e':     1.0000})
Step:  210000, Reward:   182.957 [  12.633], Avg:   146.820 (1.000) <0-02:20:15> ({'r_t':  2592.7521, 'eps':     1.0000, 'critic_loss':     9.6308, 'actor_loss':     0.2734, 'eps_e':     1.0000})
Step:  215000, Reward:   197.522 [   9.790], Avg:   147.972 (1.000) <0-02:25:27> ({'r_t':  3245.0722, 'eps':     1.0000, 'critic_loss':     4.5821, 'actor_loss':    -0.4232, 'eps_e':     1.0000})
Step:  220000, Reward:   216.836 [   9.114], Avg:   149.502 (1.000) <0-02:30:40> ({'r_t':  3319.1821, 'eps':     1.0000, 'critic_loss':     3.4162, 'actor_loss':    -0.1060, 'eps_e':     1.0000})
Step:  225000, Reward:   226.943 [  13.502], Avg:   151.186 (1.000) <0-02:35:52> ({'r_t':  3412.2265, 'eps':     1.0000, 'critic_loss':     2.1226, 'actor_loss':    -0.2414, 'eps_e':     1.0000})
Step:  230000, Reward:   226.133 [   7.340], Avg:   152.781 (1.000) <0-02:41:10> ({'r_t':  3340.2908, 'eps':     1.0000, 'critic_loss':     1.7134, 'actor_loss':    -0.2225, 'eps_e':     1.0000})
Step:  235000, Reward:   226.253 [  11.766], Avg:   154.311 (1.000) <0-02:46:19> ({'r_t':  3309.4375, 'eps':     1.0000, 'critic_loss':     0.6024, 'actor_loss':    -0.2395, 'eps_e':     1.0000})
Step:  240000, Reward:   251.528 [  11.544], Avg:   156.295 (1.000) <0-02:51:35> ({'r_t':  3370.6310, 'eps':     1.0000, 'critic_loss':     3.0768, 'actor_loss':    -0.1577, 'eps_e':     1.0000})
Step:  245000, Reward:   217.006 [  66.629], Avg:   157.509 (1.000) <0-02:56:47> ({'r_t':  3511.9807, 'eps':     1.0000, 'critic_loss':     5.8478, 'actor_loss':    -0.2320, 'eps_e':     1.0000})
Step:  250000, Reward:   233.329 [  15.118], Avg:   158.996 (1.000) <0-03:02:04> ({'r_t':  3416.1831, 'eps':     1.0000, 'critic_loss':     2.3008, 'actor_loss':     0.3280, 'eps_e':     1.0000})
Step:  255000, Reward:   232.662 [  22.573], Avg:   160.413 (1.000) <0-03:07:19> ({'r_t':  3394.1919, 'eps':     1.0000, 'critic_loss':     2.7201, 'actor_loss':    -0.0663, 'eps_e':     1.0000})
Step:  260000, Reward:   249.507 [  28.975], Avg:   162.094 (1.000) <0-03:12:42> ({'r_t':  3266.3336, 'eps':     1.0000, 'critic_loss':     2.9514, 'actor_loss':     0.0288, 'eps_e':     1.0000})
Step:  265000, Reward:   241.261 [  30.640], Avg:   163.560 (1.000) <0-03:17:51> ({'r_t':  2856.7915, 'eps':     1.0000, 'critic_loss':     3.4172, 'actor_loss':     0.0592, 'eps_e':     1.0000})
Step:  270000, Reward:   261.060 [  17.582], Avg:   165.333 (1.000) <0-03:23:09> ({'r_t':  2975.2725, 'eps':     1.0000, 'critic_loss':     4.0549, 'actor_loss':    -0.0645, 'eps_e':     1.0000})
Step:  275000, Reward:   281.324 [  11.031], Avg:   167.404 (1.000) <0-03:28:26> ({'r_t':  3106.8549, 'eps':     1.0000, 'critic_loss':     3.2896, 'actor_loss':    -0.2909, 'eps_e':     1.0000})
Step:  280000, Reward:   273.209 [  22.091], Avg:   169.260 (1.000) <0-03:33:40> ({'r_t':  3362.8084, 'eps':     1.0000, 'critic_loss':     2.5063, 'actor_loss':    -0.2905, 'eps_e':     1.0000})
Step:  285000, Reward:   269.788 [  20.895], Avg:   170.993 (1.000) <0-03:38:59> ({'r_t':  3520.7528, 'eps':     1.0000, 'critic_loss':     2.9812, 'actor_loss':    -0.2005, 'eps_e':     1.0000})
Step:  290000, Reward:   284.987 [  16.192], Avg:   172.925 (1.000) <0-03:44:15> ({'r_t':  3555.6649, 'eps':     1.0000, 'critic_loss':     2.7604, 'actor_loss':     0.0435, 'eps_e':     1.0000})
Step:  295000, Reward:   292.666 [  16.870], Avg:   174.921 (1.000) <0-03:49:33> ({'r_t':  3565.5600, 'eps':     1.0000, 'critic_loss':     4.1177, 'actor_loss':    -0.2165, 'eps_e':     1.0000})
Step:  300000, Reward:   288.403 [  11.279], Avg:   176.782 (1.000) <0-03:54:40> ({'r_t':  3825.0627, 'eps':     1.0000, 'critic_loss':     4.2531, 'actor_loss':    -0.0244, 'eps_e':     1.0000})
Step:  305000, Reward:   286.127 [  15.730], Avg:   178.545 (1.000) <0-03:59:57> ({'r_t':  4041.3815, 'eps':     1.0000, 'critic_loss':     5.4176, 'actor_loss':     0.0494, 'eps_e':     1.0000})
Step:  310000, Reward:   272.792 [  15.955], Avg:   180.041 (1.000) <0-04:05:12> ({'r_t':  4080.6234, 'eps':     1.0000, 'critic_loss':     5.0864, 'actor_loss':    -0.0692, 'eps_e':     1.0000})
Step:  315000, Reward:   262.963 [  12.572], Avg:   181.337 (1.000) <0-04:10:27> ({'r_t':  3984.6094, 'eps':     1.0000, 'critic_loss':     5.6858, 'actor_loss':     0.3545, 'eps_e':     1.0000})
Step:  320000, Reward:   247.455 [   8.953], Avg:   182.354 (1.000) <0-04:15:41> ({'r_t':  4062.0428, 'eps':     1.0000, 'critic_loss':     7.5118, 'actor_loss':    -0.3655, 'eps_e':     1.0000})
Step:  325000, Reward:   251.163 [  11.914], Avg:   183.397 (1.000) <0-04:20:52> ({'r_t':  3930.5910, 'eps':     1.0000, 'critic_loss':     5.1484, 'actor_loss':     0.4561, 'eps_e':     1.0000})
Step:  330000, Reward:   254.309 [  21.527], Avg:   184.455 (1.000) <0-04:26:13> ({'r_t':  3512.2551, 'eps':     1.0000, 'critic_loss':    44.0950, 'actor_loss':     0.6748, 'eps_e':     1.0000})
Step:  335000, Reward:   281.628 [  40.050], Avg:   185.884 (1.000) <0-04:31:28> ({'r_t':  3563.2968, 'eps':     1.0000, 'critic_loss':    10.7330, 'actor_loss':    -0.1540, 'eps_e':     1.0000})
Step:  340000, Reward:   300.786 [  28.273], Avg:   187.549 (1.000) <0-04:36:47> ({'r_t':  3880.2637, 'eps':     1.0000, 'critic_loss':    12.8427, 'actor_loss':     0.2009, 'eps_e':     1.0000})
Step:  345000, Reward:   250.709 [  51.153], Avg:   188.451 (1.000) <0-04:42:02> ({'r_t':  3979.8725, 'eps':     1.0000, 'critic_loss':    12.0691, 'actor_loss':    -0.0353, 'eps_e':     1.0000})
Step:  350000, Reward:   267.102 [  46.928], Avg:   189.559 (1.000) <0-04:47:17> ({'r_t':  4013.6119, 'eps':     1.0000, 'critic_loss':    14.0580, 'actor_loss':     0.1205, 'eps_e':     1.0000})
Step:  355000, Reward:   286.522 [  41.609], Avg:   190.906 (1.000) <0-04:52:34> ({'r_t':  3999.1120, 'eps':     1.0000, 'critic_loss':    14.4792, 'actor_loss':    -0.0370, 'eps_e':     1.0000})
Step:  360000, Reward:   253.972 [  37.502], Avg:   191.770 (1.000) <0-04:57:52> ({'r_t':  4054.3837, 'eps':     1.0000, 'critic_loss':    12.6542, 'actor_loss':    -0.0597, 'eps_e':     1.0000})
Step:  365000, Reward:   267.132 [  46.010], Avg:   192.788 (1.000) <0-05:03:05> ({'r_t':  3954.1583, 'eps':     1.0000, 'critic_loss':    13.2875, 'actor_loss':     0.2380, 'eps_e':     1.0000})
Step:  370000, Reward:   282.085 [  42.701], Avg:   193.979 (1.000) <0-05:08:16> ({'r_t':  3984.8883, 'eps':     1.0000, 'critic_loss':    13.1382, 'actor_loss':     0.1509, 'eps_e':     1.0000})
Step:  375000, Reward:   272.979 [  45.295], Avg:   195.018 (1.000) <0-05:13:31> ({'r_t':  4147.8508, 'eps':     1.0000, 'critic_loss':    10.5647, 'actor_loss':    -0.0419, 'eps_e':     1.0000})
Step:  380000, Reward:   271.317 [  44.881], Avg:   196.009 (1.000) <0-05:18:49> ({'r_t':  3823.3842, 'eps':     1.0000, 'critic_loss':    13.7652, 'actor_loss':     0.1459, 'eps_e':     1.0000})
Step:  385000, Reward:   264.388 [  52.364], Avg:   196.886 (1.000) <0-05:24:01> ({'r_t':  3834.7272, 'eps':     1.0000, 'critic_loss':    13.9142, 'actor_loss':    -0.2405, 'eps_e':     1.0000})
Step:  390000, Reward:   261.006 [  42.299], Avg:   197.698 (1.000) <0-05:29:18> ({'r_t':  4038.0138, 'eps':     1.0000, 'critic_loss':    13.6328, 'actor_loss':    -0.2955, 'eps_e':     1.0000})
Step:  395000, Reward:   249.311 [  50.805], Avg:   198.343 (1.000) <0-05:34:32> ({'r_t':  3753.4192, 'eps':     1.0000, 'critic_loss':    14.6754, 'actor_loss':     0.1345, 'eps_e':     1.0000})
Step:  400000, Reward:   253.886 [  59.340], Avg:   199.028 (1.000) <0-05:39:51> ({'r_t':  3557.8976, 'eps':     1.0000, 'critic_loss':    17.2303, 'actor_loss':     0.0603, 'eps_e':     1.0000})
Step:  405000, Reward:   262.542 [  54.739], Avg:   199.803 (1.000) <0-05:45:08> ({'r_t':  3533.9974, 'eps':     1.0000, 'critic_loss':    15.3105, 'actor_loss':    -0.0862, 'eps_e':     1.0000})
Step:  410000, Reward:   285.310 [  46.516], Avg:   200.833 (1.000) <0-05:50:19> ({'r_t':  3643.9262, 'eps':     1.0000, 'critic_loss':    15.6798, 'actor_loss':     0.0665, 'eps_e':     1.0000})
Step:  415000, Reward:   298.492 [  58.212], Avg:   201.996 (1.000) <0-05:55:33> ({'r_t':  3594.6047, 'eps':     1.0000, 'critic_loss':    16.3431, 'actor_loss':    -0.1912, 'eps_e':     1.0000})
Step:  420000, Reward:   272.135 [  42.788], Avg:   202.821 (1.000) <0-06:00:50> ({'r_t':  3140.3544, 'eps':     1.0000, 'critic_loss':    16.0530, 'actor_loss':     0.0951, 'eps_e':     1.0000})
Step:  425000, Reward:   211.677 [  27.783], Avg:   202.924 (1.000) <0-06:06:01> ({'r_t':  3371.9729, 'eps':     1.0000, 'critic_loss':    13.5806, 'actor_loss':     0.5620, 'eps_e':     1.0000})
Step:  430000, Reward:   248.910 [  33.928], Avg:   203.453 (1.000) <0-06:11:16> ({'r_t':  3520.3858, 'eps':     1.0000, 'critic_loss':    14.8509, 'actor_loss':     0.3906, 'eps_e':     1.0000})
Step:  435000, Reward:   237.967 [  41.685], Avg:   203.845 (1.000) <0-06:16:31> ({'r_t':  3598.0348, 'eps':     1.0000, 'critic_loss':    13.4621, 'actor_loss':     0.1226, 'eps_e':     1.0000})
Step:  440000, Reward:   268.142 [  35.410], Avg:   204.567 (1.000) <0-06:21:40> ({'r_t':  3688.3756, 'eps':     1.0000, 'critic_loss':    12.1162, 'actor_loss':    -0.3037, 'eps_e':     1.0000})
Step:  445000, Reward:   263.838 [  38.066], Avg:   205.226 (1.000) <0-06:26:50> ({'r_t':  3689.9162, 'eps':     1.0000, 'critic_loss':    13.9050, 'actor_loss':     0.2453, 'eps_e':     1.0000})
Step:  450000, Reward:   258.415 [  37.070], Avg:   205.810 (1.000) <0-06:32:06> ({'r_t':  3774.0493, 'eps':     1.0000, 'critic_loss':    13.4994, 'actor_loss':     0.0417, 'eps_e':     1.0000})
Step:  455000, Reward:   262.946 [  60.751], Avg:   206.431 (1.000) <0-06:37:18> ({'r_t':  3492.9769, 'eps':     1.0000, 'critic_loss':    16.7571, 'actor_loss':     0.1726, 'eps_e':     1.0000})
Step:  460000, Reward:   274.001 [  41.038], Avg:   207.158 (1.000) <0-06:42:32> ({'r_t':  3449.2292, 'eps':     1.0000, 'critic_loss':    17.0864, 'actor_loss':    -0.0538, 'eps_e':     1.0000})
Step:  465000, Reward:   290.941 [  49.633], Avg:   208.049 (1.000) <0-06:47:38> ({'r_t':  3651.6198, 'eps':     1.0000, 'critic_loss':    14.6055, 'actor_loss':     0.0839, 'eps_e':     1.0000})
Step:  470000, Reward:   268.452 [  56.943], Avg:   208.685 (1.000) <0-06:52:53> ({'r_t':  3684.4111, 'eps':     1.0000, 'critic_loss':    12.9865, 'actor_loss':     0.1991, 'eps_e':     1.0000})
Step:  475000, Reward:   264.801 [  53.487], Avg:   209.270 (1.000) <0-06:57:57> ({'r_t':  3542.4635, 'eps':     1.0000, 'critic_loss':    16.2552, 'actor_loss':     0.4369, 'eps_e':     1.0000})
Step:  480000, Reward:   255.115 [  24.701], Avg:   209.742 (1.000) <0-07:03:08> ({'r_t':  3525.3700, 'eps':     1.0000, 'critic_loss':    18.0447, 'actor_loss':     0.4348, 'eps_e':     1.0000})
Step:  485000, Reward:   258.169 [  41.415], Avg:   210.236 (1.000) <0-07:08:21> ({'r_t':  3726.2465, 'eps':     1.0000, 'critic_loss':    14.2924, 'actor_loss':    -0.0122, 'eps_e':     1.0000})
Step:  490000, Reward:   253.048 [  39.113], Avg:   210.669 (1.000) <0-07:13:36> ({'r_t':  3706.7844, 'eps':     1.0000, 'critic_loss':    13.5697, 'actor_loss':     0.5148, 'eps_e':     1.0000})
Step:  495000, Reward:   258.412 [  27.582], Avg:   211.146 (1.000) <0-07:18:48> ({'r_t':  3794.0409, 'eps':     1.0000, 'critic_loss':    13.2242, 'actor_loss':    -0.0637, 'eps_e':     1.0000})
Step:  500000, Reward:   270.852 [  49.703], Avg:   211.737 (1.000) <0-07:24:03> ({'r_t':  3516.1206, 'eps':     1.0000, 'critic_loss':    13.8588, 'actor_loss':     0.0216, 'eps_e':     1.0000})
