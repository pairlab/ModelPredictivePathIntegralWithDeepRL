Model: <class 'src.models.pytorch.agents.ppo.PPOAgent'>, Env: CarRacing-v1, Date: 13/05/2020 18:57:55
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 7163b0d0630407d45f7a19e5df21dbcbf72600bf
Branch: master

envs: <src.utils.envs.EnvManager object at 0x7f80b480b890> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f80b480b7d0>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f80b47c83b0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			observation_space = Box(30,) 
				dtype = float32
				shape = (30,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f80b47c5e50> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f80b47e3250> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				cost_map = [[ 214.381  214.299  214.217 ...  112.184  112.264  112.344]
				 [ 214.324  214.242  214.160 ...  112.124  112.204  112.284]
				 [ 214.267  214.185  214.103 ...  112.064  112.144  112.224]
				 ...
				 [  96.764   96.690   96.616 ...  242.661  242.689  242.717]
				 [  96.831   96.757   96.683 ...  242.757  242.785  242.813]
				 [  96.898   96.824   96.750 ...  242.852  242.881  242.909]]
				res = 0.1
				min_point = [-215.266 -178.250    0.000]
			max_time = 1000
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f813453cf80>
					get_reward = <function CarRacing.get_reward at 0x7f813453cef0>
					step = <function CarRacing.step at 0x7f81345479e0>
					render = <function CarRacing.render at 0x7f8134547a70>
					close = <function CarRacing.close at 0x7f8134547b00>
					id = 1
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(30,) 
			dtype = float32
			shape = (30,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f80b47e3050> 
			observation_space = Box(30,) 
				dtype = float32
				shape = (30,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (30,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f80b47e3b90> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38434), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=77, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59438), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=78, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33548), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=79, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36588), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=86, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56644), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=88, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56704), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=89, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33334), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=90, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34296), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=91, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 35092), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=92, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55782), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=93, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 39804), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=94, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51026), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=172, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45832), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=173, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56686), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=174, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50476), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=177, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41720), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f80b47e3450> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f80b47e3490> 
		state_size = (30,)
	agent = <src.models.pytorch.agents.ppo.PPOAgent object at 0x7f80b47e3790> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f80b47e3590> 
			size = (3,)
			dt = 0.2
			action = [-1.000  0.619  0.274]
			daction_dt = [-0.338  0.430  0.856]
		discrete = False
		action_size = (3,)
		state_size = (30,)
		config = <src.models.Config object at 0x7f80bef9cc50> 
			TRIAL_AT = 1000
			SAVE_AT = 10
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.995
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 32
			PPO_EPOCHS = 2
			ENTROPY_WEIGHT = 0.005
			CLIP_PARAM = 0.05
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = ppo
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f80bc08a050> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = PPONetwork(
			  (actor_local): PPOActor(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): PPOActor(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): PPOCritic(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=1024, bias=True)
			    (layer3): Linear(in_features=1024, out_features=1024, bias=True)
			    (value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): PPOCritic(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=1024, bias=True)
			    (layer3): Linear(in_features=1024, out_features=1024, bias=True)
			    (value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			training = True
			tau = 0.0004
			name = ppo
			stats = <src.utils.logger.Stats object at 0x7f80b47e3310> 
				mean_dict = {}
				sum_dict = {}
			config = <src.models.Config object at 0x7f80bef9cc50> 
				TRIAL_AT = 1000
				SAVE_AT = 10
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.995
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 32
				PPO_EPOCHS = 2
				ENTROPY_WEIGHT = 0.005
				CLIP_PARAM = 0.05
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = ppo
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class PPOActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config, use_discrete=False):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = use_discrete and type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Parameter(torch.zeros(action_size[-1]))\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\t\tself.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)\n\t\t\n\tdef forward(self, state, action_in=None, sample=True):\n\t\tstate = self.layer1(state).relu()\n\t\tstate = self.layer2(state).relu()\n\t\tstate = self.layer3(state).relu()\n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig.exp().expand_as(action_mu)\n\t\tdist = self.dist(action_mu, action_sig)\n\t\taction = dist.sample() if action_in is None else action_in.argmax(-1) if self.discrete else action_in\n\t\taction_out = one_hot_from_indices(action, action_mu.size(-1)) if self.discrete else action\n\t\tlog_prob = dist.log_prob(action)\n\t\tentropy = dist.entropy()\n\t\treturn action_out, log_prob, entropy\n', 'class PPOCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, critic_hidden)\n\t\tself.layer3 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state):\n\t\tstate = self.layer1(state).relu()\n\t\tstate = self.layer2(state).relu()\n\t\tstate = self.layer3(state).relu()\n\t\tvalue = self.value(state)\n\t\treturn value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f80b47a8290> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f80b47a8150> 
		size = (3,)
		dt = 0.2
		action = [-1.000 -0.614 -0.338]
		daction_dt = [-1.098  0.520  1.594]
	discrete = False
	action_size = (3,)
	state_size = (30,)
	config = <src.models.Config object at 0x7f80bef9cc50> 
		TRIAL_AT = 1000
		SAVE_AT = 10
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.995
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 32
		PPO_EPOCHS = 2
		ENTROPY_WEIGHT = 0.005
		CLIP_PARAM = 0.05
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = ppo
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f80b47a8210> 
		mean_dict = {}
		sum_dict = {},
config: 
   TRIAL_AT = 1000
   SAVE_AT = 10
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.995
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 32
   PPO_EPOCHS = 2
   ENTROPY_WEIGHT = 0.005
   CLIP_PARAM = 0.05
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = ppo
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
conn: None,

import torch
import numpy as np
from .base import PTACNetwork, PTAgent, Conv, one_hot_from_indices
from src.utils.rand import ReplayBuffer, PrioritizedReplayBuffer

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config, use_discrete=False):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = use_discrete and type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Parameter(torch.zeros(action_size[-1]))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)
		
	def forward(self, state, action_in=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = self.dist(action_mu, action_sig)
		action = dist.sample() if action_in is None else action_in.argmax(-1) if self.discrete else action_in
		action_out = one_hot_from_indices(action, action_mu.size(-1)) if self.discrete else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action_out, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, critic_hidden)
		self.layer3 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=PPOActor, critic=PPOCritic, gpu=True, load=None, name="ppo"):
		super().__init__(state_size, action_size, config, actor=actor, critic=critic, gpu=gpu, load=load, name=name)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			action_or_entropy = action if action_in is None else entropy.mean()
			return (x.cpu().numpy() if numpy else x for x in [action_or_entropy, log_prob])

	def get_value(self, state, grad=False, numpy=False):
		with torch.enable_grad() if grad else torch.no_grad():
			return self.critic_local(state.to(self.device)).cpu().numpy() if numpy else self.critic_local(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, config):
		values = self.get_value(states, grad=True)
		critic_loss = (values - targets).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)

		entropy, new_log_probs = self.get_action_probs(states, actions, grad=True)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-config.CLIP_PARAM, 1.0+config.CLIP_PARAM)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages) + config.ENTROPY_WEIGHT*entropy).mean()
		self.step(self.actor_optimizer, actor_loss)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)

class PPOAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, PPONetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		self.action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			values = self.network.get_value(states)
			targets, advantages = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states[:-1], actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(list(zip(states, actions, log_probs, targets, advantages)), shuffle=True)
			for _ in range((len(self.replay_buffer)*self.config.PPO_EPOCHS)//self.config.BATCH_SIZE):
				state, action, log_prob, target, advantage = self.replay_buffer.next_batch(self.config.BATCH_SIZE, torch.stack)
				self.network.optimize(state, action, log_prob, target, advantage, config=self.config)
				

Step:       0, Reward:   -32.891 [  19.878], Avg:   -32.891 (1.000) <0-00:00:00> ({'r_t':  -7.00e-05, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward:   -51.786 [  24.262], Avg:   -42.339 (1.000) <0-00:00:55> ({'r_t':  -158.7618, 'eps':     1.0000, 'critic_loss':     3.5911, 'actor_loss':     2.1333, 'eps_e':     1.0000})
Step:    2000, Reward:   -79.799 [  96.068], Avg:   -54.825 (1.000) <0-00:02:06> ({'r_t':  -170.0001, 'eps':     1.0000, 'critic_loss':     6.5232, 'actor_loss':     1.9794, 'eps_e':     1.0000})
Step:    3000, Reward:   -71.039 [  61.078], Avg:   -58.879 (1.000) <0-00:03:16> ({'r_t':  -146.9626, 'eps':     1.0000, 'critic_loss':     6.9988, 'actor_loss':     1.1798, 'eps_e':     1.0000})
Step:    4000, Reward:   -42.540 [  44.614], Avg:   -55.611 (1.000) <0-00:04:18> ({'r_t':   -87.9082, 'eps':     1.0000, 'critic_loss':     6.7525, 'actor_loss':     0.4732, 'eps_e':     1.0000})
Step:    5000, Reward:   -53.953 [  61.785], Avg:   -55.335 (1.000) <0-00:05:20> ({'r_t':   -82.6555, 'eps':     1.0000, 'critic_loss':     4.6786, 'actor_loss':     0.3660, 'eps_e':     1.0000})
Step:    6000, Reward:   -42.260 [  36.036], Avg:   -53.467 (1.000) <0-00:06:25> ({'r_t':  -120.0406, 'eps':     1.0000, 'critic_loss':     6.0108, 'actor_loss':     0.3848, 'eps_e':     1.0000})
Step:    7000, Reward:   -42.926 [  88.185], Avg:   -52.149 (1.000) <0-00:07:34> ({'r_t':  -103.8447, 'eps':     1.0000, 'critic_loss':     4.8674, 'actor_loss':     0.2710, 'eps_e':     1.0000})
Step:    8000, Reward:   -44.915 [  99.998], Avg:   -51.346 (1.000) <0-00:08:44> ({'r_t':   -66.0986, 'eps':     1.0000, 'critic_loss':     5.5351, 'actor_loss':    -0.0376, 'eps_e':     1.0000})
Step:    9000, Reward:   -19.756 [  46.221], Avg:   -48.187 (1.000) <0-00:09:50> ({'r_t':   -27.5836, 'eps':     1.0000, 'critic_loss':     3.4013, 'actor_loss':     0.0045, 'eps_e':     1.0000})
Step:   10000, Reward:    -6.181 [  34.654], Avg:   -44.368 (1.000) <0-00:10:51> ({'r_t':   -24.5918, 'eps':     1.0000, 'critic_loss':     1.7543, 'actor_loss':    -0.1182, 'eps_e':     1.0000})
Step:   11000, Reward:   -12.233 [  59.436], Avg:   -41.690 (1.000) <0-00:12:00> ({'r_t':     5.2024, 'eps':     1.0000, 'critic_loss':     1.4716, 'actor_loss':    -0.1885, 'eps_e':     1.0000})
Step:   12000, Reward:    11.151 [  10.736], Avg:   -37.625 (1.000) <0-00:13:09> ({'r_t':    15.7228, 'eps':     1.0000, 'critic_loss':     1.1167, 'actor_loss':    -0.2996, 'eps_e':     1.0000})
Step:   13000, Reward:    -1.569 [  26.764], Avg:   -35.050 (1.000) <0-00:14:19> ({'r_t':    11.2121, 'eps':     1.0000, 'critic_loss':     0.8509, 'actor_loss':    -0.3808, 'eps_e':     1.0000})
Step:   14000, Reward:     2.915 [  22.840], Avg:   -32.519 (1.000) <0-00:15:28> ({'r_t':   -39.3895, 'eps':     1.0000, 'critic_loss':     1.6797, 'actor_loss':     0.2297, 'eps_e':     1.0000})
Step:   15000, Reward:     6.956 [  22.454], Avg:   -30.052 (1.000) <0-00:16:39> ({'r_t':    30.2692, 'eps':     1.0000, 'critic_loss':     1.8548, 'actor_loss':    -0.2216, 'eps_e':     1.0000})
Step:   16000, Reward:    13.722 [  17.281], Avg:   -27.477 (1.000) <0-00:17:48> ({'r_t':    25.9274, 'eps':     1.0000, 'critic_loss':     1.1882, 'actor_loss':    -0.2098, 'eps_e':     1.0000})
Step:   17000, Reward:    -4.409 [  32.482], Avg:   -26.195 (1.000) <0-00:18:57> ({'r_t':    24.5249, 'eps':     1.0000, 'critic_loss':     1.9959, 'actor_loss':    -0.2833, 'eps_e':     1.0000})
Step:   18000, Reward:   -19.399 [  40.823], Avg:   -25.837 (1.000) <0-00:20:06> ({'r_t':    10.2084, 'eps':     1.0000, 'critic_loss':     1.8266, 'actor_loss':    -0.3622, 'eps_e':     1.0000})
Step:   19000, Reward:   -36.918 [  94.162], Avg:   -26.392 (1.000) <0-00:21:16> ({'r_t':   -19.2598, 'eps':     1.0000, 'critic_loss':     1.3599, 'actor_loss':    -0.3393, 'eps_e':     1.0000})
Step:   20000, Reward:   -26.802 [  72.960], Avg:   -26.411 (1.000) <0-00:22:26> ({'r_t':    -1.6882, 'eps':     1.0000, 'critic_loss':     1.6488, 'actor_loss':    -0.1868, 'eps_e':     1.0000})
Step:   21000, Reward:   -25.309 [ 138.918], Avg:   -26.361 (1.000) <0-00:23:37> ({'r_t':   -54.6715, 'eps':     1.0000, 'critic_loss':     4.6320, 'actor_loss':     0.3315, 'eps_e':     1.0000})
Step:   22000, Reward:   -30.848 [  71.868], Avg:   -26.556 (1.000) <0-00:24:47> ({'r_t':   -20.5015, 'eps':     1.0000, 'critic_loss':     3.7838, 'actor_loss':     0.0308, 'eps_e':     1.0000})
Step:   23000, Reward:    20.319 [  14.756], Avg:   -24.603 (1.000) <0-00:25:55> ({'r_t':   -11.7083, 'eps':     1.0000, 'critic_loss':     2.9399, 'actor_loss':    -0.1231, 'eps_e':     1.0000})
Step:   24000, Reward:    10.282 [  42.688], Avg:   -23.208 (1.000) <0-00:27:05> ({'r_t':    12.8292, 'eps':     1.0000, 'critic_loss':     2.5380, 'actor_loss':    -0.2389, 'eps_e':     1.0000})
Step:   25000, Reward:    21.698 [  11.405], Avg:   -21.480 (1.000) <0-00:28:15> ({'r_t':    17.8299, 'eps':     1.0000, 'critic_loss':     1.5968, 'actor_loss':    -0.2211, 'eps_e':     1.0000})
Step:   26000, Reward:    17.531 [  15.067], Avg:   -20.036 (1.000) <0-00:29:24> ({'r_t':    14.1156, 'eps':     1.0000, 'critic_loss':     2.0060, 'actor_loss':    -0.0566, 'eps_e':     1.0000})
Step:   27000, Reward:     4.289 [  28.747], Avg:   -19.167 (1.000) <0-00:30:34> ({'r_t':     1.1455, 'eps':     1.0000, 'critic_loss':     2.1810, 'actor_loss':     0.1048, 'eps_e':     1.0000})
Step:   28000, Reward:   -44.404 [ 152.839], Avg:   -20.037 (1.000) <0-00:31:44> ({'r_t':     3.7218, 'eps':     1.0000, 'critic_loss':     1.8864, 'actor_loss':    -0.0636, 'eps_e':     1.0000})
Step:   29000, Reward:    11.024 [  38.773], Avg:   -19.002 (1.000) <0-00:32:54> ({'r_t':     1.6202, 'eps':     1.0000, 'critic_loss':     2.6655, 'actor_loss':     0.1176, 'eps_e':     1.0000})
Step:   30000, Reward:     3.912 [  45.038], Avg:   -18.263 (1.000) <0-00:34:03> ({'r_t':    21.4141, 'eps':     1.0000, 'critic_loss':     1.5825, 'actor_loss':    -0.1749, 'eps_e':     1.0000})
Step:   31000, Reward:    10.324 [  24.546], Avg:   -17.369 (1.000) <0-00:35:13> ({'r_t':     4.6419, 'eps':     1.0000, 'critic_loss':     1.2455, 'actor_loss':    -0.1000, 'eps_e':     1.0000})
Step:   32000, Reward:    21.886 [  19.611], Avg:   -16.180 (1.000) <0-00:36:22> ({'r_t':    12.7593, 'eps':     1.0000, 'critic_loss':     2.3893, 'actor_loss':     0.1076, 'eps_e':     1.0000})
Step:   33000, Reward:    35.694 [   8.204], Avg:   -14.654 (1.000) <0-00:37:32> ({'r_t':    25.2370, 'eps':     1.0000, 'critic_loss':     1.6970, 'actor_loss':    -0.0636, 'eps_e':     1.0000})
Step:   34000, Reward:     7.015 [  78.798], Avg:   -14.035 (1.000) <0-00:38:42> ({'r_t':    29.8579, 'eps':     1.0000, 'critic_loss':     1.2314, 'actor_loss':    -0.0221, 'eps_e':     1.0000})
Step:   35000, Reward:    32.212 [  10.981], Avg:   -12.750 (1.000) <0-00:39:51> ({'r_t':    37.4746, 'eps':     1.0000, 'critic_loss':     1.9298, 'actor_loss':     0.0268, 'eps_e':     1.0000})
Step:   36000, Reward:    11.516 [  30.444], Avg:   -12.094 (1.000) <0-00:41:01> ({'r_t':     9.4361, 'eps':     1.0000, 'critic_loss':     1.7372, 'actor_loss':     0.1322, 'eps_e':     1.0000})
Step:   37000, Reward:   -16.755 [  39.158], Avg:   -12.217 (1.000) <0-00:42:11> ({'r_t':    -1.5916, 'eps':     1.0000, 'critic_loss':     1.8847, 'actor_loss':     0.2799, 'eps_e':     1.0000})
Step:   38000, Reward:    30.462 [  10.831], Avg:   -11.123 (1.000) <0-00:43:21> ({'r_t':    -4.9936, 'eps':     1.0000, 'critic_loss':     1.7691, 'actor_loss':     0.1903, 'eps_e':     1.0000})
Step:   39000, Reward:    -3.552 [  37.057], Avg:   -10.933 (1.000) <0-00:44:31> ({'r_t':    29.7015, 'eps':     1.0000, 'critic_loss':     1.1860, 'actor_loss':     0.0696, 'eps_e':     1.0000})
Step:   40000, Reward:    -8.928 [  41.105], Avg:   -10.885 (1.000) <0-00:45:40> ({'r_t':    -5.3908, 'eps':     1.0000, 'critic_loss':     1.5924, 'actor_loss':     0.0628, 'eps_e':     1.0000})
Step:   41000, Reward:    30.029 [  12.639], Avg:    -9.910 (1.000) <0-00:46:50> ({'r_t':     2.7028, 'eps':     1.0000, 'critic_loss':     1.2866, 'actor_loss':     0.0577, 'eps_e':     1.0000})
Step:   42000, Reward:    21.608 [  22.128], Avg:    -9.177 (1.000) <0-00:48:00> ({'r_t':    10.1303, 'eps':     1.0000, 'critic_loss':     1.2645, 'actor_loss':     0.1022, 'eps_e':     1.0000})
Step:   43000, Reward:    35.277 [  13.784], Avg:    -8.167 (1.000) <0-00:49:10> ({'r_t':    16.9492, 'eps':     1.0000, 'critic_loss':     1.0039, 'actor_loss':    -0.0437, 'eps_e':     1.0000})
Step:   44000, Reward:    28.037 [  16.914], Avg:    -7.363 (1.000) <0-00:50:19> ({'r_t':    34.9908, 'eps':     1.0000, 'critic_loss':     1.2293, 'actor_loss':    -0.0693, 'eps_e':     1.0000})
Step:   45000, Reward:    32.624 [  20.256], Avg:    -6.493 (1.000) <0-00:51:29> ({'r_t':    33.0042, 'eps':     1.0000, 'critic_loss':     0.9523, 'actor_loss':    -0.0235, 'eps_e':     1.0000})
Step:   46000, Reward:    30.868 [  13.822], Avg:    -5.698 (1.000) <0-00:52:39> ({'r_t':    38.6556, 'eps':     1.0000, 'critic_loss':     1.2088, 'actor_loss':     0.1165, 'eps_e':     1.0000})
Step:   47000, Reward:   -11.761 [  55.001], Avg:    -5.825 (1.000) <0-00:53:48> ({'r_t':    20.8618, 'eps':     1.0000, 'critic_loss':     0.8458, 'actor_loss':    -0.0051, 'eps_e':     1.0000})
Step:   48000, Reward:    20.131 [  27.166], Avg:    -5.295 (1.000) <0-00:54:58> ({'r_t':    -7.2756, 'eps':     1.0000, 'critic_loss':     1.7121, 'actor_loss':     0.1367, 'eps_e':     1.0000})
Step:   49000, Reward:    30.275 [  19.053], Avg:    -4.584 (1.000) <0-00:56:08> ({'r_t':    16.5020, 'eps':     1.0000, 'critic_loss':     1.3531, 'actor_loss':    -0.1121, 'eps_e':     1.0000})
Step:   50000, Reward:    34.661 [  20.895], Avg:    -3.814 (1.000) <0-00:57:17> ({'r_t':    22.1613, 'eps':     1.0000, 'critic_loss':     0.8896, 'actor_loss':    -0.1223, 'eps_e':     1.0000})
Step:   51000, Reward:    33.960 [  19.487], Avg:    -3.088 (1.000) <0-00:58:27> ({'r_t':    43.5906, 'eps':     1.0000, 'critic_loss':     1.0583, 'actor_loss':     0.0499, 'eps_e':     1.0000})
Step:   52000, Reward:    32.410 [  32.675], Avg:    -2.418 (1.000) <0-00:59:37> ({'r_t':    53.5575, 'eps':     1.0000, 'critic_loss':     1.6070, 'actor_loss':    -0.1897, 'eps_e':     1.0000})
Step:   53000, Reward:    37.973 [  22.321], Avg:    -1.670 (1.000) <0-01:00:46> ({'r_t':    31.9479, 'eps':     1.0000, 'critic_loss':     0.7651, 'actor_loss':    -0.1366, 'eps_e':     1.0000})
Step:   54000, Reward:    33.019 [  49.099], Avg:    -1.039 (1.000) <0-01:01:48> ({'r_t':    61.8898, 'eps':     1.0000, 'critic_loss':     1.2503, 'actor_loss':    -0.0790, 'eps_e':     1.0000})
Step:   55000, Reward:    24.375 [  41.388], Avg:    -0.585 (1.000) <0-01:02:56> ({'r_t':    50.3155, 'eps':     1.0000, 'critic_loss':     1.1602, 'actor_loss':    -0.0745, 'eps_e':     1.0000})
Step:   56000, Reward:    35.633 [  24.419], Avg:     0.050 (1.000) <0-01:04:07> ({'r_t':    61.9252, 'eps':     1.0000, 'critic_loss':     1.2971, 'actor_loss':    -0.2678, 'eps_e':     1.0000})
Step:   57000, Reward:    22.464 [  32.740], Avg:     0.436 (1.000) <0-01:05:15> ({'r_t':    67.0345, 'eps':     1.0000, 'critic_loss':     1.4830, 'actor_loss':    -0.0490, 'eps_e':     1.0000})
Step:   58000, Reward:    38.848 [  25.907], Avg:     1.088 (1.000) <0-01:06:17> ({'r_t':    65.3644, 'eps':     1.0000, 'critic_loss':     1.7068, 'actor_loss':     0.0260, 'eps_e':     1.0000})
Step:   59000, Reward:    31.958 [  34.956], Avg:     1.602 (1.000) <0-01:07:14> ({'r_t':    87.7928, 'eps':     1.0000, 'critic_loss':     2.2651, 'actor_loss':     0.1186, 'eps_e':     1.0000})
Step:   60000, Reward:    32.677 [  37.441], Avg:     2.111 (1.000) <0-01:08:23> ({'r_t':   103.2472, 'eps':     1.0000, 'critic_loss':     1.1912, 'actor_loss':    -0.0375, 'eps_e':     1.0000})
Step:   61000, Reward:   -42.786 [ 204.600], Avg:     1.387 (1.000) <0-01:09:33> ({'r_t':    70.3831, 'eps':     1.0000, 'critic_loss':     2.6985, 'actor_loss':     0.6332, 'eps_e':     1.0000})
Step:   62000, Reward:    24.860 [  48.577], Avg:     1.760 (1.000) <0-01:10:37> ({'r_t':    52.4183, 'eps':     1.0000, 'critic_loss':     6.0421, 'actor_loss':     0.9044, 'eps_e':     1.0000})
Step:   63000, Reward:    23.317 [  96.315], Avg:     2.097 (1.000) <0-01:11:46> ({'r_t':   102.6430, 'eps':     1.0000, 'critic_loss':     3.2122, 'actor_loss':    -0.0229, 'eps_e':     1.0000})
Step:   64000, Reward:    57.189 [  37.405], Avg:     2.944 (1.000) <0-01:12:46> ({'r_t':   112.7178, 'eps':     1.0000, 'critic_loss':     2.7893, 'actor_loss':    -0.2201, 'eps_e':     1.0000})
Step:   65000, Reward:    51.171 [  35.906], Avg:     3.675 (1.000) <0-01:13:55> ({'r_t':   162.5794, 'eps':     1.0000, 'critic_loss':     9.6646, 'actor_loss':    -0.3791, 'eps_e':     1.0000})
Step:   66000, Reward:    26.297 [  40.485], Avg:     4.013 (1.000) <0-01:15:04> ({'r_t':   104.9422, 'eps':     1.0000, 'critic_loss':     8.3024, 'actor_loss':     0.3028, 'eps_e':     1.0000})
Step:   67000, Reward:    39.384 [  38.437], Avg:     4.533 (1.000) <0-01:16:14> ({'r_t':    72.7828, 'eps':     1.0000, 'critic_loss':     8.7238, 'actor_loss':     0.7510, 'eps_e':     1.0000})
Step:   68000, Reward:    30.651 [  52.523], Avg:     4.911 (1.000) <0-01:17:22> ({'r_t':   142.7403, 'eps':     1.0000, 'critic_loss':     4.9036, 'actor_loss':    -0.0299, 'eps_e':     1.0000})
Step:   69000, Reward:    28.536 [  88.409], Avg:     5.249 (1.000) <0-01:18:31> ({'r_t':   157.6660, 'eps':     1.0000, 'critic_loss':     5.8485, 'actor_loss':    -0.2727, 'eps_e':     1.0000})
Step:   70000, Reward:    39.305 [  49.661], Avg:     5.729 (1.000) <0-01:19:40> ({'r_t':   104.8433, 'eps':     1.0000, 'critic_loss':     5.1481, 'actor_loss':     0.4332, 'eps_e':     1.0000})
Step:   71000, Reward:    44.706 [  46.481], Avg:     6.270 (1.000) <0-01:20:40> ({'r_t':   198.5201, 'eps':     1.0000, 'critic_loss':     4.6680, 'actor_loss':     0.2525, 'eps_e':     1.0000})
Step:   72000, Reward:    60.137 [  33.747], Avg:     7.008 (1.000) <0-01:21:37> ({'r_t':   148.1808, 'eps':     1.0000, 'critic_loss':     8.9580, 'actor_loss':    -0.1860, 'eps_e':     1.0000})
Step:   73000, Reward:    45.507 [  47.757], Avg:     7.528 (1.000) <0-01:22:32> ({'r_t':   163.7115, 'eps':     1.0000, 'critic_loss':     6.9795, 'actor_loss':    -0.1745, 'eps_e':     1.0000})
Step:   74000, Reward:    42.941 [  19.109], Avg:     8.000 (1.000) <0-01:23:34> ({'r_t':   172.2615, 'eps':     1.0000, 'critic_loss':     7.2348, 'actor_loss':     0.2748, 'eps_e':     1.0000})
Step:   75000, Reward:    44.474 [  19.309], Avg:     8.480 (1.000) <0-01:24:23> ({'r_t':   132.4880, 'eps':     1.0000, 'critic_loss':     6.1548, 'actor_loss':     0.7522, 'eps_e':     1.0000})
Step:   76000, Reward:    35.216 [  35.148], Avg:     8.827 (1.000) <0-01:25:33> ({'r_t':   120.6875, 'eps':     1.0000, 'critic_loss':     7.2013, 'actor_loss':     0.2585, 'eps_e':     1.0000})
Step:   77000, Reward:    46.720 [  23.466], Avg:     9.313 (1.000) <0-01:26:43> ({'r_t':   161.6336, 'eps':     1.0000, 'critic_loss':     6.5117, 'actor_loss':    -0.4884, 'eps_e':     1.0000})
Step:   78000, Reward:    48.110 [  44.217], Avg:     9.804 (1.000) <0-01:27:45> ({'r_t':   247.0229, 'eps':     1.0000, 'critic_loss':    14.2188, 'actor_loss':    -0.0252, 'eps_e':     1.0000})
Step:   79000, Reward:    34.520 [  59.555], Avg:    10.113 (1.000) <0-01:28:41> ({'r_t':   215.3462, 'eps':     1.0000, 'critic_loss':    16.5138, 'actor_loss':     0.1114, 'eps_e':     1.0000})
Step:   80000, Reward:    41.759 [  59.225], Avg:    10.504 (1.000) <0-01:29:43> ({'r_t':   193.3259, 'eps':     1.0000, 'critic_loss':    26.3716, 'actor_loss':     0.1945, 'eps_e':     1.0000})
Step:   81000, Reward:    63.267 [  19.958], Avg:    11.147 (1.000) <0-01:30:47> ({'r_t':   219.5544, 'eps':     1.0000, 'critic_loss':    13.9959, 'actor_loss':    -0.1197, 'eps_e':     1.0000})
Step:   82000, Reward:    52.847 [  43.638], Avg:    11.650 (1.000) <0-01:31:50> ({'r_t':   215.3113, 'eps':     1.0000, 'critic_loss':    17.9738, 'actor_loss':    -0.0560, 'eps_e':     1.0000})
Step:   83000, Reward:    44.063 [  40.879], Avg:    12.036 (1.000) <0-01:32:58> ({'r_t':   228.1128, 'eps':     1.0000, 'critic_loss':    18.3810, 'actor_loss':    -0.3925, 'eps_e':     1.0000})
Step:   84000, Reward:    53.083 [  37.473], Avg:    12.519 (1.000) <0-01:34:06> ({'r_t':   169.3317, 'eps':     1.0000, 'critic_loss':    16.0200, 'actor_loss':     0.0920, 'eps_e':     1.0000})
Step:   85000, Reward:    47.064 [  41.628], Avg:    12.920 (1.000) <0-01:35:12> ({'r_t':   238.7253, 'eps':     1.0000, 'critic_loss':    16.3869, 'actor_loss':    -0.2485, 'eps_e':     1.0000})
Step:   86000, Reward:    51.958 [  38.638], Avg:    13.369 (1.000) <0-01:36:10> ({'r_t':   232.0367, 'eps':     1.0000, 'critic_loss':    23.5865, 'actor_loss':     0.4774, 'eps_e':     1.0000})
Step:   87000, Reward:    53.912 [  43.676], Avg:    13.830 (1.000) <0-01:36:52> ({'r_t':   258.5641, 'eps':     1.0000, 'critic_loss':    13.7263, 'actor_loss':    -0.2895, 'eps_e':     1.0000})
Step:   88000, Reward:    69.452 [  25.457], Avg:    14.455 (1.000) <0-01:37:49> ({'r_t':   279.2851, 'eps':     1.0000, 'critic_loss':    18.3665, 'actor_loss':    -0.4257, 'eps_e':     1.0000})
Step:   89000, Reward:    62.332 [  38.863], Avg:    14.987 (1.000) <0-01:38:48> ({'r_t':   212.3486, 'eps':     1.0000, 'critic_loss':    13.8920, 'actor_loss':     0.0351, 'eps_e':     1.0000})
Step:   90000, Reward:    58.548 [  40.858], Avg:    15.465 (1.000) <0-01:39:42> ({'r_t':   218.5547, 'eps':     1.0000, 'critic_loss':    15.6344, 'actor_loss':     0.3869, 'eps_e':     1.0000})
Step:   91000, Reward:    55.886 [  48.416], Avg:    15.905 (1.000) <0-01:40:51> ({'r_t':   186.7692, 'eps':     1.0000, 'critic_loss':     7.7830, 'actor_loss':    -0.0028, 'eps_e':     1.0000})
Step:   92000, Reward:    67.978 [  32.243], Avg:    16.465 (1.000) <0-01:42:00> ({'r_t':   269.3184, 'eps':     1.0000, 'critic_loss':    13.4992, 'actor_loss':     0.0474, 'eps_e':     1.0000})
Step:   93000, Reward:    57.097 [  36.585], Avg:    16.897 (1.000) <0-01:43:03> ({'r_t':   259.4028, 'eps':     1.0000, 'critic_loss':    13.3343, 'actor_loss':     0.3271, 'eps_e':     1.0000})
Step:   94000, Reward:    62.704 [  40.641], Avg:    17.379 (1.000) <0-01:43:51> ({'r_t':   292.2662, 'eps':     1.0000, 'critic_loss':    11.3219, 'actor_loss':     0.1495, 'eps_e':     1.0000})
Step:   95000, Reward:    66.602 [  40.149], Avg:    17.892 (1.000) <0-01:44:45> ({'r_t':   306.5555, 'eps':     1.0000, 'critic_loss':    17.2013, 'actor_loss':    -0.2822, 'eps_e':     1.0000})
Step:   96000, Reward:    70.334 [  34.720], Avg:    18.432 (1.000) <0-01:45:39> ({'r_t':   283.1237, 'eps':     1.0000, 'critic_loss':    16.6453, 'actor_loss':    -0.2126, 'eps_e':     1.0000})
Step:   97000, Reward:    69.350 [  35.818], Avg:    18.952 (1.000) <0-01:46:42> ({'r_t':   280.9451, 'eps':     1.0000, 'critic_loss':    10.8048, 'actor_loss':    -0.5336, 'eps_e':     1.0000})
Step:   98000, Reward:    71.285 [  46.215], Avg:    19.481 (1.000) <0-01:47:37> ({'r_t':   256.8810, 'eps':     1.0000, 'critic_loss':    19.1142, 'actor_loss':     0.5476, 'eps_e':     1.0000})
Step:   99000, Reward:    68.132 [  33.994], Avg:    19.967 (1.000) <0-01:48:24> ({'r_t':   297.1330, 'eps':     1.0000, 'critic_loss':    24.5311, 'actor_loss':     0.0897, 'eps_e':     1.0000})
Step:  100000, Reward:    81.146 [  24.501], Avg:    20.573 (1.000) <0-01:49:16> ({'r_t':   308.4302, 'eps':     1.0000, 'critic_loss':    20.0929, 'actor_loss':     0.1348, 'eps_e':     1.0000})
Step:  101000, Reward:    79.622 [  36.894], Avg:    21.152 (1.000) <0-01:50:10> ({'r_t':   402.4884, 'eps':     1.0000, 'critic_loss':    13.5203, 'actor_loss':    -0.0636, 'eps_e':     1.0000})
Step:  102000, Reward:    77.478 [  32.493], Avg:    21.699 (1.000) <0-01:51:02> ({'r_t':   349.0022, 'eps':     1.0000, 'critic_loss':    22.2168, 'actor_loss':     0.3900, 'eps_e':     1.0000})
Step:  103000, Reward:    49.883 [  52.316], Avg:    21.970 (1.000) <0-01:51:52> ({'r_t':   365.1947, 'eps':     1.0000, 'critic_loss':     9.0895, 'actor_loss':    -0.4022, 'eps_e':     1.0000})
Step:  104000, Reward:    91.489 [  19.313], Avg:    22.632 (1.000) <0-01:52:58> ({'r_t':   386.5637, 'eps':     1.0000, 'critic_loss':     9.2219, 'actor_loss':    -0.5334, 'eps_e':     1.0000})
Step:  105000, Reward:    70.230 [  42.868], Avg:    23.081 (1.000) <0-01:53:52> ({'r_t':   295.9083, 'eps':     1.0000, 'critic_loss':     8.6491, 'actor_loss':    -0.2597, 'eps_e':     1.0000})
Step:  106000, Reward:    54.507 [  53.873], Avg:    23.374 (1.000) <0-01:54:51> ({'r_t':   323.8905, 'eps':     1.0000, 'critic_loss':     5.9104, 'actor_loss':     0.0263, 'eps_e':     1.0000})
Step:  107000, Reward:    70.739 [  38.318], Avg:    23.813 (1.000) <0-01:55:55> ({'r_t':   242.8952, 'eps':     1.0000, 'critic_loss':    10.6810, 'actor_loss':     0.3532, 'eps_e':     1.0000})
Step:  108000, Reward:    74.437 [  47.284], Avg:    24.277 (1.000) <0-01:56:48> ({'r_t':   288.6185, 'eps':     1.0000, 'critic_loss':     6.2990, 'actor_loss':    -0.1096, 'eps_e':     1.0000})
Step:  109000, Reward:    69.755 [  50.320], Avg:    24.691 (1.000) <0-01:57:35> ({'r_t':   363.2341, 'eps':     1.0000, 'critic_loss':    12.2009, 'actor_loss':     0.1907, 'eps_e':     1.0000})
Step:  110000, Reward:    99.934 [  93.814], Avg:    25.369 (1.000) <0-01:58:35> ({'r_t':   358.8416, 'eps':     1.0000, 'critic_loss':    14.2126, 'actor_loss':    -0.1509, 'eps_e':     1.0000})
Step:  111000, Reward:    69.930 [  33.950], Avg:    25.767 (1.000) <0-01:59:23> ({'r_t':   325.9212, 'eps':     1.0000, 'critic_loss':    15.9315, 'actor_loss':    -0.0229, 'eps_e':     1.0000})
Step:  112000, Reward:    63.587 [  23.690], Avg:    26.101 (1.000) <0-02:00:15> ({'r_t':   239.5681, 'eps':     1.0000, 'critic_loss':    15.1937, 'actor_loss':     0.7265, 'eps_e':     1.0000})
Step:  113000, Reward:    72.655 [  27.430], Avg:    26.510 (1.000) <0-02:01:07> ({'r_t':   280.4066, 'eps':     1.0000, 'critic_loss':    16.7194, 'actor_loss':     0.2943, 'eps_e':     1.0000})
Step:  114000, Reward:    69.444 [  28.171], Avg:    26.883 (1.000) <0-02:02:04> ({'r_t':   240.0049, 'eps':     1.0000, 'critic_loss':    10.4075, 'actor_loss':    -0.0202, 'eps_e':     1.0000})
Step:  115000, Reward:    78.066 [  28.923], Avg:    27.324 (1.000) <0-02:03:14> ({'r_t':   192.6017, 'eps':     1.0000, 'critic_loss':    13.7320, 'actor_loss':    -0.0485, 'eps_e':     1.0000})
Step:  116000, Reward:    71.715 [  24.985], Avg:    27.704 (1.000) <0-02:04:22> ({'r_t':   215.1884, 'eps':     1.0000, 'critic_loss':    11.3588, 'actor_loss':    -0.0093, 'eps_e':     1.0000})
Step:  117000, Reward:    74.470 [  29.291], Avg:    28.100 (1.000) <0-02:05:33> ({'r_t':   182.1200, 'eps':     1.0000, 'critic_loss':    11.5108, 'actor_loss':     0.1349, 'eps_e':     1.0000})
Step:  118000, Reward:    83.498 [  32.731], Avg:    28.565 (1.000) <0-02:06:40> ({'r_t':   181.9765, 'eps':     1.0000, 'critic_loss':     5.0717, 'actor_loss':    -0.2197, 'eps_e':     1.0000})
Step:  119000, Reward:    64.567 [  43.654], Avg:    28.866 (1.000) <0-02:07:46> ({'r_t':   218.6533, 'eps':     1.0000, 'critic_loss':     8.2783, 'actor_loss':     0.1559, 'eps_e':     1.0000})
Step:  120000, Reward:    75.323 [  33.882], Avg:    29.249 (1.000) <0-02:08:46> ({'r_t':   229.4919, 'eps':     1.0000, 'critic_loss':    15.9926, 'actor_loss':     1.5708, 'eps_e':     1.0000})
Step:  121000, Reward:    76.455 [  36.751], Avg:    29.636 (1.000) <0-02:09:35> ({'r_t':   297.2456, 'eps':     1.0000, 'critic_loss':    13.8854, 'actor_loss':    -0.0768, 'eps_e':     1.0000})
Step:  122000, Reward:    62.488 [  36.713], Avg:    29.903 (1.000) <0-02:10:32> ({'r_t':   294.5087, 'eps':     1.0000, 'critic_loss':    12.9841, 'actor_loss':    -0.0066, 'eps_e':     1.0000})
Step:  123000, Reward:    77.016 [  36.028], Avg:    30.283 (1.000) <0-02:11:31> ({'r_t':   213.2904, 'eps':     1.0000, 'critic_loss':     9.9796, 'actor_loss':    -0.3536, 'eps_e':     1.0000})
Step:  124000, Reward:    77.855 [  43.962], Avg:    30.664 (1.000) <0-02:12:27> ({'r_t':   283.2954, 'eps':     1.0000, 'critic_loss':    15.9497, 'actor_loss':    -0.6263, 'eps_e':     1.0000})
Step:  125000, Reward:    77.085 [  25.860], Avg:    31.032 (1.000) <0-02:13:21> ({'r_t':   308.3628, 'eps':     1.0000, 'critic_loss':    11.4646, 'actor_loss':    -0.1297, 'eps_e':     1.0000})
Step:  126000, Reward:    81.264 [  20.673], Avg:    31.428 (1.000) <0-02:14:31> ({'r_t':   268.4384, 'eps':     1.0000, 'critic_loss':    13.2705, 'actor_loss':    -0.0169, 'eps_e':     1.0000})
Step:  127000, Reward:    43.895 [  61.053], Avg:    31.525 (1.000) <0-02:15:25> ({'r_t':   296.6755, 'eps':     1.0000, 'critic_loss':    10.0754, 'actor_loss':     0.4696, 'eps_e':     1.0000})
Step:  128000, Reward:    80.350 [  35.210], Avg:    31.904 (1.000) <0-02:16:36> ({'r_t':   256.4714, 'eps':     1.0000, 'critic_loss':    11.6833, 'actor_loss':     0.1143, 'eps_e':     1.0000})
Step:  129000, Reward:    75.276 [  19.885], Avg:    32.237 (1.000) <0-02:17:44> ({'r_t':   195.6151, 'eps':     1.0000, 'critic_loss':     5.5933, 'actor_loss':     0.1521, 'eps_e':     1.0000})
Step:  130000, Reward:    81.801 [  21.685], Avg:    32.616 (1.000) <0-02:18:53> ({'r_t':   211.6754, 'eps':     1.0000, 'critic_loss':    10.3017, 'actor_loss':     0.3891, 'eps_e':     1.0000})
Step:  131000, Reward:    88.420 [  33.157], Avg:    33.039 (1.000) <0-02:20:03> ({'r_t':   277.6510, 'eps':     1.0000, 'critic_loss':     9.9586, 'actor_loss':    -0.0280, 'eps_e':     1.0000})
Step:  132000, Reward:    87.619 [  36.977], Avg:    33.449 (1.000) <0-02:21:12> ({'r_t':   250.7275, 'eps':     1.0000, 'critic_loss':     3.9042, 'actor_loss':    -0.2849, 'eps_e':     1.0000})
Step:  133000, Reward:    81.849 [  28.294], Avg:    33.810 (1.000) <0-02:22:21> ({'r_t':   223.0805, 'eps':     1.0000, 'critic_loss':     7.3584, 'actor_loss':     0.5768, 'eps_e':     1.0000})
Step:  134000, Reward:    63.758 [  70.435], Avg:    34.032 (1.000) <0-02:23:30> ({'r_t':   168.0046, 'eps':     1.0000, 'critic_loss':     8.8211, 'actor_loss':     0.5791, 'eps_e':     1.0000})
Step:  135000, Reward:    63.243 [  53.303], Avg:    34.247 (1.000) <0-02:24:41> ({'r_t':   211.7637, 'eps':     1.0000, 'critic_loss':     7.0509, 'actor_loss':     0.1272, 'eps_e':     1.0000})
Step:  136000, Reward:    87.290 [  28.116], Avg:    34.634 (1.000) <0-02:25:51> ({'r_t':   173.9671, 'eps':     1.0000, 'critic_loss':     8.3391, 'actor_loss':     0.4322, 'eps_e':     1.0000})
Step:  137000, Reward:    46.436 [ 138.756], Avg:    34.719 (1.000) <0-02:27:00> ({'r_t':   206.7027, 'eps':     1.0000, 'critic_loss':     3.8978, 'actor_loss':     0.1107, 'eps_e':     1.0000})
Step:  138000, Reward:    84.503 [  35.932], Avg:    35.078 (1.000) <0-02:28:10> ({'r_t':   205.1110, 'eps':     1.0000, 'critic_loss':    10.1229, 'actor_loss':     0.4567, 'eps_e':     1.0000})
Step:  139000, Reward:    79.823 [  23.594], Avg:    35.397 (1.000) <0-02:29:01> ({'r_t':   152.1564, 'eps':     1.0000, 'critic_loss':     7.4141, 'actor_loss':    -0.1319, 'eps_e':     1.0000})
Step:  140000, Reward:    32.545 [ 156.426], Avg:    35.377 (1.000) <0-02:30:11> ({'r_t':   163.8686, 'eps':     1.0000, 'critic_loss':     8.4305, 'actor_loss':    -0.1828, 'eps_e':     1.0000})
Step:  141000, Reward:    53.267 [  80.707], Avg:    35.503 (1.000) <0-02:31:19> ({'r_t':   166.0627, 'eps':     1.0000, 'critic_loss':     8.7992, 'actor_loss':    -0.3159, 'eps_e':     1.0000})
Step:  142000, Reward:    89.394 [  20.812], Avg:    35.880 (1.000) <0-02:32:27> ({'r_t':   229.9975, 'eps':     1.0000, 'critic_loss':     9.4653, 'actor_loss':    -0.2199, 'eps_e':     1.0000})
Step:  143000, Reward:    81.532 [  38.855], Avg:    36.197 (1.000) <0-02:33:37> ({'r_t':   165.0690, 'eps':     1.0000, 'critic_loss':     6.0934, 'actor_loss':     0.0331, 'eps_e':     1.0000})
Step:  144000, Reward:    88.449 [  19.848], Avg:    36.557 (1.000) <0-02:34:47> ({'r_t':   232.6176, 'eps':     1.0000, 'critic_loss':    10.6659, 'actor_loss':     0.2403, 'eps_e':     1.0000})
Step:  145000, Reward:    87.379 [  35.440], Avg:    36.905 (1.000) <0-02:35:55> ({'r_t':   199.7646, 'eps':     1.0000, 'critic_loss':     4.7485, 'actor_loss':    -0.4616, 'eps_e':     1.0000})
Step:  146000, Reward:    89.519 [  18.811], Avg:    37.263 (1.000) <0-02:37:05> ({'r_t':   157.4106, 'eps':     1.0000, 'critic_loss':     9.1273, 'actor_loss':     0.5405, 'eps_e':     1.0000})
Step:  147000, Reward:    75.791 [  33.232], Avg:    37.524 (1.000) <0-02:38:14> ({'r_t':   139.3915, 'eps':     1.0000, 'critic_loss':    13.6795, 'actor_loss':     0.5932, 'eps_e':     1.0000})
Step:  148000, Reward:    82.834 [  24.105], Avg:    37.828 (1.000) <0-02:39:22> ({'r_t':   185.3833, 'eps':     1.0000, 'critic_loss':     8.7621, 'actor_loss':     0.0325, 'eps_e':     1.0000})
Step:  149000, Reward:    88.211 [  28.488], Avg:    38.164 (1.000) <0-02:40:32> ({'r_t':   216.7543, 'eps':     1.0000, 'critic_loss':     8.4657, 'actor_loss':    -0.0222, 'eps_e':     1.0000})
Step:  150000, Reward:    83.433 [  39.114], Avg:    38.463 (1.000) <0-02:41:30> ({'r_t':   267.3351, 'eps':     1.0000, 'critic_loss':     8.0663, 'actor_loss':    -0.1183, 'eps_e':     1.0000})
Step:  151000, Reward:    84.798 [  37.432], Avg:    38.768 (1.000) <0-02:42:39> ({'r_t':   271.4156, 'eps':     1.0000, 'critic_loss':     6.3336, 'actor_loss':    -0.1949, 'eps_e':     1.0000})
Step:  152000, Reward:    85.237 [  37.249], Avg:    39.072 (1.000) <0-02:43:34> ({'r_t':   220.8079, 'eps':     1.0000, 'critic_loss':     5.8816, 'actor_loss':     0.0716, 'eps_e':     1.0000})
Step:  153000, Reward:    90.727 [  36.468], Avg:    39.407 (1.000) <0-02:44:43> ({'r_t':   242.1433, 'eps':     1.0000, 'critic_loss':     5.6588, 'actor_loss':    -0.1468, 'eps_e':     1.0000})
Step:  154000, Reward:    87.251 [  23.468], Avg:    39.716 (1.000) <0-02:45:52> ({'r_t':   291.5163, 'eps':     1.0000, 'critic_loss':     8.3246, 'actor_loss':     0.1066, 'eps_e':     1.0000})
Step:  155000, Reward:    77.829 [  61.871], Avg:    39.960 (1.000) <0-02:47:02> ({'r_t':   152.7922, 'eps':     1.0000, 'critic_loss':     4.6426, 'actor_loss':    -0.0821, 'eps_e':     1.0000})
Step:  156000, Reward:    85.359 [  33.323], Avg:    40.249 (1.000) <0-02:48:10> ({'r_t':   139.3959, 'eps':     1.0000, 'critic_loss':     6.3473, 'actor_loss':     0.1695, 'eps_e':     1.0000})
Step:  157000, Reward:    83.707 [  36.237], Avg:    40.525 (1.000) <0-02:49:21> ({'r_t':   117.0612, 'eps':     1.0000, 'critic_loss':     6.1811, 'actor_loss':     0.4792, 'eps_e':     1.0000})
Step:  158000, Reward:    58.820 [  97.899], Avg:    40.640 (1.000) <0-02:50:27> ({'r_t':    95.0478, 'eps':     1.0000, 'critic_loss':     6.3772, 'actor_loss':     0.3720, 'eps_e':     1.0000})
Step:  159000, Reward:    79.347 [  33.671], Avg:    40.882 (1.000) <0-02:51:36> ({'r_t':   156.7408, 'eps':     1.0000, 'critic_loss':     7.7395, 'actor_loss':     0.0476, 'eps_e':     1.0000})
Step:  160000, Reward:    53.174 [  71.432], Avg:    40.958 (1.000) <0-02:52:46> ({'r_t':   159.5636, 'eps':     1.0000, 'critic_loss':     7.4628, 'actor_loss':     0.1925, 'eps_e':     1.0000})
Step:  161000, Reward:    50.547 [  80.571], Avg:    41.017 (1.000) <0-02:53:56> ({'r_t':   203.6806, 'eps':     1.0000, 'critic_loss':     4.7086, 'actor_loss':    -0.2441, 'eps_e':     1.0000})
Step:  162000, Reward:    65.512 [  69.308], Avg:    41.167 (1.000) <0-02:55:05> ({'r_t':   117.1524, 'eps':     1.0000, 'critic_loss':     4.2274, 'actor_loss':    -0.4611, 'eps_e':     1.0000})
Step:  163000, Reward:    76.730 [  47.550], Avg:    41.384 (1.000) <0-02:56:15> ({'r_t':   187.4913, 'eps':     1.0000, 'critic_loss':    10.1953, 'actor_loss':    -0.0883, 'eps_e':     1.0000})
Step:  164000, Reward:    42.682 [ 120.628], Avg:    41.392 (1.000) <0-02:57:24> ({'r_t':   233.6244, 'eps':     1.0000, 'critic_loss':     6.1839, 'actor_loss':    -0.3169, 'eps_e':     1.0000})
Step:  165000, Reward:    55.729 [  57.600], Avg:    41.478 (1.000) <0-02:58:34> ({'r_t':    65.0610, 'eps':     1.0000, 'critic_loss':     6.0424, 'actor_loss':     0.9344, 'eps_e':     1.0000})
Step:  166000, Reward:    83.576 [  37.369], Avg:    41.730 (1.000) <0-02:59:43> ({'r_t':   185.4114, 'eps':     1.0000, 'critic_loss':     7.8480, 'actor_loss':     0.3361, 'eps_e':     1.0000})
Step:  167000, Reward:    58.946 [  61.820], Avg:    41.833 (1.000) <0-03:00:53> ({'r_t':   174.0726, 'eps':     1.0000, 'critic_loss':     9.0703, 'actor_loss':     0.1053, 'eps_e':     1.0000})
Step:  168000, Reward:    52.815 [  69.375], Avg:    41.898 (1.000) <0-03:02:03> ({'r_t':   235.2732, 'eps':     1.0000, 'critic_loss':     8.5675, 'actor_loss':     0.3701, 'eps_e':     1.0000})
Step:  169000, Reward:    65.665 [  53.398], Avg:    42.038 (1.000) <0-03:03:12> ({'r_t':    77.9153, 'eps':     1.0000, 'critic_loss':     9.4571, 'actor_loss':     0.5547, 'eps_e':     1.0000})
Step:  170000, Reward:    43.842 [  94.608], Avg:    42.048 (1.000) <0-03:04:22> ({'r_t':   180.6422, 'eps':     1.0000, 'critic_loss':     5.7216, 'actor_loss':    -0.0257, 'eps_e':     1.0000})
Step:  171000, Reward:    66.505 [  54.310], Avg:    42.190 (1.000) <0-03:05:30> ({'r_t':   170.3722, 'eps':     1.0000, 'critic_loss':     5.2068, 'actor_loss':     0.3683, 'eps_e':     1.0000})
Step:  172000, Reward:    46.968 [ 113.130], Avg:    42.218 (1.000) <0-03:06:40> ({'r_t':    36.0362, 'eps':     1.0000, 'critic_loss':     5.5919, 'actor_loss':     0.6097, 'eps_e':     1.0000})
Step:  173000, Reward:    53.405 [  82.245], Avg:    42.282 (1.000) <0-03:07:50> ({'r_t':    49.0436, 'eps':     1.0000, 'critic_loss':     7.1021, 'actor_loss':     0.5150, 'eps_e':     1.0000})
Step:  174000, Reward:    80.443 [  32.875], Avg:    42.500 (1.000) <0-03:08:59> ({'r_t':   127.2990, 'eps':     1.0000, 'critic_loss':     5.1255, 'actor_loss':     0.0546, 'eps_e':     1.0000})
Step:  175000, Reward:    14.363 [  51.810], Avg:    42.341 (1.000) <0-03:10:09> ({'r_t':    76.1395, 'eps':     1.0000, 'critic_loss':    10.0643, 'actor_loss':     1.5584, 'eps_e':     1.0000})
Step:  176000, Reward:    -1.372 [  61.048], Avg:    42.094 (1.000) <0-03:11:17> ({'r_t':    54.3929, 'eps':     1.0000, 'critic_loss':     7.7615, 'actor_loss':     1.3562, 'eps_e':     1.0000})
Step:  177000, Reward:    -9.286 [  92.891], Avg:    41.805 (1.000) <0-03:12:27> ({'r_t':    33.4407, 'eps':     1.0000, 'critic_loss':    10.0337, 'actor_loss':     0.5288, 'eps_e':     1.0000})
Step:  178000, Reward:    41.314 [  66.266], Avg:    41.802 (1.000) <0-03:13:38> ({'r_t':    44.3119, 'eps':     1.0000, 'critic_loss':    10.0699, 'actor_loss':     0.1329, 'eps_e':     1.0000})
Step:  179000, Reward:    38.225 [  80.279], Avg:    41.782 (1.000) <0-03:14:48> ({'r_t':   100.7373, 'eps':     1.0000, 'critic_loss':    17.2650, 'actor_loss':    -0.4536, 'eps_e':     1.0000})
Step:  180000, Reward:    40.211 [  91.739], Avg:    41.774 (1.000) <0-03:15:58> ({'r_t':    -4.0114, 'eps':     1.0000, 'critic_loss':    11.6180, 'actor_loss':     1.4026, 'eps_e':     1.0000})
Step:  181000, Reward:    42.005 [  64.272], Avg:    41.775 (1.000) <0-03:17:06> ({'r_t':    -9.7355, 'eps':     1.0000, 'critic_loss':     9.0439, 'actor_loss':     1.7757, 'eps_e':     1.0000})
Step:  182000, Reward:    77.562 [  47.057], Avg:    41.970 (1.000) <0-03:18:17> ({'r_t':    21.0196, 'eps':     1.0000, 'critic_loss':    11.9231, 'actor_loss':     0.6602, 'eps_e':     1.0000})
Step:  183000, Reward:    71.401 [  47.314], Avg:    42.130 (1.000) <0-03:19:26> ({'r_t':    93.5038, 'eps':     1.0000, 'critic_loss':    10.7145, 'actor_loss':     1.1062, 'eps_e':     1.0000})
Step:  184000, Reward:    11.520 [ 100.823], Avg:    41.965 (1.000) <0-03:20:36> ({'r_t':    62.8370, 'eps':     1.0000, 'critic_loss':    12.1778, 'actor_loss':     0.3949, 'eps_e':     1.0000})
Step:  185000, Reward:    24.645 [  83.525], Avg:    41.872 (1.000) <0-03:21:45> ({'r_t':   110.6994, 'eps':     1.0000, 'critic_loss':    10.3565, 'actor_loss':     0.0475, 'eps_e':     1.0000})
Step:  186000, Reward:    -0.777 [ 166.752], Avg:    41.644 (1.000) <0-03:22:55> ({'r_t':   101.2751, 'eps':     1.0000, 'critic_loss':     7.5220, 'actor_loss':    -0.0258, 'eps_e':     1.0000})
Step:  187000, Reward:    44.961 [  70.386], Avg:    41.661 (1.000) <0-03:24:05> ({'r_t':   131.3636, 'eps':     1.0000, 'critic_loss':     8.4928, 'actor_loss':     0.3728, 'eps_e':     1.0000})
Step:  188000, Reward:    75.956 [  39.568], Avg:    41.843 (1.000) <0-03:25:14> ({'r_t':   145.9926, 'eps':     1.0000, 'critic_loss':     7.1968, 'actor_loss':     0.4901, 'eps_e':     1.0000})
Step:  189000, Reward:    65.105 [  55.369], Avg:    41.965 (1.000) <0-03:26:24> ({'r_t':   147.2389, 'eps':     1.0000, 'critic_loss':     5.1760, 'actor_loss':    -0.0125, 'eps_e':     1.0000})
Step:  190000, Reward:    58.969 [ 123.390], Avg:    42.054 (1.000) <0-03:27:34> ({'r_t':   102.3859, 'eps':     1.0000, 'critic_loss':     4.4513, 'actor_loss':     0.2395, 'eps_e':     1.0000})
Step:  191000, Reward:    67.894 [  68.043], Avg:    42.189 (1.000) <0-03:28:43> ({'r_t':   188.0054, 'eps':     1.0000, 'critic_loss':     5.0572, 'actor_loss':     0.2752, 'eps_e':     1.0000})
Step:  192000, Reward:    37.678 [ 125.641], Avg:    42.166 (1.000) <0-03:29:52> ({'r_t':   166.2604, 'eps':     1.0000, 'critic_loss':     2.8361, 'actor_loss':     0.1527, 'eps_e':     1.0000})
Step:  193000, Reward:    63.397 [  59.082], Avg:    42.275 (1.000) <0-03:31:01> ({'r_t':    93.0476, 'eps':     1.0000, 'critic_loss':     3.7466, 'actor_loss':     0.6815, 'eps_e':     1.0000})
Step:  194000, Reward:    64.593 [  65.719], Avg:    42.389 (1.000) <0-03:32:10> ({'r_t':   115.6611, 'eps':     1.0000, 'critic_loss':     8.2525, 'actor_loss':     0.6462, 'eps_e':     1.0000})
Step:  195000, Reward:    76.138 [  56.387], Avg:    42.562 (1.000) <0-03:33:20> ({'r_t':   116.4878, 'eps':     1.0000, 'critic_loss':     6.4123, 'actor_loss':     0.2155, 'eps_e':     1.0000})
Step:  196000, Reward:    90.785 [  26.025], Avg:    42.806 (1.000) <0-03:34:30> ({'r_t':    99.1914, 'eps':     1.0000, 'critic_loss':     7.8431, 'actor_loss':     0.5581, 'eps_e':     1.0000})
Step:  197000, Reward:    85.299 [  26.907], Avg:    43.021 (1.000) <0-03:35:39> ({'r_t':    99.9346, 'eps':     1.0000, 'critic_loss':     5.6289, 'actor_loss':     0.3237, 'eps_e':     1.0000})
Step:  198000, Reward:    81.533 [  31.295], Avg:    43.215 (1.000) <0-03:36:49> ({'r_t':    66.7614, 'eps':     1.0000, 'critic_loss':     6.4597, 'actor_loss':    -0.0857, 'eps_e':     1.0000})
Step:  199000, Reward:    77.821 [  36.601], Avg:    43.388 (1.000) <0-03:37:59> ({'r_t':   142.9796, 'eps':     1.0000, 'critic_loss':     5.9208, 'actor_loss':     0.0861, 'eps_e':     1.0000})
Step:  200000, Reward:    98.226 [  16.550], Avg:    43.660 (1.000) <0-03:39:09> ({'r_t':    96.8561, 'eps':     1.0000, 'critic_loss':     3.3922, 'actor_loss':     0.1918, 'eps_e':     1.0000})
Step:  201000, Reward:    83.902 [  23.284], Avg:    43.860 (1.000) <0-03:40:19> ({'r_t':    81.1603, 'eps':     1.0000, 'critic_loss':     4.6608, 'actor_loss':     0.6032, 'eps_e':     1.0000})
Step:  202000, Reward:    66.115 [  65.235], Avg:    43.969 (1.000) <0-03:41:29> ({'r_t':   143.8214, 'eps':     1.0000, 'critic_loss':     5.9982, 'actor_loss':    -0.0080, 'eps_e':     1.0000})
Step:  203000, Reward:    63.703 [ 142.023], Avg:    44.066 (1.000) <0-03:42:38> ({'r_t':   155.4203, 'eps':     1.0000, 'critic_loss':     8.1580, 'actor_loss':     0.4008, 'eps_e':     1.0000})
Step:  204000, Reward:    73.963 [  54.679], Avg:    44.212 (1.000) <0-03:43:47> ({'r_t':   112.9398, 'eps':     1.0000, 'critic_loss':     5.2143, 'actor_loss':     0.1647, 'eps_e':     1.0000})
Step:  205000, Reward:    91.509 [  21.239], Avg:    44.441 (1.000) <0-03:44:58> ({'r_t':   101.6043, 'eps':     1.0000, 'critic_loss':     6.5992, 'actor_loss':    -0.1494, 'eps_e':     1.0000})
Step:  206000, Reward:    75.875 [  46.855], Avg:    44.593 (1.000) <0-03:46:07> ({'r_t':   135.4234, 'eps':     1.0000, 'critic_loss':     6.7968, 'actor_loss':     0.4564, 'eps_e':     1.0000})
Step:  207000, Reward:    50.902 [  84.768], Avg:    44.624 (1.000) <0-03:47:17> ({'r_t':   147.1674, 'eps':     1.0000, 'critic_loss':     7.0509, 'actor_loss':     0.0402, 'eps_e':     1.0000})
Step:  208000, Reward:    89.938 [  23.038], Avg:    44.840 (1.000) <0-03:48:26> ({'r_t':    83.7519, 'eps':     1.0000, 'critic_loss':     9.0771, 'actor_loss':     0.8325, 'eps_e':     1.0000})
Step:  209000, Reward:   -13.082 [ 256.284], Avg:    44.565 (1.000) <0-03:49:35> ({'r_t':    63.6743, 'eps':     1.0000, 'critic_loss':     4.4880, 'actor_loss':     0.3488, 'eps_e':     1.0000})
Step:  210000, Reward:    52.816 [  81.401], Avg:    44.604 (1.000) <0-03:50:46> ({'r_t':    82.3307, 'eps':     1.0000, 'critic_loss':     9.4904, 'actor_loss':     0.0272, 'eps_e':     1.0000})
Step:  211000, Reward:    61.519 [  73.181], Avg:    44.683 (1.000) <0-03:51:55> ({'r_t':   114.2319, 'eps':     1.0000, 'critic_loss':     7.9202, 'actor_loss':    -0.0588, 'eps_e':     1.0000})
Step:  212000, Reward:     5.244 [ 178.625], Avg:    44.498 (1.000) <0-03:53:05> ({'r_t':   175.8346, 'eps':     1.0000, 'critic_loss':     2.9351, 'actor_loss':    -0.2527, 'eps_e':     1.0000})
Step:  213000, Reward:    76.024 [  54.843], Avg:    44.646 (1.000) <0-03:54:14> ({'r_t':    91.2324, 'eps':     1.0000, 'critic_loss':     4.8182, 'actor_loss':     0.2980, 'eps_e':     1.0000})
Step:  214000, Reward:    38.475 [ 107.281], Avg:    44.617 (1.000) <0-03:55:24> ({'r_t':    69.9979, 'eps':     1.0000, 'critic_loss':     3.4701, 'actor_loss':     0.4953, 'eps_e':     1.0000})
Step:  215000, Reward:    64.243 [  62.759], Avg:    44.708 (1.000) <0-03:56:33> ({'r_t':   137.4617, 'eps':     1.0000, 'critic_loss':     6.0072, 'actor_loss':     0.3616, 'eps_e':     1.0000})
Step:  216000, Reward:    31.149 [ 157.496], Avg:    44.645 (1.000) <0-03:57:42> ({'r_t':   162.9313, 'eps':     1.0000, 'critic_loss':     6.4504, 'actor_loss':    -0.0116, 'eps_e':     1.0000})
Step:  217000, Reward:     1.304 [ 184.713], Avg:    44.447 (1.000) <0-03:58:51> ({'r_t':    89.0188, 'eps':     1.0000, 'critic_loss':     8.1568, 'actor_loss':     0.4876, 'eps_e':     1.0000})
Step:  218000, Reward:    62.058 [  49.603], Avg:    44.527 (1.000) <0-04:00:02> ({'r_t':   169.1226, 'eps':     1.0000, 'critic_loss':    10.0019, 'actor_loss':     0.1335, 'eps_e':     1.0000})
Step:  219000, Reward:    79.657 [  36.028], Avg:    44.687 (1.000) <0-04:01:10> ({'r_t':   102.6566, 'eps':     1.0000, 'critic_loss':     3.2597, 'actor_loss':    -0.2215, 'eps_e':     1.0000})
Step:  220000, Reward:    86.243 [  21.609], Avg:    44.875 (1.000) <0-04:02:21> ({'r_t':    79.1920, 'eps':     1.0000, 'critic_loss':     3.9058, 'actor_loss':     0.3067, 'eps_e':     1.0000})
Step:  221000, Reward:    66.135 [  37.422], Avg:    44.970 (1.000) <0-04:03:30> ({'r_t':   128.5779, 'eps':     1.0000, 'critic_loss':     4.6223, 'actor_loss':     0.4635, 'eps_e':     1.0000})
Step:  222000, Reward:    42.395 [ 108.068], Avg:    44.959 (1.000) <0-04:04:40> ({'r_t':    71.0915, 'eps':     1.0000, 'critic_loss':     9.5640, 'actor_loss':     1.3636, 'eps_e':     1.0000})
Step:  223000, Reward:    75.845 [  50.357], Avg:    45.097 (1.000) <0-04:05:49> ({'r_t':   141.4911, 'eps':     1.0000, 'critic_loss':     9.7041, 'actor_loss':    -0.0409, 'eps_e':     1.0000})
Step:  224000, Reward:    84.376 [  31.447], Avg:    45.271 (1.000) <0-04:07:00> ({'r_t':   139.0537, 'eps':     1.0000, 'critic_loss':     7.7297, 'actor_loss':     0.3039, 'eps_e':     1.0000})
Step:  225000, Reward:    89.886 [  23.518], Avg:    45.469 (1.000) <0-04:08:09> ({'r_t':   160.9281, 'eps':     1.0000, 'critic_loss':     5.4770, 'actor_loss':    -0.2954, 'eps_e':     1.0000})
Step:  226000, Reward:    85.907 [  35.219], Avg:    45.647 (1.000) <0-04:09:18> ({'r_t':    53.8158, 'eps':     1.0000, 'critic_loss':     3.8999, 'actor_loss':    -0.4358, 'eps_e':     1.0000})
Step:  227000, Reward:    93.706 [  15.492], Avg:    45.858 (1.000) <0-04:10:27> ({'r_t':   143.5305, 'eps':     1.0000, 'critic_loss':     5.1182, 'actor_loss':    -0.4542, 'eps_e':     1.0000})
Step:  228000, Reward:    72.865 [  41.663], Avg:    45.976 (1.000) <0-04:11:37> ({'r_t':   141.7879, 'eps':     1.0000, 'critic_loss':     6.0028, 'actor_loss':     0.1782, 'eps_e':     1.0000})
Step:  229000, Reward:    79.428 [  69.202], Avg:    46.121 (1.000) <0-04:12:47> ({'r_t':   156.0460, 'eps':     1.0000, 'critic_loss':     4.0960, 'actor_loss':     0.3214, 'eps_e':     1.0000})
Step:  230000, Reward:    89.641 [  18.050], Avg:    46.309 (1.000) <0-04:13:57> ({'r_t':   122.6599, 'eps':     1.0000, 'critic_loss':     4.2824, 'actor_loss':    -0.1041, 'eps_e':     1.0000})
Step:  231000, Reward:    69.592 [  83.064], Avg:    46.410 (1.000) <0-04:15:07> ({'r_t':   123.6587, 'eps':     1.0000, 'critic_loss':     3.1862, 'actor_loss':     0.0750, 'eps_e':     1.0000})
Step:  232000, Reward:    98.669 [   8.187], Avg:    46.634 (1.000) <0-04:16:17> ({'r_t':   136.8303, 'eps':     1.0000, 'critic_loss':     1.3070, 'actor_loss':    -0.1732, 'eps_e':     1.0000})
Step:  233000, Reward:    74.615 [  94.122], Avg:    46.754 (1.000) <0-04:17:27> ({'r_t':   132.4507, 'eps':     1.0000, 'critic_loss':     6.1499, 'actor_loss':     0.2765, 'eps_e':     1.0000})
Step:  234000, Reward:   101.755 [  15.120], Avg:    46.988 (1.000) <0-04:18:36> ({'r_t':   128.4156, 'eps':     1.0000, 'critic_loss':     1.4849, 'actor_loss':    -0.0722, 'eps_e':     1.0000})
Step:  235000, Reward:    94.299 [  39.914], Avg:    47.188 (1.000) <0-04:19:45> ({'r_t':   175.6599, 'eps':     1.0000, 'critic_loss':     3.0702, 'actor_loss':    -0.0923, 'eps_e':     1.0000})
Step:  236000, Reward:    94.828 [  24.454], Avg:    47.389 (1.000) <0-04:20:55> ({'r_t':   172.1332, 'eps':     1.0000, 'critic_loss':     2.2101, 'actor_loss':    -0.0673, 'eps_e':     1.0000})
Step:  237000, Reward:    86.575 [  26.776], Avg:    47.554 (1.000) <0-04:22:06> ({'r_t':   154.6996, 'eps':     1.0000, 'critic_loss':     3.6555, 'actor_loss':     0.0547, 'eps_e':     1.0000})
Step:  238000, Reward:   101.242 [  12.870], Avg:    47.778 (1.000) <0-04:23:16> ({'r_t':    88.3179, 'eps':     1.0000, 'critic_loss':     4.5700, 'actor_loss':     0.5414, 'eps_e':     1.0000})
Step:  239000, Reward:    93.654 [  27.542], Avg:    47.970 (1.000) <0-04:24:26> ({'r_t':   145.4523, 'eps':     1.0000, 'critic_loss':     5.0455, 'actor_loss':     0.3137, 'eps_e':     1.0000})
Step:  240000, Reward:    92.264 [  20.755], Avg:    48.153 (1.000) <0-04:25:35> ({'r_t':   145.9715, 'eps':     1.0000, 'critic_loss':     3.6221, 'actor_loss':     0.1241, 'eps_e':     1.0000})
Step:  241000, Reward:    90.676 [  16.897], Avg:    48.329 (1.000) <0-04:26:43> ({'r_t':   137.6213, 'eps':     1.0000, 'critic_loss':     5.8806, 'actor_loss':     0.3931, 'eps_e':     1.0000})
Step:  242000, Reward:    66.045 [  57.478], Avg:    48.402 (1.000) <0-04:27:53> ({'r_t':   111.0275, 'eps':     1.0000, 'critic_loss':     6.8915, 'actor_loss':     0.0713, 'eps_e':     1.0000})
Step:  243000, Reward:    84.514 [  23.462], Avg:    48.550 (1.000) <0-04:29:03> ({'r_t':   106.1051, 'eps':     1.0000, 'critic_loss':     9.4988, 'actor_loss':     0.4156, 'eps_e':     1.0000})
Step:  244000, Reward:    89.071 [  29.185], Avg:    48.715 (1.000) <0-04:30:13> ({'r_t':   108.5933, 'eps':     1.0000, 'critic_loss':     7.8673, 'actor_loss':    -0.0142, 'eps_e':     1.0000})
Step:  245000, Reward:    86.322 [  28.437], Avg:    48.868 (1.000) <0-04:31:22> ({'r_t':   165.1150, 'eps':     1.0000, 'critic_loss':     4.6219, 'actor_loss':    -0.1262, 'eps_e':     1.0000})
Step:  246000, Reward:    84.788 [  37.710], Avg:    49.014 (1.000) <0-04:32:33> ({'r_t':   128.0375, 'eps':     1.0000, 'critic_loss':     5.6868, 'actor_loss':    -0.0684, 'eps_e':     1.0000})
Step:  247000, Reward:    65.165 [  77.377], Avg:    49.079 (1.000) <0-04:33:41> ({'r_t':   136.3286, 'eps':     1.0000, 'critic_loss':     5.4252, 'actor_loss':    -0.0475, 'eps_e':     1.0000})
Step:  248000, Reward:    77.981 [  54.813], Avg:    49.195 (1.000) <0-04:34:51> ({'r_t':    88.4955, 'eps':     1.0000, 'critic_loss':     2.7759, 'actor_loss':     0.0886, 'eps_e':     1.0000})
Step:  249000, Reward:    68.474 [ 129.756], Avg:    49.272 (1.000) <0-04:36:01> ({'r_t':   144.5651, 'eps':     1.0000, 'critic_loss':     5.3890, 'actor_loss':     0.2646, 'eps_e':     1.0000})
Step:  250000, Reward:   103.767 [  21.888], Avg:    49.489 (1.000) <0-04:37:11> ({'r_t':   106.7567, 'eps':     1.0000, 'critic_loss':     5.4654, 'actor_loss':    -0.0142, 'eps_e':     1.0000})
Step:  251000, Reward:    89.541 [  29.545], Avg:    49.648 (1.000) <0-04:38:21> ({'r_t':   156.8341, 'eps':     1.0000, 'critic_loss':     3.4107, 'actor_loss':    -0.2220, 'eps_e':     1.0000})
Step:  252000, Reward:   106.980 [  13.944], Avg:    49.875 (1.000) <0-04:39:31> ({'r_t':   125.9780, 'eps':     1.0000, 'critic_loss':     2.9241, 'actor_loss':    -0.0204, 'eps_e':     1.0000})
Step:  253000, Reward:    68.015 [ 114.107], Avg:    49.946 (1.000) <0-04:40:41> ({'r_t':   112.0807, 'eps':     1.0000, 'critic_loss':     4.5693, 'actor_loss':     0.2254, 'eps_e':     1.0000})
Step:  254000, Reward:    80.446 [  86.906], Avg:    50.066 (1.000) <0-04:41:50> ({'r_t':   110.6505, 'eps':     1.0000, 'critic_loss':     5.2589, 'actor_loss':     0.3185, 'eps_e':     1.0000})
Step:  255000, Reward:    93.578 [  24.220], Avg:    50.236 (1.000) <0-04:43:02> ({'r_t':   126.9531, 'eps':     1.0000, 'critic_loss':     6.0779, 'actor_loss':     0.5991, 'eps_e':     1.0000})
Step:  256000, Reward:    99.588 [  30.361], Avg:    50.428 (1.000) <0-04:44:10> ({'r_t':   137.0490, 'eps':     1.0000, 'critic_loss':     3.0556, 'actor_loss':     0.0071, 'eps_e':     1.0000})
Step:  257000, Reward:    56.223 [ 158.465], Avg:    50.450 (1.000) <0-04:45:20> ({'r_t':   119.6373, 'eps':     1.0000, 'critic_loss':     1.6227, 'actor_loss':    -0.1266, 'eps_e':     1.0000})
Step:  258000, Reward:    91.249 [  23.522], Avg:    50.608 (1.000) <0-04:46:30> ({'r_t':    85.2953, 'eps':     1.0000, 'critic_loss':     4.0134, 'actor_loss':     0.3283, 'eps_e':     1.0000})
Step:  259000, Reward:    96.156 [  24.360], Avg:    50.783 (1.000) <0-04:47:40> ({'r_t':    91.6589, 'eps':     1.0000, 'critic_loss':     4.4195, 'actor_loss':     0.4739, 'eps_e':     1.0000})
Step:  260000, Reward:   110.143 [   6.505], Avg:    51.010 (1.000) <0-04:48:50> ({'r_t':    59.0802, 'eps':     1.0000, 'critic_loss':     4.6780, 'actor_loss':     0.5007, 'eps_e':     1.0000})
Step:  261000, Reward:   100.548 [  23.770], Avg:    51.199 (1.000) <0-04:50:00> ({'r_t':    96.1492, 'eps':     1.0000, 'critic_loss':     5.2876, 'actor_loss':     0.0849, 'eps_e':     1.0000})
Step:  262000, Reward:    63.312 [  74.703], Avg:    51.245 (1.000) <0-04:51:08> ({'r_t':   140.4008, 'eps':     1.0000, 'critic_loss':     4.8060, 'actor_loss':     0.2523, 'eps_e':     1.0000})
Step:  263000, Reward:    85.430 [  45.060], Avg:    51.375 (1.000) <0-04:52:19> ({'r_t':   103.0935, 'eps':     1.0000, 'critic_loss':     4.2621, 'actor_loss':     0.2806, 'eps_e':     1.0000})
Step:  264000, Reward:    54.559 [  71.745], Avg:    51.387 (1.000) <0-04:53:27> ({'r_t':   146.6348, 'eps':     1.0000, 'critic_loss':     4.6786, 'actor_loss':    -0.0078, 'eps_e':     1.0000})
Step:  265000, Reward:    25.123 [ 188.869], Avg:    51.288 (1.000) <0-04:54:38> ({'r_t':   132.3799, 'eps':     1.0000, 'critic_loss':     3.8786, 'actor_loss':     0.0759, 'eps_e':     1.0000})
Step:  266000, Reward:    79.264 [  96.289], Avg:    51.393 (1.000) <0-04:55:48> ({'r_t':   133.4263, 'eps':     1.0000, 'critic_loss':     2.9046, 'actor_loss':    -0.0501, 'eps_e':     1.0000})
Step:  267000, Reward:   101.334 [  16.658], Avg:    51.579 (1.000) <0-04:56:58> ({'r_t':   160.5902, 'eps':     1.0000, 'critic_loss':     3.8880, 'actor_loss':     0.0534, 'eps_e':     1.0000})
Step:  268000, Reward:   102.713 [  12.833], Avg:    51.769 (1.000) <0-04:58:08> ({'r_t':   144.7060, 'eps':     1.0000, 'critic_loss':     2.0704, 'actor_loss':    -0.0460, 'eps_e':     1.0000})
Step:  269000, Reward:    95.740 [  40.782], Avg:    51.932 (1.000) <0-04:59:17> ({'r_t':   115.6022, 'eps':     1.0000, 'critic_loss':     4.4502, 'actor_loss':     0.2002, 'eps_e':     1.0000})
Step:  270000, Reward:    90.858 [  40.317], Avg:    52.076 (1.000) <0-05:00:26> ({'r_t':   141.5080, 'eps':     1.0000, 'critic_loss':     2.8782, 'actor_loss':     0.1829, 'eps_e':     1.0000})
Step:  271000, Reward:    81.817 [  41.164], Avg:    52.185 (1.000) <0-05:01:36> ({'r_t':   117.3890, 'eps':     1.0000, 'critic_loss':     2.9582, 'actor_loss':     0.2549, 'eps_e':     1.0000})
Step:  272000, Reward:    83.320 [  55.332], Avg:    52.299 (1.000) <0-05:02:46> ({'r_t':   143.6151, 'eps':     1.0000, 'critic_loss':     2.7110, 'actor_loss':     0.3069, 'eps_e':     1.0000})
Step:  273000, Reward:    92.968 [  27.761], Avg:    52.448 (1.000) <0-05:03:56> ({'r_t':   123.3691, 'eps':     1.0000, 'critic_loss':     3.2708, 'actor_loss':     0.3214, 'eps_e':     1.0000})
Step:  274000, Reward:    90.202 [  45.796], Avg:    52.585 (1.000) <0-05:05:06> ({'r_t':   163.7511, 'eps':     1.0000, 'critic_loss':     3.5338, 'actor_loss':     0.3506, 'eps_e':     1.0000})
Step:  275000, Reward:    89.563 [  44.060], Avg:    52.719 (1.000) <0-05:06:16> ({'r_t':   126.4005, 'eps':     1.0000, 'critic_loss':     3.2213, 'actor_loss':     0.0456, 'eps_e':     1.0000})
Step:  276000, Reward:    78.839 [  56.554], Avg:    52.813 (1.000) <0-05:07:26> ({'r_t':   137.0445, 'eps':     1.0000, 'critic_loss':     2.1039, 'actor_loss':    -0.1376, 'eps_e':     1.0000})
Step:  277000, Reward:    93.800 [  35.572], Avg:    52.961 (1.000) <0-05:08:35> ({'r_t':   133.8885, 'eps':     1.0000, 'critic_loss':     3.9677, 'actor_loss':     0.1986, 'eps_e':     1.0000})
Step:  278000, Reward:    78.244 [  44.970], Avg:    53.051 (1.000) <0-05:09:45> ({'r_t':   110.4449, 'eps':     1.0000, 'critic_loss':     4.3370, 'actor_loss':     0.2068, 'eps_e':     1.0000})
Step:  279000, Reward:    75.035 [  48.026], Avg:    53.130 (1.000) <0-05:10:55> ({'r_t':   110.5450, 'eps':     1.0000, 'critic_loss':     4.1179, 'actor_loss':     0.2483, 'eps_e':     1.0000})
Step:  280000, Reward:    94.925 [  30.400], Avg:    53.279 (1.000) <0-05:12:05> ({'r_t':    95.2376, 'eps':     1.0000, 'critic_loss':     4.8809, 'actor_loss':     0.4011, 'eps_e':     1.0000})
Step:  281000, Reward:    64.480 [ 137.471], Avg:    53.318 (1.000) <0-05:13:15> ({'r_t':   127.2026, 'eps':     1.0000, 'critic_loss':     3.5311, 'actor_loss':     0.3433, 'eps_e':     1.0000})
Step:  282000, Reward:    80.087 [ 100.362], Avg:    53.413 (1.000) <0-05:14:24> ({'r_t':   152.4809, 'eps':     1.0000, 'critic_loss':     1.5385, 'actor_loss':    -0.0777, 'eps_e':     1.0000})
Step:  283000, Reward:   100.300 [  35.325], Avg:    53.578 (1.000) <0-05:15:34> ({'r_t':   158.5230, 'eps':     1.0000, 'critic_loss':     3.0278, 'actor_loss':     0.1047, 'eps_e':     1.0000})
Step:  284000, Reward:   103.646 [  24.631], Avg:    53.754 (1.000) <0-05:16:43> ({'r_t':   141.2011, 'eps':     1.0000, 'critic_loss':     3.7149, 'actor_loss':     0.2536, 'eps_e':     1.0000})
Step:  285000, Reward:    37.363 [ 162.003], Avg:    53.696 (1.000) <0-05:17:53> ({'r_t':   111.3820, 'eps':     1.0000, 'critic_loss':     2.7489, 'actor_loss':     0.0436, 'eps_e':     1.0000})
Step:  286000, Reward:    26.601 [ 182.710], Avg:    53.602 (1.000) <0-05:19:03> ({'r_t':    98.5639, 'eps':     1.0000, 'critic_loss':     5.0249, 'actor_loss':     0.5455, 'eps_e':     1.0000})
Step:  287000, Reward:   100.075 [  23.414], Avg:    53.763 (1.000) <0-05:20:12> ({'r_t':   158.9686, 'eps':     1.0000, 'critic_loss':     5.9941, 'actor_loss':     0.1949, 'eps_e':     1.0000})
Step:  288000, Reward:   103.951 [  17.737], Avg:    53.937 (1.000) <0-05:21:22> ({'r_t':   116.6400, 'eps':     1.0000, 'critic_loss':     1.8388, 'actor_loss':    -0.1260, 'eps_e':     1.0000})
Step:  289000, Reward:   100.315 [  23.773], Avg:    54.097 (1.000) <0-05:22:33> ({'r_t':   128.5768, 'eps':     1.0000, 'critic_loss':     2.7599, 'actor_loss':     0.1542, 'eps_e':     1.0000})
Step:  290000, Reward:    88.350 [  43.592], Avg:    54.215 (1.000) <0-05:23:42> ({'r_t':   113.6844, 'eps':     1.0000, 'critic_loss':     1.4152, 'actor_loss':    -0.0268, 'eps_e':     1.0000})
Step:  291000, Reward:    62.088 [ 162.772], Avg:    54.242 (1.000) <0-05:24:52> ({'r_t':   164.3523, 'eps':     1.0000, 'critic_loss':     2.8270, 'actor_loss':     0.1089, 'eps_e':     1.0000})
Step:  292000, Reward:    54.959 [  73.657], Avg:    54.244 (1.000) <0-05:26:03> ({'r_t':   147.1771, 'eps':     1.0000, 'critic_loss':     1.9469, 'actor_loss':    -0.0373, 'eps_e':     1.0000})
Step:  293000, Reward:   109.001 [  15.824], Avg:    54.430 (1.000) <0-05:27:12> ({'r_t':    91.1265, 'eps':     1.0000, 'critic_loss':     4.3690, 'actor_loss':     0.6449, 'eps_e':     1.0000})
Step:  294000, Reward:   104.367 [  17.819], Avg:    54.600 (1.000) <0-05:28:22> ({'r_t':   121.6611, 'eps':     1.0000, 'critic_loss':     2.9104, 'actor_loss':     0.2466, 'eps_e':     1.0000})
Step:  295000, Reward:    59.975 [  83.422], Avg:    54.618 (1.000) <0-05:29:32> ({'r_t':    97.7077, 'eps':     1.0000, 'critic_loss':     5.9483, 'actor_loss':     0.2264, 'eps_e':     1.0000})
Step:  296000, Reward:    90.065 [  37.480], Avg:    54.737 (1.000) <0-05:30:41> ({'r_t':   102.5740, 'eps':     1.0000, 'critic_loss':     2.6726, 'actor_loss':     0.0041, 'eps_e':     1.0000})
Step:  297000, Reward:    92.899 [  23.649], Avg:    54.865 (1.000) <0-05:31:51> ({'r_t':   152.0741, 'eps':     1.0000, 'critic_loss':     4.4196, 'actor_loss':    -0.1332, 'eps_e':     1.0000})
Step:  298000, Reward:    65.767 [  71.841], Avg:    54.902 (1.000) <0-05:33:01> ({'r_t':   117.8192, 'eps':     1.0000, 'critic_loss':     1.7822, 'actor_loss':     0.0233, 'eps_e':     1.0000})
Step:  299000, Reward:    88.449 [  29.832], Avg:    55.013 (1.000) <0-05:34:11> ({'r_t':   128.8457, 'eps':     1.0000, 'critic_loss':     1.6413, 'actor_loss':     0.1247, 'eps_e':     1.0000})
Step:  300000, Reward:    99.424 [  23.423], Avg:    55.161 (1.000) <0-05:35:21> ({'r_t':   116.2810, 'eps':     1.0000, 'critic_loss':     0.7270, 'actor_loss':    -0.0609, 'eps_e':     1.0000})
Step:  301000, Reward:    96.784 [  21.932], Avg:    55.299 (1.000) <0-05:36:31> ({'r_t':   123.9488, 'eps':     1.0000, 'critic_loss':     1.9251, 'actor_loss':     0.1584, 'eps_e':     1.0000})
Step:  302000, Reward:   105.596 [  11.422], Avg:    55.465 (1.000) <0-05:37:39> ({'r_t':   135.6168, 'eps':     1.0000, 'critic_loss':     0.8111, 'actor_loss':    -0.0370, 'eps_e':     1.0000})
Step:  303000, Reward:    80.690 [  41.003], Avg:    55.548 (1.000) <0-05:38:49> ({'r_t':   107.6605, 'eps':     1.0000, 'critic_loss':     1.3190, 'actor_loss':     0.0346, 'eps_e':     1.0000})
Step:  304000, Reward:    93.888 [  25.854], Avg:    55.673 (1.000) <0-05:39:59> ({'r_t':    93.3958, 'eps':     1.0000, 'critic_loss':     2.0915, 'actor_loss':     0.3238, 'eps_e':     1.0000})
Step:  305000, Reward:    97.863 [  21.300], Avg:    55.811 (1.000) <0-05:41:08> ({'r_t':   124.9991, 'eps':     1.0000, 'critic_loss':     3.8198, 'actor_loss':     0.6210, 'eps_e':     1.0000})
Step:  306000, Reward:    99.207 [  21.762], Avg:    55.953 (1.000) <0-05:42:18> ({'r_t':   121.0864, 'eps':     1.0000, 'critic_loss':     1.3555, 'actor_loss':     0.0870, 'eps_e':     1.0000})
Step:  307000, Reward:    94.695 [  23.465], Avg:    56.078 (1.000) <0-05:43:29> ({'r_t':   126.4269, 'eps':     1.0000, 'critic_loss':     3.1571, 'actor_loss':     0.3534, 'eps_e':     1.0000})
Step:  308000, Reward:    85.487 [  61.503], Avg:    56.174 (1.000) <0-05:44:37> ({'r_t':    85.2513, 'eps':     1.0000, 'critic_loss':     3.6688, 'actor_loss':     0.4510, 'eps_e':     1.0000})
Step:  309000, Reward:    79.236 [  29.709], Avg:    56.248 (1.000) <0-05:45:47> ({'r_t':   113.2285, 'eps':     1.0000, 'critic_loss':     1.8822, 'actor_loss':     0.2069, 'eps_e':     1.0000})
Step:  310000, Reward:   107.434 [  14.448], Avg:    56.413 (1.000) <0-05:46:57> ({'r_t':   123.3771, 'eps':     1.0000, 'critic_loss':     3.4725, 'actor_loss':     0.2593, 'eps_e':     1.0000})
Step:  311000, Reward:    65.781 [ 100.504], Avg:    56.443 (1.000) <0-05:48:07> ({'r_t':   105.1051, 'eps':     1.0000, 'critic_loss':     2.7872, 'actor_loss':     0.3056, 'eps_e':     1.0000})
Step:  312000, Reward:    88.895 [  44.266], Avg:    56.546 (1.000) <0-05:49:16> ({'r_t':   123.4324, 'eps':     1.0000, 'critic_loss':     3.5611, 'actor_loss':     0.3558, 'eps_e':     1.0000})
Step:  313000, Reward:    69.363 [  56.078], Avg:    56.587 (1.000) <0-05:50:26> ({'r_t':    79.5179, 'eps':     1.0000, 'critic_loss':     6.5542, 'actor_loss':     0.9132, 'eps_e':     1.0000})
Step:  314000, Reward:     6.462 [ 194.072], Avg:    56.428 (1.000) <0-05:51:36> ({'r_t':    97.7755, 'eps':     1.0000, 'critic_loss':     7.6602, 'actor_loss':     0.6839, 'eps_e':     1.0000})
Step:  315000, Reward:   103.038 [  20.125], Avg:    56.576 (1.000) <0-05:52:46> ({'r_t':    85.0561, 'eps':     1.0000, 'critic_loss':     3.7062, 'actor_loss':    -0.0392, 'eps_e':     1.0000})
Step:  316000, Reward:   103.777 [  13.742], Avg:    56.724 (1.000) <0-05:53:55> ({'r_t':   174.4040, 'eps':     1.0000, 'critic_loss':     4.9113, 'actor_loss':     0.0649, 'eps_e':     1.0000})
Step:  317000, Reward:    94.684 [  31.149], Avg:    56.844 (1.000) <0-05:55:05> ({'r_t':   101.5695, 'eps':     1.0000, 'critic_loss':     3.1378, 'actor_loss':     0.1827, 'eps_e':     1.0000})
Step:  318000, Reward:    62.465 [ 116.830], Avg:    56.861 (1.000) <0-05:56:15> ({'r_t':    94.6700, 'eps':     1.0000, 'critic_loss':     4.6261, 'actor_loss':     0.0323, 'eps_e':     1.0000})
Step:  319000, Reward:   104.481 [  16.045], Avg:    57.010 (1.000) <0-05:57:25> ({'r_t':   153.8892, 'eps':     1.0000, 'critic_loss':     1.4388, 'actor_loss':     0.0075, 'eps_e':     1.0000})
Step:  320000, Reward:    90.716 [  36.452], Avg:    57.115 (1.000) <0-05:58:34> ({'r_t':    65.8287, 'eps':     1.0000, 'critic_loss':     2.0708, 'actor_loss':     0.2792, 'eps_e':     1.0000})
Step:  321000, Reward:    72.529 [  90.924], Avg:    57.163 (1.000) <0-05:59:44> ({'r_t':    83.9992, 'eps':     1.0000, 'critic_loss':     5.0709, 'actor_loss':     0.7130, 'eps_e':     1.0000})
Step:  322000, Reward:    91.354 [  53.274], Avg:    57.269 (1.000) <0-06:00:54> ({'r_t':   113.4625, 'eps':     1.0000, 'critic_loss':     3.9892, 'actor_loss':     0.0733, 'eps_e':     1.0000})
Step:  323000, Reward:    85.572 [  32.769], Avg:    57.356 (1.000) <0-06:02:04> ({'r_t':   125.7188, 'eps':     1.0000, 'critic_loss':     4.2490, 'actor_loss':     0.1659, 'eps_e':     1.0000})
Step:  324000, Reward:    98.484 [  22.658], Avg:    57.483 (1.000) <0-06:03:14> ({'r_t':   114.6098, 'eps':     1.0000, 'critic_loss':     3.0181, 'actor_loss':     0.0009, 'eps_e':     1.0000})
Step:  325000, Reward:    60.687 [ 118.736], Avg:    57.493 (1.000) <0-06:04:23> ({'r_t':   162.3381, 'eps':     1.0000, 'critic_loss':     3.3667, 'actor_loss':     0.2330, 'eps_e':     1.0000})
Step:  326000, Reward:    76.515 [  63.708], Avg:    57.551 (1.000) <0-06:05:33> ({'r_t':   137.5533, 'eps':     1.0000, 'critic_loss':     3.1693, 'actor_loss':     0.2916, 'eps_e':     1.0000})
Step:  327000, Reward:    59.007 [ 128.452], Avg:    57.555 (1.000) <0-06:06:43> ({'r_t':   113.1819, 'eps':     1.0000, 'critic_loss':     1.6305, 'actor_loss':    -0.0655, 'eps_e':     1.0000})
Step:  328000, Reward:    98.525 [  15.796], Avg:    57.680 (1.000) <0-06:07:52> ({'r_t':   146.2222, 'eps':     1.0000, 'critic_loss':     2.7032, 'actor_loss':     0.0639, 'eps_e':     1.0000})
Step:  329000, Reward:    83.902 [  41.386], Avg:    57.759 (1.000) <0-06:09:02> ({'r_t':   158.1578, 'eps':     1.0000, 'critic_loss':     4.3439, 'actor_loss':     0.2026, 'eps_e':     1.0000})
Step:  330000, Reward:   104.083 [  17.079], Avg:    57.899 (1.000) <0-06:10:11> ({'r_t':   107.6001, 'eps':     1.0000, 'critic_loss':     1.3263, 'actor_loss':    -0.0806, 'eps_e':     1.0000})
Step:  331000, Reward:    43.373 [ 111.114], Avg:    57.856 (1.000) <0-06:11:20> ({'r_t':   107.2294, 'eps':     1.0000, 'critic_loss':     2.9138, 'actor_loss':     0.2388, 'eps_e':     1.0000})
Step:  332000, Reward:    94.108 [  23.387], Avg:    57.964 (1.000) <0-06:12:30> ({'r_t':   106.0275, 'eps':     1.0000, 'critic_loss':     4.7599, 'actor_loss':     0.3110, 'eps_e':     1.0000})
Step:  333000, Reward:    77.167 [  72.167], Avg:    58.022 (1.000) <0-06:13:40> ({'r_t':   134.9402, 'eps':     1.0000, 'critic_loss':     2.5989, 'actor_loss':    -0.0506, 'eps_e':     1.0000})
Step:  334000, Reward:    70.732 [  94.989], Avg:    58.060 (1.000) <0-06:14:50> ({'r_t':   120.3632, 'eps':     1.0000, 'critic_loss':     4.6581, 'actor_loss':     0.3757, 'eps_e':     1.0000})
Step:  335000, Reward:    49.974 [ 155.173], Avg:    58.036 (1.000) <0-06:16:00> ({'r_t':   110.2539, 'eps':     1.0000, 'critic_loss':     2.0236, 'actor_loss':     0.1728, 'eps_e':     1.0000})
Step:  336000, Reward:   101.164 [  18.906], Avg:    58.164 (1.000) <0-06:17:10> ({'r_t':   112.4964, 'eps':     1.0000, 'critic_loss':     8.4639, 'actor_loss':     0.4391, 'eps_e':     1.0000})
Step:  337000, Reward:    65.320 [  76.395], Avg:    58.185 (1.000) <0-06:18:19> ({'r_t':   103.4298, 'eps':     1.0000, 'critic_loss':     2.3122, 'actor_loss':     0.0598, 'eps_e':     1.0000})
Step:  338000, Reward:    82.211 [  53.434], Avg:    58.256 (1.000) <0-06:19:29> ({'r_t':   105.6832, 'eps':     1.0000, 'critic_loss':     4.4161, 'actor_loss':     0.0751, 'eps_e':     1.0000})
Step:  339000, Reward:    89.540 [  64.575], Avg:    58.348 (1.000) <0-06:20:39> ({'r_t':   137.8330, 'eps':     1.0000, 'critic_loss':     2.8851, 'actor_loss':     0.1255, 'eps_e':     1.0000})
Step:  340000, Reward:    60.482 [ 116.028], Avg:    58.354 (1.000) <0-06:21:48> ({'r_t':   134.6377, 'eps':     1.0000, 'critic_loss':     1.1534, 'actor_loss':    -0.1597, 'eps_e':     1.0000})
Step:  341000, Reward:    89.993 [  42.556], Avg:    58.447 (1.000) <0-06:22:58> ({'r_t':   100.7751, 'eps':     1.0000, 'critic_loss':     6.8614, 'actor_loss':     0.5144, 'eps_e':     1.0000})
Step:  342000, Reward:    83.214 [  47.057], Avg:    58.519 (1.000) <0-06:24:08> ({'r_t':   122.2013, 'eps':     1.0000, 'critic_loss':     1.7211, 'actor_loss':     0.0988, 'eps_e':     1.0000})
Step:  343000, Reward:   101.745 [  35.625], Avg:    58.644 (1.000) <0-06:25:17> ({'r_t':    97.1747, 'eps':     1.0000, 'critic_loss':     2.7954, 'actor_loss':     0.2553, 'eps_e':     1.0000})
Step:  344000, Reward:   108.738 [  17.830], Avg:    58.790 (1.000) <0-06:26:27> ({'r_t':    98.1282, 'eps':     1.0000, 'critic_loss':     1.7014, 'actor_loss':     0.0100, 'eps_e':     1.0000})
Step:  345000, Reward:   108.505 [  22.553], Avg:    58.933 (1.000) <0-06:27:37> ({'r_t':    88.3358, 'eps':     1.0000, 'critic_loss':     4.7416, 'actor_loss':     0.3662, 'eps_e':     1.0000})
Step:  346000, Reward:    68.763 [ 113.444], Avg:    58.962 (1.000) <0-06:28:46> ({'r_t':   151.8508, 'eps':     1.0000, 'critic_loss':     2.9524, 'actor_loss':    -0.0947, 'eps_e':     1.0000})
Step:  347000, Reward:   113.883 [  17.721], Avg:    59.119 (1.000) <0-06:29:56> ({'r_t':   115.4193, 'eps':     1.0000, 'critic_loss':     3.2376, 'actor_loss':    -0.0628, 'eps_e':     1.0000})
Step:  348000, Reward:   105.170 [  40.537], Avg:    59.251 (1.000) <0-06:31:06> ({'r_t':    74.9426, 'eps':     1.0000, 'critic_loss':     6.3754, 'actor_loss':     0.5481, 'eps_e':     1.0000})
Step:  349000, Reward:   114.278 [  18.446], Avg:    59.409 (1.000) <0-06:32:16> ({'r_t':   115.0868, 'eps':     1.0000, 'critic_loss':     3.4517, 'actor_loss':     0.0615, 'eps_e':     1.0000})
Step:  350000, Reward:    77.858 [  56.668], Avg:    59.461 (1.000) <0-06:33:25> ({'r_t':   144.2030, 'eps':     1.0000, 'critic_loss':     3.6096, 'actor_loss':     0.2493, 'eps_e':     1.0000})
Step:  351000, Reward:    96.236 [  49.663], Avg:    59.566 (1.000) <0-06:34:35> ({'r_t':   120.7893, 'eps':     1.0000, 'critic_loss':     2.5429, 'actor_loss':    -0.0917, 'eps_e':     1.0000})
Step:  352000, Reward:    64.053 [  53.272], Avg:    59.578 (1.000) <0-06:35:45> ({'r_t':   134.3882, 'eps':     1.0000, 'critic_loss':     5.7115, 'actor_loss':     0.1847, 'eps_e':     1.0000})
Step:  353000, Reward:    83.783 [  57.980], Avg:    59.647 (1.000) <0-06:36:54> ({'r_t':   106.5841, 'eps':     1.0000, 'critic_loss':     7.2683, 'actor_loss':     0.4631, 'eps_e':     1.0000})
Step:  354000, Reward:    40.742 [ 124.643], Avg:    59.593 (1.000) <0-06:38:04> ({'r_t':   112.6980, 'eps':     1.0000, 'critic_loss':     4.1292, 'actor_loss':     0.2933, 'eps_e':     1.0000})
Step:  355000, Reward:    67.672 [  66.821], Avg:    59.616 (1.000) <0-06:39:12> ({'r_t':   120.2373, 'eps':     1.0000, 'critic_loss':     3.7914, 'actor_loss':     0.3028, 'eps_e':     1.0000})
Step:  356000, Reward:    98.409 [  23.307], Avg:    59.725 (1.000) <0-06:40:22> ({'r_t':   108.5095, 'eps':     1.0000, 'critic_loss':     2.4297, 'actor_loss':     0.2565, 'eps_e':     1.0000})
Step:  357000, Reward:    37.264 [ 177.196], Avg:    59.662 (1.000) <0-06:41:32> ({'r_t':   118.5484, 'eps':     1.0000, 'critic_loss':     5.6284, 'actor_loss':     0.3874, 'eps_e':     1.0000})
Step:  358000, Reward:   107.553 [  32.041], Avg:    59.795 (1.000) <0-06:42:41> ({'r_t':    97.9918, 'eps':     1.0000, 'critic_loss':     4.8353, 'actor_loss':     0.1717, 'eps_e':     1.0000})
Step:  359000, Reward:    89.264 [  61.011], Avg:    59.877 (1.000) <0-06:43:51> ({'r_t':    74.7441, 'eps':     1.0000, 'critic_loss':     8.7279, 'actor_loss':     0.3742, 'eps_e':     1.0000})
Step:  360000, Reward:    68.349 [ 114.962], Avg:    59.901 (1.000) <0-06:45:02> ({'r_t':   134.4852, 'eps':     1.0000, 'critic_loss':     4.7267, 'actor_loss':    -0.1009, 'eps_e':     1.0000})
Step:  361000, Reward:    86.593 [  78.306], Avg:    59.975 (1.000) <0-06:46:11> ({'r_t':    92.5111, 'eps':     1.0000, 'critic_loss':     3.0646, 'actor_loss':     0.1072, 'eps_e':     1.0000})
Step:  362000, Reward:   118.246 [  24.976], Avg:    60.135 (1.000) <0-06:47:20> ({'r_t':   125.2663, 'eps':     1.0000, 'critic_loss':     5.1267, 'actor_loss':     0.3598, 'eps_e':     1.0000})
Step:  363000, Reward:    53.274 [ 152.083], Avg:    60.116 (1.000) <0-06:48:29> ({'r_t':    10.7483, 'eps':     1.0000, 'critic_loss':     4.7738, 'actor_loss':     0.7398, 'eps_e':     1.0000})
Step:  364000, Reward:    99.300 [  57.752], Avg:    60.224 (1.000) <0-06:49:39> ({'r_t':    66.6295, 'eps':     1.0000, 'critic_loss':     5.5515, 'actor_loss':     0.7223, 'eps_e':     1.0000})
Step:  365000, Reward:    86.237 [  87.448], Avg:    60.295 (1.000) <0-06:50:49> ({'r_t':   145.0301, 'eps':     1.0000, 'critic_loss':     4.0377, 'actor_loss':     0.0299, 'eps_e':     1.0000})
Step:  366000, Reward:    48.648 [ 177.455], Avg:    60.263 (1.000) <0-06:51:59> ({'r_t':   132.8117, 'eps':     1.0000, 'critic_loss':     5.2819, 'actor_loss':    -0.1496, 'eps_e':     1.0000})
Step:  367000, Reward:   -15.659 [ 211.269], Avg:    60.057 (1.000) <0-06:53:08> ({'r_t':    61.2655, 'eps':     1.0000, 'critic_loss':     6.1946, 'actor_loss':     1.0058, 'eps_e':     1.0000})
Step:  368000, Reward:    99.034 [  45.947], Avg:    60.162 (1.000) <0-06:54:18> ({'r_t':    88.7986, 'eps':     1.0000, 'critic_loss':     6.3720, 'actor_loss':     0.2692, 'eps_e':     1.0000})
Step:  369000, Reward:   -29.543 [ 203.196], Avg:    59.920 (1.000) <0-06:55:28> ({'r_t':    30.8304, 'eps':     1.0000, 'critic_loss':     7.8479, 'actor_loss':     0.9533, 'eps_e':     1.0000})
Step:  370000, Reward:   -41.872 [ 210.491], Avg:    59.645 (1.000) <0-06:56:37> ({'r_t':    16.5108, 'eps':     1.0000, 'critic_loss':    13.7070, 'actor_loss':     0.8921, 'eps_e':     1.0000})
Step:  371000, Reward:    37.248 [ 174.856], Avg:    59.585 (1.000) <0-06:57:47> ({'r_t':    80.5729, 'eps':     1.0000, 'critic_loss':    12.6127, 'actor_loss':     0.3886, 'eps_e':     1.0000})
Step:  372000, Reward:   -51.598 [ 266.832], Avg:    59.287 (1.000) <0-06:58:57> ({'r_t':    37.1675, 'eps':     1.0000, 'critic_loss':    13.9049, 'actor_loss':     0.4888, 'eps_e':     1.0000})
Step:  373000, Reward:    54.179 [ 132.222], Avg:    59.273 (1.000) <0-07:00:06> ({'r_t':    92.7653, 'eps':     1.0000, 'critic_loss':     8.0629, 'actor_loss':    -0.0499, 'eps_e':     1.0000})
Step:  374000, Reward:    82.162 [  57.949], Avg:    59.335 (1.000) <0-07:01:16> ({'r_t':   106.2468, 'eps':     1.0000, 'critic_loss':     5.6930, 'actor_loss':    -0.0628, 'eps_e':     1.0000})
Step:  375000, Reward:    70.089 [  71.877], Avg:    59.363 (1.000) <0-07:02:26> ({'r_t':   102.4754, 'eps':     1.0000, 'critic_loss':     5.3816, 'actor_loss':     0.3407, 'eps_e':     1.0000})
Step:  376000, Reward:    34.557 [  69.926], Avg:    59.297 (1.000) <0-07:03:35> ({'r_t':    58.7193, 'eps':     1.0000, 'critic_loss':     5.8952, 'actor_loss':    -0.0899, 'eps_e':     1.0000})
Step:  377000, Reward:     7.041 [ 197.749], Avg:    59.159 (1.000) <0-07:04:45> ({'r_t':    51.7664, 'eps':     1.0000, 'critic_loss':    14.5142, 'actor_loss':     0.0715, 'eps_e':     1.0000})
Step:  378000, Reward:    80.163 [  61.046], Avg:    59.214 (1.000) <0-07:05:55> ({'r_t':    95.7046, 'eps':     1.0000, 'critic_loss':     8.2517, 'actor_loss':     0.2748, 'eps_e':     1.0000})
Step:  379000, Reward:    22.600 [ 210.273], Avg:    59.118 (1.000) <0-07:07:05> ({'r_t':    57.6687, 'eps':     1.0000, 'critic_loss':     4.6691, 'actor_loss':     0.1926, 'eps_e':     1.0000})
Step:  380000, Reward:    53.279 [ 124.617], Avg:    59.103 (1.000) <0-07:08:15> ({'r_t':    57.7729, 'eps':     1.0000, 'critic_loss':     7.1959, 'actor_loss':     0.0585, 'eps_e':     1.0000})
Step:  381000, Reward:    99.392 [  54.413], Avg:    59.208 (1.000) <0-07:09:24> ({'r_t':    70.7340, 'eps':     1.0000, 'critic_loss':    10.6904, 'actor_loss':     0.1603, 'eps_e':     1.0000})
Step:  382000, Reward:    62.032 [ 147.071], Avg:    59.216 (1.000) <0-07:10:33> ({'r_t':   140.1280, 'eps':     1.0000, 'critic_loss':     3.2436, 'actor_loss':    -0.4933, 'eps_e':     1.0000})
Step:  383000, Reward:    77.087 [  92.915], Avg:    59.262 (1.000) <0-07:11:43> ({'r_t':   134.1136, 'eps':     1.0000, 'critic_loss':     5.3194, 'actor_loss':    -0.1720, 'eps_e':     1.0000})
Step:  384000, Reward:    72.525 [  76.523], Avg:    59.297 (1.000) <0-07:12:53> ({'r_t':    82.6251, 'eps':     1.0000, 'critic_loss':     3.9220, 'actor_loss':     0.0452, 'eps_e':     1.0000})
Step:  385000, Reward:    36.771 [ 129.785], Avg:    59.238 (1.000) <0-07:14:03> ({'r_t':   109.9650, 'eps':     1.0000, 'critic_loss':     4.9180, 'actor_loss':     0.4471, 'eps_e':     1.0000})
Step:  386000, Reward:    27.426 [ 143.597], Avg:    59.156 (1.000) <0-07:15:11> ({'r_t':   111.5631, 'eps':     1.0000, 'critic_loss':     8.0646, 'actor_loss':     0.5669, 'eps_e':     1.0000})
Step:  387000, Reward:    71.919 [  40.782], Avg:    59.189 (1.000) <0-07:16:21> ({'r_t':    62.5266, 'eps':     1.0000, 'critic_loss':     7.9045, 'actor_loss':     0.2378, 'eps_e':     1.0000})
Step:  388000, Reward:    51.180 [  84.069], Avg:    59.168 (1.000) <0-07:17:30> ({'r_t':    57.9596, 'eps':     1.0000, 'critic_loss':     9.5019, 'actor_loss':     0.5399, 'eps_e':     1.0000})
Step:  389000, Reward:    -1.768 [ 210.697], Avg:    59.012 (1.000) <0-07:18:40> ({'r_t':    73.3686, 'eps':     1.0000, 'critic_loss':    11.4417, 'actor_loss':    -0.0292, 'eps_e':     1.0000})
Step:  390000, Reward:    30.296 [ 121.308], Avg:    58.939 (1.000) <0-07:19:50> ({'r_t':     1.6280, 'eps':     1.0000, 'critic_loss':    14.5562, 'actor_loss':     1.2407, 'eps_e':     1.0000})
Step:  391000, Reward:    63.590 [ 134.214], Avg:    58.951 (1.000) <0-07:20:59> ({'r_t':    43.2254, 'eps':     1.0000, 'critic_loss':     9.0623, 'actor_loss':     0.4932, 'eps_e':     1.0000})
Step:  392000, Reward:   -43.147 [ 233.723], Avg:    58.691 (1.000) <0-07:22:09> ({'r_t':    46.6898, 'eps':     1.0000, 'critic_loss':     8.5888, 'actor_loss':     0.1390, 'eps_e':     1.0000})
Step:  393000, Reward:    45.383 [ 134.494], Avg:    58.657 (1.000) <0-07:23:18> ({'r_t':    89.9028, 'eps':     1.0000, 'critic_loss':     9.5777, 'actor_loss':    -0.2536, 'eps_e':     1.0000})
Step:  394000, Reward:    80.714 [ 150.745], Avg:    58.713 (1.000) <0-07:24:28> ({'r_t':    76.4513, 'eps':     1.0000, 'critic_loss':     9.2907, 'actor_loss':     0.0626, 'eps_e':     1.0000})
Step:  395000, Reward:    72.235 [ 101.755], Avg:    58.747 (1.000) <0-07:25:38> ({'r_t':    60.5762, 'eps':     1.0000, 'critic_loss':     5.7547, 'actor_loss':     0.4211, 'eps_e':     1.0000})
Step:  396000, Reward:   110.319 [  57.488], Avg:    58.877 (1.000) <0-07:26:48> ({'r_t':    20.2801, 'eps':     1.0000, 'critic_loss':     8.2890, 'actor_loss':     1.0712, 'eps_e':     1.0000})
Step:  397000, Reward:    71.530 [ 119.888], Avg:    58.909 (1.000) <0-07:27:58> ({'r_t':    54.5576, 'eps':     1.0000, 'critic_loss':     6.4443, 'actor_loss':     0.5625, 'eps_e':     1.0000})
Step:  398000, Reward:    76.905 [  79.936], Avg:    58.954 (1.000) <0-07:29:07> ({'r_t':    83.3819, 'eps':     1.0000, 'critic_loss':     7.6140, 'actor_loss':     0.1189, 'eps_e':     1.0000})
Step:  399000, Reward:    97.600 [  47.897], Avg:    59.050 (1.000) <0-07:30:17> ({'r_t':   125.2210, 'eps':     1.0000, 'critic_loss':     4.8559, 'actor_loss':    -0.3943, 'eps_e':     1.0000})
Step:  400000, Reward:    95.368 [  92.329], Avg:    59.141 (1.000) <0-07:31:27> ({'r_t':   115.6098, 'eps':     1.0000, 'critic_loss':     5.4151, 'actor_loss':    -0.2341, 'eps_e':     1.0000})
Step:  401000, Reward:    -0.176 [ 230.801], Avg:    58.993 (1.000) <0-07:32:36> ({'r_t':    97.3043, 'eps':     1.0000, 'critic_loss':     6.7284, 'actor_loss':     0.1916, 'eps_e':     1.0000})
Step:  402000, Reward:    65.973 [ 119.105], Avg:    59.011 (1.000) <0-07:33:46> ({'r_t':    82.3333, 'eps':     1.0000, 'critic_loss':     7.3697, 'actor_loss':     0.3592, 'eps_e':     1.0000})
Step:  403000, Reward:    95.127 [  60.932], Avg:    59.100 (1.000) <0-07:34:56> ({'r_t':   -19.2206, 'eps':     1.0000, 'critic_loss':    10.9939, 'actor_loss':     1.3588, 'eps_e':     1.0000})
Step:  404000, Reward:    83.035 [  84.797], Avg:    59.159 (1.000) <0-07:36:04> ({'r_t':    60.8073, 'eps':     1.0000, 'critic_loss':     8.9708, 'actor_loss':     0.6604, 'eps_e':     1.0000})
Step:  405000, Reward:    72.638 [ 172.513], Avg:    59.192 (1.000) <0-07:37:14> ({'r_t':   115.9392, 'eps':     1.0000, 'critic_loss':     4.2906, 'actor_loss':     0.0578, 'eps_e':     1.0000})
Step:  406000, Reward:    56.465 [ 131.823], Avg:    59.186 (1.000) <0-07:38:24> ({'r_t':   102.0535, 'eps':     1.0000, 'critic_loss':     5.9012, 'actor_loss':     0.0977, 'eps_e':     1.0000})
Step:  407000, Reward:   101.058 [  61.936], Avg:    59.288 (1.000) <0-07:39:33> ({'r_t':   109.4820, 'eps':     1.0000, 'critic_loss':     3.9367, 'actor_loss':     0.0761, 'eps_e':     1.0000})
Step:  408000, Reward:     8.714 [ 240.502], Avg:    59.165 (1.000) <0-07:40:43> ({'r_t':   129.7724, 'eps':     1.0000, 'critic_loss':     3.1616, 'actor_loss':     0.0007, 'eps_e':     1.0000})
Step:  409000, Reward:    91.923 [  81.381], Avg:    59.245 (1.000) <0-07:41:53> ({'r_t':    64.9570, 'eps':     1.0000, 'critic_loss':     4.7110, 'actor_loss':     0.4038, 'eps_e':     1.0000})
Step:  410000, Reward:   108.677 [  45.201], Avg:    59.365 (1.000) <0-07:43:02> ({'r_t':    66.2327, 'eps':     1.0000, 'critic_loss':     6.2817, 'actor_loss':     0.0730, 'eps_e':     1.0000})
Step:  411000, Reward:    86.978 [  96.573], Avg:    59.432 (1.000) <0-07:44:11> ({'r_t':   118.1464, 'eps':     1.0000, 'critic_loss':     5.7828, 'actor_loss':     0.0960, 'eps_e':     1.0000})
Step:  412000, Reward:    66.093 [ 193.562], Avg:    59.448 (1.000) <0-07:45:21> ({'r_t':   118.4205, 'eps':     1.0000, 'critic_loss':     4.1463, 'actor_loss':     0.7017, 'eps_e':     1.0000})
Step:  413000, Reward:    11.159 [ 212.608], Avg:    59.331 (1.000) <0-07:46:31> ({'r_t':    58.1946, 'eps':     1.0000, 'critic_loss':     5.1086, 'actor_loss':     0.8473, 'eps_e':     1.0000})
Step:  414000, Reward:    81.775 [ 100.604], Avg:    59.385 (1.000) <0-07:47:41> ({'r_t':    68.9045, 'eps':     1.0000, 'critic_loss':     6.7235, 'actor_loss':     0.6256, 'eps_e':     1.0000})
Step:  415000, Reward:   135.579 [  16.686], Avg:    59.569 (1.000) <0-07:48:51> ({'r_t':    83.7672, 'eps':     1.0000, 'critic_loss':     5.8506, 'actor_loss':     0.2430, 'eps_e':     1.0000})
Step:  416000, Reward:   116.315 [  42.779], Avg:    59.705 (1.000) <0-07:50:00> ({'r_t':   115.5823, 'eps':     1.0000, 'critic_loss':     5.1577, 'actor_loss':    -0.1511, 'eps_e':     1.0000})
Step:  417000, Reward:    10.904 [ 149.563], Avg:    59.588 (1.000) <0-07:51:10> ({'r_t':    66.8553, 'eps':     1.0000, 'critic_loss':     4.4109, 'actor_loss':     0.3048, 'eps_e':     1.0000})
Step:  418000, Reward:    79.563 [ 107.124], Avg:    59.636 (1.000) <0-07:52:20> ({'r_t':    43.9038, 'eps':     1.0000, 'critic_loss':     7.5273, 'actor_loss':     0.4269, 'eps_e':     1.0000})
Step:  419000, Reward:    49.253 [ 180.885], Avg:    59.611 (1.000) <0-07:53:30> ({'r_t':    78.1289, 'eps':     1.0000, 'critic_loss':     5.0612, 'actor_loss':     0.3209, 'eps_e':     1.0000})
Step:  420000, Reward:   125.517 [  26.917], Avg:    59.767 (1.000) <0-07:54:38> ({'r_t':    97.9898, 'eps':     1.0000, 'critic_loss':     7.4938, 'actor_loss':     0.4959, 'eps_e':     1.0000})
Step:  421000, Reward:   114.932 [  40.873], Avg:    59.898 (1.000) <0-07:55:48> ({'r_t':    79.2523, 'eps':     1.0000, 'critic_loss':     6.2128, 'actor_loss':     0.2130, 'eps_e':     1.0000})
Step:  422000, Reward:   100.128 [  96.360], Avg:    59.993 (1.000) <0-07:56:58> ({'r_t':   117.0447, 'eps':     1.0000, 'critic_loss':     3.8610, 'actor_loss':     0.1580, 'eps_e':     1.0000})
Step:  423000, Reward:   101.181 [  72.333], Avg:    60.090 (1.000) <0-07:58:07> ({'r_t':    80.2668, 'eps':     1.0000, 'critic_loss':     4.5297, 'actor_loss':     0.2323, 'eps_e':     1.0000})
Step:  424000, Reward:   104.303 [  57.663], Avg:    60.194 (1.000) <0-07:59:17> ({'r_t':   107.7704, 'eps':     1.0000, 'critic_loss':     5.9275, 'actor_loss':    -0.0575, 'eps_e':     1.0000})
Step:  425000, Reward:    13.705 [ 218.643], Avg:    60.085 (1.000) <0-08:00:27> ({'r_t':    81.9017, 'eps':     1.0000, 'critic_loss':     4.1694, 'actor_loss':     0.1423, 'eps_e':     1.0000})
Step:  426000, Reward:    58.722 [ 146.241], Avg:    60.082 (1.000) <0-08:01:37> ({'r_t':   109.2328, 'eps':     1.0000, 'critic_loss':     8.0073, 'actor_loss':     0.3815, 'eps_e':     1.0000})
Step:  427000, Reward:    95.517 [  81.122], Avg:    60.165 (1.000) <0-08:02:47> ({'r_t':    97.2447, 'eps':     1.0000, 'critic_loss':     4.6715, 'actor_loss':    -0.1646, 'eps_e':     1.0000})
Step:  428000, Reward:    44.110 [ 127.060], Avg:    60.128 (1.000) <0-08:03:56> ({'r_t':   104.6945, 'eps':     1.0000, 'critic_loss':     6.7787, 'actor_loss':    -0.3370, 'eps_e':     1.0000})
Step:  429000, Reward:    55.915 [ 157.787], Avg:    60.118 (1.000) <0-08:05:06> ({'r_t':    99.7826, 'eps':     1.0000, 'critic_loss':     5.4541, 'actor_loss':    -0.1409, 'eps_e':     1.0000})
Step:  430000, Reward:   127.925 [  25.959], Avg:    60.275 (1.000) <0-08:06:15> ({'r_t':   -24.5761, 'eps':     1.0000, 'critic_loss':     9.7930, 'actor_loss':     1.2195, 'eps_e':     1.0000})
Step:  431000, Reward:    56.936 [ 186.267], Avg:    60.267 (1.000) <0-08:07:25> ({'r_t':    74.9359, 'eps':     1.0000, 'critic_loss':     5.2458, 'actor_loss':     0.0790, 'eps_e':     1.0000})
Step:  432000, Reward:    90.046 [  92.889], Avg:    60.336 (1.000) <0-08:08:35> ({'r_t':    23.0228, 'eps':     1.0000, 'critic_loss':    13.0636, 'actor_loss':     0.6332, 'eps_e':     1.0000})
Step:  433000, Reward:   115.386 [  93.431], Avg:    60.463 (1.000) <0-08:09:44> ({'r_t':    94.8486, 'eps':     1.0000, 'critic_loss':     7.5567, 'actor_loss':     0.0800, 'eps_e':     1.0000})
Step:  434000, Reward:    35.094 [ 244.715], Avg:    60.405 (1.000) <0-08:10:54> ({'r_t':    57.9125, 'eps':     1.0000, 'critic_loss':     7.9678, 'actor_loss':     0.4959, 'eps_e':     1.0000})
Step:  435000, Reward:    49.377 [ 152.134], Avg:    60.379 (1.000) <0-08:12:04> ({'r_t':   146.6272, 'eps':     1.0000, 'critic_loss':     5.3945, 'actor_loss':    -0.0164, 'eps_e':     1.0000})
Step:  436000, Reward:    80.465 [ 105.130], Avg:    60.425 (1.000) <0-08:13:14> ({'r_t':    72.9303, 'eps':     1.0000, 'critic_loss':     6.1452, 'actor_loss':     0.5118, 'eps_e':     1.0000})
Step:  437000, Reward:    97.826 [  80.101], Avg:    60.511 (1.000) <0-08:14:23> ({'r_t':    81.9457, 'eps':     1.0000, 'critic_loss':     4.3378, 'actor_loss':     0.1751, 'eps_e':     1.0000})
Step:  438000, Reward:   117.574 [  43.083], Avg:    60.641 (1.000) <0-08:15:33> ({'r_t':    63.8789, 'eps':     1.0000, 'critic_loss':     6.7103, 'actor_loss':     0.5174, 'eps_e':     1.0000})
Step:  439000, Reward:   100.933 [ 116.116], Avg:    60.732 (1.000) <0-08:16:42> ({'r_t':    44.9136, 'eps':     1.0000, 'critic_loss':     8.0056, 'actor_loss':     0.5934, 'eps_e':     1.0000})
Step:  440000, Reward:   106.992 [  49.371], Avg:    60.837 (1.000) <0-08:17:52> ({'r_t':   107.4133, 'eps':     1.0000, 'critic_loss':     5.3125, 'actor_loss':     0.2477, 'eps_e':     1.0000})
Step:  441000, Reward:    41.419 [ 168.836], Avg:    60.793 (1.000) <0-08:19:02> ({'r_t':    82.0732, 'eps':     1.0000, 'critic_loss':     7.5320, 'actor_loss':     0.3963, 'eps_e':     1.0000})
Step:  442000, Reward:    86.371 [  73.404], Avg:    60.851 (1.000) <0-08:20:11> ({'r_t':    63.2777, 'eps':     1.0000, 'critic_loss':     5.8336, 'actor_loss':     0.1161, 'eps_e':     1.0000})
Step:  443000, Reward:   112.591 [  53.504], Avg:    60.967 (1.000) <0-08:21:21> ({'r_t':    37.3219, 'eps':     1.0000, 'critic_loss':    14.2630, 'actor_loss':     1.5807, 'eps_e':     1.0000})
Step:  444000, Reward:   103.310 [  59.768], Avg:    61.063 (1.000) <0-08:22:30> ({'r_t':   118.9169, 'eps':     1.0000, 'critic_loss':     7.6750, 'actor_loss':     0.5040, 'eps_e':     1.0000})
Step:  445000, Reward:    53.866 [ 129.999], Avg:    61.046 (1.000) <0-08:23:40> ({'r_t':   -55.2087, 'eps':     1.0000, 'critic_loss':    12.7531, 'actor_loss':     1.2692, 'eps_e':     1.0000})
Step:  446000, Reward:   103.155 [  55.737], Avg:    61.141 (1.000) <0-08:24:50> ({'r_t':    94.6020, 'eps':     1.0000, 'critic_loss':     6.9010, 'actor_loss':     0.4371, 'eps_e':     1.0000})
Step:  447000, Reward:    75.545 [ 165.187], Avg:    61.173 (1.000) <0-08:25:59> ({'r_t':    60.6090, 'eps':     1.0000, 'critic_loss':    10.6937, 'actor_loss':     0.4004, 'eps_e':     1.0000})
Step:  448000, Reward:   101.196 [  48.467], Avg:    61.262 (1.000) <0-08:27:09> ({'r_t':   107.1608, 'eps':     1.0000, 'critic_loss':     7.2745, 'actor_loss':     0.1814, 'eps_e':     1.0000})
Step:  449000, Reward:    80.792 [  62.210], Avg:    61.305 (1.000) <0-08:28:19> ({'r_t':    95.2775, 'eps':     1.0000, 'critic_loss':     5.4799, 'actor_loss':     0.1784, 'eps_e':     1.0000})
Step:  450000, Reward:    43.243 [ 121.679], Avg:    61.265 (1.000) <0-08:29:29> ({'r_t':   127.6472, 'eps':     1.0000, 'critic_loss':     6.5551, 'actor_loss':     0.4173, 'eps_e':     1.0000})
Step:  451000, Reward:    75.658 [  97.507], Avg:    61.297 (1.000) <0-08:30:38> ({'r_t':   105.0617, 'eps':     1.0000, 'critic_loss':     5.0955, 'actor_loss':     0.0705, 'eps_e':     1.0000})
Step:  452000, Reward:   104.721 [  46.241], Avg:    61.393 (1.000) <0-08:31:48> ({'r_t':   117.0326, 'eps':     1.0000, 'critic_loss':     6.5020, 'actor_loss':     0.1614, 'eps_e':     1.0000})
Step:  453000, Reward:    -2.240 [ 237.420], Avg:    61.253 (1.000) <0-08:32:56> ({'r_t':    75.4243, 'eps':     1.0000, 'critic_loss':     7.6425, 'actor_loss':     0.7154, 'eps_e':     1.0000})
Step:  454000, Reward:    68.548 [ 158.004], Avg:    61.269 (1.000) <0-08:34:06> ({'r_t':   132.8154, 'eps':     1.0000, 'critic_loss':     3.9522, 'actor_loss':     0.1742, 'eps_e':     1.0000})
Step:  455000, Reward:    89.110 [  89.722], Avg:    61.330 (1.000) <0-08:35:16> ({'r_t':    32.3903, 'eps':     1.0000, 'critic_loss':     6.7689, 'actor_loss':     0.5450, 'eps_e':     1.0000})
Step:  456000, Reward:   113.628 [  40.863], Avg:    61.444 (1.000) <0-08:36:26> ({'r_t':   100.2035, 'eps':     1.0000, 'critic_loss':     7.8596, 'actor_loss':     0.1515, 'eps_e':     1.0000})
Step:  457000, Reward:    40.995 [ 169.339], Avg:    61.400 (1.000) <0-08:37:36> ({'r_t':   123.9257, 'eps':     1.0000, 'critic_loss':     6.0230, 'actor_loss':     0.3690, 'eps_e':     1.0000})
Step:  458000, Reward:    16.388 [ 145.582], Avg:    61.302 (1.000) <0-08:38:45> ({'r_t':    99.8193, 'eps':     1.0000, 'critic_loss':     7.5485, 'actor_loss':     0.3922, 'eps_e':     1.0000})
Step:  459000, Reward:    58.718 [ 132.517], Avg:    61.296 (1.000) <0-08:39:54> ({'r_t':    48.2081, 'eps':     1.0000, 'critic_loss':     9.2198, 'actor_loss':     0.8312, 'eps_e':     1.0000})
Step:  460000, Reward:    45.956 [ 183.708], Avg:    61.263 (1.000) <0-08:41:04> ({'r_t':    86.6876, 'eps':     1.0000, 'critic_loss':    10.0414, 'actor_loss':     0.6223, 'eps_e':     1.0000})
Step:  461000, Reward:    85.599 [  75.742], Avg:    61.315 (1.000) <0-08:42:13> ({'r_t':     4.0956, 'eps':     1.0000, 'critic_loss':     8.8453, 'actor_loss':     0.6591, 'eps_e':     1.0000})
Step:  462000, Reward:     5.352 [ 209.778], Avg:    61.195 (1.000) <0-08:43:23> ({'r_t':    84.3089, 'eps':     1.0000, 'critic_loss':     9.5744, 'actor_loss':     0.5909, 'eps_e':     1.0000})
Step:  463000, Reward:    58.960 [ 158.131], Avg:    61.190 (1.000) <0-08:44:33> ({'r_t':    91.4244, 'eps':     1.0000, 'critic_loss':     8.3329, 'actor_loss':     0.2286, 'eps_e':     1.0000})
Step:  464000, Reward:    93.547 [ 110.333], Avg:    61.259 (1.000) <0-08:45:43> ({'r_t':    75.3522, 'eps':     1.0000, 'critic_loss':    12.0690, 'actor_loss':     0.4915, 'eps_e':     1.0000})
Step:  465000, Reward:    71.516 [ 156.297], Avg:    61.281 (1.000) <0-08:46:53> ({'r_t':   119.1113, 'eps':     1.0000, 'critic_loss':     4.9210, 'actor_loss':     0.1191, 'eps_e':     1.0000})
Step:  466000, Reward:    95.498 [  85.060], Avg:    61.355 (1.000) <0-08:48:03> ({'r_t':   145.1786, 'eps':     1.0000, 'critic_loss':     2.7856, 'actor_loss':    -0.3958, 'eps_e':     1.0000})
Step:  467000, Reward:    27.330 [ 152.824], Avg:    61.282 (1.000) <0-08:49:12> ({'r_t':    98.8710, 'eps':     1.0000, 'critic_loss':     6.7891, 'actor_loss':     0.1595, 'eps_e':     1.0000})
Step:  468000, Reward:    43.222 [ 139.211], Avg:    61.243 (1.000) <0-08:50:22> ({'r_t':    98.3925, 'eps':     1.0000, 'critic_loss':     6.9166, 'actor_loss':     0.0973, 'eps_e':     1.0000})
Step:  469000, Reward:    69.718 [ 166.335], Avg:    61.261 (1.000) <0-08:51:30> ({'r_t':    98.0119, 'eps':     1.0000, 'critic_loss':     7.6748, 'actor_loss':     0.5304, 'eps_e':     1.0000})
Step:  470000, Reward:   104.435 [  38.874], Avg:    61.353 (1.000) <0-08:52:40> ({'r_t':     6.3862, 'eps':     1.0000, 'critic_loss':    16.4370, 'actor_loss':     1.4368, 'eps_e':     1.0000})
Step:  471000, Reward:    43.389 [  96.592], Avg:    61.315 (1.000) <0-08:53:49> ({'r_t':    68.0121, 'eps':     1.0000, 'critic_loss':     9.8254, 'actor_loss':     0.4860, 'eps_e':     1.0000})
Step:  472000, Reward:    74.529 [  53.638], Avg:    61.343 (1.000) <0-08:55:00> ({'r_t':    99.5370, 'eps':     1.0000, 'critic_loss':     8.9629, 'actor_loss':     0.5511, 'eps_e':     1.0000})
Step:  473000, Reward:     4.094 [ 196.918], Avg:    61.222 (1.000) <0-08:56:10> ({'r_t':    93.2140, 'eps':     1.0000, 'critic_loss':     9.9523, 'actor_loss':     0.2835, 'eps_e':     1.0000})
Step:  474000, Reward:    38.775 [ 189.537], Avg:    61.175 (1.000) <0-08:57:18> ({'r_t':    93.8753, 'eps':     1.0000, 'critic_loss':    13.8762, 'actor_loss':     0.6182, 'eps_e':     1.0000})
Step:  475000, Reward:    85.846 [  66.960], Avg:    61.227 (1.000) <0-08:58:28> ({'r_t':    92.0207, 'eps':     1.0000, 'critic_loss':     8.1833, 'actor_loss':     0.0930, 'eps_e':     1.0000})
Step:  476000, Reward:    84.229 [ 112.274], Avg:    61.275 (1.000) <0-08:59:37> ({'r_t':    97.1838, 'eps':     1.0000, 'critic_loss':     6.3987, 'actor_loss':     0.2647, 'eps_e':     1.0000})
Step:  477000, Reward:    74.752 [ 103.214], Avg:    61.303 (1.000) <0-09:00:48> ({'r_t':   126.1918, 'eps':     1.0000, 'critic_loss':     5.8481, 'actor_loss':     0.3694, 'eps_e':     1.0000})
Step:  478000, Reward:   108.390 [  52.983], Avg:    61.401 (1.000) <0-09:01:57> ({'r_t':   123.3022, 'eps':     1.0000, 'critic_loss':     8.9115, 'actor_loss':     0.1164, 'eps_e':     1.0000})
Step:  479000, Reward:   105.642 [  49.191], Avg:    61.494 (1.000) <0-09:03:07> ({'r_t':   103.7052, 'eps':     1.0000, 'critic_loss':    10.8014, 'actor_loss':     0.2130, 'eps_e':     1.0000})
Step:  480000, Reward:    35.328 [ 233.810], Avg:    61.439 (1.000) <0-09:04:17> ({'r_t':    89.5851, 'eps':     1.0000, 'critic_loss':    11.3360, 'actor_loss':     0.7710, 'eps_e':     1.0000})
Step:  481000, Reward:    72.228 [ 121.305], Avg:    61.462 (1.000) <0-09:05:26> ({'r_t':   116.2944, 'eps':     1.0000, 'critic_loss':     5.1223, 'actor_loss':    -0.0603, 'eps_e':     1.0000})
Step:  482000, Reward:    75.497 [ 143.318], Avg:    61.491 (1.000) <0-09:06:36> ({'r_t':    59.4431, 'eps':     1.0000, 'critic_loss':     8.6480, 'actor_loss':     0.9276, 'eps_e':     1.0000})
Step:  483000, Reward:   -20.466 [ 246.050], Avg:    61.321 (1.000) <0-09:07:46> ({'r_t':   -33.5124, 'eps':     1.0000, 'critic_loss':    15.3836, 'actor_loss':     1.2969, 'eps_e':     1.0000})
Step:  484000, Reward:    76.603 [ 137.251], Avg:    61.353 (1.000) <0-09:08:55> ({'r_t':    65.0973, 'eps':     1.0000, 'critic_loss':     7.1640, 'actor_loss':    -0.1592, 'eps_e':     1.0000})
Step:  485000, Reward:    69.663 [ 158.698], Avg:    61.370 (1.000) <0-09:10:05> ({'r_t':   146.7778, 'eps':     1.0000, 'critic_loss':     4.2590, 'actor_loss':    -0.4362, 'eps_e':     1.0000})
Step:  486000, Reward:    30.575 [ 155.878], Avg:    61.307 (1.000) <0-09:11:14> ({'r_t':   115.7319, 'eps':     1.0000, 'critic_loss':     4.8938, 'actor_loss':     0.2232, 'eps_e':     1.0000})
Step:  487000, Reward:    93.531 [  75.681], Avg:    61.373 (1.000) <0-09:12:24> ({'r_t':    20.7585, 'eps':     1.0000, 'critic_loss':     8.0270, 'actor_loss':     1.0052, 'eps_e':     1.0000})
Step:  488000, Reward:    64.165 [ 151.257], Avg:    61.378 (1.000) <0-09:13:33> ({'r_t':    29.8376, 'eps':     1.0000, 'critic_loss':     7.2895, 'actor_loss':     1.2928, 'eps_e':     1.0000})
Step:  489000, Reward:    10.591 [ 191.627], Avg:    61.275 (1.000) <0-09:14:43> ({'r_t':    99.8446, 'eps':     1.0000, 'critic_loss':     5.1606, 'actor_loss':     0.3093, 'eps_e':     1.0000})
Step:  490000, Reward:    80.209 [  50.814], Avg:    61.313 (1.000) <0-09:15:53> ({'r_t':    83.5606, 'eps':     1.0000, 'critic_loss':     8.1244, 'actor_loss':     0.7675, 'eps_e':     1.0000})
Step:  491000, Reward:   100.606 [  62.106], Avg:    61.393 (1.000) <0-09:17:03> ({'r_t':   109.4406, 'eps':     1.0000, 'critic_loss':     7.3176, 'actor_loss':     0.7449, 'eps_e':     1.0000})
Step:  492000, Reward:    86.554 [  46.457], Avg:    61.444 (1.000) <0-09:18:13> ({'r_t':   105.7945, 'eps':     1.0000, 'critic_loss':     5.1224, 'actor_loss':     0.2505, 'eps_e':     1.0000})
Step:  493000, Reward:   110.340 [  60.175], Avg:    61.543 (1.000) <0-09:19:22> ({'r_t':     9.2410, 'eps':     1.0000, 'critic_loss':     8.5853, 'actor_loss':     0.8223, 'eps_e':     1.0000})
Step:  494000, Reward:    62.917 [ 173.135], Avg:    61.546 (1.000) <0-09:20:32> ({'r_t':    63.9199, 'eps':     1.0000, 'critic_loss':    10.7892, 'actor_loss':     0.5723, 'eps_e':     1.0000})
Step:  495000, Reward:   126.182 [  43.995], Avg:    61.676 (1.000) <0-09:21:41> ({'r_t':   153.6556, 'eps':     1.0000, 'critic_loss':     3.6820, 'actor_loss':    -0.4574, 'eps_e':     1.0000})
Step:  496000, Reward:    47.881 [ 164.069], Avg:    61.649 (1.000) <0-09:22:52> ({'r_t':   102.5750, 'eps':     1.0000, 'critic_loss':     6.0678, 'actor_loss':     0.0737, 'eps_e':     1.0000})
Step:  497000, Reward:    96.325 [  71.311], Avg:    61.718 (1.000) <0-09:24:01> ({'r_t':    92.7743, 'eps':     1.0000, 'critic_loss':     3.4192, 'actor_loss':     0.1755, 'eps_e':     1.0000})
Step:  498000, Reward:   115.849 [  53.273], Avg:    61.827 (1.000) <0-09:25:11> ({'r_t':    82.2157, 'eps':     1.0000, 'critic_loss':     4.7453, 'actor_loss':     0.7805, 'eps_e':     1.0000})
Step:  499000, Reward:   131.256 [  36.277], Avg:    61.966 (1.000) <0-09:26:21> ({'r_t':    93.7688, 'eps':     1.0000, 'critic_loss':     4.8112, 'actor_loss':     0.3765, 'eps_e':     1.0000})
Step:  500000, Reward:    59.305 [ 161.528], Avg:    61.960 (1.000) <0-09:27:31> ({'r_t':   138.2549, 'eps':     1.0000, 'critic_loss':     3.0931, 'actor_loss':    -0.3954, 'eps_e':     1.0000})
