Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CarRacing-v1, Date: 11/06/2020 11:13:40
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-59-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: cafa9d7f44947d13519bfd96a26c51f367d422cb
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 10
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   TRAIN_EVERY = 10000
   BATCH_SIZE = 500
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 10
      LAMBDA = 0.1
      COV = 1
   dynamics_size = 13
   state_size = (80,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [10000, 10001, 10002, 10003, 10004, 10005, 10006, 10007, 10008, 10009, 10010, 10011, 10012, 10013, 10014, 10015, 10016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 1000000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.97
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f67b011a710> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f67b81ac350>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f67b0074e60>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
				info = <mlagents_envs.base_env.DecisionSteps object at 0x7f67b0086190>
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f67b80a0150> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f67b0086410> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost
							# reward = progress + np.tanh(vy/self.vtarget) - cost
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_size = 13
			obs = [ 2.072e-09 -3.908e-03 -2.341e-08  1.422e-12 -1.954e-01  1.333e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  3.411e-13 -5.821e-11 -3.638e-12  0.000e+00  2.000e-02  3.657e-01  4.017e-01  4.572e-01  5.260e-01  6.036e-01  2.700e-01  3.171e-01  3.850e-01  4.646e-01  5.509e-01  1.792e-01  2.444e-01  3.277e-01  4.184e-01  5.125e-01  1.063e-01  1.973e-01  2.942e-01  3.927e-01  4.918e-01  1.024e-01  1.953e-01  2.929e-01  3.917e-01  4.910e-01]
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 		return state
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.spec = next_spec
			
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f682efc9710>
					step = <function CarRacing.step at 0x7f682efc9680>
					render = <function CarRacing.render at 0x7f6858478c20>
					dynamics_spec = <staticmethod object at 0x7f682efc8e90>
					track_spec = <function CarRacing.track_spec at 0x7f6858478d40>
					observation = <function CarRacing.observation at 0x7f6858478dd0>
					dynamics_keys = <staticmethod object at 0x7f682efc8d90>
					observation_spec = <staticmethod object at 0x7f682efc8dd0>
					close = <function CarRacing.close at 0x7f6858478f80>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(80,) 
			dtype = float32
			shape = (80,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f67b006c610> 
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (80,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f67b006cad0> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {10001: <socket.socket fd=114, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36688), raddr=('127.0.0.1', 10001)>, 10002: <socket.socket fd=115, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57422), raddr=('127.0.0.1', 10002)>, 10003: <socket.socket fd=116, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38014), raddr=('127.0.0.1', 10003)>, 10004: <socket.socket fd=117, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58076), raddr=('127.0.0.1', 10004)>, 10005: <socket.socket fd=118, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48582), raddr=('127.0.0.1', 10005)>, 10006: <socket.socket fd=119, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41910), raddr=('127.0.0.1', 10006)>, 10007: <socket.socket fd=120, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 35394), raddr=('127.0.0.1', 10007)>, 10008: <socket.socket fd=121, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 37988), raddr=('127.0.0.1', 10008)>, 10009: <socket.socket fd=122, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 60240), raddr=('127.0.0.1', 10009)>, 10010: <socket.socket fd=123, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51592), raddr=('127.0.0.1', 10010)>, 10011: <socket.socket fd=124, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50742), raddr=('127.0.0.1', 10011)>, 10012: <socket.socket fd=125, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 37130), raddr=('127.0.0.1', 10012)>, 10013: <socket.socket fd=126, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 37930), raddr=('127.0.0.1', 10013)>, 10014: <socket.socket fd=127, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41822), raddr=('127.0.0.1', 10014)>, 10015: <socket.socket fd=128, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48362), raddr=('127.0.0.1', 10015)>, 10016: <socket.socket fd=130, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53316), raddr=('127.0.0.1', 10016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f67b006c310> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f67b0086810> 
		state_size = (80,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7f67b0086310> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f67b0086290> 
			size = (3,)
			dt = 0.2
			action = [ 0.502 -0.571  0.358]
			daction_dt = [ 1.374  2.507 -2.489]
		discrete = False
		action_size = (3,)
		state_size = (80,)
		config = <src.utils.config.Config object at 0x7f67b81c8450> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 10
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			TRAIN_EVERY = 10000
			BATCH_SIZE = 500
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7f685839cc90> 
				NSAMPLES = 100
				HORIZON = 10
				LAMBDA = 0.1
				COV = 1
			dynamics_size = 13
			state_size = (80,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 1000000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7f67b9acbb50> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.97
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7f67b00869d0> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7f67b0086790> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f67b81c8450> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 10
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				TRAIN_EVERY = 10000
				BATCH_SIZE = 500
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7f685839cc90> 
					NSAMPLES = 100
					HORIZON = 10
					LAMBDA = 0.1
					COV = 1
				dynamics_size = 13
				state_size = (80,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 1000000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7f67b9acbb50> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.97
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7f67b0086b10> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=29, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(29, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=13, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7f67b0086690> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7f67b81c8450> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = 10
						MAX_BUFFER_SIZE = 100000
						REPLAY_BATCH_SIZE = 32
						TARGET_UPDATE_RATE = 0.0004
						TRAIN_EVERY = 10000
						BATCH_SIZE = 500
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7f685839cc90> 
							NSAMPLES = 100
							HORIZON = 10
							LAMBDA = 0.1
							COV = 1
						dynamics_size = 13
						state_size = (80,)
						action_size = (3,)
						env_name = CarRacing-v1
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 1000000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7f67b9acbb50> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.97
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (80,)
					action_size = (3,)
					discrete = False
					dyn_index = 13
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f67b804ebd0>
				state_size = (80,)
				action_size = (3,)
			discrete = False
			mu = [ 0.000  0.000  0.000]
			cov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			icov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			lamda = 0.1
			horizon = 10
			nsamples = 100
			action_size = (3,)
			control = [[[-0.074  0.741 -0.732]
			  [ 0.945  0.176 -0.246]
			  [-0.481  0.279  0.370]
			  [-0.516  0.185 -0.815]
			  [-0.623 -0.906  0.095]
			  [-0.436 -0.295  0.918]
			  [-0.594 -0.070 -0.659]
			  [-0.395  0.464  0.047]
			  [-0.562  0.716 -0.005]
			  [-0.412  0.207  0.458]]]
			noise = [[[[ 0.765  0.500 -1.283]
			   [-0.069 -0.196 -0.157]
			   [ 0.075 -1.964 -0.538]
			   ...
			   [ 1.158  0.405 -0.159]
			   [ 0.477  0.695 -0.847]
			   [ 1.940  0.652 -0.095]]
			
			  [[ 1.632 -0.596 -1.522]
			   [-0.681  0.257 -1.392]
			   [-0.789 -2.116 -0.263]
			   ...
			   [-0.305 -0.866 -0.622]
			   [ 1.353  0.231 -1.928]
			   [-0.616  2.594  0.904]]
			
			  [[ 0.997 -0.065 -1.207]
			   [-0.116 -1.027 -0.387]
			   [ 1.459 -0.499 -0.335]
			   ...
			   [ 0.417 -1.188  0.462]
			   [-0.053  1.441 -0.997]
			   [-0.815 -0.745  0.507]]
			
			  ...
			
			  [[ 0.536  0.951  0.756]
			   [ 1.155  0.179 -0.141]
			   [-0.649 -0.944  0.492]
			   ...
			   [ 2.105  1.144 -0.814]
			   [-1.457 -0.767  0.144]
			   [ 0.193  1.471 -0.688]]
			
			  [[ 1.030 -1.311  0.107]
			   [ 1.400  0.580 -0.387]
			   [ 0.233 -0.484 -0.202]
			   ...
			   [ 0.742 -0.991 -1.225]
			   [ 0.484  0.264 -0.747]
			   [-0.484 -1.035 -0.852]]
			
			  [[ 1.206  0.494 -0.038]
			   [-0.421  0.130 -0.075]
			   [-0.005 -0.535  0.906]
			   ...
			   [ 2.210 -0.318 -0.241]
			   [ 0.243 -0.303  1.096]
			   [ 0.517 -0.851  0.708]]]]
			init_cost = [[ 1.817e-01  1.258e-02  6.084e-02  1.832e-01 -5.869e-01 -2.103e-01 -5.852e-01 -1.775e-01  6.056e-02 -6.317e-05  4.391e-01 -9.438e-02 -6.723e-02 -3.158e-01  3.285e-01 -5.178e-01  6.266e-02 -5.361e-02  2.692e-01  7.933e-02  4.290e-02 -1.606e-01 -7.636e-02  1.455e-02 -4.477e-01  1.982e-02  7.903e-02 -5.295e-01 -1.682e-01 -2.667e-01 -1.708e-01  3.048e-01  5.873e-01 -3.514e-01 -2.044e-01 -1.689e-01  2.060e-01 -2.098e-01 -1.899e-01 -1.196e-02  2.657e-01  2.911e-01 -1.511e-01  1.488e-02 -1.982e-01  2.134e-01 -7.475e-02 -4.383e-01 -3.357e-01 -3.147e-01 -1.718e-01 -1.635e-01 -4.115e-01 -3.017e-01  3.762e-01  1.781e-01 -3.474e-01  8.099e-02  2.346e-01 -2.537e-01  7.436e-02  1.210e-01  2.558e-01 -1.802e-01 -1.626e-01 -6.630e-02  5.354e-01 -2.241e-01 -1.846e-01 -4.334e-01 -2.137e-01  3.505e-01  4.504e-01  1.868e-01 -4.837e-02 -3.700e-02 -4.782e-01  1.131e-01  2.862e-01  2.390e-01 -2.397e-01 -1.196e-01  6.159e-01  9.024e-02 -6.426e-01 -6.960e-02  1.798e-01  3.641e-02 -3.463e-01 -2.944e-01  5.524e-01  5.989e-01 -1.495e-01  2.692e-01  3.492e-01 -1.767e-01  7.139e-02  4.166e-01 -4.151e-01  8.914e-03]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f67b8050090> 
			buffer = deque([], maxlen=100000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
		ep_lens = deque([], maxlen=100000)
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f67b0041750> 
		size = (3,)
		dt = 0.2
		action = [-0.420 -0.004 -0.890]
		daction_dt = [-1.700 -0.658 -1.023]
	discrete = False
	action_size = (3,)
	state_size = (80,)
	config = <src.utils.config.Config object at 0x7f67b81c8450> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 10
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		TRAIN_EVERY = 10000
		BATCH_SIZE = 500
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7f685839cc90> 
			NSAMPLES = 100
			HORIZON = 10
			LAMBDA = 0.1
			COV = 1
		dynamics_size = 13
		state_size = (80,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 1000000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7f67b9acbb50> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.97
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7f67a9ba0cd0> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from collections import deque
from scipy.stats import multivariate_normal
from src.utils.misc import load_module, pad
from src.utils.rand import RandomAgent, ReplayBuffer
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.discrete = type(action_size)!=tuple
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV*(1+4*int(self.discrete))
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		noise = self.noise[...,:horizon,:] * max(eps if eps else 0, 0.1)
		controls = np.clip(self.control[:,None,:horizon,:] + noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1) + self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control[...,:horizon,:] += np.sum(weights[:,:,None,None]*noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))/self.horizon

	def optimize(self, states, actions, next_states, rewards, dones, **kwargs):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones, **kwargs)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")
		self.ep_lens = deque(maxlen=config.MAX_BUFFER_SIZE)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state)
		if eps >= 1: return action_random
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			self.ep_lens.append(len(buffer))
			states, actions, next_states, rewards, dones = map(lambda x: self.to_tensor(x)[None], zip(*buffer))
			buffer.clear()
			mask = torch.ones_like(rewards)
			values = self.network.envmodel.value(actions, states, next_states)[0]
			rewards = self.compute_gae(0*values[-1], rewards.transpose(0,1), dones.transpose(0,1), values)[0].transpose(0,1)
			states, actions, next_states, rewards, dones, mask = map(lambda x: x.cpu().numpy(), [states, actions, next_states, rewards, dones, mask])
			states, actions, next_states, rewards, dones, mask = map(lambda x: pad(x[0], self.config.NUM_STEPS), [states, actions, next_states, rewards, dones, mask])
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones, mask)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:# and self.time % self.config.TRAIN_EVERY == 0:
			states, actions, next_states, rewards, dones, mask = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			loss = self.network.optimize(states, actions, next_states, rewards, dones, mask=mask)
			# samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			# dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			# loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			# pbar = tqdm.tqdm(loader)
			# for states, actions, next_states, rewards, dones in pbar:
			# 	self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
			# 	pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			# self.network.envmodel.network.schedule(np.mean(self.losses))
			self.eps = (self.time/int(np.mean(self.ep_lens)+1))%1
			self.stats.mean(loss=loss)

	def get_stats(self):
		return {**super().get_stats(), "len":len(self.replay_buffer), "ep_len":np.mean(self.ep_lens) if len(self.ep_lens) else 0}


Step:       0, Reward:  -215.394 [ 170.102], Avg:  -215.394 (1.000) <0-00:00:00> ({'r_t':    -1.0359, 'eps':     1.0000, 'lr':     0.0001, 'len':   0.00e+00, 'ep_len':   0.00e+00, 'eps_e':     1.0000, 'lr_e':     0.0001, 'len_e':   0.00e+00, 'ep_len_e':   0.00e+00})
Step:    1000, Reward:   -54.749 [   0.032], Avg:  -135.071 (0.427) <0-00:00:36> ({'r_t':  -988.2214, 'eps':     0.4271, 'loss':   304.2641, 'dyn_loss':   163.3231, 'dot_loss':    18.6637, 'ddot_loss':     9.9010, 'rew_loss':   182.6689, 'lr':     0.0001, 'len':  1645.0000, 'ep_len':    95.1341, 'eps_e':     0.4271, 'lr_e':     0.0001, 'len_e':  1645.0000, 'ep_len_e':    95.1341})
Step:    2000, Reward:   -54.792 [   0.205], Avg:  -108.312 (0.483) <0-00:01:14> ({'r_t':  -842.3628, 'eps':     0.4831, 'loss':   162.8824, 'dyn_loss':    37.5251, 'dot_loss':     4.2854, 'ddot_loss':     4.2523, 'rew_loss':   175.7168, 'lr':     0.0001, 'len':  3282.0000, 'ep_len':    88.4729, 'eps_e':     0.4831, 'lr_e':     0.0001, 'len_e':  3282.0000, 'ep_len_e':    88.4729})
Step:    3000, Reward:   -57.290 [  10.543], Avg:   -95.556 (0.978) <0-00:01:54> ({'r_t':  -860.8829, 'eps':     0.9780, 'loss':   145.8646, 'dyn_loss':    27.1102, 'dot_loss':     2.4696, 'ddot_loss':     2.8881, 'rew_loss':   170.8629, 'lr':     0.0001, 'len':  4968.0000, 'ep_len':    90.5154, 'eps_e':     0.9780, 'lr_e':     0.0001, 'len_e':  4968.0000, 'ep_len_e':    90.5154})
Step:    4000, Reward:   -59.962 [   7.102], Avg:   -88.437 (0.456) <0-00:02:34> ({'r_t':  -842.8663, 'eps':     0.4556, 'loss':   136.4200, 'dyn_loss':    21.9222, 'dot_loss':     1.8281, 'ddot_loss':     2.3918, 'rew_loss':   167.5350, 'lr':     0.0001, 'len':  6646.0000, 'ep_len':    89.2238, 'eps_e':     0.4556, 'lr_e':     0.0001, 'len_e':  6646.0000, 'ep_len_e':    89.2238})
Step:    5000, Reward:   -55.110 [   7.185], Avg:   -82.883 (0.191) <0-00:03:14> ({'r_t':  -795.9907, 'eps':     0.1910, 'loss':   128.1519, 'dyn_loss':    18.5448, 'dot_loss':     1.4769, 'ddot_loss':     2.0621, 'rew_loss':   164.6739, 'lr':     0.0001, 'len':  8355.0000, 'ep_len':    88.4420, 'eps_e':     0.1910, 'lr_e':     0.0001, 'len_e':  8355.0000, 'ep_len_e':    88.4420})
Step:    6000, Reward:   -47.343 [   4.170], Avg:   -77.806 (0.193) <0-00:03:53> ({'r_t':  -716.9571, 'eps':     0.1932, 'loss':   126.6587, 'dyn_loss':    17.4022, 'dot_loss':     1.2221, 'ddot_loss':     1.8439, 'rew_loss':   166.7131, 'lr':     0.0001, 'len': 10035.0000, 'ep_len':    87.4871, 'eps_e':     0.1932, 'lr_e':     0.0001, 'len_e': 10035.0000, 'ep_len_e':    87.4871})
Step:    7000, Reward:   -44.166 [   3.874], Avg:   -73.601 (0.471) <0-00:04:33> ({'r_t':  -696.1024, 'eps':     0.4713, 'loss':   124.6875, 'dyn_loss':    15.0175, 'dot_loss':     1.0941, 'ddot_loss':     1.7644, 'rew_loss':   164.4016, 'lr':     0.0001, 'len': 11700.0000, 'ep_len':    86.7562, 'eps_e':     0.4713, 'lr_e':     0.0001, 'len_e': 11700.0000, 'ep_len_e':    86.7562})
Step:    8000, Reward:   -46.315 [   5.694], Avg:   -70.569 (0.966) <0-00:05:12> ({'r_t':  -663.2981, 'eps':     0.9655, 'loss':   125.2188, 'dyn_loss':    16.5840, 'dot_loss':     1.0634, 'ddot_loss':     1.8139, 'rew_loss':   167.6793, 'lr':     0.0001, 'len': 13420.0000, 'ep_len':    86.4247, 'eps_e':     0.9655, 'lr_e':     0.0001, 'len_e': 13420.0000, 'ep_len_e':    86.4247})
Step:    9000, Reward:   -43.059 [   5.528], Avg:   -67.818 (0.663) <0-00:05:51> ({'r_t':  -657.8148, 'eps':     0.6628, 'loss':   126.9196, 'dyn_loss':    16.5140, 'dot_loss':     1.0022, 'ddot_loss':     1.8027, 'rew_loss':   169.7964, 'lr':     0.0001, 'len': 15085.0000, 'ep_len':    85.9928, 'eps_e':     0.6628, 'lr_e':     0.0001, 'len_e': 15085.0000, 'ep_len_e':    85.9928})
Step:   10000, Reward:   -41.108 [   9.799], Avg:   -65.390 (0.954) <0-00:06:30> ({'r_t':  -602.0275, 'eps':     0.9540, 'loss':   124.9326, 'dyn_loss':    16.3827, 'dot_loss':     0.9883, 'ddot_loss':     1.8660, 'rew_loss':   169.8661, 'lr':     0.0001, 'len': 16787.0000, 'ep_len':    86.1649, 'eps_e':     0.9540, 'lr_e':     0.0001, 'len_e': 16787.0000, 'ep_len_e':    86.1649})
Step:   11000, Reward:   -39.297 [   8.924], Avg:   -63.215 (0.448) <0-00:07:10> ({'r_t':  -673.0848, 'eps':     0.4483, 'loss':   125.8432, 'dyn_loss':    18.1795, 'dot_loss':     0.9168, 'ddot_loss':     1.7891, 'rew_loss':   170.1333, 'lr':     0.0001, 'len': 18465.0000, 'ep_len':    86.1435, 'eps_e':     0.4483, 'lr_e':     0.0001, 'len_e': 18465.0000, 'ep_len_e':    86.1435})
Step:   12000, Reward:   -37.478 [  11.692], Avg:   -61.235 (0.943) <0-00:07:49> ({'r_t':  -676.6696, 'eps':     0.9425, 'loss':   125.9805, 'dyn_loss':    19.2249, 'dot_loss':     0.8696, 'ddot_loss':     1.7528, 'rew_loss':   171.1544, 'lr':     0.0001, 'len': 20168.0000, 'ep_len':    86.2116, 'eps_e':     0.9425, 'lr_e':     0.0001, 'len_e': 20168.0000, 'ep_len_e':    86.2116})
Step:   13000, Reward:   -37.054 [   9.093], Avg:   -59.508 (0.437) <0-00:08:29> ({'r_t':  -643.1767, 'eps':     0.4368, 'loss':   128.0496, 'dyn_loss':    19.9933, 'dot_loss':     0.8252, 'ddot_loss':     1.6944, 'rew_loss':   172.4970, 'lr':     0.0001, 'len': 21796.0000, 'ep_len':    86.5717, 'eps_e':     0.4368, 'lr_e':     0.0001, 'len_e': 21796.0000, 'ep_len_e':    86.5717})
Step:   14000, Reward:   -33.259 [   9.675], Avg:   -57.758 (0.931) <0-00:09:08> ({'r_t':  -584.3910, 'eps':     0.9310, 'loss':   127.5571, 'dyn_loss':    18.3322, 'dot_loss':     0.7753, 'ddot_loss':     1.6205, 'rew_loss':   172.6839, 'lr':     0.0001, 'len': 23515.0000, 'ep_len':    86.6667, 'eps_e':     0.9310, 'lr_e':     0.0001, 'len_e': 23515.0000, 'ep_len_e':    86.6667})
Step:   15000, Reward:   -36.434 [  12.312], Avg:   -56.425 (0.425) <0-00:09:48> ({'r_t':  -651.7287, 'eps':     0.4253, 'loss':   128.1001, 'dyn_loss':    21.6652, 'dot_loss':     0.7659, 'ddot_loss':     1.6043, 'rew_loss':   175.1236, 'lr':     0.0001, 'len': 25160.0000, 'ep_len':    86.6960, 'eps_e':     0.4253, 'lr_e':     0.0001, 'len_e': 25160.0000, 'ep_len_e':    86.6960})
Step:   16000, Reward:   -32.609 [  14.672], Avg:   -55.025 (0.920) <0-00:10:28> ({'r_t':  -585.0889, 'eps':     0.9195, 'loss':   131.8547, 'dyn_loss':    21.5076, 'dot_loss':     0.7428, 'ddot_loss':     1.5632, 'rew_loss':   176.5064, 'lr':     0.0001, 'len': 26885.0000, 'ep_len':    86.7734, 'eps_e':     0.9195, 'lr_e':     0.0001, 'len_e': 26885.0000, 'ep_len_e':    86.7734})
Step:   17000, Reward:   -26.785 [  17.279], Avg:   -53.456 (0.414) <0-00:11:08> ({'r_t':  -606.3917, 'eps':     0.4138, 'loss':   130.2056, 'dyn_loss':    22.6851, 'dot_loss':     0.7124, 'ddot_loss':     1.5051, 'rew_loss':   174.8510, 'lr':     0.0001, 'len': 28535.0000, 'ep_len':    86.9766, 'eps_e':     0.4138, 'lr_e':     0.0001, 'len_e': 28535.0000, 'ep_len_e':    86.9766})
Step:   18000, Reward:   -29.739 [  12.914], Avg:   -52.207 (0.557) <0-00:11:47> ({'r_t':  -548.5198, 'eps':     0.5568, 'loss':   133.2526, 'dyn_loss':    24.0566, 'dot_loss':     0.6982, 'ddot_loss':     1.4781, 'rew_loss':   178.7040, 'lr':     0.0001, 'len': 30246.0000, 'ep_len':    87.1477, 'eps_e':     0.5568, 'lr_e':     0.0001, 'len_e': 30246.0000, 'ep_len_e':    87.1477})
Step:   19000, Reward:   -27.572 [  11.715], Avg:   -50.976 (0.920) <0-00:12:27> ({'r_t':  -583.7427, 'eps':     0.9205, 'loss':   132.6464, 'dyn_loss':    26.2006, 'dot_loss':     0.6739, 'ddot_loss':     1.4233, 'rew_loss':   177.6790, 'lr':     0.0001, 'len': 31916.0000, 'ep_len':    87.3944, 'eps_e':     0.9205, 'lr_e':     0.0001, 'len_e': 31916.0000, 'ep_len_e':    87.3944})
Step:   20000, Reward:   -27.710 [  10.375], Avg:   -49.868 (0.284) <0-00:13:06> ({'r_t':  -598.0844, 'eps':     0.2841, 'loss':   134.8721, 'dyn_loss':    27.8829, 'dot_loss':     0.6702, 'ddot_loss':     1.4255, 'rew_loss':   179.5058, 'lr':     0.0001, 'len': 33565.0000, 'ep_len':    87.6343, 'eps_e':     0.2841, 'lr_e':     0.0001, 'len_e': 33565.0000, 'ep_len_e':    87.6343})
Step:   21000, Reward:   -18.998 [  13.026], Avg:   -48.465 (0.648) <0-00:13:46> ({'r_t':  -588.4262, 'eps':     0.6477, 'loss':   135.3107, 'dyn_loss':    29.0483, 'dot_loss':     0.6872, 'ddot_loss':     1.4612, 'rew_loss':   180.5599, 'lr':     0.0001, 'len': 35309.0000, 'ep_len':    87.8171, 'eps_e':     0.6477, 'lr_e':     0.0001, 'len_e': 35309.0000, 'ep_len_e':    87.8171})
Step:   22000, Reward:   -26.090 [  10.428], Avg:   -47.492 (0.202) <0-00:14:26> ({'r_t':  -619.5088, 'eps':     0.2022, 'loss':   137.6055, 'dyn_loss':    28.6948, 'dot_loss':     0.6605, 'ddot_loss':     1.4190, 'rew_loss':   182.5501, 'lr':     0.0001, 'len': 36940.0000, 'ep_len':    88.0331, 'eps_e':     0.2022, 'lr_e':     0.0001, 'len_e': 36940.0000, 'ep_len_e':    88.0331})
Step:   23000, Reward:   -23.802 [  14.034], Avg:   -46.505 (0.438) <0-00:15:06> ({'r_t':  -564.8948, 'eps':     0.4382, 'loss':   137.8342, 'dyn_loss':    30.7232, 'dot_loss':     0.6431, 'ddot_loss':     1.3832, 'rew_loss':   183.5110, 'lr':     0.0001, 'len': 38601.0000, 'ep_len':    88.2460, 'eps_e':     0.4382, 'lr_e':     0.0001, 'len_e': 38601.0000, 'ep_len_e':    88.2460})
Step:   24000, Reward:   -22.838 [  10.729], Avg:   -45.558 (0.674) <0-00:15:46> ({'r_t':  -598.8376, 'eps':     0.6742, 'loss':   137.6905, 'dyn_loss':    31.2939, 'dot_loss':     0.6401, 'ddot_loss':     1.3861, 'rew_loss':   182.5207, 'lr':     0.0001, 'len': 40327.0000, 'ep_len':    88.5270, 'eps_e':     0.6742, 'lr_e':     0.0001, 'len_e': 40327.0000, 'ep_len_e':    88.5270})
Step:   25000, Reward:   -20.991 [  19.797], Avg:   -44.613 (0.910) <0-00:16:27> ({'r_t':  -611.5422, 'eps':     0.9101, 'loss':   137.9007, 'dyn_loss':    32.9877, 'dot_loss':     0.6461, 'ddot_loss':     1.4002, 'rew_loss':   182.2114, 'lr':     0.0001, 'len': 41987.0000, 'ep_len':    88.7396, 'eps_e':     0.9101, 'lr_e':     0.0001, 'len_e': 41987.0000, 'ep_len_e':    88.7396})
Step:   26000, Reward:   -18.729 [  15.567], Avg:   -43.655 (0.146) <0-00:17:07> ({'r_t':  -572.5456, 'eps':     0.1461, 'loss':   139.7885, 'dyn_loss':    36.0643, 'dot_loss':     0.6443, 'ddot_loss':     1.3998, 'rew_loss':   184.0354, 'lr':     0.0001, 'len': 43638.0000, 'ep_len':    88.9396, 'eps_e':     0.1461, 'lr_e':     0.0001, 'len_e': 43638.0000, 'ep_len_e':    88.9396})
Step:   27000, Reward:   -11.454 [  17.859], Avg:   -42.504 (0.011) <0-00:17:48> ({'r_t':  -576.6138, 'eps':     0.0111, 'loss':   139.5503, 'dyn_loss':    35.1224, 'dot_loss':     0.6250, 'ddot_loss':     1.3666, 'rew_loss':   184.0064, 'lr':     0.0001, 'len': 45333.0000, 'ep_len':    89.2859, 'eps_e':     0.0111, 'lr_e':     0.0001, 'len_e': 45333.0000, 'ep_len_e':    89.2859})
Step:   28000, Reward:    -4.020 [  13.459], Avg:   -41.177 (0.122) <0-00:18:28> ({'r_t':  -579.2078, 'eps':     0.1222, 'loss':   140.9566, 'dyn_loss':    36.8022, 'dot_loss':     0.6143, 'ddot_loss':     1.3599, 'rew_loss':   185.9202, 'lr':     0.0001, 'len': 46998.0000, 'ep_len':    89.3982, 'eps_e':     0.1222, 'lr_e':     0.0001, 'len_e': 46998.0000, 'ep_len_e':    89.3982})
Step:   29000, Reward:     0.671 [  13.814], Avg:   -39.783 (0.233) <0-00:19:07> ({'r_t':  -523.2374, 'eps':     0.2333, 'loss':   140.4274, 'dyn_loss':    40.3820, 'dot_loss':     0.6390, 'ddot_loss':     1.4118, 'rew_loss':   186.1402, 'lr':     0.0001, 'len': 48653.0000, 'ep_len':    89.6824, 'eps_e':     0.2333, 'lr_e':     0.0001, 'len_e': 48653.0000, 'ep_len_e':    89.6824})
Step:   30000, Reward:     0.609 [  22.026], Avg:   -38.480 (0.344) <0-00:19:47> ({'r_t':  -551.0790, 'eps':     0.3444, 'loss':   144.2922, 'dyn_loss':    41.1091, 'dot_loss':     0.6094, 'ddot_loss':     1.3267, 'rew_loss':   189.1809, 'lr':     0.0001, 'len': 50306.0000, 'ep_len':    89.8568, 'eps_e':     0.3444, 'lr_e':     0.0001, 'len_e': 50306.0000, 'ep_len_e':    89.8568})
Step:   31000, Reward:     1.859 [  14.846], Avg:   -37.219 (0.670) <0-00:20:27> ({'r_t':  -565.4305, 'eps':     0.6703, 'loss':   144.1384, 'dyn_loss':    40.0713, 'dot_loss':     0.6074, 'ddot_loss':     1.3288, 'rew_loss':   188.0954, 'lr':     0.0001, 'len': 51974.0000, 'ep_len':    90.0045, 'eps_e':     0.6703, 'lr_e':     0.0001, 'len_e': 51974.0000, 'ep_len_e':    90.0045})
Step:   32000, Reward:    11.922 [  13.284], Avg:   -35.730 (0.659) <0-00:21:07> ({'r_t':  -525.4483, 'eps':     0.6593, 'loss':   145.9172, 'dyn_loss':    41.8851, 'dot_loss':     0.6285, 'ddot_loss':     1.3704, 'rew_loss':   190.8920, 'lr':     0.0001, 'len': 53727.0000, 'ep_len':    90.2714, 'eps_e':     0.6593, 'lr_e':     0.0001, 'len_e': 53727.0000, 'ep_len_e':    90.2714})
Step:   33000, Reward:    13.611 [  18.045], Avg:   -34.279 (0.648) <0-00:21:47> ({'r_t':  -581.9253, 'eps':     0.6484, 'loss':   148.6905, 'dyn_loss':    42.2088, 'dot_loss':     0.6184, 'ddot_loss':     1.3675, 'rew_loss':   193.4312, 'lr':     0.0001, 'len': 55399.0000, 'ep_len':    90.4474, 'eps_e':     0.6484, 'lr_e':     0.0001, 'len_e': 55399.0000, 'ep_len_e':    90.4474})
Step:   34000, Reward:    12.539 [  23.955], Avg:   -32.941 (0.637) <0-00:22:27> ({'r_t':  -589.8226, 'eps':     0.6374, 'loss':   149.9714, 'dyn_loss':    44.9949, 'dot_loss':     0.6422, 'ddot_loss':     1.4181, 'rew_loss':   193.9020, 'lr':     0.0001, 'len': 57049.0000, 'ep_len':    90.6345, 'eps_e':     0.6374, 'lr_e':     0.0001, 'len_e': 57049.0000, 'ep_len_e':    90.6345})
Step:   35000, Reward:    22.441 [  14.628], Avg:   -31.403 (0.626) <0-00:23:07> ({'r_t':  -565.5823, 'eps':     0.6264, 'loss':   150.7492, 'dyn_loss':    47.4197, 'dot_loss':     0.6312, 'ddot_loss':     1.3880, 'rew_loss':   195.0089, 'lr':     0.0001, 'len': 58758.0000, 'ep_len':    90.9191, 'eps_e':     0.6264, 'lr_e':     0.0001, 'len_e': 58758.0000, 'ep_len_e':    90.9191})
Step:   36000, Reward:     9.867 [  11.676], Avg:   -30.287 (0.315) <0-00:23:47> ({'r_t':  -512.4372, 'eps':     0.3152, 'loss':   150.5310, 'dyn_loss':    48.0117, 'dot_loss':     0.6381, 'ddot_loss':     1.4053, 'rew_loss':   195.0476, 'lr':     0.0001, 'len': 60355.0000, 'ep_len':    91.0315, 'eps_e':     0.3152, 'lr_e':     0.0001, 'len_e': 60355.0000, 'ep_len_e':    91.0315})
Step:   37000, Reward:    17.837 [  16.835], Avg:   -29.021 (0.185) <0-00:24:27> ({'r_t':  -583.5292, 'eps':     0.1848, 'loss':   152.4933, 'dyn_loss':    53.8857, 'dot_loss':     0.6513, 'ddot_loss':     1.4291, 'rew_loss':   196.2112, 'lr':     0.0001, 'len': 62051.0000, 'ep_len':    91.2866, 'eps_e':     0.1848, 'lr_e':     0.0001, 'len_e': 62051.0000, 'ep_len_e':    91.2866})
Step:   38000, Reward:     9.482 [  10.034], Avg:   -28.033 (0.054) <0-00:25:07> ({'r_t':  -523.8910, 'eps':     0.0543, 'loss':   151.8906, 'dyn_loss':    52.5158, 'dot_loss':     0.6520, 'ddot_loss':     1.4276, 'rew_loss':   194.9582, 'lr':     0.0001, 'len': 63706.0000, 'ep_len':    91.5035, 'eps_e':     0.0543, 'lr_e':     0.0001, 'len_e': 63706.0000, 'ep_len_e':    91.5035})
Step:   39000, Reward:    23.209 [  19.063], Avg:   -26.752 (0.924) <0-00:25:47> ({'r_t':  -586.6990, 'eps':     0.9239, 'loss':   154.0587, 'dyn_loss':    54.0134, 'dot_loss':     0.6658, 'ddot_loss':     1.4514, 'rew_loss':   196.5138, 'lr':     0.0001, 'len': 65398.0000, 'ep_len':    91.7331, 'eps_e':     0.9239, 'lr_e':     0.0001, 'len_e': 65398.0000, 'ep_len_e':    91.7331})
Step:   40000, Reward:    23.789 [  14.017], Avg:   -25.520 (0.793) <0-00:26:27> ({'r_t':  -559.4749, 'eps':     0.7935, 'loss':   153.7870, 'dyn_loss':    56.3936, 'dot_loss':     0.6691, 'ddot_loss':     1.4691, 'rew_loss':   196.7050, 'lr':     0.0001, 'len': 67079.0000, 'ep_len':    91.9566, 'eps_e':     0.7935, 'lr_e':     0.0001, 'len_e': 67079.0000, 'ep_len_e':    91.9566})
Step:   41000, Reward:    24.663 [  12.798], Avg:   -24.325 (0.871) <0-00:27:07> ({'r_t':  -620.1230, 'eps':     0.8710, 'loss':   158.4528, 'dyn_loss':    60.3711, 'dot_loss':     0.6701, 'ddot_loss':     1.4725, 'rew_loss':   202.3514, 'lr':     0.0001, 'len': 68755.0000, 'ep_len':    92.1839, 'eps_e':     0.8710, 'lr_e':     0.0001, 'len_e': 68755.0000, 'ep_len_e':    92.1839})
Step:   42000, Reward:    27.183 [   9.858], Avg:   -23.127 (0.624) <0-00:27:48> ({'r_t':  -618.2875, 'eps':     0.6237, 'loss':   157.2446, 'dyn_loss':    58.2652, 'dot_loss':     0.6399, 'ddot_loss':     1.4113, 'rew_loss':   200.7817, 'lr':     0.0001, 'len': 70474.0000, 'ep_len':    92.3629, 'eps_e':     0.6237, 'lr_e':     0.0001, 'len_e': 70474.0000, 'ep_len_e':    92.3629})
Step:   43000, Reward:    20.209 [  17.569], Avg:   -22.142 (0.376) <0-00:28:28> ({'r_t':  -580.9476, 'eps':     0.3763, 'loss':   157.8249, 'dyn_loss':    57.4955, 'dot_loss':     0.6747, 'ddot_loss':     1.4963, 'rew_loss':   201.4973, 'lr':     0.0001, 'len': 72109.0000, 'ep_len':    92.5203, 'eps_e':     0.3763, 'lr_e':     0.0001, 'len_e': 72109.0000, 'ep_len_e':    92.5203})
Step:   44000, Reward:    16.947 [  16.968], Avg:   -21.273 (0.129) <0-00:29:08> ({'r_t':  -556.8929, 'eps':     0.1290, 'loss':   160.6354, 'dyn_loss':    61.2055, 'dot_loss':     0.6817, 'ddot_loss':     1.5141, 'rew_loss':   204.8953, 'lr':     0.0001, 'len': 73743.0000, 'ep_len':    92.6599, 'eps_e':     0.1290, 'lr_e':     0.0001, 'len_e': 73743.0000, 'ep_len_e':    92.6599})
Step:   45000, Reward:    11.060 [  20.026], Avg:   -20.571 (0.882) <0-00:29:48> ({'r_t':  -498.6242, 'eps':     0.8817, 'loss':   159.7367, 'dyn_loss':    62.8799, 'dot_loss':     0.6778, 'ddot_loss':     1.4955, 'rew_loss':   203.0706, 'lr':     0.0001, 'len': 75437.0000, 'ep_len':    92.8433, 'eps_e':     0.8817, 'lr_e':     0.0001, 'len_e': 75437.0000, 'ep_len_e':    92.8433})
Step:   46000, Reward:    31.174 [  10.841], Avg:   -19.470 (0.372) <0-00:30:29> ({'r_t':  -551.0501, 'eps':     0.3723, 'loss':   162.0112, 'dyn_loss':    63.4593, 'dot_loss':     0.7012, 'ddot_loss':     1.5457, 'rew_loss':   206.4812, 'lr':     0.0001, 'len': 77056.0000, 'ep_len':    93.0560, 'eps_e':     0.3723, 'lr_e':     0.0001, 'len_e': 77056.0000, 'ep_len_e':    93.0560})
Step:   47000, Reward:    20.709 [   9.958], Avg:   -18.633 (0.011) <0-00:31:09> ({'r_t':  -577.7196, 'eps':     0.0106, 'loss':   161.7927, 'dyn_loss':    67.8329, 'dot_loss':     0.6967, 'ddot_loss':     1.5218, 'rew_loss':   204.8590, 'lr':     0.0001, 'len': 78762.0000, 'ep_len':    93.2839, 'eps_e':     0.0106, 'lr_e':     0.0001, 'len_e': 78762.0000, 'ep_len_e':    93.2839})
Step:   48000, Reward:    17.237 [  11.181], Avg:   -17.901 (0.649) <0-00:31:49> ({'r_t':  -545.9900, 'eps':     0.6489, 'loss':   161.2818, 'dyn_loss':    62.5657, 'dot_loss':     0.6922, 'ddot_loss':     1.5441, 'rew_loss':   202.2241, 'lr':     0.0001, 'len': 80497.0000, 'ep_len':    93.4351, 'eps_e':     0.6489, 'lr_e':     0.0001, 'len_e': 80497.0000, 'ep_len_e':    93.4351})
Step:   49000, Reward:    15.448 [   9.278], Avg:   -17.234 (0.287) <0-00:32:29> ({'r_t':  -575.6843, 'eps':     0.2872, 'loss':   163.8759, 'dyn_loss':    71.4350, 'dot_loss':     0.7135, 'ddot_loss':     1.5676, 'rew_loss':   207.0127, 'lr':     0.0001, 'len': 82080.0000, 'ep_len':    93.5214, 'eps_e':     0.2872, 'lr_e':     0.0001, 'len_e': 82080.0000, 'ep_len_e':    93.5214})
Step:   50000, Reward:     7.237 [  14.250], Avg:   -16.754 (0.926) <0-00:33:10> ({'r_t':  -548.4030, 'eps':     0.9255, 'loss':   163.1752, 'dyn_loss':    65.3279, 'dot_loss':     0.7176, 'ddot_loss':     1.5867, 'rew_loss':   205.4537, 'lr':     0.0001, 'len': 83802.0000, 'ep_len':    93.6882, 'eps_e':     0.9255, 'lr_e':     0.0001, 'len_e': 83802.0000, 'ep_len_e':    93.6882})
Step:   51000, Reward:    28.992 [  17.513], Avg:   -15.874 (0.564) <0-00:33:50> ({'r_t':  -544.6357, 'eps':     0.5638, 'loss':   165.5615, 'dyn_loss':    77.2768, 'dot_loss':     0.6908, 'ddot_loss':     1.5494, 'rew_loss':   209.4649, 'lr':     0.0001, 'len': 85522.0000, 'ep_len':    93.8796, 'eps_e':     0.5638, 'lr_e':     0.0001, 'len_e': 85522.0000, 'ep_len_e':    93.8796})
Step:   52000, Reward:    22.967 [  21.257], Avg:   -15.141 (0.379) <0-00:34:30> ({'r_t':  -535.6223, 'eps':     0.3789, 'loss':   165.7655, 'dyn_loss':    67.3484, 'dot_loss':     0.7308, 'ddot_loss':     1.6119, 'rew_loss':   207.2521, 'lr':     0.0001, 'len': 87146.0000, 'ep_len':    94.0313, 'eps_e':     0.3789, 'lr_e':     0.0001, 'len_e': 87146.0000, 'ep_len_e':    94.0313})
Step:   53000, Reward:    20.238 [  17.865], Avg:   -14.486 (0.905) <0-00:35:11> ({'r_t':  -514.8572, 'eps':     0.9053, 'loss':   166.7459, 'dyn_loss':    75.8400, 'dot_loss':     0.7121, 'ddot_loss':     1.6025, 'rew_loss':   210.0111, 'lr':     0.0001, 'len': 88807.0000, 'ep_len':    94.1841, 'eps_e':     0.9053, 'lr_e':     0.0001, 'len_e': 88807.0000, 'ep_len_e':    94.1841})
Step:   54000, Reward:     9.706 [  14.129], Avg:   -14.046 (0.432) <0-00:35:51> ({'r_t':  -531.4182, 'eps':     0.4316, 'loss':   168.4427, 'dyn_loss':    73.3911, 'dot_loss':     0.7160, 'ddot_loss':     1.5712, 'rew_loss':   210.5432, 'lr':     0.0001, 'len': 90461.0000, 'ep_len':    94.2882, 'eps_e':     0.4316, 'lr_e':     0.0001, 'len_e': 90461.0000, 'ep_len_e':    94.2882})
Step:   55000, Reward:    25.077 [  23.649], Avg:   -13.348 (0.958) <0-00:36:31> ({'r_t':  -586.3768, 'eps':     0.9579, 'loss':   165.5823, 'dyn_loss':    72.1800, 'dot_loss':     0.7370, 'ddot_loss':     1.6522, 'rew_loss':   207.6175, 'lr':     0.0001, 'len': 92130.0000, 'ep_len':    94.4068, 'eps_e':     0.9579, 'lr_e':     0.0001, 'len_e': 92130.0000, 'ep_len_e':    94.4068})
Step:   56000, Reward:    26.680 [  19.545], Avg:   -12.645 (0.484) <0-00:37:12> ({'r_t':  -594.8495, 'eps':     0.4842, 'loss':   168.2332, 'dyn_loss':    71.8011, 'dot_loss':     0.7216, 'ddot_loss':     1.5992, 'rew_loss':   209.1512, 'lr':     0.0001, 'len': 93824.0000, 'ep_len':    94.5060, 'eps_e':     0.4842, 'lr_e':     0.0001, 'len_e': 93824.0000, 'ep_len_e':    94.5060})
Step:   57000, Reward:    26.952 [   9.963], Avg:   -11.963 (0.011) <0-00:37:53> ({'r_t':  -517.2947, 'eps':     0.0105, 'loss':   167.8153, 'dyn_loss':    78.4747, 'dot_loss':     0.7174, 'ddot_loss':     1.6053, 'rew_loss':   208.4140, 'lr':     0.0001, 'len': 95478.0000, 'ep_len':    94.5912, 'eps_e':     0.0105, 'lr_e':     0.0001, 'len_e': 95478.0000, 'ep_len_e':    94.5912})
Step:   58000, Reward:    30.252 [  18.564], Avg:   -11.247 (0.537) <0-00:38:35> ({'r_t':  -524.0579, 'eps':     0.5368, 'loss':   169.6321, 'dyn_loss':    73.4448, 'dot_loss':     0.7431, 'ddot_loss':     1.6888, 'rew_loss':   209.9174, 'lr':     0.0001, 'len': 97178.0000, 'ep_len':    94.7255, 'eps_e':     0.5368, 'lr_e':     0.0001, 'len_e': 97178.0000, 'ep_len_e':    94.7255})
Step:   59000, Reward:    22.713 [  20.019], Avg:   -10.681 (0.063) <0-00:39:15> ({'r_t':  -545.7785, 'eps':     0.0632, 'loss':   170.5934, 'dyn_loss':    79.5072, 'dot_loss':     0.7501, 'ddot_loss':     1.7032, 'rew_loss':   211.8363, 'lr':     0.0001, 'len': 98813.0000, 'ep_len':    94.8422, 'eps_e':     0.0632, 'lr_e':     0.0001, 'len_e': 98813.0000, 'ep_len_e':    94.8422})
Step:   60000, Reward:    22.346 [  18.936], Avg:   -10.140 (0.589) <0-00:39:56> ({'r_t':  -603.9905, 'eps':     0.5895, 'loss':   171.9858, 'dyn_loss':    74.5549, 'dot_loss':     0.7431, 'ddot_loss':     1.6647, 'rew_loss':   212.5721, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    94.9633, 'eps_e':     0.5895, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    94.9633})
Step:   61000, Reward:    29.085 [   9.616], Avg:    -9.507 (0.427) <0-00:40:37> ({'r_t':  -524.1070, 'eps':     0.4271, 'loss':   169.2077, 'dyn_loss':    78.7254, 'dot_loss':     0.7657, 'ddot_loss':     1.7121, 'rew_loss':   209.2744, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.0625, 'eps_e':     0.4271, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.0625})
Step:   62000, Reward:    34.137 [   6.529], Avg:    -8.814 (0.844) <0-00:41:18> ({'r_t':  -575.2451, 'eps':     0.8438, 'loss':   170.4662, 'dyn_loss':    78.4421, 'dot_loss':     0.7501, 'ddot_loss':     1.7007, 'rew_loss':   210.1339, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.1592, 'eps_e':     0.8438, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.1592})
Step:   63000, Reward:    16.133 [  19.212], Avg:    -8.424 (0.260) <0-00:41:59> ({'r_t':  -646.1166, 'eps':     0.2604, 'loss':   172.4909, 'dyn_loss':    85.5293, 'dot_loss':     0.7707, 'ddot_loss':     1.7474, 'rew_loss':   213.0437, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.2551, 'eps_e':     0.2604, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.2551})
Step:   64000, Reward:    32.761 [  13.730], Avg:    -7.791 (0.677) <0-00:42:40> ({'r_t':  -499.7772, 'eps':     0.6771, 'loss':   173.5878, 'dyn_loss':    82.7526, 'dot_loss':     0.7525, 'ddot_loss':     1.6946, 'rew_loss':   212.5522, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.3655, 'eps_e':     0.6771, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.3655})
Step:   65000, Reward:    30.954 [  11.943], Avg:    -7.204 (0.094) <0-00:43:21> ({'r_t':  -541.9641, 'eps':     0.0938, 'loss':   175.4690, 'dyn_loss':    85.5288, 'dot_loss':     0.7881, 'ddot_loss':     1.7776, 'rew_loss':   212.3216, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.4495, 'eps_e':     0.0938, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.4495})
Step:   66000, Reward:    21.475 [  19.461], Avg:    -6.776 (0.510) <0-00:44:03> ({'r_t':  -505.8874, 'eps':     0.5104, 'loss':   175.8816, 'dyn_loss':    93.6276, 'dot_loss':     0.7649, 'ddot_loss':     1.7391, 'rew_loss':   213.9505, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.5156, 'eps_e':     0.5104, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.5156})
Step:   67000, Reward:    22.841 [   9.522], Avg:    -6.340 (0.927) <0-00:44:44> ({'r_t':  -568.6637, 'eps':     0.9271, 'loss':   179.3705, 'dyn_loss':    94.3169, 'dot_loss':     0.8023, 'ddot_loss':     1.8150, 'rew_loss':   217.0041, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.6478, 'eps_e':     0.9271, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.6478})
Step:   68000, Reward:   -16.845 [  43.855], Avg:    -6.492 (0.344) <0-00:45:27> ({'r_t':  -571.5964, 'eps':     0.3438, 'loss':   179.2505, 'dyn_loss':    90.3823, 'dot_loss':     0.7844, 'ddot_loss':     1.7941, 'rew_loss':   216.0728, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.8050, 'eps_e':     0.3438, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.8050})
Step:   69000, Reward:    -2.851 [  27.539], Avg:    -6.440 (0.760) <0-00:46:10> ({'r_t':  -518.9892, 'eps':     0.7604, 'loss':   182.5372, 'dyn_loss':    94.0749, 'dot_loss':     0.7990, 'ddot_loss':     1.8118, 'rew_loss':   221.0480, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.8819, 'eps_e':     0.7604, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.8819})
Step:   70000, Reward:    18.744 [  23.432], Avg:    -6.086 (0.177) <0-00:46:51> ({'r_t':  -592.3319, 'eps':     0.1771, 'loss':   181.2458, 'dyn_loss':   103.2225, 'dot_loss':     0.7947, 'ddot_loss':     1.8145, 'rew_loss':   218.4589, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    95.9549, 'eps_e':     0.1771, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    95.9549})
Step:   71000, Reward:    24.917 [   6.370], Avg:    -5.655 (0.969) <0-00:47:33> ({'r_t':  -531.1307, 'eps':     0.9691, 'loss':   182.0025, 'dyn_loss':   105.0033, 'dot_loss':     0.8069, 'ddot_loss':     1.8539, 'rew_loss':   219.6395, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.0402, 'eps_e':     0.9691, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.0402})
Step:   72000, Reward:    17.622 [  10.446], Avg:    -5.336 (0.278) <0-00:48:15> ({'r_t':  -540.9304, 'eps':     0.2784, 'loss':   181.1443, 'dyn_loss':   102.3652, 'dot_loss':     0.8376, 'ddot_loss':     1.8942, 'rew_loss':   217.0198, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.1244, 'eps_e':     0.2784, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.1244})
Step:   73000, Reward:    26.216 [  22.526], Avg:    -4.910 (0.588) <0-00:48:56> ({'r_t':  -545.6428, 'eps':     0.5876, 'loss':   184.0754, 'dyn_loss':    97.6291, 'dot_loss':     0.8466, 'ddot_loss':     1.9202, 'rew_loss':   219.8521, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.2122, 'eps_e':     0.5876, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.2122})
Step:   74000, Reward:    29.517 [  11.944], Avg:    -4.451 (0.897) <0-00:49:38> ({'r_t':  -588.2704, 'eps':     0.8969, 'loss':   184.2414, 'dyn_loss':   101.9291, 'dot_loss':     0.8198, 'ddot_loss':     1.8932, 'rew_loss':   218.6492, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.3029, 'eps_e':     0.8969, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.3029})
Step:   75000, Reward:    18.274 [  30.156], Avg:    -4.152 (0.206) <0-00:50:20> ({'r_t':  -593.7964, 'eps':     0.2062, 'loss':   185.4670, 'dyn_loss':   100.9716, 'dot_loss':     0.8389, 'ddot_loss':     1.9332, 'rew_loss':   219.0756, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.3903, 'eps_e':     0.2062, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.3903})
Step:   76000, Reward:    24.264 [  23.072], Avg:    -3.783 (0.515) <0-00:51:02> ({'r_t':  -576.2148, 'eps':     0.5155, 'loss':   187.5359, 'dyn_loss':    96.5930, 'dot_loss':     0.8244, 'ddot_loss':     1.8847, 'rew_loss':   222.5213, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.5003, 'eps_e':     0.5155, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.5003})
Step:   77000, Reward:   -11.993 [  31.321], Avg:    -3.888 (0.825) <0-00:51:44> ({'r_t':  -586.5195, 'eps':     0.8247, 'loss':   185.3522, 'dyn_loss':   101.1558, 'dot_loss':     0.8217, 'ddot_loss':     1.8930, 'rew_loss':   220.2965, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.5442, 'eps_e':     0.8247, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.5442})
Step:   78000, Reward:    20.476 [  18.621], Avg:    -3.580 (0.134) <0-00:52:26> ({'r_t':  -543.8256, 'eps':     0.1340, 'loss':   185.9939, 'dyn_loss':   106.8323, 'dot_loss':     0.7933, 'ddot_loss':     1.8111, 'rew_loss':   220.6065, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.6088, 'eps_e':     0.1340, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.6088})
Step:   79000, Reward:    11.109 [  13.687], Avg:    -3.396 (0.443) <0-00:53:07> ({'r_t':  -616.9340, 'eps':     0.4433, 'loss':   189.8336, 'dyn_loss':   112.4469, 'dot_loss':     0.8609, 'ddot_loss':     1.9688, 'rew_loss':   225.0087, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.6883, 'eps_e':     0.4433, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.6883})
Step:   80000, Reward:     5.261 [  22.597], Avg:    -3.289 (0.753) <0-00:53:50> ({'r_t':  -537.5426, 'eps':     0.7526, 'loss':   191.3784, 'dyn_loss':   108.8558, 'dot_loss':     0.8698, 'ddot_loss':     1.9980, 'rew_loss':   226.1312, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.7605, 'eps_e':     0.7526, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.7605})
Step:   81000, Reward:    18.554 [   9.117], Avg:    -3.023 (0.062) <0-00:54:32> ({'r_t':  -510.1976, 'eps':     0.0619, 'loss':   191.3681, 'dyn_loss':   113.8123, 'dot_loss':     0.8753, 'ddot_loss':     2.0041, 'rew_loss':   225.8920, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.8236, 'eps_e':     0.0619, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.8236})
Step:   82000, Reward:    34.418 [  21.536], Avg:    -2.572 (0.371) <0-00:55:13> ({'r_t':  -592.4081, 'eps':     0.3711, 'loss':   189.4686, 'dyn_loss':   114.4257, 'dot_loss':     0.8814, 'ddot_loss':     2.0313, 'rew_loss':   223.8218, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.8621, 'eps_e':     0.3711, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.8621})
Step:   83000, Reward:    32.875 [   8.313], Avg:    -2.150 (0.680) <0-00:55:55> ({'r_t':  -507.4559, 'eps':     0.6804, 'loss':   192.3165, 'dyn_loss':   113.1453, 'dot_loss':     0.8594, 'ddot_loss':     2.0083, 'rew_loss':   225.9057, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    96.9757, 'eps_e':     0.6804, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    96.9757})
Step:   84000, Reward:    25.394 [  23.904], Avg:    -1.826 (0.153) <0-00:56:37> ({'r_t':  -566.1256, 'eps':     0.1531, 'loss':   191.6321, 'dyn_loss':   114.8841, 'dot_loss':     0.8604, 'ddot_loss':     1.9906, 'rew_loss':   226.9559, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.0850, 'eps_e':     0.1531, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.0850})
Step:   85000, Reward:    28.710 [  21.491], Avg:    -1.471 (0.357) <0-00:57:18> ({'r_t':  -560.0982, 'eps':     0.3571, 'loss':   195.6999, 'dyn_loss':   114.1491, 'dot_loss':     0.9408, 'ddot_loss':     2.1474, 'rew_loss':   229.6139, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.1717, 'eps_e':     0.3571, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.1717})
Step:   86000, Reward:    18.600 [  26.135], Avg:    -1.240 (0.561) <0-00:58:00> ({'r_t':  -515.5121, 'eps':     0.5612, 'loss':   195.2861, 'dyn_loss':   119.3197, 'dot_loss':     0.8959, 'ddot_loss':     2.0665, 'rew_loss':   228.9627, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.2079, 'eps_e':     0.5612, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.2079})
Step:   87000, Reward:    20.621 [  26.973], Avg:    -0.991 (0.765) <0-00:58:42> ({'r_t':  -520.5985, 'eps':     0.7653, 'loss':   195.2931, 'dyn_loss':   119.2901, 'dot_loss':     0.8673, 'ddot_loss':     2.0089, 'rew_loss':   229.7689, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.2722, 'eps_e':     0.7653, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.2722})
Step:   88000, Reward:    32.406 [   4.881], Avg:    -0.616 (0.969) <0-00:59:23> ({'r_t':  -577.5399, 'eps':     0.9694, 'loss':   195.5594, 'dyn_loss':   122.3257, 'dot_loss':     0.9150, 'ddot_loss':     2.1019, 'rew_loss':   228.7634, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.3249, 'eps_e':     0.9694, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.3249})
Step:   89000, Reward:    -6.779 [  35.901], Avg:    -0.685 (0.173) <0-01:00:06> ({'r_t':  -568.5127, 'eps':     0.1735, 'loss':   196.7527, 'dyn_loss':   115.2430, 'dot_loss':     0.8813, 'ddot_loss':     2.0540, 'rew_loss':   231.0781, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.3913, 'eps_e':     0.1735, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.3913})
Step:   90000, Reward:     4.828 [  33.568], Avg:    -0.624 (0.378) <0-01:00:49> ({'r_t':  -570.6608, 'eps':     0.3776, 'loss':   197.8356, 'dyn_loss':   118.4214, 'dot_loss':     0.8865, 'ddot_loss':     2.0437, 'rew_loss':   230.5813, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.4281, 'eps_e':     0.3776, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.4281})
Step:   91000, Reward:    28.530 [  12.795], Avg:    -0.307 (0.582) <0-01:01:31> ({'r_t':  -505.1978, 'eps':     0.5816, 'loss':   199.7568, 'dyn_loss':   131.7782, 'dot_loss':     0.8909, 'ddot_loss':     2.0713, 'rew_loss':   233.7460, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.4998, 'eps_e':     0.5816, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.4998})
Step:   92000, Reward:    30.521 [   8.902], Avg:     0.024 (0.786) <0-01:02:13> ({'r_t':  -544.0996, 'eps':     0.7857, 'loss':   199.1082, 'dyn_loss':   127.1212, 'dot_loss':     0.9083, 'ddot_loss':     2.1088, 'rew_loss':   231.6139, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.5630, 'eps_e':     0.7857, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.5630})
Step:   93000, Reward:    -8.265 [   7.891], Avg:    -0.064 (0.990) <0-01:02:54> ({'r_t':  -583.1715, 'eps':     0.9898, 'loss':   200.3702, 'dyn_loss':   118.6493, 'dot_loss':     0.9470, 'ddot_loss':     2.1719, 'rew_loss':   233.2030, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.6176, 'eps_e':     0.9898, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.6176})
Step:   94000, Reward:    16.985 [  27.444], Avg:     0.116 (0.194) <0-01:03:37> ({'r_t':  -599.9710, 'eps':     0.1939, 'loss':   199.9157, 'dyn_loss':   137.2502, 'dot_loss':     0.9160, 'ddot_loss':     2.1136, 'rew_loss':   234.0187, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.6950, 'eps_e':     0.1939, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.6950})
Step:   95000, Reward:    35.437 [   7.287], Avg:     0.483 (0.398) <0-01:04:18> ({'r_t':  -577.4283, 'eps':     0.3980, 'loss':   197.9018, 'dyn_loss':   128.8974, 'dot_loss':     0.9290, 'ddot_loss':     2.1369, 'rew_loss':   231.1023, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.7214, 'eps_e':     0.3980, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.7214})
Step:   96000, Reward:    32.498 [  26.130], Avg:     0.814 (0.602) <0-01:05:00> ({'r_t':  -527.3429, 'eps':     0.6020, 'loss':   199.3867, 'dyn_loss':   124.1571, 'dot_loss':     0.9136, 'ddot_loss':     2.1154, 'rew_loss':   230.5275, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.8043, 'eps_e':     0.6020, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.8043})
Step:   97000, Reward:    31.164 [   7.265], Avg:     1.123 (0.806) <0-01:05:42> ({'r_t':  -547.8885, 'eps':     0.8061, 'loss':   201.1864, 'dyn_loss':   126.3419, 'dot_loss':     0.9118, 'ddot_loss':     2.1463, 'rew_loss':   234.3846, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.8747, 'eps_e':     0.8061, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.8747})
Step:   98000, Reward:    20.297 [  19.615], Avg:     1.317 (0.010) <0-01:06:24> ({'r_t':  -528.0409, 'eps':     0.0102, 'loss':   199.7216, 'dyn_loss':   123.4152, 'dot_loss':     0.9373, 'ddot_loss':     2.1574, 'rew_loss':   232.0558, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.9276, 'eps_e':     0.0102, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.9276})
Step:   99000, Reward:    28.469 [  25.156], Avg:     1.588 (0.214) <0-01:07:06> ({'r_t':  -596.4900, 'eps':     0.2143, 'loss':   199.4720, 'dyn_loss':   124.8242, 'dot_loss':     0.9024, 'ddot_loss':     2.0949, 'rew_loss':   231.5801, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    97.9817, 'eps_e':     0.2143, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    97.9817})
Step:  100000, Reward:    22.342 [   9.835], Avg:     1.794 (0.111) <0-01:07:49> ({'r_t':  -556.0545, 'eps':     0.1111, 'loss':   199.2310, 'dyn_loss':   121.0861, 'dot_loss':     0.9347, 'ddot_loss':     2.1774, 'rew_loss':   231.0672, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.0543, 'eps_e':     0.1111, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.0543})
Step:  101000, Reward:    23.278 [   7.490], Avg:     2.005 (0.212) <0-01:08:31> ({'r_t':  -561.2147, 'eps':     0.2121, 'loss':   203.4264, 'dyn_loss':   129.1812, 'dot_loss':     0.9300, 'ddot_loss':     2.1700, 'rew_loss':   236.8701, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.1167, 'eps_e':     0.2121, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.1167})
Step:  102000, Reward:    19.841 [  14.944], Avg:     2.178 (0.313) <0-01:09:13> ({'r_t':  -553.2147, 'eps':     0.3131, 'loss':   200.8832, 'dyn_loss':   129.9581, 'dot_loss':     0.9498, 'ddot_loss':     2.2076, 'rew_loss':   232.5704, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.1877, 'eps_e':     0.3131, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.1877})
Step:  103000, Reward:    29.634 [  23.175], Avg:     2.442 (0.414) <0-01:09:55> ({'r_t':  -577.7289, 'eps':     0.4141, 'loss':   201.7102, 'dyn_loss':   130.4305, 'dot_loss':     0.9407, 'ddot_loss':     2.2012, 'rew_loss':   234.4602, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.2520, 'eps_e':     0.4141, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.2520})
Step:  104000, Reward:    33.674 [  12.731], Avg:     2.739 (0.515) <0-01:10:37> ({'r_t':  -510.2794, 'eps':     0.5152, 'loss':   206.2152, 'dyn_loss':   138.4487, 'dot_loss':     0.9369, 'ddot_loss':     2.1780, 'rew_loss':   238.9584, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.3061, 'eps_e':     0.5152, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.3061})
Step:  105000, Reward:    33.055 [   9.049], Avg:     3.025 (0.616) <0-01:11:19> ({'r_t':  -525.0914, 'eps':     0.6162, 'loss':   203.7624, 'dyn_loss':   128.3918, 'dot_loss':     0.8903, 'ddot_loss':     2.0887, 'rew_loss':   236.1315, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.3504, 'eps_e':     0.6162, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.3504})
Step:  106000, Reward:     2.473 [  31.888], Avg:     3.020 (0.717) <0-01:12:02> ({'r_t':  -511.3224, 'eps':     0.7172, 'loss':   203.3071, 'dyn_loss':   132.6425, 'dot_loss':     0.9293, 'ddot_loss':     2.1756, 'rew_loss':   235.4505, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.3952, 'eps_e':     0.7172, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.3952})
Step:  107000, Reward:    25.152 [  15.190], Avg:     3.225 (0.818) <0-01:12:44> ({'r_t':  -538.3734, 'eps':     0.8182, 'loss':   205.9430, 'dyn_loss':   130.6356, 'dot_loss':     0.9397, 'ddot_loss':     2.1942, 'rew_loss':   236.8751, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.4179, 'eps_e':     0.8182, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.4179})
Step:  108000, Reward:    26.585 [  14.916], Avg:     3.439 (0.919) <0-01:13:26> ({'r_t':  -542.5730, 'eps':     0.9192, 'loss':   201.2799, 'dyn_loss':   126.5940, 'dot_loss':     0.9413, 'ddot_loss':     2.2223, 'rew_loss':   232.9367, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.4850, 'eps_e':     0.9192, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.4850})
Step:  109000, Reward:    33.624 [   7.949], Avg:     3.714 (0.020) <0-01:14:07> ({'r_t':  -502.5799, 'eps':     0.0202, 'loss':   205.6141, 'dyn_loss':   124.6433, 'dot_loss':     0.9239, 'ddot_loss':     2.1520, 'rew_loss':   237.4770, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.5272, 'eps_e':     0.0202, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.5272})
Step:  110000, Reward:    15.257 [  35.001], Avg:     3.818 (0.121) <0-01:14:49> ({'r_t':  -550.0695, 'eps':     0.1212, 'loss':   206.0492, 'dyn_loss':   130.3738, 'dot_loss':     0.9356, 'ddot_loss':     2.1945, 'rew_loss':   237.8974, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.5518, 'eps_e':     0.1212, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.5518})
Step:  111000, Reward:    33.640 [   9.674], Avg:     4.084 (0.222) <0-01:15:31> ({'r_t':  -515.5712, 'eps':     0.2222, 'loss':   204.8835, 'dyn_loss':   133.2530, 'dot_loss':     0.9387, 'ddot_loss':     2.2351, 'rew_loss':   237.8983, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.5938, 'eps_e':     0.2222, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.5938})
Step:  112000, Reward:    32.329 [   7.990], Avg:     4.334 (0.323) <0-01:16:13> ({'r_t':  -498.1957, 'eps':     0.3232, 'loss':   205.2998, 'dyn_loss':   140.5966, 'dot_loss':     0.9693, 'ddot_loss':     2.2748, 'rew_loss':   238.0915, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.6364, 'eps_e':     0.3232, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.6364})
Step:  113000, Reward:    38.227 [   8.077], Avg:     4.631 (0.424) <0-01:16:55> ({'r_t':  -522.3102, 'eps':     0.4242, 'loss':   202.8576, 'dyn_loss':   122.0855, 'dot_loss':     0.9662, 'ddot_loss':     2.2596, 'rew_loss':   233.8094, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.6838, 'eps_e':     0.4242, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.6838})
Step:  114000, Reward:    33.627 [  29.302], Avg:     4.883 (0.525) <0-01:17:37> ({'r_t':  -568.9084, 'eps':     0.5253, 'loss':   206.5705, 'dyn_loss':   135.1938, 'dot_loss':     0.9240, 'ddot_loss':     2.1442, 'rew_loss':   239.7196, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.7146, 'eps_e':     0.5253, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.7146})
Step:  115000, Reward:    30.241 [  12.982], Avg:     5.102 (0.626) <0-01:18:20> ({'r_t':  -474.9404, 'eps':     0.6263, 'loss':   205.6873, 'dyn_loss':   135.3528, 'dot_loss':     0.8891, 'ddot_loss':     2.0835, 'rew_loss':   236.9528, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.7591, 'eps_e':     0.6263, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.7591})
Step:  116000, Reward:    13.582 [  28.543], Avg:     5.174 (0.727) <0-01:19:02> ({'r_t':  -532.1702, 'eps':     0.7273, 'loss':   205.2074, 'dyn_loss':   132.5625, 'dot_loss':     0.9231, 'ddot_loss':     2.1704, 'rew_loss':   237.2352, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.8089, 'eps_e':     0.7273, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.8089})
Step:  117000, Reward:    29.972 [  15.675], Avg:     5.385 (0.828) <0-01:19:45> ({'r_t':  -525.2624, 'eps':     0.8283, 'loss':   206.9542, 'dyn_loss':   129.6098, 'dot_loss':     0.9183, 'ddot_loss':     2.1468, 'rew_loss':   238.5186, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.8502, 'eps_e':     0.8283, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.8502})
Step:  118000, Reward:    29.172 [  18.621], Avg:     5.584 (0.929) <0-01:20:27> ({'r_t':  -532.3218, 'eps':     0.9293, 'loss':   203.4266, 'dyn_loss':   129.6560, 'dot_loss':     0.9038, 'ddot_loss':     2.0989, 'rew_loss':   235.4937, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.8974, 'eps_e':     0.9293, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.8974})
Step:  119000, Reward:    16.369 [  28.729], Avg:     5.674 (0.030) <0-01:21:08> ({'r_t':  -615.2138, 'eps':     0.0303, 'loss':   210.1065, 'dyn_loss':   137.6956, 'dot_loss':     0.9577, 'ddot_loss':     2.2205, 'rew_loss':   242.3310, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    98.9568, 'eps_e':     0.0303, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    98.9568})
Step:  120000, Reward:    35.271 [   4.988], Avg:     5.919 (0.010) <0-01:21:50> ({'r_t':  -528.5858, 'eps':     0.0100, 'loss':   206.4106, 'dyn_loss':   134.4807, 'dot_loss':     0.9020, 'ddot_loss':     2.1297, 'rew_loss':   239.0010, 'lr':     0.0001, 'len': 100000.0000, 'ep_len':    99.0092, 'eps_e':     0.0100, 'lr_e':     0.0001, 'len_e': 100000.0000, 'ep_len_e':    99.0092})
