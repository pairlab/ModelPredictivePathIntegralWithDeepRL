Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CarRacing-v1, Date: 09/06/2020 20:06:22
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 4571b990d7f93478b12bf210e69b8d83acfa7c38
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = None
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 2500
   TARGET_UPDATE_RATE = 0.0004
   TRAIN_EVERY = 5000
   BATCH_SIZE = 500
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 20
      LAMBDA = 0.1
      COV = 1
   dynamics_size = 13
   state_size = (80,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 1000000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.97
      PATIENCE = 100
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 1024
      REWARD_HIDDEN = 512
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fa42c5b0250> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7fa42c6e7e90>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7fa42c0b8dd0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7fa42c0b6c50> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7fa42c0b6890> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost
							# reward = progress + np.tanh(vy/self.vtarget) - cost
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_size = 13
			obs = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  2.000e-02  3.657e-01  4.017e-01  4.572e-01  5.260e-01  6.036e-01  2.700e-01  3.171e-01  3.850e-01  4.646e-01  5.509e-01  1.792e-01  2.444e-01  3.277e-01  4.184e-01  5.125e-01  1.063e-01  1.973e-01  2.942e-01  3.927e-01  4.918e-01  1.024e-01  1.953e-01  2.929e-01  3.917e-01  4.910e-01]
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 		return state
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.spec = next_spec
			
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7fa4ac2b2680>
					step = <function CarRacing.step at 0x7fa4ac2b25f0>
					render = <function CarRacing.render at 0x7fa4d6719b90>
					dynamics_spec = <staticmethod object at 0x7fa4ac2b0d90>
					track_spec = <function CarRacing.track_spec at 0x7fa4d6719cb0>
					observation = <function CarRacing.observation at 0x7fa4d6719d40>
					dynamics_keys = <staticmethod object at 0x7fa4ac2b0c90>
					observation_spec = <staticmethod object at 0x7fa4ac2b0cd0>
					close = <function CarRacing.close at 0x7fa4d6719ef0>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(80,) 
			dtype = float32
			shape = (80,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fa42c0b6610> 
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (80,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fa42c0b6bd0> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=131, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40246), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=132, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50616), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=133, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48560), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=134, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57754), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=135, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40834), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=136, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 39820), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=137, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33050), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=138, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40924), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=139, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51266), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=140, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33340), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=141, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45102), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=142, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34512), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=143, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34324), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=144, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 43206), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=145, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50116), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=146, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53704), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fa42c0b6650> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fa42c12dcd0> 
		state_size = (80,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fa42c12d410> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fa42c12ddd0> 
			size = (3,)
			dt = 0.2
			action = [-0.881 -0.786  1.000]
			daction_dt = [-1.772  1.506 -0.061]
		discrete = False
		action_size = (3,)
		state_size = (80,)
		config = <src.utils.config.Config object at 0x7fa4340fb9d0> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = None
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 2500
			TARGET_UPDATE_RATE = 0.0004
			TRAIN_EVERY = 5000
			BATCH_SIZE = 500
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fa4d67247d0> 
				NSAMPLES = 100
				HORIZON = 20
				LAMBDA = 0.1
				COV = 1
			dynamics_size = 13
			state_size = (80,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 1000000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fa4340e7dd0> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.97
				PATIENCE = 100
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 1024
				REWARD_HIDDEN = 512
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fa42c0e52d0> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fa42c0e50d0> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fa4340fb9d0> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = None
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 2500
				TARGET_UPDATE_RATE = 0.0004
				TRAIN_EVERY = 5000
				BATCH_SIZE = 500
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fa4d67247d0> 
					NSAMPLES = 100
					HORIZON = 20
					LAMBDA = 0.1
					COV = 1
				dynamics_size = 13
				state_size = (80,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 1000000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fa4340e7dd0> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.97
					PATIENCE = 100
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 1024
					REWARD_HIDDEN = 512
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fa42c0e5090> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=29, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=512, out_features=512, bias=True)
					    (linear4): Linear(in_features=512, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(29, 1024)
					    (linear1): Linear(in_features=1024, out_features=1024, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=1024, out_features=1024, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=1024, out_features=13, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fa42c0e5510> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fa4340fb9d0> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = None
						MAX_BUFFER_SIZE = 100000
						REPLAY_BATCH_SIZE = 2500
						TARGET_UPDATE_RATE = 0.0004
						TRAIN_EVERY = 5000
						BATCH_SIZE = 500
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fa4d67247d0> 
							NSAMPLES = 100
							HORIZON = 20
							LAMBDA = 0.1
							COV = 1
						dynamics_size = 13
						state_size = (80,)
						action_size = (3,)
						env_name = CarRacing-v1
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 1000000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fa4340e7dd0> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.97
							PATIENCE = 100
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 1024
							REWARD_HIDDEN = 512
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (80,)
					action_size = (3,)
					discrete = False
					dyn_index = 13
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa42c0e5a50>
			mu = [ 0.000  0.000  0.000]
			cov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			icov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			lamda = 0.1
			horizon = 20
			nsamples = 100
			action_size = (3,)
			control = [[[-0.216 -0.090 -0.492]
			  [-0.178 -0.522 -0.499]
			  [-0.767  0.165  0.525]
			  [-0.279 -0.085 -0.804]
			  [ 0.919 -0.295 -0.794]
			  [ 0.042  0.047  0.669]
			  [ 0.737  0.952  0.616]
			  [-0.337  0.588 -0.815]
			  [-0.174 -0.817 -0.860]
			  [-0.396  0.751 -0.456]
			  [ 0.406  0.539 -0.605]
			  [-0.883 -0.068 -0.903]
			  [ 0.969 -0.001  0.099]
			  [-0.996  0.866  0.492]
			  [-0.343  0.955  0.683]
			  [-0.467  0.828  0.110]
			  [ 0.990  0.996 -0.298]
			  [ 0.057  0.375 -0.573]
			  [-0.643  0.454 -0.293]
			  [ 0.485  0.543 -0.704]]]
			noise = [[[[-1.032  0.958 -0.431]
			   [ 1.071 -1.048  0.935]
			   [-0.642  0.906 -1.593]
			   ...
			   [-0.591 -1.259 -1.626]
			   [-2.557 -0.825  0.213]
			   [-0.847 -1.219  0.189]]
			
			  [[ 0.693  0.157 -0.440]
			   [-0.959  1.025 -1.821]
			   [ 0.021 -1.541 -0.474]
			   ...
			   [ 0.126 -1.158  1.225]
			   [ 1.566 -1.107  0.692]
			   [ 1.524  1.419  1.190]]
			
			  [[-0.219  1.818 -1.228]
			   [-0.994 -1.017  0.751]
			   [-0.200  0.873 -0.673]
			   ...
			   [-0.097  0.798  0.240]
			   [-0.379  0.795  0.805]
			   [ 0.578  0.089  0.116]]
			
			  ...
			
			  [[ 1.159 -0.692 -0.455]
			   [ 1.290  0.706 -0.274]
			   [-1.154  1.346  0.344]
			   ...
			   [ 0.412  0.463 -1.330]
			   [-1.583 -0.146 -0.011]
			   [-0.846  0.289  0.451]]
			
			  [[ 0.791 -1.814 -0.135]
			   [-0.342 -0.425  0.203]
			   [-0.628  0.614 -1.498]
			   ...
			   [-0.246  2.617 -0.020]
			   [ 0.818 -0.163 -1.378]
			   [ 1.840 -0.133 -0.174]]
			
			  [[ 0.167 -0.061 -0.939]
			   [ 0.219 -1.483 -0.261]
			   [-0.290 -0.908 -0.189]
			   ...
			   [ 2.629 -1.286 -0.966]
			   [ 0.529  1.446 -0.803]
			   [-0.383  0.690  0.798]]]]
			init_cost = [[ 0.129  0.065 -0.206 -0.057 -0.064 -0.053 -0.053 -0.502  0.201  0.163  0.129 -0.226  0.092  0.119 -0.361 -0.181  0.157  0.184  0.131 -0.077  0.124  0.064  0.133  0.079 -0.641  0.050 -0.081  0.025 -0.358 -0.054 -0.235 -0.128 -0.239  0.142  0.200  0.109 -0.020  0.227  0.054  0.022  0.103 -0.199  0.393  0.522  0.257  0.029  0.086 -0.744 -0.112  0.073 -0.039  0.140 -0.429 -0.215  0.073 -0.040 -0.049 -0.032  0.140  0.066  0.087  0.035  0.172  0.177 -0.074  0.014  0.225 -0.191  0.082  0.007 -0.146  0.355  0.603  0.434  0.381  0.018  0.171 -0.034  0.020  0.043  0.083 -0.287  0.299  0.169 -0.342 -0.058 -0.070 -0.310  0.427  0.066 -0.167 -0.031  0.049 -0.053 -0.225 -0.202  0.244 -0.367 -0.024  0.148]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fa42c0e5a90> 
			buffer = deque([], maxlen=100000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fa42c080290> 
		size = (3,)
		dt = 0.2
		action = [-1.000  0.479  1.000]
		daction_dt = [-0.893 -3.431  0.696]
	discrete = False
	action_size = (3,)
	state_size = (80,)
	config = <src.utils.config.Config object at 0x7fa4340fb9d0> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = None
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 2500
		TARGET_UPDATE_RATE = 0.0004
		TRAIN_EVERY = 5000
		BATCH_SIZE = 500
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fa4d67247d0> 
			NSAMPLES = 100
			HORIZON = 20
			LAMBDA = 0.1
			COV = 1
		dynamics_size = 13
		state_size = (80,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 1000000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fa4340e7dd0> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.97
			PATIENCE = 100
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 1024
			REWARD_HIDDEN = 512
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fa40dbad850> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		noise = self.noise[...,:horizon,:] * max(eps if eps else 0, 0.1)
		controls = np.clip(self.control[:,None,:horizon,:] + noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1) + self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control[...,:horizon,:] += np.sum(weights[:,:,None,None]*noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))/self.horizon

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: self.to_tensor(x)[None], zip(*buffer))
			buffer.clear()
			values = self.network.envmodel.value(actions, states, next_states)[0]
			rewards = self.compute_gae(0*values[-1], rewards.transpose(0,1), dones.transpose(0,1), values)[0].transpose(0,1)
			states, actions, next_states, rewards, dones = map(lambda x: x.cpu().numpy(), [states, actions, next_states, rewards, dones])
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.TRAIN_EVERY)/self.config.TRAIN_EVERY if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:   -66.861 [  26.840], Avg:   -66.861 (1.000) <0-00:00:00> ({'r_t':    -1.0359, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:   -69.925 [  25.526], Avg:   -68.393 (1.000) <0-00:00:31> ({'r_t': -1204.3273, 'eps':     1.0000, 'len':    45.8120, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward:   -60.489 [  11.525], Avg:   -65.758 (1.000) <0-00:00:59> ({'r_t': -1288.7296, 'eps':     1.0000, 'len':   140.3860, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward:   -57.298 [   8.315], Avg:   -63.643 (1.000) <0-00:01:25> ({'r_t': -1235.6547, 'eps':     1.0000, 'len':   245.7420, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward:   -70.038 [  26.595], Avg:   -64.922 (1.000) <0-00:02:00> ({'r_t': -1182.6835, 'eps':     1.0000, 'len':   346.8880, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward:   -75.736 [  41.512], Avg:   -66.725 (1.000) <0-00:02:33> ({'r_t': -1172.0281, 'eps':     1.0000, 'len':   455.9700, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward:   -72.260 [  27.422], Avg:   -67.515 (1.000) <0-00:03:05> ({'r_t': -1180.8002, 'eps':     1.0000, 'len':   560.0070, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward:   -56.505 [   9.408], Avg:   -66.139 (1.000) <0-00:03:33> ({'r_t': -1193.8108, 'eps':     1.0000, 'len':   661.9880, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward:   -54.405 [   7.332], Avg:   -64.835 (1.000) <0-00:04:01> ({'r_t': -1230.5423, 'eps':     1.0000, 'len':   760.0340, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward:   -61.578 [  16.032], Avg:   -64.510 (1.000) <0-00:04:28> ({'r_t': -1240.2299, 'eps':     1.0000, 'len':   858.7570, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward:   -67.356 [  18.944], Avg:   -64.768 (1.000) <0-00:04:59> ({'r_t': -1255.1045, 'eps':     1.0000, 'len':   954.3970, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward:   -69.155 [  36.613], Avg:   -65.134 (1.000) <0-00:05:33> ({'r_t': -1201.6769, 'eps':     1.0000, 'len':  1061.2330, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward:   -70.595 [  30.193], Avg:   -65.554 (1.000) <0-00:06:05> ({'r_t': -1223.0700, 'eps':     1.0000, 'len':  1167.9150, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   13000, Reward:   -59.515 [  11.837], Avg:   -65.123 (1.000) <0-00:06:33> ({'r_t': -1262.1463, 'eps':     1.0000, 'len':  1270.8950, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   14000, Reward:   -61.540 [  20.162], Avg:   -64.884 (1.000) <0-00:07:04> ({'r_t': -1285.9372, 'eps':     1.0000, 'len':  1367.0710, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   15000, Reward:   -68.494 [  27.183], Avg:   -65.109 (1.000) <0-00:07:36> ({'r_t': -1261.8382, 'eps':     1.0000, 'len':  1465.0250, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   16000, Reward:   -73.640 [  38.618], Avg:   -65.611 (1.000) <0-00:08:13> ({'r_t': -1189.0777, 'eps':     1.0000, 'len':  1566.3680, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   17000, Reward:   -62.651 [  18.868], Avg:   -65.447 (1.000) <0-00:08:44> ({'r_t': -1247.5075, 'eps':     1.0000, 'len':  1665.9980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   18000, Reward:   -59.257 [  10.207], Avg:   -65.121 (1.000) <0-00:09:11> ({'r_t': -1273.0933, 'eps':     1.0000, 'len':  1764.5590, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   19000, Reward:   -57.482 [   9.203], Avg:   -64.739 (1.000) <0-00:09:41> ({'r_t': -1205.6521, 'eps':     1.0000, 'len':  1861.9460, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   20000, Reward:   -63.654 [  16.275], Avg:   -64.687 (1.000) <0-00:10:11> ({'r_t': -1218.9161, 'eps':     1.0000, 'len':  1962.4510, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   21000, Reward:   -63.288 [  21.780], Avg:   -64.624 (1.000) <0-00:10:40> ({'r_t': -1217.7710, 'eps':     1.0000, 'len':  2055.9130, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   22000, Reward:   -61.085 [  19.407], Avg:   -64.470 (1.000) <0-00:11:09> ({'r_t': -1267.0494, 'eps':     1.0000, 'len':  2144.7330, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   23000, Reward:   -59.910 [  12.609], Avg:   -64.280 (1.000) <0-00:11:39> ({'r_t': -1265.5425, 'eps':     1.0000, 'len':  2244.0980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   24000, Reward:   -71.247 [  21.203], Avg:   -64.559 (1.000) <0-00:12:11> ({'r_t': -1259.7541, 'eps':     1.0000, 'len':  2340.6890, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   25000, Reward:   -69.652 [  34.055], Avg:   -64.754 (1.000) <0-00:12:45> ({'r_t': -1227.8243, 'eps':     1.0000, 'len':  2436.3120, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   26000, Reward:   -68.618 [  24.998], Avg:   -64.898 (1.000) <0-00:13:15> ({'r_t': -1285.1150, 'eps':     1.0000, 'len':  2534.4370, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   27000, Reward:   -66.967 [  21.416], Avg:   -64.971 (1.000) <0-00:13:43> ({'r_t': -1231.6731, 'eps':     1.0000, 'len':  2628.0980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   28000, Reward:   -67.084 [  20.428], Avg:   -65.044 (1.000) <0-00:14:14> ({'r_t': -1221.9261, 'eps':     1.0000, 'len':  2722.4270, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   29000, Reward:   -56.194 [   7.322], Avg:   -64.749 (1.000) <0-00:14:40> ({'r_t': -1224.7906, 'eps':     1.0000, 'len':  2830.8170, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   30000, Reward:   -46.973 [  32.562], Avg:   -64.176 (0.000) <0-00:16:17> ({'r_t': -1296.1846, 'eps':     0.0002, 'len':  2921.6030, 'dyn_loss':  1276.9038, 'dot_loss':    67.9073, 'ddot_loss':    23.5164, 'rew_loss':    82.0554, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   31000, Reward:   -28.407 [  48.321], Avg:   -63.058 (0.200) <0-00:17:51> ({'r_t':  -474.3311, 'eps':     0.2002, 'len':  3065.0190, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   32000, Reward:   -40.952 [  23.328], Avg:   -62.388 (0.400) <0-00:19:08> ({'r_t':  -515.1903, 'eps':     0.4002, 'len':  3251.6410, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   33000, Reward:   -49.246 [  31.000], Avg:   -62.002 (0.600) <0-00:20:10> ({'r_t':  -546.6811, 'eps':     0.6002, 'len':  3433.4400, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   34000, Reward:   -20.422 [  35.211], Avg:   -60.814 (0.800) <0-00:20:58> ({'r_t':  -683.6382, 'eps':     0.8002, 'len':  3593.1390, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   35000, Reward:   -91.552 [ 124.365], Avg:   -61.668 (0.000) <0-00:22:58> ({'r_t': -1177.3412, 'eps':     0.0002, 'len':  3714.8240, 'dyn_loss':   151.6144, 'dot_loss':    20.3371, 'ddot_loss':    16.2285, 'rew_loss':   115.3751, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   36000, Reward:  -156.552 [ 188.324], Avg:   -64.232 (0.200) <0-00:25:05> ({'r_t':  -628.6064, 'eps':     0.2002, 'len':  3809.6400, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   37000, Reward:  -144.022 [ 141.700], Avg:   -66.332 (0.400) <0-00:26:48> ({'r_t':  -691.5345, 'eps':     0.4002, 'len':  3892.8970, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   38000, Reward:  -113.994 [ 107.021], Avg:   -67.554 (0.600) <0-00:28:12> ({'r_t':  -823.1774, 'eps':     0.6002, 'len':  3973.8830, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   39000, Reward:  -135.777 [ 153.858], Avg:   -69.259 (0.800) <0-00:29:31> ({'r_t': -1066.9898, 'eps':     0.8002, 'len':  4050.7680, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   40000, Reward:   -40.270 [  20.201], Avg:   -68.552 (0.000) <0-00:31:12> ({'r_t': -1098.9963, 'eps':     0.0002, 'len':  4153.1490, 'dyn_loss':    95.9164, 'dot_loss':    14.2067, 'ddot_loss':    14.0812, 'rew_loss':   129.0755, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   41000, Reward:   -35.247 [  48.986], Avg:   -67.759 (0.200) <0-00:32:58> ({'r_t':  -365.9848, 'eps':     0.2002, 'len':  4263.2420, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   42000, Reward:   -32.412 [  36.516], Avg:   -66.937 (0.400) <0-00:34:23> ({'r_t':  -491.7501, 'eps':     0.4002, 'len':  4368.4290, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   43000, Reward:   -45.916 [  57.507], Avg:   -66.460 (0.600) <0-00:35:47> ({'r_t':  -755.4960, 'eps':     0.6002, 'len':  4465.3720, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   44000, Reward:   -61.601 [ 134.922], Avg:   -66.352 (0.800) <0-00:37:00> ({'r_t':  -767.9113, 'eps':     0.8002, 'len':  4557.7330, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   45000, Reward:   -82.170 [ 157.526], Avg:   -66.695 (0.000) <0-00:39:10> ({'r_t': -1171.6871, 'eps':     0.0002, 'len':  4661.3670, 'dyn_loss':    73.6213, 'dot_loss':    10.9548, 'ddot_loss':    12.4089, 'rew_loss':   138.4302, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   46000, Reward:   -28.952 [  19.262], Avg:   -65.892 (0.200) <0-00:40:49> ({'r_t':  -389.1495, 'eps':     0.2002, 'len':  4769.0880, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   47000, Reward:   -62.996 [  74.614], Avg:   -65.832 (0.400) <0-00:42:22> ({'r_t':  -621.6804, 'eps':     0.4002, 'len':  4881.7590, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   48000, Reward:  -105.466 [ 202.084], Avg:   -66.641 (0.600) <0-00:43:57> ({'r_t':  -666.2382, 'eps':     0.6002, 'len':  4980.8940, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   49000, Reward:   -39.974 [  37.988], Avg:   -66.108 (0.800) <0-00:44:48> ({'r_t':  -834.3941, 'eps':     0.8002, 'len':  5092.5870, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   50000, Reward:   -41.274 [  75.921], Avg:   -65.621 (0.000) <0-00:46:40> ({'r_t': -1169.6578, 'eps':     0.0002, 'len':  5204.7120, 'dyn_loss':    62.5138, 'dot_loss':     8.9750, 'ddot_loss':    11.0527, 'rew_loss':   152.4362, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   51000, Reward:   -81.277 [ 195.793], Avg:   -65.922 (0.200) <0-00:48:49> ({'r_t':  -298.3961, 'eps':     0.2002, 'len':  5319.3250, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   52000, Reward:   -42.101 [  73.667], Avg:   -65.472 (0.400) <0-00:50:18> ({'r_t':  -496.5088, 'eps':     0.4002, 'len':  5432.3750, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   53000, Reward:   -33.673 [  48.025], Avg:   -64.883 (0.600) <0-00:51:29> ({'r_t':  -558.4231, 'eps':     0.6002, 'len':  5535.1290, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   54000, Reward:   -17.588 [  15.008], Avg:   -64.024 (0.800) <0-00:52:18> ({'r_t':  -744.3517, 'eps':     0.8002, 'len':  5649.1080, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   55000, Reward:   -56.259 [  63.036], Avg:   -63.885 (0.000) <0-00:54:05> ({'r_t': -1054.5926, 'eps':     0.0002, 'len':  5762.3390, 'dyn_loss':    53.4990, 'dot_loss':     7.3719, 'ddot_loss':     9.7976, 'rew_loss':   152.4071, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   56000, Reward:   -36.696 [  34.700], Avg:   -63.408 (0.200) <0-00:55:50> ({'r_t':  -368.9797, 'eps':     0.2002, 'len':  5876.6200, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   57000, Reward:   -46.708 [  61.458], Avg:   -63.120 (0.400) <0-00:57:22> ({'r_t':  -388.8388, 'eps':     0.4002, 'len':  5983.7890, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   58000, Reward:   -66.670 [ 167.424], Avg:   -63.180 (0.600) <0-00:58:58> ({'r_t':  -456.9750, 'eps':     0.6002, 'len':  6090.8230, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   59000, Reward:   -54.370 [  75.132], Avg:   -63.033 (0.800) <0-01:00:00> ({'r_t':  -728.8131, 'eps':     0.8002, 'len':  6202.9240, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   60000, Reward:   -45.583 [  57.562], Avg:   -62.747 (0.000) <0-01:01:47> ({'r_t': -1101.0332, 'eps':     0.0002, 'len':  6318.5460, 'dyn_loss':    44.3394, 'dot_loss':     6.1516, 'ddot_loss':     8.6291, 'rew_loss':   146.5787, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   61000, Reward:   -57.502 [  99.057], Avg:   -62.663 (0.200) <0-01:03:43> ({'r_t':  -302.9955, 'eps':     0.2002, 'len':  6430.7690, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   62000, Reward:   -67.514 [ 129.787], Avg:   -62.740 (0.400) <0-01:05:34> ({'r_t':  -535.1449, 'eps':     0.4002, 'len':  6527.9370, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   63000, Reward:   -83.191 [ 147.785], Avg:   -63.059 (0.600) <0-01:07:10> ({'r_t':  -449.9014, 'eps':     0.6002, 'len':  6624.0340, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   64000, Reward:   -36.825 [  98.415], Avg:   -62.656 (0.800) <0-01:08:17> ({'r_t':  -675.6516, 'eps':     0.8002, 'len':  6733.4620, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   65000, Reward:   -33.973 [  34.883], Avg:   -62.221 (0.000) <0-01:10:00> ({'r_t': -1133.1086, 'eps':     0.0002, 'len':  6845.9430, 'dyn_loss':    36.5071, 'dot_loss':     5.2143, 'ddot_loss':     7.8963, 'rew_loss':   164.4981, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   66000, Reward:   -38.268 [  32.872], Avg:   -61.863 (0.200) <0-01:11:42> ({'r_t':  -430.4299, 'eps':     0.2002, 'len':  6954.4020, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   67000, Reward:   -40.976 [  44.835], Avg:   -61.556 (0.400) <0-01:13:09> ({'r_t':  -382.5893, 'eps':     0.4002, 'len':  7047.0850, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   68000, Reward:   -44.597 [  70.775], Avg:   -61.311 (0.600) <0-01:14:30> ({'r_t':  -300.7725, 'eps':     0.6002, 'len':  7157.2000, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   69000, Reward:   -73.642 [  99.603], Avg:   -61.487 (0.800) <0-01:15:49> ({'r_t':  -624.5826, 'eps':     0.8002, 'len':  7275.4220, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   70000, Reward:  -139.468 [  99.309], Avg:   -62.585 (0.000) <0-01:17:41> ({'r_t': -1111.4766, 'eps':     0.0002, 'len':  7387.9720, 'dyn_loss':    31.1464, 'dot_loss':     4.6124, 'ddot_loss':     7.3458, 'rew_loss':   154.4791, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   71000, Reward:  -158.780 [ 136.987], Avg:   -63.921 (0.200) <0-01:19:49> ({'r_t':  -939.2873, 'eps':     0.2002, 'len':  7484.1900, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   72000, Reward:  -174.744 [ 141.493], Avg:   -65.439 (0.400) <0-01:21:29> ({'r_t':  -883.2866, 'eps':     0.4002, 'len':  7550.3470, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   73000, Reward:  -127.284 [ 108.253], Avg:   -66.275 (0.600) <0-01:22:50> ({'r_t':  -664.3444, 'eps':     0.6002, 'len':  7624.4370, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   74000, Reward:  -158.284 [ 159.955], Avg:   -67.502 (0.800) <0-01:24:06> ({'r_t':  -566.8568, 'eps':     0.8002, 'len':  7737.0890, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   75000, Reward:   -79.738 [  74.888], Avg:   -67.663 (0.000) <0-01:26:03> ({'r_t': -1094.5928, 'eps':     0.0002, 'len':  7857.2860, 'dyn_loss':    30.2168, 'dot_loss':     4.3969, 'ddot_loss':     7.2676, 'rew_loss':   158.4252, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   76000, Reward:   -54.962 [  49.201], Avg:   -67.498 (0.200) <0-01:27:56> ({'r_t':  -400.5279, 'eps':     0.2002, 'len':  7950.0980, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   77000, Reward:  -108.028 [ 108.124], Avg:   -68.017 (0.400) <0-01:29:48> ({'r_t':  -574.6011, 'eps':     0.4002, 'len':  8023.7160, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   78000, Reward:  -124.850 [ 106.537], Avg:   -68.737 (0.600) <0-01:31:23> ({'r_t':  -432.9234, 'eps':     0.6002, 'len':  8091.0040, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   79000, Reward:   -79.048 [  79.552], Avg:   -68.866 (0.800) <0-01:32:34> ({'r_t':  -715.8936, 'eps':     0.8002, 'len':  8183.1450, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   80000, Reward:   -65.116 [  43.720], Avg:   -68.819 (0.000) <0-01:34:19> ({'r_t': -1114.5593, 'eps':     0.0002, 'len':  8291.8730, 'dyn_loss':    26.9269, 'dot_loss':     4.1549, 'ddot_loss':     7.1835, 'rew_loss':   153.3206, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   81000, Reward:   -54.395 [  55.637], Avg:   -68.643 (0.200) <0-01:36:06> ({'r_t':  -362.6556, 'eps':     0.2002, 'len':  8402.8810, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   82000, Reward:   -67.048 [  84.821], Avg:   -68.624 (0.400) <0-01:37:49> ({'r_t':   124.6300, 'eps':     0.4002, 'len':  8505.6230, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   83000, Reward:   -48.398 [  40.424], Avg:   -68.383 (0.600) <0-01:39:00> ({'r_t':   103.2803, 'eps':     0.6002, 'len':  8628.1690, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   84000, Reward:   -39.521 [  29.873], Avg:   -68.044 (0.800) <0-01:39:56> ({'r_t':  -512.5570, 'eps':     0.8002, 'len':  8750.1840, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   85000, Reward:   -36.997 [ 123.114], Avg:   -67.683 (0.000) <0-01:42:06> ({'r_t': -1057.0848, 'eps':     0.0002, 'len':  8864.0480, 'dyn_loss':    27.4227, 'dot_loss':     4.1647, 'ddot_loss':     7.3771, 'rew_loss':   169.2086, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   86000, Reward:   -44.312 [  83.604], Avg:   -67.414 (0.200) <0-01:43:53> ({'r_t':   -53.0304, 'eps':     0.2002, 'len':  8972.7100, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   87000, Reward:   -44.624 [  53.156], Avg:   -67.155 (0.400) <0-01:45:22> ({'r_t':    60.9830, 'eps':     0.4002, 'len':  9096.7280, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   88000, Reward:   -36.858 [  64.868], Avg:   -66.815 (0.600) <0-01:46:33> ({'r_t':   -73.1297, 'eps':     0.6002, 'len':  9222.2410, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   89000, Reward:   -33.264 [  55.340], Avg:   -66.442 (0.800) <0-01:47:30> ({'r_t':  -516.1031, 'eps':     0.8002, 'len':  9338.0540, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   90000, Reward:    25.075 [  33.407], Avg:   -65.436 (0.000) <0-01:49:08> ({'r_t': -1118.4422, 'eps':     0.0002, 'len':  9450.5380, 'dyn_loss':    26.1305, 'dot_loss':     4.1974, 'ddot_loss':     7.7601, 'rew_loss':   174.6033, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   91000, Reward:    31.646 [  37.386], Avg:   -64.381 (0.200) <0-01:50:45> ({'r_t':   147.1427, 'eps':     0.2002, 'len':  9568.4640, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   92000, Reward:     4.423 [  72.046], Avg:   -63.641 (0.400) <0-01:52:12> ({'r_t':   197.7061, 'eps':     0.4002, 'len':  9704.4160, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   93000, Reward:    -0.902 [ 113.466], Avg:   -62.974 (0.600) <0-01:53:31> ({'r_t':    49.4364, 'eps':     0.6002, 'len':  9840.9500, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   94000, Reward:    11.970 [  52.188], Avg:   -62.185 (0.800) <0-01:54:25> ({'r_t':  -524.0024, 'eps':     0.8002, 'len':  9976.4910, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:   95000, Reward:    71.144 [  41.209], Avg:   -60.796 (0.000) <0-01:56:04> ({'r_t': -1054.4070, 'eps':     0.0002, 'len': 10101.4150, 'dyn_loss':    24.3309, 'dot_loss':     4.2000, 'ddot_loss':     8.0286, 'rew_loss':   174.4783, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:   96000, Reward:    26.091 [  49.674], Avg:   -59.900 (0.200) <0-01:57:43> ({'r_t':   408.8510, 'eps':     0.2002, 'len': 10220.6000, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:   97000, Reward:    45.892 [  48.414], Avg:   -58.821 (0.400) <0-01:59:06> ({'r_t':   483.8823, 'eps':     0.4002, 'len': 10353.5820, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:   98000, Reward:    32.361 [  63.525], Avg:   -57.900 (0.600) <0-02:00:11> ({'r_t':   181.0773, 'eps':     0.6002, 'len': 10485.8370, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:   99000, Reward:    46.215 [  38.590], Avg:   -56.859 (0.800) <0-02:01:00> ({'r_t':  -555.0949, 'eps':     0.8002, 'len': 10608.7070, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  100000, Reward:    36.884 [  42.593], Avg:   -55.931 (0.000) <0-02:02:47> ({'r_t': -1120.6284, 'eps':     0.0002, 'len': 10714.0850, 'dyn_loss':    23.2840, 'dot_loss':     4.1491, 'ddot_loss':     8.2243, 'rew_loss':   179.2835, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  101000, Reward:    73.729 [  46.183], Avg:   -54.659 (0.200) <0-02:04:27> ({'r_t':   294.2004, 'eps':     0.2002, 'len': 10825.0250, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  102000, Reward:    53.018 [  44.415], Avg:   -53.614 (0.400) <0-02:05:49> ({'r_t':   346.1702, 'eps':     0.4002, 'len': 10949.6680, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  103000, Reward:    86.763 [  51.298], Avg:   -52.264 (0.600) <0-02:06:56> ({'r_t':   205.5471, 'eps':     0.6002, 'len': 11077.2270, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  104000, Reward:    59.502 [  51.620], Avg:   -51.200 (0.800) <0-02:07:46> ({'r_t':  -445.8397, 'eps':     0.8002, 'len': 11198.1930, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  105000, Reward:    89.208 [  49.144], Avg:   -49.875 (0.000) <0-02:09:32> ({'r_t': -1051.3013, 'eps':     0.0002, 'len': 11314.2810, 'dyn_loss':    23.1291, 'dot_loss':     4.1585, 'ddot_loss':     8.3976, 'rew_loss':   186.6050, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  106000, Reward:   109.253 [  18.450], Avg:   -48.388 (0.200) <0-02:11:11> ({'r_t':   535.6473, 'eps':     0.2002, 'len': 11416.4240, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  107000, Reward:    91.243 [  48.566], Avg:   -47.095 (0.400) <0-02:12:35> ({'r_t':   597.3462, 'eps':     0.4002, 'len': 11524.4770, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  108000, Reward:    96.740 [  39.508], Avg:   -45.776 (0.600) <0-02:13:41> ({'r_t':   318.1349, 'eps':     0.6002, 'len': 11637.9320, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  109000, Reward:    87.362 [  43.424], Avg:   -44.565 (0.800) <0-02:14:33> ({'r_t':  -454.9232, 'eps':     0.8002, 'len': 11757.0810, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  110000, Reward:    66.203 [  65.437], Avg:   -43.567 (0.000) <0-02:16:13> ({'r_t': -1072.3865, 'eps':     0.0002, 'len': 11873.9250, 'dyn_loss':    24.2475, 'dot_loss':     4.3249, 'ddot_loss':     8.8345, 'rew_loss':   187.1855, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  111000, Reward:    79.276 [  55.488], Avg:   -42.470 (0.200) <0-02:17:54> ({'r_t':   445.8494, 'eps':     0.2002, 'len': 11981.0080, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  112000, Reward:   105.056 [  40.112], Avg:   -41.165 (0.400) <0-02:19:17> ({'r_t':   563.8650, 'eps':     0.4002, 'len': 12087.8750, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  113000, Reward:    95.044 [  30.778], Avg:   -39.970 (0.600) <0-02:20:25> ({'r_t':   172.8040, 'eps':     0.6002, 'len': 12200.7500, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  114000, Reward:    69.275 [  60.444], Avg:   -39.020 (0.800) <0-02:21:15> ({'r_t':  -567.4947, 'eps':     0.8002, 'len': 12313.0480, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  115000, Reward:    91.790 [  32.775], Avg:   -37.892 (0.000) <0-02:22:54> ({'r_t': -1102.2526, 'eps':     0.0002, 'len': 12425.9800, 'dyn_loss':    22.3743, 'dot_loss':     4.2834, 'ddot_loss':     8.9594, 'rew_loss':   193.1064, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  116000, Reward:    79.545 [  55.464], Avg:   -36.889 (0.200) <0-02:24:38> ({'r_t':   590.7758, 'eps':     0.2002, 'len': 12535.6810, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  117000, Reward:    90.797 [  42.821], Avg:   -35.807 (0.400) <0-02:26:00> ({'r_t':   539.3112, 'eps':     0.4002, 'len': 12648.7070, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  118000, Reward:    80.629 [  50.077], Avg:   -34.828 (0.600) <0-02:27:08> ({'r_t':   158.3674, 'eps':     0.6002, 'len': 12757.7690, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  119000, Reward:    81.614 [  27.941], Avg:   -33.858 (0.800) <0-02:28:00> ({'r_t':  -571.2120, 'eps':     0.8002, 'len': 12862.8610, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  120000, Reward:    48.877 [  35.320], Avg:   -33.174 (0.000) <0-02:29:44> ({'r_t': -1109.7908, 'eps':     0.0002, 'len': 12977.8030, 'dyn_loss':    22.0804, 'dot_loss':     4.2848, 'ddot_loss':     9.0393, 'rew_loss':   196.0719, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  121000, Reward:    66.173 [  51.735], Avg:   -32.360 (0.200) <0-02:31:28> ({'r_t':   277.2762, 'eps':     0.2002, 'len': 13073.0610, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  122000, Reward:    49.229 [  47.322], Avg:   -31.696 (0.400) <0-02:32:57> ({'r_t':   260.5615, 'eps':     0.4002, 'len': 13160.8940, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  123000, Reward:    94.470 [  30.033], Avg:   -30.679 (0.600) <0-02:34:05> ({'r_t':   -66.1596, 'eps':     0.6002, 'len': 13253.4900, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  124000, Reward:    57.708 [  40.135], Avg:   -29.972 (0.800) <0-02:35:02> ({'r_t':  -606.5816, 'eps':     0.8002, 'len': 13350.9380, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  125000, Reward:    69.360 [  48.389], Avg:   -29.184 (0.000) <0-02:36:47> ({'r_t': -1132.8011, 'eps':     0.0002, 'len': 13455.7850, 'dyn_loss':    21.8168, 'dot_loss':     4.2388, 'ddot_loss':     9.0393, 'rew_loss':   202.9997, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  126000, Reward:    85.874 [  43.056], Avg:   -28.278 (0.200) <0-02:38:35> ({'r_t':   521.3794, 'eps':     0.2002, 'len': 13553.3770, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  127000, Reward:    87.512 [  32.883], Avg:   -27.373 (0.400) <0-02:40:03> ({'r_t':   525.2606, 'eps':     0.4002, 'len': 13655.7960, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  128000, Reward:    93.875 [  41.173], Avg:   -26.433 (0.600) <0-02:41:17> ({'r_t':   146.0206, 'eps':     0.6002, 'len': 13763.5500, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  129000, Reward:    81.076 [  24.741], Avg:   -25.606 (0.800) <0-02:42:10> ({'r_t':  -647.5715, 'eps':     0.8002, 'len': 13869.1760, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  130000, Reward:    71.520 [  62.824], Avg:   -24.865 (0.000) <0-02:43:51> ({'r_t': -1091.6729, 'eps':     0.0002, 'len': 13969.7590, 'dyn_loss':    20.5345, 'dot_loss':     4.0790, 'ddot_loss':     8.7396, 'rew_loss':   210.0040, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  131000, Reward:    77.825 [  54.893], Avg:   -24.087 (0.200) <0-02:45:32> ({'r_t':   546.8069, 'eps':     0.2002, 'len': 14068.3300, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  132000, Reward:    87.974 [  58.323], Avg:   -23.244 (0.400) <0-02:46:55> ({'r_t':   453.9029, 'eps':     0.4002, 'len': 14168.6780, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  133000, Reward:    72.888 [  82.861], Avg:   -22.527 (0.600) <0-02:48:05> ({'r_t':    59.1888, 'eps':     0.6002, 'len': 14271.3720, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  134000, Reward:    64.638 [  93.917], Avg:   -21.881 (0.800) <0-02:49:07> ({'r_t':  -611.3447, 'eps':     0.8002, 'len': 14374.5200, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  135000, Reward:    80.574 [  55.136], Avg:   -21.128 (0.000) <0-02:50:47> ({'r_t': -1131.0834, 'eps':     0.0002, 'len': 14491.9730, 'dyn_loss':    20.2673, 'dot_loss':     3.9842, 'ddot_loss':     8.5583, 'rew_loss':   206.1810, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  136000, Reward:    69.291 [  60.547], Avg:   -20.468 (0.200) <0-02:52:26> ({'r_t':   527.5284, 'eps':     0.2002, 'len': 14592.9050, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  137000, Reward:    82.543 [  45.970], Avg:   -19.721 (0.400) <0-02:53:52> ({'r_t':   508.8828, 'eps':     0.4002, 'len': 14685.9740, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  138000, Reward:    58.594 [  79.871], Avg:   -19.158 (0.600) <0-02:55:05> ({'r_t':    93.5739, 'eps':     0.6002, 'len': 14783.0730, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  139000, Reward:    75.281 [  66.637], Avg:   -18.483 (0.800) <0-02:56:03> ({'r_t':  -543.6295, 'eps':     0.8002, 'len': 14883.6190, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  140000, Reward:    51.341 [  76.984], Avg:   -17.988 (0.000) <0-02:57:47> ({'r_t': -1079.6670, 'eps':     0.0002, 'len': 14997.9560, 'dyn_loss':    19.8671, 'dot_loss':     3.9002, 'ddot_loss':     8.4026, 'rew_loss':   208.7574, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  141000, Reward:   115.007 [  36.351], Avg:   -17.051 (0.200) <0-02:59:30> ({'r_t':   510.8412, 'eps':     0.2002, 'len': 15095.9660, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  142000, Reward:   113.527 [  42.981], Avg:   -16.138 (0.400) <0-03:00:58> ({'r_t':   397.3620, 'eps':     0.4002, 'len': 15177.9150, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  143000, Reward:    69.288 [  78.267], Avg:   -15.545 (0.600) <0-03:02:20> ({'r_t':     1.1254, 'eps':     0.6002, 'len': 15263.8180, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  144000, Reward:    86.462 [  59.511], Avg:   -14.842 (0.800) <0-03:03:16> ({'r_t':  -550.3981, 'eps':     0.8002, 'len': 15367.0440, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  145000, Reward:    85.088 [  90.461], Avg:   -14.157 (0.000) <0-03:05:08> ({'r_t': -1066.7478, 'eps':     0.0002, 'len': 15477.0370, 'dyn_loss':    19.2303, 'dot_loss':     3.7725, 'ddot_loss':     8.1072, 'rew_loss':   203.8859, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  146000, Reward:   132.925 [  74.784], Avg:   -13.157 (0.200) <0-03:06:54> ({'r_t':   557.8662, 'eps':     0.2002, 'len': 15567.8620, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  147000, Reward:   141.397 [  53.863], Avg:   -12.112 (0.400) <0-03:08:20> ({'r_t':   453.5360, 'eps':     0.4002, 'len': 15640.4490, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  148000, Reward:   127.570 [ 122.488], Avg:   -11.175 (0.600) <0-03:09:32> ({'r_t':   181.8804, 'eps':     0.6002, 'len': 15727.0700, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  149000, Reward:   109.330 [  58.301], Avg:   -10.371 (0.800) <0-03:10:34> ({'r_t':  -529.6013, 'eps':     0.8002, 'len': 15825.5100, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  150000, Reward:    98.811 [ 102.860], Avg:    -9.648 (0.000) <0-03:12:27> ({'r_t': -1069.7080, 'eps':     0.0002, 'len': 15933.4910, 'dyn_loss':    19.9182, 'dot_loss':     3.7901, 'ddot_loss':     8.1488, 'rew_loss':   211.8155, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  151000, Reward:   167.053 [  34.998], Avg:    -8.486 (0.200) <0-03:14:13> ({'r_t':   644.5107, 'eps':     0.2002, 'len': 16023.9730, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  152000, Reward:   168.478 [  39.860], Avg:    -7.329 (0.400) <0-03:15:43> ({'r_t':   519.6051, 'eps':     0.4002, 'len': 16102.8530, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  153000, Reward:   134.027 [  71.991], Avg:    -6.411 (0.600) <0-03:16:56> ({'r_t':   118.4591, 'eps':     0.6002, 'len': 16189.4050, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  154000, Reward:   115.121 [  83.809], Avg:    -5.627 (0.800) <0-03:18:14> ({'r_t':  -518.7250, 'eps':     0.8002, 'len': 16289.5230, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  155000, Reward:   147.771 [  34.401], Avg:    -4.644 (0.000) <0-03:19:59> ({'r_t': -1108.3602, 'eps':     0.0002, 'len': 16396.3650, 'dyn_loss':    19.3379, 'dot_loss':     3.7212, 'ddot_loss':     8.0303, 'rew_loss':   217.0093, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  156000, Reward:   152.969 [  38.851], Avg:    -3.640 (0.200) <0-03:21:44> ({'r_t':   585.9511, 'eps':     0.2002, 'len': 16485.9570, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  157000, Reward:   158.385 [  40.844], Avg:    -2.615 (0.400) <0-03:23:09> ({'r_t':   593.2475, 'eps':     0.4002, 'len': 16570.0810, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  158000, Reward:   154.262 [  50.684], Avg:    -1.628 (0.600) <0-03:24:20> ({'r_t':    59.0103, 'eps':     0.6002, 'len': 16659.3260, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  159000, Reward:   137.122 [  57.426], Avg:    -0.761 (0.800) <0-03:25:20> ({'r_t':  -622.2178, 'eps':     0.8002, 'len': 16755.5650, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  160000, Reward:    98.391 [  50.286], Avg:    -0.145 (0.000) <0-03:27:09> ({'r_t': -1128.4744, 'eps':     0.0002, 'len': 16856.7100, 'dyn_loss':    18.4725, 'dot_loss':     3.6314, 'ddot_loss':     7.8311, 'rew_loss':   217.8334, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  161000, Reward:   111.479 [  48.937], Avg:     0.544 (0.200) <0-03:28:55> ({'r_t':   467.9126, 'eps':     0.2002, 'len': 16945.4300, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  162000, Reward:    76.232 [ 119.825], Avg:     1.008 (0.400) <0-03:30:44> ({'r_t':   342.5174, 'eps':     0.4002, 'len': 17014.2230, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  163000, Reward:    87.693 [  50.582], Avg:     1.537 (0.600) <0-03:31:58> ({'r_t':   -97.5479, 'eps':     0.6002, 'len': 17090.7940, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  164000, Reward:   107.510 [  47.593], Avg:     2.179 (0.800) <0-03:32:58> ({'r_t':  -586.9617, 'eps':     0.8002, 'len': 17184.7780, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  165000, Reward:   136.880 [  90.113], Avg:     2.991 (0.000) <0-03:34:42> ({'r_t': -1096.7394, 'eps':     0.0002, 'len': 17286.3060, 'dyn_loss':    18.3525, 'dot_loss':     3.6393, 'ddot_loss':     7.8492, 'rew_loss':   238.0887, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  166000, Reward:   187.045 [  58.522], Avg:     4.093 (0.200) <0-03:36:27> ({'r_t':   728.5065, 'eps':     0.2002, 'len': 17373.5000, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  167000, Reward:   154.303 [  68.487], Avg:     4.987 (0.400) <0-03:37:54> ({'r_t':   379.8962, 'eps':     0.4002, 'len': 17446.0770, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  168000, Reward:   139.370 [  80.285], Avg:     5.782 (0.600) <0-03:39:07> ({'r_t':    17.2964, 'eps':     0.6002, 'len': 17526.0990, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  169000, Reward:   135.244 [  99.184], Avg:     6.544 (0.800) <0-03:40:09> ({'r_t':  -546.3046, 'eps':     0.8002, 'len': 17624.8090, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  170000, Reward:    46.211 [  76.751], Avg:     6.776 (0.000) <0-03:42:07> ({'r_t': -1102.9666, 'eps':     0.0002, 'len': 17739.4290, 'dyn_loss':    18.1443, 'dot_loss':     3.4547, 'ddot_loss':     7.4038, 'rew_loss':   226.3466, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  171000, Reward:   112.444 [  75.393], Avg:     7.390 (0.200) <0-03:43:54> ({'r_t':   335.1436, 'eps':     0.2002, 'len': 17836.3980, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  172000, Reward:    73.903 [  68.839], Avg:     7.774 (0.400) <0-03:45:23> ({'r_t':   268.6599, 'eps':     0.4002, 'len': 17909.5070, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  173000, Reward:    48.506 [  63.352], Avg:     8.009 (0.600) <0-03:46:43> ({'r_t':  -110.3944, 'eps':     0.6002, 'len': 17988.6910, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  174000, Reward:    41.674 [  73.554], Avg:     8.201 (0.800) <0-03:47:43> ({'r_t':  -625.7426, 'eps':     0.8002, 'len': 18080.7230, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  175000, Reward:   117.052 [  82.108], Avg:     8.819 (0.000) <0-03:49:32> ({'r_t': -1096.4509, 'eps':     0.0002, 'len': 18183.9140, 'dyn_loss':    18.6372, 'dot_loss':     3.4669, 'ddot_loss':     7.3951, 'rew_loss':   232.2774, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  176000, Reward:   144.278 [  72.478], Avg:     9.585 (0.200) <0-03:51:21> ({'r_t':   490.3544, 'eps':     0.2002, 'len': 18266.5080, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  177000, Reward:   149.602 [  94.083], Avg:    10.371 (0.400) <0-03:52:56> ({'r_t':   413.6167, 'eps':     0.4002, 'len': 18331.1060, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  178000, Reward:   109.299 [ 108.418], Avg:    10.924 (0.600) <0-03:54:28> ({'r_t':    28.1720, 'eps':     0.6002, 'len': 18406.4360, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  179000, Reward:   128.817 [  69.404], Avg:    11.579 (0.800) <0-03:55:32> ({'r_t':  -570.3891, 'eps':     0.8002, 'len': 18493.2000, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  180000, Reward:   123.708 [ 108.190], Avg:    12.198 (0.000) <0-03:57:18> ({'r_t': -1103.7426, 'eps':     0.0002, 'len': 18601.6620, 'dyn_loss':    18.0109, 'dot_loss':     3.3856, 'ddot_loss':     7.2464, 'rew_loss':   241.4259, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  181000, Reward:   180.492 [  65.406], Avg:    13.123 (0.200) <0-03:59:02> ({'r_t':   833.2898, 'eps':     0.2002, 'len': 18691.6580, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  182000, Reward:   121.689 [  80.430], Avg:    13.716 (0.400) <0-04:00:29> ({'r_t':   579.9490, 'eps':     0.4002, 'len': 18762.8880, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  183000, Reward:   167.921 [  94.531], Avg:    14.554 (0.600) <0-04:01:45> ({'r_t':    44.2842, 'eps':     0.6002, 'len': 18839.7620, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  184000, Reward:   161.354 [ 100.846], Avg:    15.348 (0.800) <0-04:03:02> ({'r_t':  -565.8878, 'eps':     0.8002, 'len': 18930.7530, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  185000, Reward:   178.531 [  71.151], Avg:    16.225 (0.000) <0-04:04:50> ({'r_t': -1134.4898, 'eps':     0.0002, 'len': 19029.0730, 'dyn_loss':    19.0148, 'dot_loss':     3.4310, 'ddot_loss':     7.3016, 'rew_loss':   242.2465, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  186000, Reward:   164.617 [  81.040], Avg:    17.019 (0.200) <0-04:06:39> ({'r_t':   852.9820, 'eps':     0.2002, 'len': 19110.2460, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  187000, Reward:   184.033 [  83.447], Avg:    17.907 (0.400) <0-04:08:10> ({'r_t':   540.5965, 'eps':     0.4002, 'len': 19181.6920, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  188000, Reward:   180.708 [  77.192], Avg:    18.769 (0.600) <0-04:09:23> ({'r_t':    58.6583, 'eps':     0.6002, 'len': 19255.3030, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  189000, Reward:   188.216 [  68.748], Avg:    19.660 (0.800) <0-04:10:20> ({'r_t':  -663.3869, 'eps':     0.8002, 'len': 19335.5840, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  190000, Reward:    30.256 [  94.138], Avg:    19.716 (0.000) <0-04:12:15> ({'r_t': -1147.7466, 'eps':     0.0002, 'len': 19436.7090, 'dyn_loss':    18.0846, 'dot_loss':     3.2769, 'ddot_loss':     6.9873, 'rew_loss':   239.0966, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  191000, Reward:    94.746 [ 103.440], Avg:    20.107 (0.200) <0-04:14:15> ({'r_t':   384.7971, 'eps':     0.2002, 'len': 19522.6970, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  192000, Reward:    62.538 [  98.531], Avg:    20.327 (0.400) <0-04:15:51> ({'r_t':   371.9040, 'eps':     0.4002, 'len': 19589.9970, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  193000, Reward:   123.689 [  52.396], Avg:    20.859 (0.600) <0-04:17:06> ({'r_t':   -57.6480, 'eps':     0.6002, 'len': 19662.4320, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  194000, Reward:    49.709 [  94.348], Avg:    21.007 (0.800) <0-04:18:09> ({'r_t':  -540.8792, 'eps':     0.8002, 'len': 19748.5480, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  195000, Reward:   179.566 [  47.742], Avg:    21.816 (0.000) <0-04:20:01> ({'r_t': -1084.9375, 'eps':     0.0002, 'len': 19850.5220, 'dyn_loss':    17.7739, 'dot_loss':     3.1730, 'ddot_loss':     6.7673, 'rew_loss':   246.4551, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  196000, Reward:   209.654 [  61.489], Avg:    22.770 (0.200) <0-04:21:46> ({'r_t':   887.6410, 'eps':     0.2002, 'len': 19938.4670, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  197000, Reward:   215.446 [  45.330], Avg:    23.743 (0.400) <0-04:23:15> ({'r_t':   577.9555, 'eps':     0.4002, 'len': 20006.8300, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  198000, Reward:   200.956 [  61.142], Avg:    24.633 (0.600) <0-04:24:29> ({'r_t':   105.8581, 'eps':     0.6002, 'len': 20075.0050, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  199000, Reward:   190.693 [  98.259], Avg:    25.464 (0.800) <0-04:25:33> ({'r_t':  -571.9521, 'eps':     0.8002, 'len': 20155.8350, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  200000, Reward:   198.791 [  94.162], Avg:    26.326 (0.000) <0-04:27:25> ({'r_t': -1162.6096, 'eps':     0.0002, 'len': 20251.2030, 'dyn_loss':    18.9928, 'dot_loss':     3.3230, 'ddot_loss':     7.0495, 'rew_loss':   256.8399, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  201000, Reward:   243.947 [  82.739], Avg:    27.403 (0.200) <0-04:29:11> ({'r_t':   922.8934, 'eps':     0.2002, 'len': 20330.1770, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  202000, Reward:   263.560 [  23.032], Avg:    28.567 (0.400) <0-04:30:40> ({'r_t':   590.6905, 'eps':     0.4002, 'len': 20395.2790, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  203000, Reward:   218.076 [ 101.887], Avg:    29.496 (0.600) <0-04:31:53> ({'r_t':   -62.9727, 'eps':     0.6002, 'len': 20462.8920, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  204000, Reward:   245.707 [  28.153], Avg:    30.550 (0.800) <0-04:32:51> ({'r_t':  -639.7069, 'eps':     0.8002, 'len': 20545.6840, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  205000, Reward:   238.026 [  94.111], Avg:    31.557 (0.000) <0-04:34:45> ({'r_t': -1099.6568, 'eps':     0.0002, 'len': 20640.2030, 'dyn_loss':    18.2157, 'dot_loss':     3.2200, 'ddot_loss':     6.8190, 'rew_loss':   257.6966, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  206000, Reward:   310.612 [  16.652], Avg:    32.906 (0.200) <0-04:36:31> ({'r_t':   992.2160, 'eps':     0.2002, 'len': 20723.3050, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  207000, Reward:   273.369 [  61.393], Avg:    34.062 (0.400) <0-04:38:08> ({'r_t':   632.1459, 'eps':     0.4002, 'len': 20785.9690, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  208000, Reward:   275.652 [  56.699], Avg:    35.218 (0.600) <0-04:39:30> ({'r_t':    -6.4481, 'eps':     0.6002, 'len': 20849.4930, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  209000, Reward:   219.560 [ 128.441], Avg:    36.095 (0.800) <0-04:40:30> ({'r_t':  -606.7981, 'eps':     0.8002, 'len': 20931.6730, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  210000, Reward:   218.578 [ 109.721], Avg:    36.960 (0.000) <0-04:42:28> ({'r_t': -1125.6270, 'eps':     0.0002, 'len': 21025.9960, 'dyn_loss':    17.0536, 'dot_loss':     3.0897, 'ddot_loss':     6.5932, 'rew_loss':   268.4717, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  211000, Reward:   286.960 [  47.797], Avg:    38.140 (0.200) <0-04:44:17> ({'r_t':   791.0520, 'eps':     0.2002, 'len': 21110.1910, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  212000, Reward:   253.652 [  63.760], Avg:    39.151 (0.400) <0-04:45:53> ({'r_t':   698.9896, 'eps':     0.4002, 'len': 21173.0580, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  213000, Reward:   279.603 [  62.245], Avg:    40.275 (0.600) <0-04:47:09> ({'r_t':   -13.4436, 'eps':     0.6002, 'len': 21236.3650, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  214000, Reward:   208.589 [  85.940], Avg:    41.058 (0.800) <0-04:48:11> ({'r_t':  -542.6012, 'eps':     0.8002, 'len': 21313.2220, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  215000, Reward:   236.131 [  84.368], Avg:    41.961 (0.000) <0-04:50:14> ({'r_t': -1168.8611, 'eps':     0.0002, 'len': 21410.6420, 'dyn_loss':    16.7765, 'dot_loss':     3.1235, 'ddot_loss':     6.6914, 'rew_loss':   272.2749, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  216000, Reward:   230.149 [ 126.701], Avg:    42.828 (0.200) <0-04:52:08> ({'r_t':   805.2838, 'eps':     0.2002, 'len': 21490.6570, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  217000, Reward:   236.623 [ 119.065], Avg:    43.717 (0.400) <0-04:53:39> ({'r_t':   610.8127, 'eps':     0.4002, 'len': 21551.2880, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  218000, Reward:   219.922 [ 119.148], Avg:    44.522 (0.600) <0-04:54:59> ({'r_t':   -11.0902, 'eps':     0.6002, 'len': 21610.7540, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  219000, Reward:   208.877 [ 104.809], Avg:    45.269 (0.800) <0-04:56:03> ({'r_t':  -648.5020, 'eps':     0.8002, 'len': 21685.5170, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  220000, Reward:   164.123 [ 130.238], Avg:    45.807 (0.000) <0-04:58:03> ({'r_t': -1081.4036, 'eps':     0.0002, 'len': 21780.6740, 'dyn_loss':    16.4392, 'dot_loss':     2.9674, 'ddot_loss':     6.3371, 'rew_loss':   266.0386, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  221000, Reward:   178.468 [ 102.182], Avg:    46.404 (0.200) <0-05:00:01> ({'r_t':   741.1793, 'eps':     0.2002, 'len': 21857.2390, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  222000, Reward:   197.078 [  99.167], Avg:    47.080 (0.400) <0-05:01:41> ({'r_t':   632.0756, 'eps':     0.4002, 'len': 21912.5900, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  223000, Reward:   194.887 [  92.766], Avg:    47.740 (0.600) <0-05:03:04> ({'r_t':   -14.2295, 'eps':     0.6002, 'len': 21971.5830, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  224000, Reward:   159.599 [ 117.328], Avg:    48.237 (0.800) <0-05:04:10> ({'r_t':  -650.0680, 'eps':     0.8002, 'len': 22048.4390, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  225000, Reward:   185.618 [  96.549], Avg:    48.845 (0.000) <0-05:06:09> ({'r_t': -1112.2355, 'eps':     0.0002, 'len': 22145.4870, 'dyn_loss':    17.0035, 'dot_loss':     3.0034, 'ddot_loss':     6.3882, 'rew_loss':   265.5345, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  226000, Reward:   201.750 [ 126.086], Avg:    49.518 (0.200) <0-05:07:59> ({'r_t':   765.3021, 'eps':     0.2002, 'len': 22231.4040, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  227000, Reward:   204.948 [ 108.401], Avg:    50.200 (0.400) <0-05:09:38> ({'r_t':   623.6273, 'eps':     0.4002, 'len': 22289.4070, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  228000, Reward:   227.536 [  86.496], Avg:    50.974 (0.600) <0-05:10:57> ({'r_t':    16.7763, 'eps':     0.6002, 'len': 22350.5160, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  229000, Reward:   161.777 [ 133.617], Avg:    51.456 (0.800) <0-05:12:09> ({'r_t':  -618.8123, 'eps':     0.8002, 'len': 22423.9700, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  230000, Reward:   187.308 [ 101.044], Avg:    52.044 (0.000) <0-05:14:12> ({'r_t': -1127.0847, 'eps':     0.0002, 'len': 22517.1560, 'dyn_loss':    16.9508, 'dot_loss':     2.9923, 'ddot_loss':     6.3498, 'rew_loss':   263.3448, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  231000, Reward:   241.414 [  88.877], Avg:    52.860 (0.200) <0-05:16:06> ({'r_t':   742.7864, 'eps':     0.2002, 'len': 22598.5430, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  232000, Reward:   237.855 [  94.273], Avg:    53.654 (0.400) <0-05:17:44> ({'r_t':   522.6694, 'eps':     0.4002, 'len': 22660.6130, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  233000, Reward:   185.411 [ 122.874], Avg:    54.217 (0.600) <0-05:19:06> ({'r_t':  -126.6178, 'eps':     0.6002, 'len': 22726.2450, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  234000, Reward:   176.216 [ 118.460], Avg:    54.737 (0.800) <0-05:20:11> ({'r_t':  -626.3230, 'eps':     0.8002, 'len': 22804.3880, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  235000, Reward:   178.633 [ 137.539], Avg:    55.262 (0.000) <0-05:22:10> ({'r_t': -1106.0940, 'eps':     0.0002, 'len': 22903.3810, 'dyn_loss':    16.9588, 'dot_loss':     2.9127, 'ddot_loss':     6.1736, 'rew_loss':   270.0808, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  236000, Reward:   238.110 [  86.544], Avg:    56.033 (0.200) <0-05:24:05> ({'r_t':   799.3483, 'eps':     0.2002, 'len': 22995.2600, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  237000, Reward:   181.243 [ 129.199], Avg:    56.559 (0.400) <0-05:25:40> ({'r_t':   513.8555, 'eps':     0.4002, 'len': 23054.9130, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  238000, Reward:   210.096 [ 107.326], Avg:    57.202 (0.600) <0-05:27:00> ({'r_t':   -78.2856, 'eps':     0.6002, 'len': 23114.5600, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  239000, Reward:   175.185 [ 131.667], Avg:    57.693 (0.800) <0-05:28:03> ({'r_t':  -583.0255, 'eps':     0.8002, 'len': 23190.2060, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  240000, Reward:   113.475 [ 138.754], Avg:    57.925 (0.000) <0-05:30:06> ({'r_t': -1073.5736, 'eps':     0.0002, 'len': 23294.2510, 'dyn_loss':    16.6537, 'dot_loss':     2.9484, 'ddot_loss':     6.2674, 'rew_loss':   267.1919, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  241000, Reward:   205.248 [  75.568], Avg:    58.533 (0.200) <0-05:32:00> ({'r_t':   697.9931, 'eps':     0.2002, 'len': 23376.4560, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  242000, Reward:   209.124 [  76.264], Avg:    59.153 (0.400) <0-05:33:37> ({'r_t':   479.9876, 'eps':     0.4002, 'len': 23429.5470, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  243000, Reward:   187.825 [  94.387], Avg:    59.681 (0.600) <0-05:34:59> ({'r_t':   -39.5536, 'eps':     0.6002, 'len': 23484.6600, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  244000, Reward:   188.071 [  97.294], Avg:    60.205 (0.800) <0-05:36:05> ({'r_t':  -694.6851, 'eps':     0.8002, 'len': 23555.5170, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  245000, Reward:   228.489 [  38.198], Avg:    60.889 (0.000) <0-05:38:07> ({'r_t': -1124.9403, 'eps':     0.0002, 'len': 23649.5550, 'dyn_loss':    15.6633, 'dot_loss':     2.8110, 'ddot_loss':     6.0136, 'rew_loss':   273.2629, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  246000, Reward:   219.221 [  41.312], Avg:    61.530 (0.200) <0-05:39:59> ({'r_t':   784.0146, 'eps':     0.2002, 'len': 23727.2900, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  247000, Reward:   224.968 [  48.965], Avg:    62.189 (0.400) <0-05:41:34> ({'r_t':   399.6109, 'eps':     0.4002, 'len': 23778.5950, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  248000, Reward:   233.335 [  45.154], Avg:    62.876 (0.600) <0-05:42:54> ({'r_t':   -66.2969, 'eps':     0.6002, 'len': 23835.2340, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  249000, Reward:   242.188 [  32.922], Avg:    63.593 (0.800) <0-05:43:58> ({'r_t':  -681.3271, 'eps':     0.8002, 'len': 23906.9770, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  250000, Reward:   216.167 [  60.878], Avg:    64.201 (0.000) <0-05:45:59> ({'r_t': -1061.9388, 'eps':     0.0002, 'len': 24007.5620, 'dyn_loss':    16.1203, 'dot_loss':     2.8087, 'ddot_loss':     5.9659, 'rew_loss':   276.8999, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  251000, Reward:   257.817 [  34.938], Avg:    64.969 (0.200) <0-05:47:48> ({'r_t':   872.5322, 'eps':     0.2002, 'len': 24090.0340, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  252000, Reward:   240.417 [  45.522], Avg:    65.663 (0.400) <0-05:49:22> ({'r_t':   431.3012, 'eps':     0.4002, 'len': 24144.8310, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  253000, Reward:   223.721 [  91.485], Avg:    66.285 (0.600) <0-05:50:44> ({'r_t':   -60.5072, 'eps':     0.6002, 'len': 24201.0620, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  254000, Reward:   252.511 [  33.803], Avg:    67.015 (0.800) <0-05:51:46> ({'r_t':  -684.8491, 'eps':     0.8002, 'len': 24270.4060, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  255000, Reward:   176.672 [  64.620], Avg:    67.444 (0.000) <0-05:53:51> ({'r_t': -1139.6892, 'eps':     0.0002, 'len': 24360.5280, 'dyn_loss':    15.7237, 'dot_loss':     2.8333, 'ddot_loss':     6.0652, 'rew_loss':   279.6686, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  256000, Reward:   170.060 [  78.113], Avg:    67.843 (0.200) <0-05:55:47> ({'r_t':   726.7706, 'eps':     0.2002, 'len': 24439.0390, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  257000, Reward:   191.265 [  46.503], Avg:    68.322 (0.400) <0-05:57:30> ({'r_t':   387.2357, 'eps':     0.4002, 'len': 24497.0920, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  258000, Reward:   151.255 [ 111.658], Avg:    68.642 (0.600) <0-05:58:55> ({'r_t':  -173.6181, 'eps':     0.6002, 'len': 24554.1250, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  259000, Reward:   120.876 [ 100.179], Avg:    68.843 (0.800) <0-06:00:03> ({'r_t':  -647.7767, 'eps':     0.8002, 'len': 24622.6930, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  260000, Reward:   189.105 [  92.876], Avg:    69.303 (0.000) <0-06:02:06> ({'r_t': -1119.3455, 'eps':     0.0002, 'len': 24718.8190, 'dyn_loss':    15.4187, 'dot_loss':     2.7178, 'ddot_loss':     5.8134, 'rew_loss':   281.2083, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  261000, Reward:   222.463 [  79.913], Avg:    69.888 (0.200) <0-06:03:59> ({'r_t':   736.2491, 'eps':     0.2002, 'len': 24802.6290, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  262000, Reward:   204.405 [  97.937], Avg:    70.399 (0.400) <0-06:05:33> ({'r_t':   448.8210, 'eps':     0.4002, 'len': 24857.4850, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  263000, Reward:   210.241 [ 100.699], Avg:    70.929 (0.600) <0-06:06:51> ({'r_t':  -151.0939, 'eps':     0.6002, 'len': 24912.7770, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  264000, Reward:   159.607 [ 123.684], Avg:    71.264 (0.800) <0-06:07:55> ({'r_t':  -648.8524, 'eps':     0.8002, 'len': 24983.6450, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  265000, Reward:   251.465 [  32.884], Avg:    71.941 (0.000) <0-06:09:57> ({'r_t': -1128.5702, 'eps':     0.0002, 'len': 25078.8000, 'dyn_loss':    15.4430, 'dot_loss':     2.7507, 'ddot_loss':     5.8593, 'rew_loss':   282.1848, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  266000, Reward:   248.889 [  43.527], Avg:    72.604 (0.200) <0-06:11:51> ({'r_t':   723.9576, 'eps':     0.2002, 'len': 25166.4770, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  267000, Reward:   246.211 [  48.415], Avg:    73.252 (0.400) <0-06:13:27> ({'r_t':   438.7346, 'eps':     0.4002, 'len': 25217.4320, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  268000, Reward:   231.348 [  47.833], Avg:    73.839 (0.600) <0-06:14:51> ({'r_t':   -61.5220, 'eps':     0.6002, 'len': 25274.3610, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  269000, Reward:   234.636 [  35.800], Avg:    74.435 (0.800) <0-06:15:58> ({'r_t':  -674.8118, 'eps':     0.8002, 'len': 25343.3180, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  270000, Reward:   246.861 [  48.227], Avg:    75.071 (0.000) <0-06:18:03> ({'r_t': -1101.3369, 'eps':     0.0002, 'len': 25441.0610, 'dyn_loss':    15.4018, 'dot_loss':     2.6683, 'ddot_loss':     5.6786, 'rew_loss':   289.2022, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  271000, Reward:   250.511 [  35.729], Avg:    75.716 (0.200) <0-06:19:56> ({'r_t':   738.8972, 'eps':     0.2002, 'len': 25522.1870, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  272000, Reward:   275.112 [  47.269], Avg:    76.447 (0.400) <0-06:21:30> ({'r_t':   478.4440, 'eps':     0.4002, 'len': 25574.6690, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  273000, Reward:   244.989 [  82.925], Avg:    77.062 (0.600) <0-06:22:49> ({'r_t':  -125.5594, 'eps':     0.6002, 'len': 25628.1980, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  274000, Reward:   219.101 [ 107.846], Avg:    77.578 (0.800) <0-06:23:52> ({'r_t':  -687.9312, 'eps':     0.8002, 'len': 25693.3990, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  275000, Reward:   276.301 [  23.866], Avg:    78.298 (0.000) <0-06:25:55> ({'r_t': -1116.3004, 'eps':     0.0002, 'len': 25783.0030, 'dyn_loss':    14.8001, 'dot_loss':     2.6126, 'ddot_loss':     5.5752, 'rew_loss':   279.0447, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  276000, Reward:   311.831 [  34.018], Avg:    79.141 (0.200) <0-06:27:45> ({'r_t':   963.4147, 'eps':     0.2002, 'len': 25860.1470, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  277000, Reward:   303.027 [  28.543], Avg:    79.947 (0.400) <0-06:29:18> ({'r_t':   594.7813, 'eps':     0.4002, 'len': 25913.6140, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  278000, Reward:   297.354 [  25.114], Avg:    80.726 (0.600) <0-06:30:35> ({'r_t':   -48.8071, 'eps':     0.6002, 'len': 25966.3840, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  279000, Reward:   301.369 [  26.551], Avg:    81.514 (0.800) <0-06:31:37> ({'r_t':  -684.0280, 'eps':     0.8002, 'len': 26037.8140, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  280000, Reward:   266.197 [  34.152], Avg:    82.171 (0.000) <0-06:33:39> ({'r_t': -1168.1319, 'eps':     0.0002, 'len': 26126.2710, 'dyn_loss':    14.1947, 'dot_loss':     2.5820, 'ddot_loss':     5.5330, 'rew_loss':   284.8556, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  281000, Reward:   265.845 [  35.929], Avg:    82.823 (0.200) <0-06:35:31> ({'r_t':   729.4785, 'eps':     0.2002, 'len': 26200.1080, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  282000, Reward:   275.748 [  33.404], Avg:    83.504 (0.400) <0-06:37:05> ({'r_t':   512.5308, 'eps':     0.4002, 'len': 26252.4130, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  283000, Reward:   267.850 [  35.319], Avg:    84.153 (0.600) <0-06:38:24> ({'r_t':   -31.0825, 'eps':     0.6002, 'len': 26308.5410, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  284000, Reward:   239.307 [  82.134], Avg:    84.698 (0.800) <0-06:39:26> ({'r_t':  -668.4505, 'eps':     0.8002, 'len': 26382.5720, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  285000, Reward:   247.839 [  30.768], Avg:    85.268 (0.000) <0-06:41:31> ({'r_t': -1059.5249, 'eps':     0.0002, 'len': 26480.6700, 'dyn_loss':    15.6767, 'dot_loss':     2.5850, 'ddot_loss':     5.4865, 'rew_loss':   284.6772, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  286000, Reward:   255.807 [  38.645], Avg:    85.862 (0.200) <0-06:43:25> ({'r_t':   707.6007, 'eps':     0.2002, 'len': 26559.5270, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  287000, Reward:   262.331 [  37.564], Avg:    86.475 (0.400) <0-06:45:00> ({'r_t':   549.9924, 'eps':     0.4002, 'len': 26610.0320, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  288000, Reward:   224.607 [  78.049], Avg:    86.953 (0.600) <0-06:46:19> ({'r_t':   -61.9884, 'eps':     0.6002, 'len': 26663.0600, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  289000, Reward:   241.295 [  39.280], Avg:    87.485 (0.800) <0-06:47:23> ({'r_t':  -637.3528, 'eps':     0.8002, 'len': 26729.9130, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  290000, Reward:   178.560 [  95.816], Avg:    87.798 (0.000) <0-06:49:32> ({'r_t': -1135.2413, 'eps':     0.0002, 'len': 26821.5350, 'dyn_loss':    14.3578, 'dot_loss':     2.4901, 'ddot_loss':     5.3270, 'rew_loss':   288.9171, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  291000, Reward:   216.802 [  50.326], Avg:    88.240 (0.200) <0-06:51:28> ({'r_t':   686.7443, 'eps':     0.2002, 'len': 26900.4300, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  292000, Reward:   234.081 [  34.461], Avg:    88.738 (0.400) <0-06:53:05> ({'r_t':   372.2378, 'eps':     0.4002, 'len': 26949.0280, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  293000, Reward:   212.477 [  39.491], Avg:    89.159 (0.600) <0-06:54:26> ({'r_t':  -180.0842, 'eps':     0.6002, 'len': 27000.1310, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  294000, Reward:   148.606 [ 119.338], Avg:    89.360 (0.800) <0-06:55:33> ({'r_t':  -638.3729, 'eps':     0.8002, 'len': 27068.1320, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  295000, Reward:   229.319 [  27.778], Avg:    89.833 (0.000) <0-06:57:39> ({'r_t': -1155.4637, 'eps':     0.0002, 'len': 27163.6070, 'dyn_loss':    14.7145, 'dot_loss':     2.5921, 'ddot_loss':     5.5213, 'rew_loss':   280.6642, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  296000, Reward:   224.446 [  41.382], Avg:    90.286 (0.200) <0-06:59:32> ({'r_t':   707.0701, 'eps':     0.2002, 'len': 27238.8270, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  297000, Reward:   238.661 [  27.830], Avg:    90.784 (0.400) <0-07:01:09> ({'r_t':   459.5137, 'eps':     0.4002, 'len': 27286.4740, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  298000, Reward:   224.723 [  32.048], Avg:    91.232 (0.600) <0-07:02:30> ({'r_t':   -75.0584, 'eps':     0.6002, 'len': 27332.9780, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  299000, Reward:   233.144 [  25.892], Avg:    91.705 (0.800) <0-07:03:36> ({'r_t':  -704.9827, 'eps':     0.8002, 'len': 27391.0800, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  300000, Reward:   215.924 [  40.298], Avg:    92.118 (0.000) <0-07:05:46> ({'r_t': -1103.7383, 'eps':     0.0002, 'len': 27481.8360, 'dyn_loss':    14.6815, 'dot_loss':     2.5412, 'ddot_loss':     5.4121, 'rew_loss':   280.1644, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  301000, Reward:   236.118 [  42.134], Avg:    92.595 (0.200) <0-07:07:41> ({'r_t':   581.3027, 'eps':     0.2002, 'len': 27555.2010, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  302000, Reward:   231.893 [  50.334], Avg:    93.054 (0.400) <0-07:09:20> ({'r_t':   314.7840, 'eps':     0.4002, 'len': 27603.3220, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  303000, Reward:   241.862 [  37.778], Avg:    93.544 (0.600) <0-07:10:40> ({'r_t':  -201.2985, 'eps':     0.6002, 'len': 27656.1440, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  304000, Reward:   224.470 [  40.054], Avg:    93.973 (0.800) <0-07:11:45> ({'r_t':  -623.7768, 'eps':     0.8002, 'len': 27724.1420, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  305000, Reward:   206.700 [  70.617], Avg:    94.342 (0.000) <0-07:13:55> ({'r_t': -1084.7778, 'eps':     0.0002, 'len': 27824.1580, 'dyn_loss':    14.5520, 'dot_loss':     2.5001, 'ddot_loss':     5.3335, 'rew_loss':   287.4159, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  306000, Reward:   251.687 [  31.716], Avg:    94.854 (0.200) <0-07:15:53> ({'r_t':   707.8343, 'eps':     0.2002, 'len': 27897.2070, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  307000, Reward:   256.002 [  27.171], Avg:    95.377 (0.400) <0-07:17:32> ({'r_t':   334.4234, 'eps':     0.4002, 'len': 27940.2380, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  308000, Reward:   234.340 [  32.884], Avg:    95.827 (0.600) <0-07:18:54> ({'r_t':  -140.9497, 'eps':     0.6002, 'len': 27986.0570, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  309000, Reward:   235.474 [  39.580], Avg:    96.277 (0.800) <0-07:20:04> ({'r_t':  -754.0922, 'eps':     0.8002, 'len': 28055.5770, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  310000, Reward:   288.221 [  33.425], Avg:    96.895 (0.000) <0-07:22:09> ({'r_t': -1157.8782, 'eps':     0.0002, 'len': 28148.4070, 'dyn_loss':    13.3472, 'dot_loss':     2.4026, 'ddot_loss':     5.1582, 'rew_loss':   283.8034, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  311000, Reward:   289.158 [  35.828], Avg:    97.511 (0.200) <0-07:24:02> ({'r_t':   823.2646, 'eps':     0.2002, 'len': 28219.2810, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  312000, Reward:   289.612 [  36.822], Avg:    98.125 (0.400) <0-07:25:37> ({'r_t':   515.9046, 'eps':     0.4002, 'len': 28268.4620, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  313000, Reward:   288.572 [  31.441], Avg:    98.731 (0.600) <0-07:26:57> ({'r_t':   -49.2344, 'eps':     0.6002, 'len': 28316.7040, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  314000, Reward:   282.098 [  18.706], Avg:    99.313 (0.800) <0-07:28:02> ({'r_t':  -715.8120, 'eps':     0.8002, 'len': 28377.3380, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  315000, Reward:   253.076 [  29.248], Avg:    99.800 (0.000) <0-07:30:08> ({'r_t': -1063.7825, 'eps':     0.0002, 'len': 28464.2780, 'dyn_loss':    13.7569, 'dot_loss':     2.4356, 'ddot_loss':     5.2471, 'rew_loss':   283.8571, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  316000, Reward:   270.074 [  34.286], Avg:   100.337 (0.200) <0-07:31:57> ({'r_t':   822.9095, 'eps':     0.2002, 'len': 28539.5510, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  317000, Reward:   268.401 [  29.933], Avg:   100.866 (0.400) <0-07:33:32> ({'r_t':   513.5715, 'eps':     0.4002, 'len': 28594.0680, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  318000, Reward:   238.987 [  81.144], Avg:   101.298 (0.600) <0-07:34:52> ({'r_t':   -28.2549, 'eps':     0.6002, 'len': 28650.1650, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  319000, Reward:   235.041 [  77.156], Avg:   101.716 (0.800) <0-07:35:54> ({'r_t':  -615.9367, 'eps':     0.8002, 'len': 28716.3570, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  320000, Reward:   230.065 [  31.259], Avg:   102.116 (0.000) <0-07:38:05> ({'r_t': -1131.6442, 'eps':     0.0002, 'len': 28811.3920, 'dyn_loss':    13.7219, 'dot_loss':     2.3758, 'ddot_loss':     5.0757, 'rew_loss':   287.1514, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  321000, Reward:   251.187 [  29.166], Avg:   102.579 (0.200) <0-07:40:00> ({'r_t':   666.3384, 'eps':     0.2002, 'len': 28885.8300, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  322000, Reward:   250.843 [  42.594], Avg:   103.038 (0.400) <0-07:41:41> ({'r_t':   368.9168, 'eps':     0.4002, 'len': 28930.5050, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  323000, Reward:   216.741 [  77.426], Avg:   103.389 (0.600) <0-07:43:02> ({'r_t':  -111.6615, 'eps':     0.6002, 'len': 28975.0750, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  324000, Reward:   211.062 [  78.424], Avg:   103.720 (0.800) <0-07:44:11> ({'r_t':  -652.0004, 'eps':     0.8002, 'len': 29045.3800, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  325000, Reward:   199.644 [ 123.086], Avg:   104.015 (0.000) <0-07:46:20> ({'r_t': -1091.0374, 'eps':     0.0002, 'len': 29139.6940, 'dyn_loss':    13.8620, 'dot_loss':     2.3991, 'ddot_loss':     5.1317, 'rew_loss':   287.6957, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  326000, Reward:   248.897 [  99.853], Avg:   104.458 (0.200) <0-07:48:15> ({'r_t':   672.9302, 'eps':     0.2002, 'len': 29227.6390, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  327000, Reward:   231.063 [ 113.310], Avg:   104.844 (0.400) <0-07:49:55> ({'r_t':   402.1927, 'eps':     0.4002, 'len': 29279.0460, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  328000, Reward:   237.815 [ 112.476], Avg:   105.248 (0.600) <0-07:51:14> ({'r_t':  -129.4571, 'eps':     0.6002, 'len': 29328.3170, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  329000, Reward:   145.478 [ 156.441], Avg:   105.370 (0.800) <0-07:52:21> ({'r_t':  -696.6273, 'eps':     0.8002, 'len': 29393.6560, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  330000, Reward:   310.169 [  26.184], Avg:   105.989 (0.000) <0-07:54:30> ({'r_t': -1130.1138, 'eps':     0.0002, 'len': 29481.8350, 'dyn_loss':    13.4999, 'dot_loss':     2.3600, 'ddot_loss':     5.0728, 'rew_loss':   285.0213, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  331000, Reward:   297.747 [  24.257], Avg:   106.566 (0.200) <0-07:56:22> ({'r_t':   927.4516, 'eps':     0.2002, 'len': 29561.1030, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  332000, Reward:   313.809 [  19.714], Avg:   107.189 (0.400) <0-07:57:56> ({'r_t':   614.3288, 'eps':     0.4002, 'len': 29612.9770, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  333000, Reward:   298.683 [  25.536], Avg:   107.762 (0.600) <0-07:59:18> ({'r_t':  -154.1608, 'eps':     0.6002, 'len': 29664.9720, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  334000, Reward:   292.488 [  29.213], Avg:   108.313 (0.800) <0-08:00:23> ({'r_t':  -685.7917, 'eps':     0.8002, 'len': 29735.1780, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  335000, Reward:   228.724 [  31.736], Avg:   108.672 (0.000) <0-08:02:32> ({'r_t': -1149.0025, 'eps':     0.0002, 'len': 29824.8010, 'dyn_loss':    13.2935, 'dot_loss':     2.3317, 'ddot_loss':     5.0027, 'rew_loss':   290.0666, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  336000, Reward:   245.704 [  32.487], Avg:   109.078 (0.200) <0-08:04:25> ({'r_t':   691.2253, 'eps':     0.2002, 'len': 29900.5980, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  337000, Reward:   252.221 [  22.377], Avg:   109.502 (0.400) <0-08:06:01> ({'r_t':   529.4687, 'eps':     0.4002, 'len': 29948.5440, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  338000, Reward:   232.150 [  24.016], Avg:   109.864 (0.600) <0-08:07:22> ({'r_t':   -94.9599, 'eps':     0.6002, 'len': 29997.1220, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  339000, Reward:   234.542 [  19.375], Avg:   110.230 (0.800) <0-08:08:27> ({'r_t':  -709.8649, 'eps':     0.8002, 'len': 30063.7150, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  340000, Reward:   282.992 [  38.990], Avg:   110.737 (0.000) <0-08:10:41> ({'r_t': -1015.6865, 'eps':     0.0002, 'len': 30161.2420, 'dyn_loss':    13.3711, 'dot_loss':     2.3007, 'ddot_loss':     4.9327, 'rew_loss':   287.9630, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  341000, Reward:   286.141 [  54.777], Avg:   111.250 (0.200) <0-08:12:42> ({'r_t':   868.3740, 'eps':     0.2002, 'len': 30237.6450, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  342000, Reward:   303.046 [  36.152], Avg:   111.809 (0.400) <0-08:14:23> ({'r_t':   511.3457, 'eps':     0.4002, 'len': 30286.2440, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  343000, Reward:   271.347 [  87.190], Avg:   112.273 (0.600) <0-08:15:43> ({'r_t':   -90.5587, 'eps':     0.6002, 'len': 30333.0910, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  344000, Reward:   275.616 [  34.633], Avg:   112.746 (0.800) <0-08:16:50> ({'r_t':  -640.1232, 'eps':     0.8002, 'len': 30398.7580, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  345000, Reward:   173.296 [  73.638], Avg:   112.921 (0.000) <0-08:19:03> ({'r_t': -1181.5550, 'eps':     0.0002, 'len': 30487.1440, 'dyn_loss':    12.6934, 'dot_loss':     2.2578, 'ddot_loss':     4.8544, 'rew_loss':   289.8938, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  346000, Reward:   198.564 [  70.210], Avg:   113.168 (0.200) <0-08:21:02> ({'r_t':   536.7648, 'eps':     0.2002, 'len': 30558.5400, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  347000, Reward:   187.885 [  75.137], Avg:   113.383 (0.400) <0-08:22:40> ({'r_t':   401.3920, 'eps':     0.4002, 'len': 30609.6990, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  348000, Reward:   206.550 [  32.467], Avg:   113.650 (0.600) <0-08:24:02> ({'r_t':  -108.5480, 'eps':     0.6002, 'len': 30658.2610, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  349000, Reward:   154.165 [  95.089], Avg:   113.765 (0.800) <0-08:25:09> ({'r_t':  -728.2545, 'eps':     0.8002, 'len': 30720.0030, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  350000, Reward:   254.287 [  23.437], Avg:   114.166 (0.000) <0-08:27:20> ({'r_t': -1119.1177, 'eps':     0.0002, 'len': 30810.5730, 'dyn_loss':    13.0144, 'dot_loss':     2.2668, 'ddot_loss':     4.8718, 'rew_loss':   283.0390, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  351000, Reward:   264.890 [  27.634], Avg:   114.594 (0.200) <0-08:29:14> ({'r_t':   747.7319, 'eps':     0.2002, 'len': 30883.1230, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  352000, Reward:   261.323 [  20.289], Avg:   115.010 (0.400) <0-08:30:51> ({'r_t':   528.8385, 'eps':     0.4002, 'len': 30930.2460, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  353000, Reward:   261.856 [  27.251], Avg:   115.424 (0.600) <0-08:32:12> ({'r_t':  -110.3571, 'eps':     0.6002, 'len': 30977.4040, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  354000, Reward:   253.012 [  23.366], Avg:   115.812 (0.800) <0-08:33:19> ({'r_t':  -608.8447, 'eps':     0.8002, 'len': 31046.1420, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  355000, Reward:   293.979 [  25.000], Avg:   116.312 (0.000) <0-08:35:27> ({'r_t': -1090.3372, 'eps':     0.0002, 'len': 31137.5900, 'dyn_loss':    12.5737, 'dot_loss':     2.2436, 'ddot_loss':     4.8381, 'rew_loss':   287.8190, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  356000, Reward:   302.958 [  17.848], Avg:   116.835 (0.200) <0-08:37:18> ({'r_t':   894.6943, 'eps':     0.2002, 'len': 31219.2880, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  357000, Reward:   298.381 [  20.020], Avg:   117.342 (0.400) <0-08:38:53> ({'r_t':   570.1207, 'eps':     0.4002, 'len': 31267.8300, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  358000, Reward:   300.974 [  37.191], Avg:   117.854 (0.600) <0-08:40:13> ({'r_t':   -26.0571, 'eps':     0.6002, 'len': 31320.0800, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  359000, Reward:   292.795 [  18.757], Avg:   118.340 (0.800) <0-08:41:18> ({'r_t':  -684.0503, 'eps':     0.8002, 'len': 31385.4810, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  360000, Reward:   309.755 [  21.908], Avg:   118.870 (0.000) <0-08:43:26> ({'r_t': -1111.1872, 'eps':     0.0002, 'len': 31475.9940, 'dyn_loss':    12.6640, 'dot_loss':     2.2312, 'ddot_loss':     4.7993, 'rew_loss':   287.7198, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  361000, Reward:   323.521 [  25.558], Avg:   119.435 (0.200) <0-08:45:16> ({'r_t':  1007.7858, 'eps':     0.2002, 'len': 31553.3000, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  362000, Reward:   313.516 [  28.057], Avg:   119.970 (0.400) <0-08:46:48> ({'r_t':   569.5718, 'eps':     0.4002, 'len': 31606.4080, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  363000, Reward:   320.432 [  22.194], Avg:   120.521 (0.600) <0-08:48:05> ({'r_t':    68.2237, 'eps':     0.6002, 'len': 31657.2520, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  364000, Reward:   306.105 [  26.924], Avg:   121.029 (0.800) <0-08:49:08> ({'r_t':  -678.2511, 'eps':     0.8002, 'len': 31725.5190, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  365000, Reward:   225.035 [ 114.430], Avg:   121.313 (0.000) <0-08:51:27> ({'r_t': -1082.6703, 'eps':     0.0002, 'len': 31824.3570, 'dyn_loss':    12.6000, 'dot_loss':     2.2278, 'ddot_loss':     4.7916, 'rew_loss':   291.0758, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  366000, Reward:   297.890 [  32.687], Avg:   121.795 (0.200) <0-08:53:19> ({'r_t':   831.8904, 'eps':     0.2002, 'len': 31906.1590, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  367000, Reward:   291.763 [  37.929], Avg:   122.256 (0.400) <0-08:54:57> ({'r_t':   598.6063, 'eps':     0.4002, 'len': 31956.8260, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  368000, Reward:   259.767 [  87.316], Avg:   122.629 (0.600) <0-08:56:18> ({'r_t':   -55.3363, 'eps':     0.6002, 'len': 32005.5400, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  369000, Reward:   255.969 [  43.439], Avg:   122.989 (0.800) <0-08:57:25> ({'r_t':  -618.8509, 'eps':     0.8002, 'len': 32066.5690, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  370000, Reward:   256.674 [  35.701], Avg:   123.350 (0.000) <0-08:59:37> ({'r_t': -1104.2753, 'eps':     0.0002, 'len': 32161.2360, 'dyn_loss':    12.4757, 'dot_loss':     2.1858, 'ddot_loss':     4.7056, 'rew_loss':   285.4202, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  371000, Reward:   245.180 [  34.088], Avg:   123.677 (0.200) <0-09:01:31> ({'r_t':   739.0334, 'eps':     0.2002, 'len': 32235.8730, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  372000, Reward:   238.096 [  81.204], Avg:   123.984 (0.400) <0-09:03:11> ({'r_t':   510.6620, 'eps':     0.4002, 'len': 32283.3950, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  373000, Reward:   269.711 [  22.236], Avg:   124.374 (0.600) <0-09:04:32> ({'r_t':   -32.8579, 'eps':     0.6002, 'len': 32331.0100, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  374000, Reward:   242.363 [  30.858], Avg:   124.688 (0.800) <0-09:05:39> ({'r_t':  -667.1907, 'eps':     0.8002, 'len': 32395.4460, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  375000, Reward:   126.036 [  68.044], Avg:   124.692 (0.000) <0-09:07:58> ({'r_t': -1107.5311, 'eps':     0.0002, 'len': 32485.7350, 'dyn_loss':    12.5035, 'dot_loss':     2.1583, 'ddot_loss':     4.6255, 'rew_loss':   295.5760, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  376000, Reward:   130.925 [  82.441], Avg:   124.708 (0.200) <0-09:09:57> ({'r_t':   496.2876, 'eps':     0.2002, 'len': 32564.0520, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  377000, Reward:   156.833 [  45.359], Avg:   124.793 (0.400) <0-09:11:37> ({'r_t':   527.4027, 'eps':     0.4002, 'len': 32614.9870, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  378000, Reward:   144.124 [  67.815], Avg:   124.844 (0.600) <0-09:12:59> ({'r_t':    39.5259, 'eps':     0.6002, 'len': 32665.3600, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  379000, Reward:   149.508 [  43.085], Avg:   124.909 (0.800) <0-09:14:07> ({'r_t':  -632.7598, 'eps':     0.8002, 'len': 32735.6980, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  380000, Reward:   205.035 [  33.659], Avg:   125.120 (0.000) <0-09:16:23> ({'r_t': -1042.4812, 'eps':     0.0002, 'len': 32829.1740, 'dyn_loss':    11.9761, 'dot_loss':     2.1550, 'ddot_loss':     4.6719, 'rew_loss':   290.3538, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  381000, Reward:   239.796 [  27.744], Avg:   125.420 (0.200) <0-09:18:17> ({'r_t':   601.1056, 'eps':     0.2002, 'len': 32906.5820, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  382000, Reward:   223.341 [  33.354], Avg:   125.676 (0.400) <0-09:19:57> ({'r_t':   343.3565, 'eps':     0.4002, 'len': 32950.4920, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  383000, Reward:   219.785 [  23.529], Avg:   125.921 (0.600) <0-09:21:21> ({'r_t':    19.0241, 'eps':     0.6002, 'len': 32994.4240, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  384000, Reward:   177.283 [  58.200], Avg:   126.054 (0.800) <0-09:22:38> ({'r_t':  -586.3370, 'eps':     0.8002, 'len': 33057.3490, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  385000, Reward:   231.752 [  38.877], Avg:   126.328 (0.000) <0-09:24:49> ({'r_t': -1074.3800, 'eps':     0.0002, 'len': 33153.8720, 'dyn_loss':    11.9634, 'dot_loss':     2.1253, 'ddot_loss':     4.5853, 'rew_loss':   290.8728, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  386000, Reward:   222.913 [  56.096], Avg:   126.577 (0.200) <0-09:26:45> ({'r_t':   750.3257, 'eps':     0.2002, 'len': 33234.0070, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  387000, Reward:   229.762 [  40.334], Avg:   126.843 (0.400) <0-09:28:24> ({'r_t':   664.9101, 'eps':     0.4002, 'len': 33282.9580, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  388000, Reward:   224.276 [  51.907], Avg:   127.094 (0.600) <0-09:29:47> ({'r_t':   101.2751, 'eps':     0.6002, 'len': 33336.3590, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  389000, Reward:   224.852 [  40.287], Avg:   127.344 (0.800) <0-09:30:57> ({'r_t':  -681.8306, 'eps':     0.8002, 'len': 33403.4720, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  390000, Reward:   207.934 [ 108.070], Avg:   127.551 (0.000) <0-09:33:11> ({'r_t': -1189.6039, 'eps':     0.0002, 'len': 33482.5510, 'dyn_loss':    12.2711, 'dot_loss':     2.1414, 'ddot_loss':     4.6157, 'rew_loss':   292.2063, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  391000, Reward:   217.366 [ 115.398], Avg:   127.780 (0.200) <0-09:35:08> ({'r_t':   688.0379, 'eps':     0.2002, 'len': 33553.9080, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  392000, Reward:   235.423 [  81.664], Avg:   128.054 (0.400) <0-09:36:46> ({'r_t':   624.2872, 'eps':     0.4002, 'len': 33604.5940, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  393000, Reward:   226.928 [  81.810], Avg:   128.305 (0.600) <0-09:38:10> ({'r_t':   -45.3053, 'eps':     0.6002, 'len': 33655.6330, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  394000, Reward:   232.132 [  48.692], Avg:   128.567 (0.800) <0-09:39:20> ({'r_t':  -664.7192, 'eps':     0.8002, 'len': 33719.4960, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  395000, Reward:   229.888 [ 104.334], Avg:   128.823 (0.000) <0-09:41:45> ({'r_t': -1082.0547, 'eps':     0.0002, 'len': 33811.0190, 'dyn_loss':    12.6552, 'dot_loss':     2.1815, 'ddot_loss':     4.6713, 'rew_loss':   294.3803, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  396000, Reward:   233.394 [  90.104], Avg:   129.087 (0.200) <0-09:43:38> ({'r_t':   854.3757, 'eps':     0.2002, 'len': 33887.2960, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  397000, Reward:   284.488 [  43.431], Avg:   129.477 (0.400) <0-09:45:13> ({'r_t':   641.8232, 'eps':     0.4002, 'len': 33938.9390, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  398000, Reward:   292.687 [  34.150], Avg:   129.886 (0.600) <0-09:46:32> ({'r_t':    10.1654, 'eps':     0.6002, 'len': 33989.9740, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  399000, Reward:   251.848 [  45.076], Avg:   130.191 (0.800) <0-09:47:36> ({'r_t':  -644.5774, 'eps':     0.8002, 'len': 34050.8800, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  400000, Reward:   192.628 [  65.619], Avg:   130.347 (0.000) <0-09:50:00> ({'r_t': -1130.1388, 'eps':     0.0002, 'len': 34141.4920, 'dyn_loss':    12.0402, 'dot_loss':     2.1365, 'ddot_loss':     4.5942, 'rew_loss':   287.9820, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  401000, Reward:   170.114 [ 106.437], Avg:   130.446 (0.200) <0-09:52:06> ({'r_t':   669.4775, 'eps':     0.2002, 'len': 34222.4010, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  402000, Reward:   175.570 [ 103.510], Avg:   130.558 (0.400) <0-09:53:52> ({'r_t':   694.1762, 'eps':     0.4002, 'len': 34274.9710, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  403000, Reward:   199.981 [  91.949], Avg:   130.730 (0.600) <0-09:55:21> ({'r_t':    54.2998, 'eps':     0.6002, 'len': 34328.8050, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  404000, Reward:   175.678 [ 102.287], Avg:   130.841 (0.800) <0-09:56:39> ({'r_t':  -651.6334, 'eps':     0.8002, 'len': 34396.9840, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  405000, Reward:   249.937 [  85.376], Avg:   131.134 (0.000) <0-09:58:53> ({'r_t': -1062.5276, 'eps':     0.0002, 'len': 34497.9280, 'dyn_loss':    12.4527, 'dot_loss':     2.1558, 'ddot_loss':     4.6349, 'rew_loss':   288.2114, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  406000, Reward:   266.934 [  38.774], Avg:   131.468 (0.200) <0-10:00:47> ({'r_t':   759.8704, 'eps':     0.2002, 'len': 34579.4800, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  407000, Reward:   278.930 [  30.644], Avg:   131.829 (0.400) <0-10:02:25> ({'r_t':   601.9731, 'eps':     0.4002, 'len': 34627.2350, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  408000, Reward:   258.156 [  88.517], Avg:   132.138 (0.600) <0-10:03:47> ({'r_t':    64.6496, 'eps':     0.6002, 'len': 34678.4380, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  409000, Reward:   249.450 [  86.622], Avg:   132.424 (0.800) <0-10:04:56> ({'r_t':  -627.3414, 'eps':     0.8002, 'len': 34748.0220, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  410000, Reward:   222.873 [ 102.071], Avg:   132.644 (0.000) <0-10:07:21> ({'r_t': -1089.0953, 'eps':     0.0002, 'len': 34838.0390, 'dyn_loss':    11.9777, 'dot_loss':     2.1321, 'ddot_loss':     4.6084, 'rew_loss':   300.8106, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  411000, Reward:   203.641 [ 105.237], Avg:   132.816 (0.200) <0-10:09:23> ({'r_t':   713.3934, 'eps':     0.2002, 'len': 34915.4850, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  412000, Reward:   248.281 [  97.495], Avg:   133.096 (0.400) <0-10:11:12> ({'r_t':   555.1288, 'eps':     0.4002, 'len': 34965.1550, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  413000, Reward:   233.220 [  69.379], Avg:   133.338 (0.600) <0-10:12:43> ({'r_t':   -46.0134, 'eps':     0.6002, 'len': 35016.6990, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  414000, Reward:   230.674 [  74.993], Avg:   133.572 (0.800) <0-10:14:01> ({'r_t':  -638.5486, 'eps':     0.8002, 'len': 35082.3160, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  415000, Reward:   217.640 [  75.230], Avg:   133.774 (0.000) <0-10:16:17> ({'r_t': -1109.4762, 'eps':     0.0002, 'len': 35175.6030, 'dyn_loss':    11.8489, 'dot_loss':     2.0783, 'ddot_loss':     4.4852, 'rew_loss':   291.5504, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  416000, Reward:   236.787 [  80.870], Avg:   134.021 (0.200) <0-10:18:10> ({'r_t':   642.4540, 'eps':     0.2002, 'len': 35249.3580, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  417000, Reward:   229.433 [  47.257], Avg:   134.250 (0.400) <0-10:19:52> ({'r_t':   416.4674, 'eps':     0.4002, 'len': 35292.0300, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  418000, Reward:   211.533 [  49.325], Avg:   134.434 (0.600) <0-10:21:16> ({'r_t':   -56.7319, 'eps':     0.6002, 'len': 35338.9130, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  419000, Reward:   162.784 [ 110.044], Avg:   134.502 (0.800) <0-10:22:27> ({'r_t':  -663.4891, 'eps':     0.8002, 'len': 35404.6350, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  420000, Reward:   133.440 [  86.690], Avg:   134.499 (0.000) <0-10:24:48> ({'r_t': -1159.5885, 'eps':     0.0002, 'len': 35499.0210, 'dyn_loss':    11.7202, 'dot_loss':     2.0572, 'ddot_loss':     4.4496, 'rew_loss':   292.7567, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  421000, Reward:   160.765 [  76.002], Avg:   134.561 (0.200) <0-10:26:44> ({'r_t':   569.9955, 'eps':     0.2002, 'len': 35576.8200, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  422000, Reward:   181.732 [  46.186], Avg:   134.673 (0.400) <0-10:28:26> ({'r_t':   517.4519, 'eps':     0.4002, 'len': 35623.5510, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  423000, Reward:   161.008 [  82.388], Avg:   134.735 (0.600) <0-10:29:55> ({'r_t':    20.7490, 'eps':     0.6002, 'len': 35674.4910, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  424000, Reward:   137.487 [  77.761], Avg:   134.741 (0.800) <0-10:31:09> ({'r_t':  -606.9054, 'eps':     0.8002, 'len': 35739.1490, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  425000, Reward:   215.469 [ 112.506], Avg:   134.931 (0.000) <0-10:33:27> ({'r_t': -1150.0570, 'eps':     0.0002, 'len': 35828.3350, 'dyn_loss':    12.0887, 'dot_loss':     2.1075, 'ddot_loss':     4.5416, 'rew_loss':   298.1370, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  426000, Reward:   257.023 [  89.686], Avg:   135.217 (0.200) <0-10:35:24> ({'r_t':   761.8799, 'eps':     0.2002, 'len': 35905.7460, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  427000, Reward:   288.170 [  42.072], Avg:   135.574 (0.400) <0-10:36:59> ({'r_t':   588.3625, 'eps':     0.4002, 'len': 35955.5140, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  428000, Reward:   258.463 [  98.686], Avg:   135.861 (0.600) <0-10:38:24> ({'r_t':   -29.2525, 'eps':     0.6002, 'len': 36002.7710, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  429000, Reward:   180.793 [ 136.387], Avg:   135.965 (0.800) <0-10:39:31> ({'r_t':  -580.4772, 'eps':     0.8002, 'len': 36067.1270, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  430000, Reward:   136.968 [ 132.231], Avg:   135.968 (0.000) <0-10:41:52> ({'r_t': -1097.1770, 'eps':     0.0002, 'len': 36163.4090, 'dyn_loss':    11.9237, 'dot_loss':     2.0576, 'ddot_loss':     4.4406, 'rew_loss':   296.2267, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  431000, Reward:   240.378 [  87.045], Avg:   136.209 (0.200) <0-10:43:48> ({'r_t':   543.9532, 'eps':     0.2002, 'len': 36260.0140, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  432000, Reward:   153.140 [ 125.205], Avg:   136.248 (0.400) <0-10:45:29> ({'r_t':   556.1583, 'eps':     0.4002, 'len': 36315.2600, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  433000, Reward:   230.180 [ 113.888], Avg:   136.465 (0.600) <0-10:46:52> ({'r_t':   -53.2597, 'eps':     0.6002, 'len': 36365.2750, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  434000, Reward:    79.729 [ 139.029], Avg:   136.334 (0.800) <0-10:48:03> ({'r_t':  -674.6926, 'eps':     0.8002, 'len': 36430.8600, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  435000, Reward:   159.084 [ 108.933], Avg:   136.386 (0.000) <0-10:50:20> ({'r_t': -1093.1044, 'eps':     0.0002, 'len': 36518.8440, 'dyn_loss':    11.8060, 'dot_loss':     2.0517, 'ddot_loss':     4.4226, 'rew_loss':   296.6278, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  436000, Reward:   194.886 [ 111.970], Avg:   136.520 (0.200) <0-10:52:12> ({'r_t':   554.6229, 'eps':     0.2002, 'len': 36598.9410, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  437000, Reward:   168.926 [ 122.871], Avg:   136.594 (0.400) <0-10:53:51> ({'r_t':   426.6296, 'eps':     0.4002, 'len': 36647.4600, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  438000, Reward:   197.866 [ 105.277], Avg:   136.734 (0.600) <0-10:55:19> ({'r_t':  -107.3237, 'eps':     0.6002, 'len': 36693.2800, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  439000, Reward:   162.575 [ 113.624], Avg:   136.793 (0.800) <0-10:56:26> ({'r_t':  -617.6300, 'eps':     0.8002, 'len': 36748.5730, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  440000, Reward:   239.400 [ 102.140], Avg:   137.025 (0.000) <0-10:58:44> ({'r_t': -1045.5663, 'eps':     0.0002, 'len': 36832.2510, 'dyn_loss':    11.6703, 'dot_loss':     2.0478, 'ddot_loss':     4.4271, 'rew_loss':   293.7819, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  441000, Reward:   228.242 [ 114.429], Avg:   137.232 (0.200) <0-11:00:42> ({'r_t':   804.4716, 'eps':     0.2002, 'len': 36911.7350, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  442000, Reward:   275.664 [  95.662], Avg:   137.544 (0.400) <0-11:02:18> ({'r_t':   516.9529, 'eps':     0.4002, 'len': 36956.3270, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  443000, Reward:   246.281 [  79.765], Avg:   137.789 (0.600) <0-11:03:49> ({'r_t':   -53.9654, 'eps':     0.6002, 'len': 37001.7710, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  444000, Reward:   252.688 [  80.118], Avg:   138.047 (0.800) <0-11:04:59> ({'r_t':  -589.9348, 'eps':     0.8002, 'len': 37064.2350, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  445000, Reward:   165.109 [  64.106], Avg:   138.108 (0.000) <0-11:07:17> ({'r_t': -1164.1075, 'eps':     0.0002, 'len': 37146.8520, 'dyn_loss':    11.3023, 'dot_loss':     1.9978, 'ddot_loss':     4.3240, 'rew_loss':   304.1895, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  446000, Reward:   170.198 [  66.309], Avg:   138.180 (0.200) <0-11:09:12> ({'r_t':   585.8438, 'eps':     0.2002, 'len': 37219.8560, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  447000, Reward:   183.841 [  36.793], Avg:   138.282 (0.400) <0-11:10:53> ({'r_t':   474.7979, 'eps':     0.4002, 'len': 37265.9880, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  448000, Reward:   185.418 [  71.375], Avg:   138.387 (0.600) <0-11:12:16> ({'r_t':    61.5354, 'eps':     0.6002, 'len': 37312.3890, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  449000, Reward:   153.138 [  72.818], Avg:   138.419 (0.800) <0-11:13:28> ({'r_t':  -680.1131, 'eps':     0.8002, 'len': 37372.3790, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  450000, Reward:   291.303 [  22.213], Avg:   138.758 (0.000) <0-11:15:45> ({'r_t': -1138.2568, 'eps':     0.0002, 'len': 37472.5120, 'dyn_loss':    11.7295, 'dot_loss':     2.0244, 'ddot_loss':     4.3770, 'rew_loss':   290.9759, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  451000, Reward:   290.824 [  32.404], Avg:   139.095 (0.200) <0-11:17:41> ({'r_t':   833.5995, 'eps':     0.2002, 'len': 37545.8860, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  452000, Reward:   302.838 [  32.569], Avg:   139.456 (0.400) <0-11:19:16> ({'r_t':   614.2915, 'eps':     0.4002, 'len': 37593.6830, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  453000, Reward:   307.893 [  39.777], Avg:   139.827 (0.600) <0-11:20:40> ({'r_t':    52.7084, 'eps':     0.6002, 'len': 37641.5790, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  454000, Reward:   285.706 [  28.883], Avg:   140.148 (0.800) <0-11:21:48> ({'r_t':  -616.6045, 'eps':     0.8002, 'len': 37703.5340, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  455000, Reward:   142.774 [ 108.476], Avg:   140.154 (0.000) <0-11:24:18> ({'r_t': -1113.2840, 'eps':     0.0002, 'len': 37794.2600, 'dyn_loss':    11.3820, 'dot_loss':     1.9691, 'ddot_loss':     4.2497, 'rew_loss':   295.6439, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  456000, Reward:   199.604 [  90.728], Avg:   140.284 (0.200) <0-11:26:24> ({'r_t':   595.2537, 'eps':     0.2002, 'len': 37877.5880, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  457000, Reward:   171.354 [ 104.158], Avg:   140.352 (0.400) <0-11:28:13> ({'r_t':   512.1767, 'eps':     0.4002, 'len': 37922.5360, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  458000, Reward:   225.123 [  69.412], Avg:   140.536 (0.600) <0-11:29:45> ({'r_t':    -9.2611, 'eps':     0.6002, 'len': 37968.2500, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  459000, Reward:   159.336 [ 125.252], Avg:   140.577 (0.800) <0-11:31:02> ({'r_t':  -573.5242, 'eps':     0.8002, 'len': 38026.0880, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  460000, Reward:   195.110 [  55.467], Avg:   140.695 (0.000) <0-11:33:19> ({'r_t': -1107.4252, 'eps':     0.0002, 'len': 38116.1210, 'dyn_loss':    11.4196, 'dot_loss':     1.9911, 'ddot_loss':     4.3206, 'rew_loss':   300.4611, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  461000, Reward:   195.667 [ 104.890], Avg:   140.814 (0.200) <0-11:35:10> ({'r_t':   733.6353, 'eps':     0.2002, 'len': 38196.1140, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  462000, Reward:   204.785 [  64.584], Avg:   140.953 (0.400) <0-11:36:45> ({'r_t':   588.0429, 'eps':     0.4002, 'len': 38248.0000, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  463000, Reward:   233.793 [  37.812], Avg:   141.153 (0.600) <0-11:38:08> ({'r_t':    50.8387, 'eps':     0.6002, 'len': 38297.7960, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  464000, Reward:   168.313 [  77.747], Avg:   141.211 (0.800) <0-11:39:18> ({'r_t':  -613.2959, 'eps':     0.8002, 'len': 38356.8860, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  465000, Reward:   202.770 [ 126.940], Avg:   141.343 (0.000) <0-11:41:33> ({'r_t': -1069.4247, 'eps':     0.0002, 'len': 38448.9750, 'dyn_loss':    11.3733, 'dot_loss':     1.9836, 'ddot_loss':     4.2940, 'rew_loss':   303.3871, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  466000, Reward:   243.969 [  87.018], Avg:   141.563 (0.200) <0-11:43:26> ({'r_t':   767.3266, 'eps':     0.2002, 'len': 38534.1480, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  467000, Reward:   269.063 [  42.447], Avg:   141.835 (0.400) <0-11:45:04> ({'r_t':   669.1667, 'eps':     0.4002, 'len': 38586.0330, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  468000, Reward:   272.232 [  30.784], Avg:   142.113 (0.600) <0-11:46:24> ({'r_t':    54.0085, 'eps':     0.6002, 'len': 38637.5060, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  469000, Reward:   243.008 [  81.697], Avg:   142.328 (0.800) <0-11:47:29> ({'r_t':  -624.0389, 'eps':     0.8002, 'len': 38707.9340, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  470000, Reward:   167.674 [  41.581], Avg:   142.382 (0.000) <0-11:49:54> ({'r_t': -1164.3683, 'eps':     0.0002, 'len': 38803.2660, 'dyn_loss':    11.7638, 'dot_loss':     2.0267, 'ddot_loss':     4.3515, 'rew_loss':   301.5003, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  471000, Reward:   182.409 [  92.514], Avg:   142.467 (0.200) <0-11:51:59> ({'r_t':   639.7392, 'eps':     0.2002, 'len': 38877.3480, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  472000, Reward:   184.401 [  68.119], Avg:   142.555 (0.400) <0-11:53:47> ({'r_t':   523.5244, 'eps':     0.4002, 'len': 38922.9500, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  473000, Reward:   176.059 [  64.621], Avg:   142.626 (0.600) <0-11:55:19> ({'r_t':    22.6981, 'eps':     0.6002, 'len': 38971.8640, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  474000, Reward:   179.220 [  83.470], Avg:   142.703 (0.800) <0-11:56:37> ({'r_t':  -673.9009, 'eps':     0.8002, 'len': 39038.9330, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  475000, Reward:   250.739 [  97.670], Avg:   142.930 (0.000) <0-11:58:59> ({'r_t': -1147.0299, 'eps':     0.0002, 'len': 39125.9710, 'dyn_loss':    11.7072, 'dot_loss':     2.0354, 'ddot_loss':     4.3816, 'rew_loss':   298.4887, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  476000, Reward:   280.944 [  52.678], Avg:   143.219 (0.200) <0-12:00:59> ({'r_t':   890.9102, 'eps':     0.2002, 'len': 39200.2910, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  477000, Reward:   276.018 [  48.468], Avg:   143.497 (0.400) <0-12:02:39> ({'r_t':   729.5429, 'eps':     0.4002, 'len': 39249.4210, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  478000, Reward:   255.284 [  65.279], Avg:   143.731 (0.600) <0-12:04:07> ({'r_t':    71.4290, 'eps':     0.6002, 'len': 39301.1430, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  479000, Reward:   239.676 [  87.553], Avg:   143.930 (0.800) <0-12:05:17> ({'r_t':  -585.4357, 'eps':     0.8002, 'len': 39367.2620, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  480000, Reward:   139.031 [ 146.895], Avg:   143.920 (0.000) <0-12:07:45> ({'r_t': -1129.1158, 'eps':     0.0002, 'len': 39456.1340, 'dyn_loss':    11.3374, 'dot_loss':     2.0164, 'ddot_loss':     4.3771, 'rew_loss':   295.3454, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  481000, Reward:   203.868 [  94.688], Avg:   144.045 (0.200) <0-12:09:43> ({'r_t':   653.2011, 'eps':     0.2002, 'len': 39537.2320, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  482000, Reward:   165.592 [ 118.105], Avg:   144.089 (0.400) <0-12:11:28> ({'r_t':   549.5257, 'eps':     0.4002, 'len': 39586.9660, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  483000, Reward:   206.720 [ 121.109], Avg:   144.219 (0.600) <0-12:12:55> ({'r_t':    -5.9921, 'eps':     0.6002, 'len': 39633.9800, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  484000, Reward:   161.379 [ 130.208], Avg:   144.254 (0.800) <0-12:14:04> ({'r_t':  -592.8716, 'eps':     0.8002, 'len': 39700.6320, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  485000, Reward:   118.650 [ 120.370], Avg:   144.201 (0.000) <0-12:16:28> ({'r_t': -1074.1383, 'eps':     0.0002, 'len': 39790.2610, 'dyn_loss':    11.5040, 'dot_loss':     1.9840, 'ddot_loss':     4.2979, 'rew_loss':   297.4897, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  486000, Reward:   173.852 [ 100.609], Avg:   144.262 (0.200) <0-12:18:22> ({'r_t':   657.1695, 'eps':     0.2002, 'len': 39865.2580, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  487000, Reward:   226.376 [  53.121], Avg:   144.431 (0.400) <0-12:20:05> ({'r_t':   629.3990, 'eps':     0.4002, 'len': 39914.4590, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  488000, Reward:   146.990 [ 117.831], Avg:   144.436 (0.600) <0-12:21:32> ({'r_t':    91.2923, 'eps':     0.6002, 'len': 39964.0570, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  489000, Reward:   163.279 [  90.305], Avg:   144.474 (0.800) <0-12:22:42> ({'r_t':  -632.3278, 'eps':     0.8002, 'len': 40028.4880, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  490000, Reward:   234.273 [ 142.262], Avg:   144.657 (0.000) <0-12:25:00> ({'r_t': -1024.0359, 'eps':     0.0002, 'len': 40133.3220, 'dyn_loss':    11.6356, 'dot_loss':     2.0070, 'ddot_loss':     4.3187, 'rew_loss':   294.1749, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  491000, Reward:   289.563 [  83.021], Avg:   144.952 (0.200) <0-12:27:02> ({'r_t':   836.7256, 'eps':     0.2002, 'len': 40210.1970, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  492000, Reward:   277.203 [  87.685], Avg:   145.220 (0.400) <0-12:28:51> ({'r_t':   735.1326, 'eps':     0.4002, 'len': 40260.1750, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  493000, Reward:   286.154 [ 132.395], Avg:   145.505 (0.600) <0-12:30:10> ({'r_t':    76.8169, 'eps':     0.6002, 'len': 40311.4780, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  494000, Reward:   197.902 [ 146.236], Avg:   145.611 (0.800) <0-12:31:24> ({'r_t':  -655.4769, 'eps':     0.8002, 'len': 40381.8450, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  495000, Reward:   226.831 [  89.289], Avg:   145.775 (0.000) <0-12:33:48> ({'r_t': -1099.1521, 'eps':     0.0002, 'len': 40483.0690, 'dyn_loss':    11.4102, 'dot_loss':     1.9824, 'ddot_loss':     4.2707, 'rew_loss':   305.4529, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  496000, Reward:   240.666 [  56.938], Avg:   145.966 (0.200) <0-12:35:46> ({'r_t':   841.3820, 'eps':     0.2002, 'len': 40557.0860, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  497000, Reward:   255.698 [  85.501], Avg:   146.186 (0.400) <0-12:37:34> ({'r_t':   676.7327, 'eps':     0.4002, 'len': 40604.2110, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  498000, Reward:   232.869 [ 105.613], Avg:   146.360 (0.600) <0-12:39:06> ({'r_t':    12.5234, 'eps':     0.6002, 'len': 40657.6270, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  499000, Reward:   276.292 [  53.394], Avg:   146.620 (0.800) <0-12:40:14> ({'r_t':  -650.1400, 'eps':     0.8002, 'len': 40722.1920, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  500000, Reward:   241.761 [  50.542], Avg:   146.810 (0.000) <0-12:42:37> ({'r_t': -1109.5370, 'eps':     0.0002, 'len': 40813.6000, 'dyn_loss':    10.8118, 'dot_loss':     1.8870, 'ddot_loss':     4.0979, 'rew_loss':   297.2081, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  501000, Reward:   255.166 [  34.026], Avg:   147.025 (0.200) <0-12:44:31> ({'r_t':   874.4806, 'eps':     0.2002, 'len': 40891.4860, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  502000, Reward:   252.670 [  50.796], Avg:   147.235 (0.400) <0-12:46:08> ({'r_t':   677.0291, 'eps':     0.4002, 'len': 40942.4500, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  503000, Reward:   262.208 [  64.145], Avg:   147.464 (0.600) <0-12:47:33> ({'r_t':   132.7091, 'eps':     0.6002, 'len': 40993.3400, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  504000, Reward:   235.549 [  88.301], Avg:   147.638 (0.800) <0-12:48:42> ({'r_t':  -650.6945, 'eps':     0.8002, 'len': 41059.9360, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  505000, Reward:   138.334 [ 191.629], Avg:   147.620 (0.000) <0-12:50:58> ({'r_t': -1129.0609, 'eps':     0.0002, 'len': 41153.2120, 'dyn_loss':    11.5143, 'dot_loss':     1.9803, 'ddot_loss':     4.2786, 'rew_loss':   303.2321, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  506000, Reward:   240.359 [ 169.982], Avg:   147.802 (0.200) <0-12:52:49> ({'r_t':   848.3115, 'eps':     0.2002, 'len': 41237.7420, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  507000, Reward:   289.574 [ 142.681], Avg:   148.082 (0.400) <0-12:54:24> ({'r_t':   674.6214, 'eps':     0.4002, 'len': 41293.2960, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  508000, Reward:   271.101 [ 125.520], Avg:   148.323 (0.600) <0-12:55:45> ({'r_t':     8.3378, 'eps':     0.6002, 'len': 41341.2030, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  509000, Reward:   206.261 [ 177.663], Avg:   148.437 (0.800) <0-12:56:50> ({'r_t':  -676.8457, 'eps':     0.8002, 'len': 41400.0250, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  510000, Reward:   278.992 [ 129.504], Avg:   148.692 (0.000) <0-12:59:05> ({'r_t': -1099.6072, 'eps':     0.0002, 'len': 41497.6170, 'dyn_loss':    10.9647, 'dot_loss':     1.9402, 'ddot_loss':     4.2140, 'rew_loss':   301.7321, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  511000, Reward:   272.940 [ 125.580], Avg:   148.935 (0.200) <0-13:00:57> ({'r_t':   981.7047, 'eps':     0.2002, 'len': 41581.7570, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  512000, Reward:   336.159 [  31.492], Avg:   149.300 (0.400) <0-13:02:34> ({'r_t':   810.2339, 'eps':     0.4002, 'len': 41630.8470, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  513000, Reward:   318.467 [  97.105], Avg:   149.629 (0.600) <0-13:03:54> ({'r_t':   142.3494, 'eps':     0.6002, 'len': 41682.0310, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  514000, Reward:   320.332 [  35.322], Avg:   149.961 (0.800) <0-13:04:57> ({'r_t':  -637.3368, 'eps':     0.8002, 'len': 41751.1380, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  515000, Reward:   305.947 [  99.542], Avg:   150.263 (0.000) <0-13:07:13> ({'r_t': -1128.7557, 'eps':     0.0002, 'len': 41846.4800, 'dyn_loss':    10.9762, 'dot_loss':     1.9354, 'ddot_loss':     4.2121, 'rew_loss':   312.8412, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  516000, Reward:   327.332 [  38.037], Avg:   150.605 (0.200) <0-13:09:06> ({'r_t':  1071.9815, 'eps':     0.2002, 'len': 41928.7840, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  517000, Reward:   325.253 [  68.755], Avg:   150.943 (0.400) <0-13:10:48> ({'r_t':   739.1880, 'eps':     0.4002, 'len': 41979.9420, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  518000, Reward:   278.173 [  94.121], Avg:   151.188 (0.600) <0-13:12:17> ({'r_t':    12.3204, 'eps':     0.6002, 'len': 42029.8860, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  519000, Reward:   310.321 [  60.453], Avg:   151.494 (0.800) <0-13:13:29> ({'r_t':  -630.3276, 'eps':     0.8002, 'len': 42094.1480, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  520000, Reward:    73.247 [ 161.052], Avg:   151.343 (0.000) <0-13:15:53> ({'r_t': -1127.1451, 'eps':     0.0002, 'len': 42180.8560, 'dyn_loss':    10.8038, 'dot_loss':     1.9032, 'ddot_loss':     4.1347, 'rew_loss':   296.7708, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  521000, Reward:   230.724 [ 125.121], Avg:   151.496 (0.200) <0-13:17:48> ({'r_t':   818.6816, 'eps':     0.2002, 'len': 42253.7670, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  522000, Reward:   182.013 [ 164.172], Avg:   151.554 (0.400) <0-13:19:35> ({'r_t':   719.4109, 'eps':     0.4002, 'len': 42304.9850, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  523000, Reward:   223.151 [ 112.114], Avg:   151.691 (0.600) <0-13:20:56> ({'r_t':   143.9321, 'eps':     0.6002, 'len': 42355.2820, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  524000, Reward:   127.774 [ 166.984], Avg:   151.645 (0.800) <0-13:22:01> ({'r_t':  -645.8337, 'eps':     0.8002, 'len': 42424.2330, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  525000, Reward:   192.249 [ 153.926], Avg:   151.722 (0.000) <0-13:24:24> ({'r_t': -1113.5521, 'eps':     0.0002, 'len': 42512.9520, 'dyn_loss':    10.6461, 'dot_loss':     1.9282, 'ddot_loss':     4.2146, 'rew_loss':   298.6847, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  526000, Reward:   271.784 [ 107.525], Avg:   151.950 (0.200) <0-13:26:21> ({'r_t':   827.8676, 'eps':     0.2002, 'len': 42590.9850, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  527000, Reward:   250.526 [ 121.164], Avg:   152.137 (0.400) <0-13:28:07> ({'r_t':   778.2671, 'eps':     0.4002, 'len': 42641.8270, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  528000, Reward:   271.670 [ 100.534], Avg:   152.363 (0.600) <0-13:29:32> ({'r_t':   105.2521, 'eps':     0.6002, 'len': 42691.9020, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  529000, Reward:   173.129 [ 173.229], Avg:   152.402 (0.800) <0-13:30:41> ({'r_t':  -677.2889, 'eps':     0.8002, 'len': 42755.0930, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  530000, Reward:   188.009 [ 163.639], Avg:   152.469 (0.000) <0-13:33:02> ({'r_t': -1094.2724, 'eps':     0.0002, 'len': 42846.1050, 'dyn_loss':    11.0597, 'dot_loss':     1.9177, 'ddot_loss':     4.1619, 'rew_loss':   300.3167, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  531000, Reward:   287.381 [ 110.152], Avg:   152.723 (0.200) <0-13:34:54> ({'r_t':   826.9200, 'eps':     0.2002, 'len': 42926.7850, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  532000, Reward:   228.646 [ 167.459], Avg:   152.865 (0.400) <0-13:36:32> ({'r_t':   593.7142, 'eps':     0.4002, 'len': 42973.8010, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  533000, Reward:   222.056 [ 172.296], Avg:   152.995 (0.600) <0-13:37:58> ({'r_t':   106.6324, 'eps':     0.6002, 'len': 43015.1450, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  534000, Reward:    92.376 [ 166.393], Avg:   152.881 (0.800) <0-13:39:04> ({'r_t':  -664.5646, 'eps':     0.8002, 'len': 43079.5820, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  535000, Reward:   277.312 [  76.218], Avg:   153.113 (0.000) <0-13:41:22> ({'r_t': -1125.8087, 'eps':     0.0002, 'len': 43176.2260, 'dyn_loss':    11.1937, 'dot_loss':     1.9549, 'ddot_loss':     4.2427, 'rew_loss':   308.8002, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  536000, Reward:   295.791 [  55.753], Avg:   153.379 (0.200) <0-13:43:15> ({'r_t':   834.1805, 'eps':     0.2002, 'len': 43251.6010, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  537000, Reward:   248.395 [ 101.938], Avg:   153.556 (0.400) <0-13:44:54> ({'r_t':   596.3011, 'eps':     0.4002, 'len': 43298.2110, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  538000, Reward:   238.776 [ 105.024], Avg:   153.714 (0.600) <0-13:46:24> ({'r_t':    30.9223, 'eps':     0.6002, 'len': 43345.9700, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  539000, Reward:   255.708 [  63.192], Avg:   153.903 (0.800) <0-13:47:34> ({'r_t':  -599.3819, 'eps':     0.8002, 'len': 43408.5480, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  540000, Reward:   266.282 [  89.895], Avg:   154.110 (0.000) <0-13:49:52> ({'r_t': -1107.4211, 'eps':     0.0002, 'len': 43497.6860, 'dyn_loss':    11.1752, 'dot_loss':     1.9301, 'ddot_loss':     4.1930, 'rew_loss':   310.4343, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  541000, Reward:   255.574 [  96.541], Avg:   154.298 (0.200) <0-13:51:52> ({'r_t':   800.8412, 'eps':     0.2002, 'len': 43576.3540, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  542000, Reward:   301.782 [  31.077], Avg:   154.569 (0.400) <0-13:53:25> ({'r_t':   678.1933, 'eps':     0.4002, 'len': 43625.9980, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  543000, Reward:   270.466 [  49.185], Avg:   154.782 (0.600) <0-13:54:45> ({'r_t':    75.9764, 'eps':     0.6002, 'len': 43669.3040, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  544000, Reward:   251.673 [  91.889], Avg:   154.960 (0.800) <0-13:55:48> ({'r_t':  -643.7852, 'eps':     0.8002, 'len': 43731.3350, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  545000, Reward:   227.603 [ 163.284], Avg:   155.093 (0.000) <0-13:58:06> ({'r_t': -1070.4007, 'eps':     0.0002, 'len': 43820.9340, 'dyn_loss':    10.7265, 'dot_loss':     1.9001, 'ddot_loss':     4.1509, 'rew_loss':   305.3553, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  546000, Reward:   302.821 [ 104.278], Avg:   155.363 (0.200) <0-14:00:03> ({'r_t':   918.5471, 'eps':     0.2002, 'len': 43897.7080, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  547000, Reward:   328.492 [  42.511], Avg:   155.679 (0.400) <0-14:01:45> ({'r_t':   797.1638, 'eps':     0.4002, 'len': 43948.3090, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  548000, Reward:   285.536 [  99.991], Avg:   155.916 (0.600) <0-14:03:07> ({'r_t':    40.2402, 'eps':     0.6002, 'len': 43995.6370, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  549000, Reward:   240.100 [ 145.423], Avg:   156.069 (0.800) <0-14:04:14> ({'r_t':  -647.9333, 'eps':     0.8002, 'len': 44063.8090, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  550000, Reward:   223.277 [ 113.966], Avg:   156.191 (0.000) <0-14:06:44> ({'r_t': -1059.4526, 'eps':     0.0002, 'len': 44153.2240, 'dyn_loss':    10.9932, 'dot_loss':     1.9398, 'ddot_loss':     4.2123, 'rew_loss':   312.4744, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  551000, Reward:   249.529 [  78.516], Avg:   156.360 (0.200) <0-14:08:49> ({'r_t':   840.3839, 'eps':     0.2002, 'len': 44227.0470, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  552000, Reward:   247.004 [ 109.762], Avg:   156.524 (0.400) <0-14:10:37> ({'r_t':   736.2593, 'eps':     0.4002, 'len': 44274.2130, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  553000, Reward:   259.177 [ 100.273], Avg:   156.709 (0.600) <0-14:12:02> ({'r_t':   119.9658, 'eps':     0.6002, 'len': 44319.1640, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  554000, Reward:   162.686 [ 163.142], Avg:   156.720 (0.800) <0-14:13:20> ({'r_t':  -646.2789, 'eps':     0.8002, 'len': 44380.4290, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  555000, Reward:   172.243 [ 185.802], Avg:   156.748 (0.000) <0-14:15:38> ({'r_t': -1108.5068, 'eps':     0.0002, 'len': 44473.3920, 'dyn_loss':    10.8001, 'dot_loss':     1.8909, 'ddot_loss':     4.1165, 'rew_loss':   309.7292, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  556000, Reward:   324.620 [ 109.945], Avg:   157.049 (0.200) <0-14:17:31> ({'r_t':   992.3865, 'eps':     0.2002, 'len': 44559.2680, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  557000, Reward:   351.828 [  25.023], Avg:   157.398 (0.400) <0-14:19:07> ({'r_t':   781.4574, 'eps':     0.4002, 'len': 44611.3390, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  558000, Reward:   223.100 [ 188.549], Avg:   157.516 (0.600) <0-14:20:28> ({'r_t':    90.8522, 'eps':     0.6002, 'len': 44659.7180, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  559000, Reward:   242.274 [ 171.930], Avg:   157.667 (0.800) <0-14:21:33> ({'r_t':  -651.3342, 'eps':     0.8002, 'len': 44727.4190, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  560000, Reward:   -32.486 [  89.764], Avg:   157.328 (0.000) <0-14:23:50> ({'r_t': -1087.7522, 'eps':     0.0002, 'len': 44820.5240, 'dyn_loss':    11.3122, 'dot_loss':     1.9457, 'ddot_loss':     4.2096, 'rew_loss':   310.8390, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  561000, Reward:   177.702 [ 175.123], Avg:   157.364 (0.200) <0-14:25:57> ({'r_t':   206.3843, 'eps':     0.2002, 'len': 44937.2150, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  562000, Reward:   158.066 [ 179.363], Avg:   157.366 (0.400) <0-14:27:37> ({'r_t':   678.1963, 'eps':     0.4002, 'len': 45005.8820, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  563000, Reward:   135.987 [ 198.795], Avg:   157.328 (0.600) <0-14:29:11> ({'r_t':   166.4534, 'eps':     0.6002, 'len': 45054.1610, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  564000, Reward:   -11.826 [ 126.225], Avg:   157.028 (0.800) <0-14:30:15> ({'r_t':  -593.1333, 'eps':     0.8002, 'len': 45123.4820, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  565000, Reward:   196.912 [ 148.159], Avg:   157.099 (0.000) <0-14:32:35> ({'r_t': -1131.7974, 'eps':     0.0002, 'len': 45213.5820, 'dyn_loss':    11.0122, 'dot_loss':     1.9153, 'ddot_loss':     4.1656, 'rew_loss':   307.0136, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  566000, Reward:   271.392 [  95.169], Avg:   157.300 (0.200) <0-14:34:29> ({'r_t':   888.0059, 'eps':     0.2002, 'len': 45287.0530, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  567000, Reward:   281.107 [  95.111], Avg:   157.518 (0.400) <0-14:36:04> ({'r_t':   727.6202, 'eps':     0.4002, 'len': 45335.4570, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  568000, Reward:   287.139 [  93.997], Avg:   157.746 (0.600) <0-14:37:25> ({'r_t':    70.1177, 'eps':     0.6002, 'len': 45381.6740, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  569000, Reward:   241.357 [ 114.123], Avg:   157.893 (0.800) <0-14:38:31> ({'r_t':  -578.2732, 'eps':     0.8002, 'len': 45439.1200, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  570000, Reward:   107.180 [ 182.433], Avg:   157.804 (0.000) <0-14:40:52> ({'r_t': -1096.0953, 'eps':     0.0002, 'len': 45530.0080, 'dyn_loss':    11.1071, 'dot_loss':     1.9276, 'ddot_loss':     4.1855, 'rew_loss':   314.0997, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  571000, Reward:   304.017 [ 149.991], Avg:   158.060 (0.200) <0-14:42:58> ({'r_t':   811.7374, 'eps':     0.2002, 'len': 45621.3840, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  572000, Reward:   292.113 [ 137.788], Avg:   158.293 (0.400) <0-14:44:37> ({'r_t':   866.8742, 'eps':     0.4002, 'len': 45675.2060, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  573000, Reward:   298.358 [ 138.558], Avg:   158.537 (0.600) <0-14:45:56> ({'r_t':    81.8169, 'eps':     0.6002, 'len': 45724.4690, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  574000, Reward:   187.965 [ 187.027], Avg:   158.589 (0.800) <0-14:47:02> ({'r_t':  -584.9395, 'eps':     0.8002, 'len': 45791.4940, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  575000, Reward:   191.913 [ 173.392], Avg:   158.647 (0.000) <0-14:49:22> ({'r_t': -1126.9081, 'eps':     0.0002, 'len': 45878.5630, 'dyn_loss':    10.9437, 'dot_loss':     1.9205, 'ddot_loss':     4.1733, 'rew_loss':   314.0933, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  576000, Reward:   266.167 [ 120.401], Avg:   158.833 (0.200) <0-14:51:19> ({'r_t':   812.0699, 'eps':     0.2002, 'len': 45963.7160, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  577000, Reward:   272.206 [ 129.324], Avg:   159.029 (0.400) <0-14:52:55> ({'r_t':   621.7144, 'eps':     0.4002, 'len': 46014.2510, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  578000, Reward:   250.933 [ 147.104], Avg:   159.188 (0.600) <0-14:54:15> ({'r_t':   -42.4019, 'eps':     0.6002, 'len': 46058.4810, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  579000, Reward:   187.328 [ 165.128], Avg:   159.236 (0.800) <0-14:55:23> ({'r_t':  -643.9535, 'eps':     0.8002, 'len': 46124.9290, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  580000, Reward:   243.371 [ 112.583], Avg:   159.381 (0.000) <0-14:57:44> ({'r_t': -1120.7058, 'eps':     0.0002, 'len': 46221.6840, 'dyn_loss':    10.9465, 'dot_loss':     1.8981, 'ddot_loss':     4.1172, 'rew_loss':   310.4197, 'lr':     0.0001, 'eps_e':     0.0002, 'lr_e':     0.0001})
Step:  581000, Reward:   270.685 [ 107.076], Avg:   159.572 (0.200) <0-14:59:38> ({'r_t':   849.4547, 'eps':     0.2002, 'len': 46307.7030, 'lr':     0.0001, 'eps_e':     0.2002, 'lr_e':     0.0001})
Step:  582000, Reward:   262.735 [ 107.338], Avg:   159.749 (0.400) <0-15:01:17> ({'r_t':   634.6186, 'eps':     0.4002, 'len': 46360.5890, 'lr':     0.0001, 'eps_e':     0.4002, 'lr_e':     0.0001})
Step:  583000, Reward:   248.525 [ 125.263], Avg:   159.901 (0.600) <0-15:02:40> ({'r_t':   112.3376, 'eps':     0.6002, 'len': 46404.3230, 'lr':     0.0001, 'eps_e':     0.6002, 'lr_e':     0.0001})
Step:  584000, Reward:   222.293 [ 136.842], Avg:   160.008 (0.800) <0-15:03:46> ({'r_t':  -599.2608, 'eps':     0.8002, 'len': 46468.3260, 'lr':     0.0001, 'eps_e':     0.8002, 'lr_e':     0.0001})
Step:  585000, Reward:   163.972 [ 172.384], Avg:   160.015 (0.000) <0-15:06:04> ({'r_t': -1061.8672, 'eps':     0.0002, 'len': 46565.4850, 'dyn_loss':    10.8879, 'dot_loss':     1.8978, 'ddot_loss':     4.1259, 'rew_loss':   307.1722, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  586000, Reward:   309.584 [  30.956], Avg:   160.270 (0.200) <0-15:07:58> ({'r_t':   824.9532, 'eps':     0.2002, 'len': 46658.3860, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  587000, Reward:   262.509 [ 120.921], Avg:   160.443 (0.400) <0-15:09:37> ({'r_t':   744.6841, 'eps':     0.4002, 'len': 46715.2830, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  588000, Reward:   314.567 [  36.044], Avg:   160.705 (0.600) <0-15:10:57> ({'r_t':   114.0000, 'eps':     0.6002, 'len': 46764.1090, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  589000, Reward:   226.033 [ 136.146], Avg:   160.816 (0.800) <0-15:12:04> ({'r_t':  -622.2586, 'eps':     0.8002, 'len': 46831.4140, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  590000, Reward:   216.123 [ 129.510], Avg:   160.909 (0.000) <0-15:14:30> ({'r_t': -1132.8358, 'eps':     0.0002, 'len': 46931.9740, 'dyn_loss':    10.8422, 'dot_loss':     1.9045, 'ddot_loss':     4.1427, 'rew_loss':   310.3854, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  591000, Reward:   301.595 [  98.128], Avg:   161.147 (0.200) <0-15:16:25> ({'r_t':   956.2306, 'eps':     0.2002, 'len': 47010.2530, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  592000, Reward:   256.594 [ 112.311], Avg:   161.308 (0.400) <0-15:18:11> ({'r_t':   617.8976, 'eps':     0.4002, 'len': 47061.3830, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  593000, Reward:   284.539 [  94.045], Avg:   161.515 (0.600) <0-15:19:45> ({'r_t':    76.2768, 'eps':     0.6002, 'len': 47108.5070, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  594000, Reward:   284.323 [  58.351], Avg:   161.722 (0.800) <0-15:20:51> ({'r_t':  -622.6788, 'eps':     0.8002, 'len': 47167.9910, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  595000, Reward:    59.879 [ 119.468], Avg:   161.551 (0.000) <0-15:23:22> ({'r_t': -1082.0393, 'eps':     0.0002, 'len': 47260.8450, 'dyn_loss':    10.6959, 'dot_loss':     1.8603, 'ddot_loss':     4.0518, 'rew_loss':   308.8350, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  596000, Reward:   127.515 [ 130.706], Avg:   161.494 (0.200) <0-15:25:28> ({'r_t':   501.9325, 'eps':     0.2002, 'len': 47354.3320, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  597000, Reward:   154.842 [  89.003], Avg:   161.483 (0.400) <0-15:27:07> ({'r_t':   745.1671, 'eps':     0.4002, 'len': 47411.6590, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  598000, Reward:   108.700 [ 102.514], Avg:   161.395 (0.600) <0-15:28:36> ({'r_t':   210.2304, 'eps':     0.6002, 'len': 47463.4040, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  599000, Reward:    94.703 [ 135.768], Avg:   161.284 (0.800) <0-15:29:46> ({'r_t':  -571.1981, 'eps':     0.8002, 'len': 47528.3070, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  600000, Reward:   241.506 [ 151.848], Avg:   161.417 (0.000) <0-15:32:05> ({'r_t': -1039.2582, 'eps':     0.0002, 'len': 47620.8450, 'dyn_loss':    10.9087, 'dot_loss':     1.9361, 'ddot_loss':     4.2176, 'rew_loss':   313.3883, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  601000, Reward:   308.813 [ 103.274], Avg:   161.662 (0.200) <0-15:33:57> ({'r_t':   966.0330, 'eps':     0.2002, 'len': 47706.5390, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  602000, Reward:   296.763 [ 132.658], Avg:   161.886 (0.400) <0-15:35:32> ({'r_t':   776.6471, 'eps':     0.4002, 'len': 47758.9520, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  603000, Reward:   286.979 [ 131.025], Avg:   162.093 (0.600) <0-15:36:55> ({'r_t':    85.8646, 'eps':     0.6002, 'len': 47808.0060, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  604000, Reward:   258.844 [ 152.935], Avg:   162.253 (0.800) <0-15:38:00> ({'r_t':  -610.9603, 'eps':     0.8002, 'len': 47872.1240, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  605000, Reward:   146.804 [ 181.578], Avg:   162.227 (0.000) <0-15:40:20> ({'r_t': -1137.0166, 'eps':     0.0002, 'len': 47960.9720, 'dyn_loss':    11.1366, 'dot_loss':     1.9120, 'ddot_loss':     4.1665, 'rew_loss':   315.7200, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  606000, Reward:   287.656 [  98.583], Avg:   162.434 (0.200) <0-15:42:16> ({'r_t':   817.1709, 'eps':     0.2002, 'len': 48047.6820, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  607000, Reward:   229.806 [ 167.385], Avg:   162.545 (0.400) <0-15:43:51> ({'r_t':   759.2732, 'eps':     0.4002, 'len': 48103.3850, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  608000, Reward:   276.151 [ 130.147], Avg:   162.731 (0.600) <0-15:45:13> ({'r_t':    93.2542, 'eps':     0.6002, 'len': 48154.7040, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  609000, Reward:   171.561 [ 176.870], Avg:   162.746 (0.800) <0-15:46:18> ({'r_t':  -568.4420, 'eps':     0.8002, 'len': 48218.5020, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  610000, Reward:   275.448 [ 152.727], Avg:   162.930 (0.000) <0-15:48:45> ({'r_t': -1114.5033, 'eps':     0.0002, 'len': 48308.7260, 'dyn_loss':    10.7223, 'dot_loss':     1.8810, 'ddot_loss':     4.0966, 'rew_loss':   316.5034, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  611000, Reward:   333.753 [ 104.213], Avg:   163.209 (0.200) <0-15:50:43> ({'r_t':  1014.1981, 'eps':     0.2002, 'len': 48392.1730, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  612000, Reward:   262.087 [ 181.458], Avg:   163.371 (0.400) <0-15:52:21> ({'r_t':   708.5755, 'eps':     0.4002, 'len': 48441.1610, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  613000, Reward:   355.531 [  34.330], Avg:   163.684 (0.600) <0-15:53:45> ({'r_t':   132.4840, 'eps':     0.6002, 'len': 48486.4010, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  614000, Reward:   299.789 [ 140.458], Avg:   163.905 (0.800) <0-15:54:53> ({'r_t':  -657.7332, 'eps':     0.8002, 'len': 48546.6760, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  615000, Reward:   236.151 [ 153.346], Avg:   164.022 (0.000) <0-15:57:26> ({'r_t': -1091.2419, 'eps':     0.0002, 'len': 48641.8800, 'dyn_loss':    11.0694, 'dot_loss':     1.8805, 'ddot_loss':     4.0755, 'rew_loss':   323.4029, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  616000, Reward:   298.741 [ 117.479], Avg:   164.241 (0.200) <0-15:59:23> ({'r_t':   907.3190, 'eps':     0.2002, 'len': 48727.2000, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  617000, Reward:   319.462 [ 101.966], Avg:   164.492 (0.400) <0-16:01:00> ({'r_t':   741.9503, 'eps':     0.4002, 'len': 48779.0110, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  618000, Reward:   316.333 [ 141.935], Avg:   164.737 (0.600) <0-16:02:22> ({'r_t':    48.2571, 'eps':     0.6002, 'len': 48829.0210, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  619000, Reward:   321.732 [  28.613], Avg:   164.990 (0.800) <0-16:03:30> ({'r_t':  -671.7281, 'eps':     0.8002, 'len': 48896.9010, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  620000, Reward:   322.730 [  40.885], Avg:   165.244 (0.000) <0-16:05:58> ({'r_t': -1078.1703, 'eps':     0.0002, 'len': 48994.9650, 'dyn_loss':    10.8336, 'dot_loss':     1.8884, 'ddot_loss':     4.1070, 'rew_loss':   320.2267, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  621000, Reward:   319.051 [  97.237], Avg:   165.492 (0.200) <0-16:07:49> ({'r_t':  1050.0596, 'eps':     0.2002, 'len': 49071.7970, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  622000, Reward:   311.473 [ 105.033], Avg:   165.726 (0.400) <0-16:09:35> ({'r_t':   855.6958, 'eps':     0.4002, 'len': 49122.5770, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  623000, Reward:   330.826 [  50.474], Avg:   165.991 (0.600) <0-16:10:58> ({'r_t':   167.2013, 'eps':     0.6002, 'len': 49173.0720, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  624000, Reward:   326.265 [  32.239], Avg:   166.247 (0.800) <0-16:12:05> ({'r_t':  -587.2571, 'eps':     0.8002, 'len': 49237.1370, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  625000, Reward:   343.862 [  29.707], Avg:   166.531 (0.000) <0-16:14:27> ({'r_t': -1067.3405, 'eps':     0.0002, 'len': 49325.6800, 'dyn_loss':    10.6865, 'dot_loss':     1.8725, 'ddot_loss':     4.0775, 'rew_loss':   324.9239, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  626000, Reward:   364.841 [  15.542], Avg:   166.847 (0.200) <0-16:16:19> ({'r_t':  1085.2807, 'eps':     0.2002, 'len': 49406.9920, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  627000, Reward:   364.531 [  23.179], Avg:   167.162 (0.400) <0-16:17:55> ({'r_t':   861.9816, 'eps':     0.4002, 'len': 49460.2990, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  628000, Reward:   353.240 [  18.902], Avg:   167.458 (0.600) <0-16:19:15> ({'r_t':    92.3507, 'eps':     0.6002, 'len': 49513.0250, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  629000, Reward:   345.549 [  21.299], Avg:   167.740 (0.800) <0-16:20:19> ({'r_t':  -612.2184, 'eps':     0.8002, 'len': 49581.8140, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  630000, Reward:   219.589 [ 133.935], Avg:   167.822 (0.000) <0-16:22:54> ({'r_t': -1187.8971, 'eps':     0.0002, 'len': 49671.8820, 'dyn_loss':    10.9604, 'dot_loss':     1.9095, 'ddot_loss':     4.1640, 'rew_loss':   327.5354, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  631000, Reward:   258.991 [ 145.875], Avg:   167.967 (0.200) <0-16:25:02> ({'r_t':   835.4795, 'eps':     0.2002, 'len': 49746.5160, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  632000, Reward:   246.293 [ 165.987], Avg:   168.090 (0.400) <0-16:26:53> ({'r_t':   805.2374, 'eps':     0.4002, 'len': 49799.4020, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  633000, Reward:   188.236 [ 177.059], Avg:   168.122 (0.600) <0-16:28:28> ({'r_t':   202.4194, 'eps':     0.6002, 'len': 49853.6860, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  634000, Reward:   194.420 [ 162.289], Avg:   168.164 (0.800) <0-16:29:48> ({'r_t':  -607.1010, 'eps':     0.8002, 'len': 49918.5000, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  635000, Reward:   233.437 [ 139.693], Avg:   168.266 (0.000) <0-16:32:23> ({'r_t': -1061.4055, 'eps':     0.0002, 'len': 50006.6820, 'dyn_loss':    10.9360, 'dot_loss':     1.8890, 'ddot_loss':     4.0956, 'rew_loss':   316.5358, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  636000, Reward:   335.623 [  31.290], Avg:   168.529 (0.200) <0-16:34:20> ({'r_t':   940.3904, 'eps':     0.2002, 'len': 50084.1630, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  637000, Reward:   319.063 [  77.777], Avg:   168.765 (0.400) <0-16:35:59> ({'r_t':   797.1415, 'eps':     0.4002, 'len': 50134.8390, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  638000, Reward:   230.696 [ 171.493], Avg:   168.862 (0.600) <0-16:37:20> ({'r_t':   110.4878, 'eps':     0.6002, 'len': 50185.3470, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  639000, Reward:   264.924 [ 105.091], Avg:   169.012 (0.800) <0-16:38:36> ({'r_t':  -644.5114, 'eps':     0.8002, 'len': 50252.1000, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  640000, Reward:   259.581 [ 152.919], Avg:   169.153 (0.000) <0-16:40:59> ({'r_t': -1128.0302, 'eps':     0.0002, 'len': 50344.2130, 'dyn_loss':    10.6875, 'dot_loss':     1.8545, 'ddot_loss':     4.0435, 'rew_loss':   319.4396, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  641000, Reward:   320.231 [ 105.334], Avg:   169.389 (0.200) <0-16:42:52> ({'r_t':   992.0239, 'eps':     0.2002, 'len': 50430.0690, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  642000, Reward:   367.513 [  31.973], Avg:   169.697 (0.400) <0-16:44:26> ({'r_t':   803.5766, 'eps':     0.4002, 'len': 50485.1020, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  643000, Reward:   362.110 [  31.824], Avg:   169.996 (0.600) <0-16:45:46> ({'r_t':   132.7594, 'eps':     0.6002, 'len': 50538.0770, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  644000, Reward:   325.286 [  38.144], Avg:   170.236 (0.800) <0-16:46:55> ({'r_t':  -641.5499, 'eps':     0.8002, 'len': 50598.9420, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  645000, Reward:   143.240 [ 200.594], Avg:   170.194 (0.000) <0-16:49:14> ({'r_t': -1093.2631, 'eps':     0.0002, 'len': 50690.4080, 'dyn_loss':    10.8192, 'dot_loss':     1.8643, 'ddot_loss':     4.0643, 'rew_loss':   320.7142, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  646000, Reward:   281.038 [ 166.355], Avg:   170.366 (0.200) <0-16:51:08> ({'r_t':   854.2869, 'eps':     0.2002, 'len': 50782.6010, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  647000, Reward:   292.927 [ 145.825], Avg:   170.555 (0.400) <0-16:52:47> ({'r_t':   944.7537, 'eps':     0.4002, 'len': 50842.1270, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  648000, Reward:   247.722 [ 171.094], Avg:   170.674 (0.600) <0-16:54:11> ({'r_t':   131.2954, 'eps':     0.6002, 'len': 50900.4550, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  649000, Reward:    92.116 [ 190.785], Avg:   170.553 (0.800) <0-16:55:15> ({'r_t':  -630.6727, 'eps':     0.8002, 'len': 50970.5470, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  650000, Reward:   257.430 [ 129.145], Avg:   170.686 (0.000) <0-16:57:46> ({'r_t': -1062.6096, 'eps':     0.0002, 'len': 51066.7200, 'dyn_loss':    10.4984, 'dot_loss':     1.8592, 'ddot_loss':     4.0506, 'rew_loss':   331.9193, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  651000, Reward:   329.383 [  26.877], Avg:   170.930 (0.200) <0-16:59:40> ({'r_t':   981.0929, 'eps':     0.2002, 'len': 51141.0720, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  652000, Reward:   344.034 [  39.815], Avg:   171.195 (0.400) <0-17:01:20> ({'r_t':   796.7339, 'eps':     0.4002, 'len': 51191.0430, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  653000, Reward:   287.361 [  99.233], Avg:   171.373 (0.600) <0-17:02:42> ({'r_t':   103.9039, 'eps':     0.6002, 'len': 51240.7060, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  654000, Reward:   248.766 [ 148.773], Avg:   171.491 (0.800) <0-17:03:48> ({'r_t':  -628.7152, 'eps':     0.8002, 'len': 51301.2930, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  655000, Reward:   239.310 [ 124.489], Avg:   171.594 (0.000) <0-17:06:15> ({'r_t': -1070.3242, 'eps':     0.0002, 'len': 51396.9120, 'dyn_loss':    10.6777, 'dot_loss':     1.8713, 'ddot_loss':     4.0776, 'rew_loss':   326.3378, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  656000, Reward:   260.968 [  91.488], Avg:   171.730 (0.200) <0-17:08:22> ({'r_t':   812.1074, 'eps':     0.2002, 'len': 51481.2520, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  657000, Reward:   215.492 [ 149.747], Avg:   171.797 (0.400) <0-17:10:06> ({'r_t':   885.7777, 'eps':     0.4002, 'len': 51533.1890, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  658000, Reward:   280.448 [  65.305], Avg:   171.961 (0.600) <0-17:11:38> ({'r_t':   164.4876, 'eps':     0.6002, 'len': 51586.4530, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  659000, Reward:   170.478 [ 180.466], Avg:   171.959 (0.800) <0-17:12:49> ({'r_t':  -629.9175, 'eps':     0.8002, 'len': 51653.8910, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  660000, Reward:   246.089 [ 175.213], Avg:   172.071 (0.000) <0-17:15:11> ({'r_t': -1123.7013, 'eps':     0.0002, 'len': 51749.8190, 'dyn_loss':    10.6665, 'dot_loss':     1.8664, 'ddot_loss':     4.0693, 'rew_loss':   323.8219, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  661000, Reward:   379.137 [  29.333], Avg:   172.384 (0.200) <0-17:17:03> ({'r_t':   984.9495, 'eps':     0.2002, 'len': 51834.2280, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  662000, Reward:   327.534 [ 107.241], Avg:   172.618 (0.400) <0-17:18:39> ({'r_t':   835.2892, 'eps':     0.4002, 'len': 51887.6740, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  663000, Reward:   313.296 [ 142.363], Avg:   172.830 (0.600) <0-17:19:59> ({'r_t':   114.4651, 'eps':     0.6002, 'len': 51939.7000, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  664000, Reward:   242.581 [ 174.038], Avg:   172.935 (0.800) <0-17:21:06> ({'r_t':  -623.6747, 'eps':     0.8002, 'len': 52001.1160, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  665000, Reward:   253.750 [  74.846], Avg:   173.056 (0.000) <0-17:23:34> ({'r_t': -1083.9162, 'eps':     0.0002, 'len': 52092.1460, 'dyn_loss':    10.6430, 'dot_loss':     1.8457, 'ddot_loss':     4.0268, 'rew_loss':   327.3787, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  666000, Reward:   242.618 [ 142.563], Avg:   173.161 (0.200) <0-17:25:35> ({'r_t':   924.9096, 'eps':     0.2002, 'len': 52171.3010, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  667000, Reward:   248.951 [ 137.215], Avg:   173.274 (0.400) <0-17:27:19> ({'r_t':   818.4094, 'eps':     0.4002, 'len': 52222.2570, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  668000, Reward:   279.859 [  95.827], Avg:   173.433 (0.600) <0-17:28:43> ({'r_t':   174.5174, 'eps':     0.6002, 'len': 52273.6470, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  669000, Reward:   110.738 [ 170.827], Avg:   173.340 (0.800) <0-17:29:51> ({'r_t':  -613.4660, 'eps':     0.8002, 'len': 52340.8420, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  670000, Reward:   173.286 [ 182.468], Avg:   173.340 (0.000) <0-17:32:14> ({'r_t': -1121.3655, 'eps':     0.0002, 'len': 52438.1020, 'dyn_loss':    10.9090, 'dot_loss':     1.8674, 'ddot_loss':     4.0617, 'rew_loss':   329.3657, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  671000, Reward:   256.153 [ 161.387], Avg:   173.463 (0.200) <0-17:34:08> ({'r_t':   948.5988, 'eps':     0.2002, 'len': 52531.2180, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  672000, Reward:   276.248 [ 138.442], Avg:   173.616 (0.400) <0-17:35:53> ({'r_t':   864.0426, 'eps':     0.4002, 'len': 52585.9590, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  673000, Reward:   238.163 [ 181.561], Avg:   173.711 (0.600) <0-17:37:15> ({'r_t':    28.5171, 'eps':     0.6002, 'len': 52637.6160, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  674000, Reward:   227.466 [ 172.137], Avg:   173.791 (0.800) <0-17:38:21> ({'r_t':  -623.2249, 'eps':     0.8002, 'len': 52708.2190, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  675000, Reward:    59.747 [ 177.647], Avg:   173.622 (0.000) <0-17:40:41> ({'r_t': -1131.2967, 'eps':     0.0002, 'len': 52811.9190, 'dyn_loss':    10.5844, 'dot_loss':     1.8516, 'ddot_loss':     4.0356, 'rew_loss':   327.7588, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  676000, Reward:   247.624 [ 178.718], Avg:   173.732 (0.200) <0-17:42:34> ({'r_t':   812.2160, 'eps':     0.2002, 'len': 52905.9390, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  677000, Reward:   241.023 [ 181.575], Avg:   173.831 (0.400) <0-17:44:11> ({'r_t':   801.4630, 'eps':     0.4002, 'len': 52963.4100, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  678000, Reward:   272.806 [ 159.382], Avg:   173.977 (0.600) <0-17:45:31> ({'r_t':   180.6313, 'eps':     0.6002, 'len': 53013.5740, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  679000, Reward:    84.795 [ 190.474], Avg:   173.846 (0.800) <0-17:46:35> ({'r_t':  -607.9054, 'eps':     0.8002, 'len': 53071.0780, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  680000, Reward:   116.567 [ 193.065], Avg:   173.761 (0.000) <0-17:48:54> ({'r_t': -1128.2020, 'eps':     0.0002, 'len': 53162.0980, 'dyn_loss':    10.6285, 'dot_loss':     1.8457, 'ddot_loss':     4.0223, 'rew_loss':   326.9831, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  681000, Reward:   285.364 [ 164.029], Avg:   173.925 (0.200) <0-17:50:47> ({'r_t':  1035.5259, 'eps':     0.2002, 'len': 53256.3760, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  682000, Reward:   326.990 [ 103.565], Avg:   174.149 (0.400) <0-17:52:21> ({'r_t':   925.7463, 'eps':     0.4002, 'len': 53317.7540, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  683000, Reward:   327.620 [  99.693], Avg:   174.374 (0.600) <0-17:53:39> ({'r_t':    74.0265, 'eps':     0.6002, 'len': 53372.3930, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  684000, Reward:   197.465 [ 194.173], Avg:   174.407 (0.800) <0-17:54:45> ({'r_t':  -626.8418, 'eps':     0.8002, 'len': 53441.7670, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  685000, Reward:    39.540 [ 138.703], Avg:   174.211 (0.000) <0-17:57:07> ({'r_t': -1118.6666, 'eps':     0.0002, 'len': 53530.1090, 'dyn_loss':    10.8890, 'dot_loss':     1.8924, 'ddot_loss':     4.1281, 'rew_loss':   335.2451, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  686000, Reward:   268.377 [ 105.203], Avg:   174.348 (0.200) <0-17:59:00> ({'r_t':   743.5118, 'eps':     0.2002, 'len': 53616.9130, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  687000, Reward:   218.536 [ 115.991], Avg:   174.412 (0.400) <0-18:00:42> ({'r_t':   713.1407, 'eps':     0.4002, 'len': 53670.4160, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  688000, Reward:   128.735 [ 173.340], Avg:   174.346 (0.600) <0-18:02:06> ({'r_t':    83.2680, 'eps':     0.6002, 'len': 53720.1210, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  689000, Reward:   100.988 [ 152.490], Avg:   174.239 (0.800) <0-18:03:24> ({'r_t':  -613.0619, 'eps':     0.8002, 'len': 53784.5260, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  690000, Reward:   249.426 [ 147.735], Avg:   174.348 (0.000) <0-18:05:47> ({'r_t': -1090.3297, 'eps':     0.0002, 'len': 53877.9460, 'dyn_loss':    10.3517, 'dot_loss':     1.8235, 'ddot_loss':     3.9848, 'rew_loss':   325.6749, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  691000, Reward:   335.887 [  36.598], Avg:   174.582 (0.200) <0-18:07:39> ({'r_t':   917.6563, 'eps':     0.2002, 'len': 53965.3000, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  692000, Reward:   314.948 [  97.439], Avg:   174.784 (0.400) <0-18:09:15> ({'r_t':   924.9593, 'eps':     0.4002, 'len': 54019.3560, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  693000, Reward:   289.712 [ 139.035], Avg:   174.950 (0.600) <0-18:10:39> ({'r_t':   153.9409, 'eps':     0.6002, 'len': 54078.2490, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  694000, Reward:   228.557 [ 148.860], Avg:   175.027 (0.800) <0-18:11:48> ({'r_t':  -586.7810, 'eps':     0.8002, 'len': 54150.2040, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  695000, Reward:   164.864 [ 196.789], Avg:   175.012 (0.000) <0-18:14:11> ({'r_t': -1082.6607, 'eps':     0.0002, 'len': 54247.6330, 'dyn_loss':    10.3819, 'dot_loss':     1.8172, 'ddot_loss':     3.9627, 'rew_loss':   334.7247, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  696000, Reward:   212.450 [ 209.699], Avg:   175.066 (0.200) <0-18:16:03> ({'r_t':  1078.1126, 'eps':     0.2002, 'len': 54332.1030, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  697000, Reward:   359.933 [ 116.327], Avg:   175.331 (0.400) <0-18:17:37> ({'r_t':   862.1382, 'eps':     0.4002, 'len': 54383.8860, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  698000, Reward:   293.257 [ 169.323], Avg:   175.500 (0.600) <0-18:18:57> ({'r_t':   129.8180, 'eps':     0.6002, 'len': 54435.6310, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  699000, Reward:   196.325 [ 195.932], Avg:   175.529 (0.800) <0-18:20:03> ({'r_t':  -613.1872, 'eps':     0.8002, 'len': 54499.5900, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  700000, Reward:   210.502 [ 180.343], Avg:   175.579 (0.000) <0-18:22:27> ({'r_t': -1092.9356, 'eps':     0.0002, 'len': 54589.6920, 'dyn_loss':    10.5628, 'dot_loss':     1.8369, 'ddot_loss':     4.0008, 'rew_loss':   329.0620, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  701000, Reward:   280.335 [ 161.040], Avg:   175.728 (0.200) <0-18:24:21> ({'r_t':  1054.8884, 'eps':     0.2002, 'len': 54671.1520, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  702000, Reward:   313.519 [ 141.801], Avg:   175.924 (0.400) <0-18:25:58> ({'r_t':   889.6346, 'eps':     0.4002, 'len': 54723.0530, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  703000, Reward:   368.113 [  47.391], Avg:   176.197 (0.600) <0-18:27:19> ({'r_t':   205.1750, 'eps':     0.6002, 'len': 54776.5580, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  704000, Reward:   257.487 [ 180.344], Avg:   176.313 (0.800) <0-18:28:24> ({'r_t':  -580.7691, 'eps':     0.8002, 'len': 54840.3820, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  705000, Reward:   100.852 [ 207.941], Avg:   176.206 (0.000) <0-18:30:45> ({'r_t': -1050.1963, 'eps':     0.0002, 'len': 54937.0320, 'dyn_loss':    10.3956, 'dot_loss':     1.8407, 'ddot_loss':     4.0228, 'rew_loss':   337.1572, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  706000, Reward:   170.810 [ 227.011], Avg:   176.198 (0.200) <0-18:32:40> ({'r_t':   392.6285, 'eps':     0.2002, 'len': 55062.8580, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  707000, Reward:   339.611 [ 154.885], Avg:   176.429 (0.400) <0-18:34:20> ({'r_t':   867.0304, 'eps':     0.4002, 'len': 55138.9420, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  708000, Reward:   226.413 [ 220.058], Avg:   176.500 (0.600) <0-18:35:42> ({'r_t':   197.9288, 'eps':     0.6002, 'len': 55190.1710, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  709000, Reward:    26.014 [ 169.756], Avg:   176.288 (0.800) <0-18:36:45> ({'r_t':  -586.7020, 'eps':     0.8002, 'len': 55250.6980, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  710000, Reward:   240.004 [ 176.945], Avg:   176.377 (0.000) <0-18:39:02> ({'r_t': -1129.5743, 'eps':     0.0002, 'len': 55340.8660, 'dyn_loss':    10.7736, 'dot_loss':     1.8514, 'ddot_loss':     4.0333, 'rew_loss':   333.5391, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  711000, Reward:   332.818 [  64.646], Avg:   176.597 (0.200) <0-18:40:56> ({'r_t':  1147.1185, 'eps':     0.2002, 'len': 55422.8440, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  712000, Reward:   316.014 [ 150.361], Avg:   176.792 (0.400) <0-18:42:36> ({'r_t':   932.3217, 'eps':     0.4002, 'len': 55476.3100, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  713000, Reward:   308.769 [ 120.362], Avg:   176.977 (0.600) <0-18:43:55> ({'r_t':   318.1938, 'eps':     0.6002, 'len': 55527.5420, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  714000, Reward:   273.309 [ 169.216], Avg:   177.112 (0.800) <0-18:44:58> ({'r_t':  -619.8695, 'eps':     0.8002, 'len': 55590.8770, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  715000, Reward:   185.881 [ 187.288], Avg:   177.124 (0.000) <0-18:47:21> ({'r_t': -1106.8524, 'eps':     0.0002, 'len': 55683.6690, 'dyn_loss':    10.7190, 'dot_loss':     1.8517, 'ddot_loss':     4.0345, 'rew_loss':   338.6334, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  716000, Reward:   238.683 [ 170.734], Avg:   177.210 (0.200) <0-18:49:18> ({'r_t':   908.1776, 'eps':     0.2002, 'len': 55766.0740, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  717000, Reward:   292.225 [ 147.374], Avg:   177.370 (0.400) <0-18:50:58> ({'r_t':   894.2813, 'eps':     0.4002, 'len': 55822.4950, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  718000, Reward:   272.240 [ 161.076], Avg:   177.502 (0.600) <0-18:52:21> ({'r_t':   151.0915, 'eps':     0.6002, 'len': 55872.6170, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  719000, Reward:   177.207 [ 195.592], Avg:   177.502 (0.800) <0-18:53:24> ({'r_t':  -570.6166, 'eps':     0.8002, 'len': 55935.2330, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  720000, Reward:   334.097 [  40.045], Avg:   177.719 (0.000) <0-18:55:49> ({'r_t': -1056.7079, 'eps':     0.0002, 'len': 56029.5620, 'dyn_loss':    10.4118, 'dot_loss':     1.8377, 'ddot_loss':     4.0294, 'rew_loss':   341.3288, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  721000, Reward:   355.434 [  42.296], Avg:   177.965 (0.200) <0-18:57:43> ({'r_t':  1165.3522, 'eps':     0.2002, 'len': 56108.6060, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  722000, Reward:   314.563 [ 104.072], Avg:   178.154 (0.400) <0-18:59:33> ({'r_t':   837.7322, 'eps':     0.4002, 'len': 56163.0690, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  723000, Reward:   346.099 [  58.581], Avg:   178.386 (0.600) <0-19:00:52> ({'r_t':   211.1353, 'eps':     0.6002, 'len': 56213.8430, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  724000, Reward:   258.900 [ 124.103], Avg:   178.497 (0.800) <0-19:02:03> ({'r_t':  -616.0963, 'eps':     0.8002, 'len': 56275.0980, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  725000, Reward:   148.328 [ 199.377], Avg:   178.456 (0.000) <0-19:04:37> ({'r_t': -1054.0373, 'eps':     0.0002, 'len': 56367.3350, 'dyn_loss':    10.7502, 'dot_loss':     1.8405, 'ddot_loss':     4.0252, 'rew_loss':   331.0566, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  726000, Reward:   222.038 [ 189.008], Avg:   178.516 (0.200) <0-19:06:36> ({'r_t':   952.4643, 'eps':     0.2002, 'len': 56450.6660, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  727000, Reward:   293.993 [ 159.300], Avg:   178.674 (0.400) <0-19:08:26> ({'r_t':   855.6967, 'eps':     0.4002, 'len': 56503.8980, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  728000, Reward:   300.818 [ 168.271], Avg:   178.842 (0.600) <0-19:09:59> ({'r_t':   173.8178, 'eps':     0.6002, 'len': 56559.9210, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  729000, Reward:   138.296 [ 202.280], Avg:   178.786 (0.800) <0-19:11:07> ({'r_t':  -596.7951, 'eps':     0.8002, 'len': 56622.3280, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  730000, Reward:   328.664 [  62.415], Avg:   178.991 (0.000) <0-19:13:39> ({'r_t': -1054.0459, 'eps':     0.0002, 'len': 56713.2630, 'dyn_loss':    10.7115, 'dot_loss':     1.8602, 'ddot_loss':     4.0591, 'rew_loss':   345.4547, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  731000, Reward:   338.478 [  60.738], Avg:   179.209 (0.200) <0-19:15:41> ({'r_t':  1042.1611, 'eps':     0.2002, 'len': 56796.2770, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  732000, Reward:   323.114 [ 100.704], Avg:   179.405 (0.400) <0-19:17:30> ({'r_t':   747.3111, 'eps':     0.4002, 'len': 56845.8400, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  733000, Reward:   351.252 [  27.647], Avg:   179.639 (0.600) <0-19:18:49> ({'r_t':    57.7508, 'eps':     0.6002, 'len': 56897.0600, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  734000, Reward:   291.225 [ 129.637], Avg:   179.791 (0.800) <0-19:20:07> ({'r_t':  -653.6776, 'eps':     0.8002, 'len': 56957.8140, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  735000, Reward:   294.894 [ 133.034], Avg:   179.948 (0.000) <0-19:22:30> ({'r_t': -1112.5713, 'eps':     0.0002, 'len': 57044.1550, 'dyn_loss':    10.6842, 'dot_loss':     1.8422, 'ddot_loss':     4.0031, 'rew_loss':   341.2832, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  736000, Reward:   363.710 [  38.122], Avg:   180.197 (0.200) <0-19:24:25> ({'r_t':  1106.3943, 'eps':     0.2002, 'len': 57116.1570, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  737000, Reward:   360.560 [  68.040], Avg:   180.441 (0.400) <0-19:26:12> ({'r_t':   826.7125, 'eps':     0.4002, 'len': 57168.7640, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  738000, Reward:   310.729 [ 113.873], Avg:   180.618 (0.600) <0-19:27:42> ({'r_t':   151.9217, 'eps':     0.6002, 'len': 57217.2860, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  739000, Reward:   325.470 [ 104.450], Avg:   180.813 (0.800) <0-19:28:48> ({'r_t':  -601.2467, 'eps':     0.8002, 'len': 57278.8090, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  740000, Reward:   257.945 [ 116.354], Avg:   180.918 (0.000) <0-19:31:18> ({'r_t': -1070.5280, 'eps':     0.0002, 'len': 57367.7270, 'dyn_loss':    10.3259, 'dot_loss':     1.8185, 'ddot_loss':     3.9876, 'rew_loss':   341.9164, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  741000, Reward:   263.091 [ 118.615], Avg:   181.028 (0.200) <0-19:33:25> ({'r_t':   967.6228, 'eps':     0.2002, 'len': 57443.4360, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  742000, Reward:   256.014 [ 119.139], Avg:   181.129 (0.400) <0-19:35:09> ({'r_t':   849.1090, 'eps':     0.4002, 'len': 57495.7710, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  743000, Reward:   199.600 [ 163.301], Avg:   181.154 (0.600) <0-19:36:36> ({'r_t':   254.2171, 'eps':     0.6002, 'len': 57545.8940, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  744000, Reward:   244.391 [ 129.650], Avg:   181.239 (0.800) <0-19:37:54> ({'r_t':  -608.7327, 'eps':     0.8002, 'len': 57606.7320, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  745000, Reward:   120.436 [ 171.658], Avg:   181.157 (0.000) <0-19:40:29> ({'r_t': -1054.2712, 'eps':     0.0002, 'len': 57698.0480, 'dyn_loss':    10.2825, 'dot_loss':     1.7967, 'ddot_loss':     3.9187, 'rew_loss':   339.4380, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  746000, Reward:    85.818 [ 177.853], Avg:   181.030 (0.200) <0-19:42:36> ({'r_t':   770.1298, 'eps':     0.2002, 'len': 57791.3790, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  747000, Reward:   238.183 [ 170.386], Avg:   181.106 (0.400) <0-19:44:25> ({'r_t':   730.9768, 'eps':     0.4002, 'len': 57844.1230, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  748000, Reward:   181.399 [ 167.108], Avg:   181.107 (0.600) <0-19:45:59> ({'r_t':   100.4463, 'eps':     0.6002, 'len': 57892.1380, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  749000, Reward:   113.665 [ 167.544], Avg:   181.017 (0.800) <0-19:47:18> ({'r_t':  -637.1785, 'eps':     0.8002, 'len': 57953.7130, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  750000, Reward:   119.089 [ 144.082], Avg:   180.934 (0.000) <0-19:49:55> ({'r_t': -1128.0621, 'eps':     0.0002, 'len': 58046.8900, 'dyn_loss':    10.5872, 'dot_loss':     1.8140, 'ddot_loss':     3.9553, 'rew_loss':   339.3907, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  751000, Reward:   143.870 [ 143.592], Avg:   180.885 (0.200) <0-19:52:02> ({'r_t':   580.1825, 'eps':     0.2002, 'len': 58125.3450, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  752000, Reward:   122.831 [ 159.074], Avg:   180.808 (0.400) <0-19:53:51> ({'r_t':   689.0471, 'eps':     0.4002, 'len': 58175.2560, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  753000, Reward:   115.898 [ 127.835], Avg:   180.722 (0.600) <0-19:55:25> ({'r_t':    82.4141, 'eps':     0.6002, 'len': 58225.1650, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  754000, Reward:   132.108 [ 155.946], Avg:   180.657 (0.800) <0-19:56:43> ({'r_t':  -576.5782, 'eps':     0.8002, 'len': 58289.8940, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  755000, Reward:    70.981 [ 179.790], Avg:   180.512 (0.000) <0-19:59:11> ({'r_t': -1068.4852, 'eps':     0.0002, 'len': 58378.0790, 'dyn_loss':    10.6004, 'dot_loss':     1.8566, 'ddot_loss':     4.0552, 'rew_loss':   346.1556, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  756000, Reward:   309.780 [ 155.247], Avg:   180.683 (0.200) <0-20:01:02> ({'r_t':   960.0424, 'eps':     0.2002, 'len': 58477.0090, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  757000, Reward:   331.205 [ 147.840], Avg:   180.882 (0.400) <0-20:02:33> ({'r_t':   849.1101, 'eps':     0.4002, 'len': 58539.5960, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  758000, Reward:   288.573 [ 171.365], Avg:   181.024 (0.600) <0-20:03:52> ({'r_t':   108.7368, 'eps':     0.6002, 'len': 58595.6560, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  759000, Reward:    45.426 [ 172.025], Avg:   180.845 (0.800) <0-20:04:54> ({'r_t':  -619.3586, 'eps':     0.8002, 'len': 58662.4740, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  760000, Reward:   195.086 [ 176.092], Avg:   180.864 (0.000) <0-20:07:26> ({'r_t': -1125.2102, 'eps':     0.0002, 'len': 58754.4840, 'dyn_loss':    10.4393, 'dot_loss':     1.8186, 'ddot_loss':     3.9681, 'rew_loss':   352.6389, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  761000, Reward:   280.055 [ 139.273], Avg:   180.994 (0.200) <0-20:09:27> ({'r_t':   938.7672, 'eps':     0.2002, 'len': 58837.6410, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  762000, Reward:   352.230 [  62.623], Avg:   181.218 (0.400) <0-20:11:08> ({'r_t':   695.4884, 'eps':     0.4002, 'len': 58890.1360, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  763000, Reward:   184.401 [ 187.412], Avg:   181.223 (0.600) <0-20:12:42> ({'r_t':   131.7989, 'eps':     0.6002, 'len': 58941.2280, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  764000, Reward:   148.742 [ 196.364], Avg:   181.180 (0.800) <0-20:14:00> ({'r_t':  -655.2858, 'eps':     0.8002, 'len': 59005.8470, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  765000, Reward:   296.898 [ 139.862], Avg:   181.331 (0.000) <0-20:16:24> ({'r_t': -1090.1995, 'eps':     0.0002, 'len': 59096.6730, 'dyn_loss':    10.3564, 'dot_loss':     1.8005, 'ddot_loss':     3.9422, 'rew_loss':   338.0375, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  766000, Reward:   352.877 [ 110.361], Avg:   181.555 (0.200) <0-20:18:15> ({'r_t':  1086.0689, 'eps':     0.2002, 'len': 59175.8660, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  767000, Reward:   362.315 [  46.699], Avg:   181.790 (0.400) <0-20:19:54> ({'r_t':   888.2683, 'eps':     0.4002, 'len': 59227.1820, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  768000, Reward:   313.262 [ 141.904], Avg:   181.961 (0.600) <0-20:21:13> ({'r_t':    90.4271, 'eps':     0.6002, 'len': 59279.4170, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  769000, Reward:   246.000 [ 182.070], Avg:   182.044 (0.800) <0-20:22:27> ({'r_t':  -575.0826, 'eps':     0.8002, 'len': 59346.3460, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  770000, Reward:    55.423 [ 139.867], Avg:   181.880 (0.000) <0-20:25:02> ({'r_t': -1097.6686, 'eps':     0.0002, 'len': 59439.3160, 'dyn_loss':    10.6054, 'dot_loss':     1.8182, 'ddot_loss':     3.9599, 'rew_loss':   344.8767, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  771000, Reward:   172.308 [ 191.392], Avg:   181.868 (0.200) <0-20:27:09> ({'r_t':   581.7899, 'eps':     0.2002, 'len': 59528.3370, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  772000, Reward:   162.894 [ 152.477], Avg:   181.843 (0.400) <0-20:28:59> ({'r_t':   383.6633, 'eps':     0.4002, 'len': 59574.1240, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  773000, Reward:   161.875 [ 138.893], Avg:   181.817 (0.600) <0-20:30:34> ({'r_t':    65.1131, 'eps':     0.6002, 'len': 59622.1000, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  774000, Reward:   131.388 [ 165.167], Avg:   181.752 (0.800) <0-20:31:52> ({'r_t':  -660.9986, 'eps':     0.8002, 'len': 59691.5210, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  775000, Reward:   331.505 [ 105.620], Avg:   181.945 (0.000) <0-20:34:19> ({'r_t': -1057.0750, 'eps':     0.0002, 'len': 59784.8030, 'dyn_loss':    10.4862, 'dot_loss':     1.8152, 'ddot_loss':     3.9536, 'rew_loss':   345.7928, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  776000, Reward:   334.449 [ 155.023], Avg:   182.142 (0.200) <0-20:36:11> ({'r_t':  1249.5180, 'eps':     0.2002, 'len': 59869.2450, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  777000, Reward:   383.188 [  37.404], Avg:   182.400 (0.400) <0-20:37:50> ({'r_t':  1011.9742, 'eps':     0.4002, 'len': 59924.9230, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  778000, Reward:   324.235 [ 150.414], Avg:   182.582 (0.600) <0-20:39:06> ({'r_t':   164.5870, 'eps':     0.6002, 'len': 59978.9580, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  779000, Reward:   291.510 [ 168.525], Avg:   182.722 (0.800) <0-20:40:09> ({'r_t':  -599.1869, 'eps':     0.8002, 'len': 60055.1420, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  780000, Reward:   379.882 [  24.831], Avg:   182.974 (0.000) <0-20:42:31> ({'r_t': -1119.3726, 'eps':     0.0002, 'len': 60154.0330, 'dyn_loss':    10.7385, 'dot_loss':     1.8322, 'ddot_loss':     4.0017, 'rew_loss':   346.3465, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  781000, Reward:   381.223 [  32.311], Avg:   183.228 (0.200) <0-20:44:24> ({'r_t':  1257.1083, 'eps':     0.2002, 'len': 60227.2350, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  782000, Reward:   401.855 [  22.883], Avg:   183.507 (0.400) <0-20:45:57> ({'r_t':   769.1414, 'eps':     0.4002, 'len': 60279.2300, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  783000, Reward:   391.531 [  29.788], Avg:   183.772 (0.600) <0-20:47:16> ({'r_t':   115.9485, 'eps':     0.6002, 'len': 60330.7840, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  784000, Reward:   360.582 [ 108.308], Avg:   183.997 (0.800) <0-20:48:18> ({'r_t':  -581.6224, 'eps':     0.8002, 'len': 60398.3700, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  785000, Reward:   212.236 [ 172.088], Avg:   184.033 (0.000) <0-20:50:54> ({'r_t': -1069.4798, 'eps':     0.0002, 'len': 60496.5030, 'dyn_loss':    10.3453, 'dot_loss':     1.8192, 'ddot_loss':     3.9957, 'rew_loss':   344.3586, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  786000, Reward:   360.264 [  49.003], Avg:   184.257 (0.200) <0-20:52:52> ({'r_t':   896.6079, 'eps':     0.2002, 'len': 60579.4140, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  787000, Reward:   322.732 [ 121.552], Avg:   184.433 (0.400) <0-20:54:42> ({'r_t':   754.9218, 'eps':     0.4002, 'len': 60634.1580, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  788000, Reward:   301.739 [ 118.875], Avg:   184.582 (0.600) <0-20:56:16> ({'r_t':   162.9267, 'eps':     0.6002, 'len': 60686.2620, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  789000, Reward:   221.296 [ 180.581], Avg:   184.628 (0.800) <0-20:57:35> ({'r_t':  -625.3841, 'eps':     0.8002, 'len': 60746.4970, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  790000, Reward:   296.714 [  97.695], Avg:   184.770 (0.000) <0-21:00:05> ({'r_t': -1074.8450, 'eps':     0.0002, 'len': 60830.3750, 'dyn_loss':    10.2965, 'dot_loss':     1.8244, 'ddot_loss':     4.0000, 'rew_loss':   350.3211, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  791000, Reward:   318.410 [  73.123], Avg:   184.939 (0.200) <0-21:02:08> ({'r_t':  1014.3705, 'eps':     0.2002, 'len': 60902.9620, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  792000, Reward:   322.668 [  66.116], Avg:   185.112 (0.400) <0-21:03:51> ({'r_t':   768.5454, 'eps':     0.4002, 'len': 60952.6930, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  793000, Reward:   312.811 [  75.987], Avg:   185.273 (0.600) <0-21:05:26> ({'r_t':   120.7726, 'eps':     0.6002, 'len': 61002.4170, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  794000, Reward:   337.986 [  87.797], Avg:   185.465 (0.800) <0-21:06:41> ({'r_t':  -620.4674, 'eps':     0.8002, 'len': 61069.8260, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  795000, Reward:    63.101 [ 145.083], Avg:   185.311 (0.000) <0-21:09:19> ({'r_t': -1146.1929, 'eps':     0.0002, 'len': 61161.4930, 'dyn_loss':    10.4075, 'dot_loss':     1.8243, 'ddot_loss':     3.9898, 'rew_loss':   346.4736, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  796000, Reward:   149.835 [ 145.758], Avg:   185.267 (0.200) <0-21:11:27> ({'r_t':   642.1472, 'eps':     0.2002, 'len': 61238.2850, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  797000, Reward:   182.393 [ 145.327], Avg:   185.263 (0.400) <0-21:13:17> ({'r_t':   941.0508, 'eps':     0.4002, 'len': 61293.3420, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  798000, Reward:   180.659 [ 155.151], Avg:   185.258 (0.600) <0-21:14:52> ({'r_t':   -12.0655, 'eps':     0.6002, 'len': 61347.4290, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  799000, Reward:    93.987 [ 136.420], Avg:   185.144 (0.800) <0-21:16:10> ({'r_t':  -612.0602, 'eps':     0.8002, 'len': 61422.5970, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  800000, Reward:   238.729 [ 209.877], Avg:   185.210 (0.000) <0-21:18:34> ({'r_t': -1125.0581, 'eps':     0.0002, 'len': 61513.4700, 'dyn_loss':    10.2791, 'dot_loss':     1.7715, 'ddot_loss':     3.8709, 'rew_loss':   353.5474, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  801000, Reward:   289.916 [ 203.439], Avg:   185.341 (0.200) <0-21:20:28> ({'r_t':  1183.8155, 'eps':     0.2002, 'len': 61598.5590, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  802000, Reward:   404.473 [  20.947], Avg:   185.614 (0.400) <0-21:22:03> ({'r_t':  1024.0456, 'eps':     0.4002, 'len': 61657.0930, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  803000, Reward:   289.248 [ 200.049], Avg:   185.743 (0.600) <0-21:23:22> ({'r_t':   155.0976, 'eps':     0.6002, 'len': 61715.8750, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  804000, Reward:   220.496 [ 217.219], Avg:   185.786 (0.800) <0-21:24:26> ({'r_t':  -577.8072, 'eps':     0.8002, 'len': 61788.8890, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  805000, Reward:   300.206 [ 114.097], Avg:   185.928 (0.000) <0-21:27:04> ({'r_t': -1088.0853, 'eps':     0.0002, 'len': 61886.1400, 'dyn_loss':    10.1579, 'dot_loss':     1.7878, 'ddot_loss':     3.9001, 'rew_loss':   345.9329, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  806000, Reward:   284.843 [ 131.390], Avg:   186.050 (0.200) <0-21:29:12> ({'r_t':   942.8570, 'eps':     0.2002, 'len': 61961.5650, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  807000, Reward:   278.877 [ 154.074], Avg:   186.165 (0.400) <0-21:31:02> ({'r_t':   918.0955, 'eps':     0.4002, 'len': 62012.1860, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  808000, Reward:   218.003 [ 196.453], Avg:   186.205 (0.600) <0-21:32:36> ({'r_t':   221.0577, 'eps':     0.6002, 'len': 62062.7140, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  809000, Reward:   204.995 [ 174.879], Avg:   186.228 (0.800) <0-21:33:55> ({'r_t':  -643.3693, 'eps':     0.8002, 'len': 62136.2920, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  810000, Reward:   328.926 [ 116.799], Avg:   186.404 (0.000) <0-21:36:15> ({'r_t': -1083.5776, 'eps':     0.0002, 'len': 62227.0340, 'dyn_loss':    10.2784, 'dot_loss':     1.8125, 'ddot_loss':     3.9643, 'rew_loss':   345.7979, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  811000, Reward:   357.564 [  43.908], Avg:   186.615 (0.200) <0-21:38:10> ({'r_t':  1217.4965, 'eps':     0.2002, 'len': 62307.0840, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  812000, Reward:   343.522 [ 105.675], Avg:   186.808 (0.400) <0-21:39:44> ({'r_t':   935.9173, 'eps':     0.4002, 'len': 62361.3050, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  813000, Reward:   338.416 [ 111.616], Avg:   186.994 (0.600) <0-21:41:13> ({'r_t':   173.0805, 'eps':     0.6002, 'len': 62415.9260, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  814000, Reward:   281.660 [ 163.362], Avg:   187.110 (0.800) <0-21:42:22> ({'r_t':  -594.3052, 'eps':     0.8002, 'len': 62483.1140, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  815000, Reward:   268.217 [ 186.573], Avg:   187.209 (0.000) <0-21:44:42> ({'r_t': -1071.8643, 'eps':     0.0002, 'len': 62578.9990, 'dyn_loss':    10.2916, 'dot_loss':     1.8077, 'ddot_loss':     3.9566, 'rew_loss':   347.9391, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  816000, Reward:   377.144 [ 111.550], Avg:   187.442 (0.200) <0-21:46:31> ({'r_t':  1175.1037, 'eps':     0.2002, 'len': 62669.1360, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  817000, Reward:   352.269 [ 123.914], Avg:   187.643 (0.400) <0-21:48:04> ({'r_t':   994.3839, 'eps':     0.4002, 'len': 62728.5340, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  818000, Reward:   326.600 [ 145.582], Avg:   187.813 (0.600) <0-21:49:20> ({'r_t':   150.4412, 'eps':     0.6002, 'len': 62782.6760, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  819000, Reward:   284.137 [ 165.389], Avg:   187.931 (0.800) <0-21:50:26> ({'r_t':  -608.9880, 'eps':     0.8002, 'len': 62852.0540, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  820000, Reward:   297.991 [ 173.320], Avg:   188.065 (0.000) <0-21:52:46> ({'r_t': -1099.4279, 'eps':     0.0002, 'len': 62943.8210, 'dyn_loss':    10.3700, 'dot_loss':     1.8113, 'ddot_loss':     3.9661, 'rew_loss':   352.4780, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  821000, Reward:   404.964 [  13.608], Avg:   188.328 (0.200) <0-21:54:35> ({'r_t':  1367.0462, 'eps':     0.2002, 'len': 63025.4680, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  822000, Reward:   393.385 [  26.614], Avg:   188.578 (0.400) <0-21:56:10> ({'r_t':  1040.8906, 'eps':     0.4002, 'len': 63081.0370, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  823000, Reward:   394.407 [  26.425], Avg:   188.827 (0.600) <0-21:57:27> ({'r_t':   191.6028, 'eps':     0.6002, 'len': 63134.3360, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  824000, Reward:   385.615 [  24.308], Avg:   189.066 (0.800) <0-21:58:30> ({'r_t':  -645.4483, 'eps':     0.8002, 'len': 63197.9030, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  825000, Reward:   300.297 [ 145.651], Avg:   189.201 (0.000) <0-22:00:54> ({'r_t': -1066.2762, 'eps':     0.0002, 'len': 63284.7340, 'dyn_loss':    10.5631, 'dot_loss':     1.8236, 'ddot_loss':     3.9770, 'rew_loss':   359.1571, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  826000, Reward:   361.138 [ 108.380], Avg:   189.409 (0.200) <0-22:02:43> ({'r_t':  1254.1453, 'eps':     0.2002, 'len': 63370.0700, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  827000, Reward:   383.867 [  28.317], Avg:   189.643 (0.400) <0-22:04:18> ({'r_t':   909.5959, 'eps':     0.4002, 'len': 63424.9570, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  828000, Reward:   392.842 [  25.590], Avg:   189.889 (0.600) <0-22:05:35> ({'r_t':   207.6131, 'eps':     0.6002, 'len': 63477.5340, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  829000, Reward:   255.285 [ 180.485], Avg:   189.967 (0.800) <0-22:06:38> ({'r_t':  -698.0514, 'eps':     0.8002, 'len': 63538.1830, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  830000, Reward:   268.656 [ 185.843], Avg:   190.062 (0.000) <0-22:09:02> ({'r_t': -1104.4186, 'eps':     0.0002, 'len': 63630.8990, 'dyn_loss':    10.4430, 'dot_loss':     1.8101, 'ddot_loss':     3.9620, 'rew_loss':   351.8055, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  831000, Reward:   372.336 [ 117.856], Avg:   190.281 (0.200) <0-22:10:51> ({'r_t':  1212.6865, 'eps':     0.2002, 'len': 63714.4050, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  832000, Reward:   380.598 [ 111.490], Avg:   190.510 (0.400) <0-22:12:27> ({'r_t':   920.9145, 'eps':     0.4002, 'len': 63769.5710, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  833000, Reward:   377.821 [ 112.986], Avg:   190.734 (0.600) <0-22:13:45> ({'r_t':   162.1707, 'eps':     0.6002, 'len': 63824.1500, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  834000, Reward:   350.369 [ 106.071], Avg:   190.925 (0.800) <0-22:14:49> ({'r_t':  -606.9090, 'eps':     0.8002, 'len': 63890.5010, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  835000, Reward:   324.104 [  32.391], Avg:   191.085 (0.000) <0-22:17:13> ({'r_t': -1099.3428, 'eps':     0.0002, 'len': 63979.5650, 'dyn_loss':    10.2872, 'dot_loss':     1.8030, 'ddot_loss':     3.9506, 'rew_loss':   366.6891, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  836000, Reward:   240.234 [ 174.322], Avg:   191.143 (0.200) <0-22:19:07> ({'r_t':  1005.4457, 'eps':     0.2002, 'len': 64064.9670, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  837000, Reward:   319.574 [ 102.213], Avg:   191.297 (0.400) <0-22:20:44> ({'r_t':   780.5580, 'eps':     0.4002, 'len': 64117.3800, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  838000, Reward:   320.098 [ 103.430], Avg:   191.450 (0.600) <0-22:22:08> ({'r_t':   156.5762, 'eps':     0.6002, 'len': 64165.9200, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  839000, Reward:   241.982 [ 147.767], Avg:   191.510 (0.800) <0-22:23:19> ({'r_t':  -617.5217, 'eps':     0.8002, 'len': 64222.4490, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  840000, Reward:   360.170 [  19.181], Avg:   191.711 (0.000) <0-22:25:43> ({'r_t': -1085.8388, 'eps':     0.0002, 'len': 64319.4050, 'dyn_loss':    10.2629, 'dot_loss':     1.7957, 'ddot_loss':     3.9303, 'rew_loss':   357.5526, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  841000, Reward:   327.724 [ 112.481], Avg:   191.872 (0.200) <0-22:27:37> ({'r_t':  1183.7785, 'eps':     0.2002, 'len': 64401.4900, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  842000, Reward:   365.116 [  35.583], Avg:   192.078 (0.400) <0-22:29:12> ({'r_t':   775.4856, 'eps':     0.4002, 'len': 64455.1430, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  843000, Reward:   346.064 [  63.288], Avg:   192.260 (0.600) <0-22:30:43> ({'r_t':   144.6667, 'eps':     0.6002, 'len': 64506.0000, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  844000, Reward:   358.148 [  40.931], Avg:   192.457 (0.800) <0-22:31:49> ({'r_t':  -611.9556, 'eps':     0.8002, 'len': 64569.3610, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  845000, Reward:   142.263 [ 183.104], Avg:   192.397 (0.000) <0-22:34:18> ({'r_t': -1128.9290, 'eps':     0.0002, 'len': 64652.4570, 'dyn_loss':    10.1719, 'dot_loss':     1.7934, 'ddot_loss':     3.9248, 'rew_loss':   355.4574, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  846000, Reward:   304.398 [ 102.589], Avg:   192.530 (0.200) <0-22:36:11> ({'r_t':  1012.0640, 'eps':     0.2002, 'len': 64741.5090, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  847000, Reward:   301.232 [ 143.047], Avg:   192.658 (0.400) <0-22:37:50> ({'r_t':   847.1531, 'eps':     0.4002, 'len': 64798.0020, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  848000, Reward:   271.828 [ 158.577], Avg:   192.751 (0.600) <0-22:39:09> ({'r_t':   111.6446, 'eps':     0.6002, 'len': 64846.6020, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  849000, Reward:   176.007 [ 177.476], Avg:   192.731 (0.800) <0-22:40:17> ({'r_t':  -703.5408, 'eps':     0.8002, 'len': 64907.7980, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  850000, Reward:    41.640 [ 178.578], Avg:   192.554 (0.000) <0-22:42:42> ({'r_t': -1086.7247, 'eps':     0.0002, 'len': 65001.3960, 'dyn_loss':    10.1540, 'dot_loss':     1.7915, 'ddot_loss':     3.9163, 'rew_loss':   357.3087, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  851000, Reward:   245.318 [ 208.884], Avg:   192.616 (0.200) <0-22:44:36> ({'r_t':   614.7210, 'eps':     0.2002, 'len': 65109.4070, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  852000, Reward:   317.025 [ 152.679], Avg:   192.761 (0.400) <0-22:46:21> ({'r_t':   908.1998, 'eps':     0.4002, 'len': 65173.5420, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  853000, Reward:   201.728 [ 207.953], Avg:   192.772 (0.600) <0-22:47:55> ({'r_t':   176.2264, 'eps':     0.6002, 'len': 65226.7640, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  854000, Reward:     5.221 [ 141.878], Avg:   192.553 (0.800) <0-22:49:02> ({'r_t':  -580.2610, 'eps':     0.8002, 'len': 65295.2340, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  855000, Reward:   222.206 [ 192.461], Avg:   192.587 (0.000) <0-22:51:32> ({'r_t': -1059.7740, 'eps':     0.0002, 'len': 65391.5760, 'dyn_loss':    10.4067, 'dot_loss':     1.8359, 'ddot_loss':     4.0197, 'rew_loss':   357.6584, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  856000, Reward:   372.989 [  57.162], Avg:   192.798 (0.200) <0-22:53:29> ({'r_t':  1223.1049, 'eps':     0.2002, 'len': 65482.9990, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  857000, Reward:   329.286 [ 114.959], Avg:   192.957 (0.400) <0-22:55:14> ({'r_t':   938.5405, 'eps':     0.4002, 'len': 65540.9160, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  858000, Reward:   353.442 [ 114.233], Avg:   193.144 (0.600) <0-22:56:34> ({'r_t':   229.5312, 'eps':     0.6002, 'len': 65595.2030, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  859000, Reward:   261.708 [ 170.659], Avg:   193.223 (0.800) <0-22:57:53> ({'r_t':  -610.3422, 'eps':     0.8002, 'len': 65660.8250, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  860000, Reward:   358.751 [ 110.602], Avg:   193.416 (0.000) <0-23:00:17> ({'r_t': -1164.0450, 'eps':     0.0002, 'len': 65741.2060, 'dyn_loss':    10.2150, 'dot_loss':     1.7998, 'ddot_loss':     3.9315, 'rew_loss':   360.9483, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  861000, Reward:   368.724 [ 112.881], Avg:   193.619 (0.200) <0-23:02:09> ({'r_t':  1187.2486, 'eps':     0.2002, 'len': 65819.3370, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  862000, Reward:   413.364 [  23.273], Avg:   193.874 (0.400) <0-23:03:42> ({'r_t':  1081.4013, 'eps':     0.4002, 'len': 65876.6750, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  863000, Reward:   352.166 [ 156.825], Avg:   194.057 (0.600) <0-23:05:02> ({'r_t':   241.4633, 'eps':     0.6002, 'len': 65934.0130, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  864000, Reward:   366.012 [ 108.797], Avg:   194.256 (0.800) <0-23:06:03> ({'r_t':  -600.0065, 'eps':     0.8002, 'len': 66003.8600, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  865000, Reward:   -35.420 [  87.916], Avg:   193.990 (0.000) <0-23:08:41> ({'r_t': -1033.8031, 'eps':     0.0002, 'len': 66101.2960, 'dyn_loss':     9.9698, 'dot_loss':     1.7873, 'ddot_loss':     3.9374, 'rew_loss':   358.1284, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  866000, Reward:   124.300 [ 172.970], Avg:   193.910 (0.200) <0-23:10:42> ({'r_t':   348.0421, 'eps':     0.2002, 'len': 66206.2770, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  867000, Reward:   157.925 [ 173.631], Avg:   193.869 (0.400) <0-23:12:33> ({'r_t':   767.4237, 'eps':     0.4002, 'len': 66268.6080, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  868000, Reward:   101.060 [ 184.614], Avg:   193.762 (0.600) <0-23:14:04> ({'r_t':   157.4102, 'eps':     0.6002, 'len': 66320.3780, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  869000, Reward:    37.396 [ 169.552], Avg:   193.582 (0.800) <0-23:15:17> ({'r_t':  -694.2559, 'eps':     0.8002, 'len': 66383.9510, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  870000, Reward:   289.600 [ 167.454], Avg:   193.692 (0.000) <0-23:17:41> ({'r_t': -1106.9297, 'eps':     0.0002, 'len': 66477.2110, 'dyn_loss':    10.2853, 'dot_loss':     1.7912, 'ddot_loss':     3.9174, 'rew_loss':   361.9621, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  871000, Reward:   407.547 [  15.436], Avg:   193.938 (0.200) <0-23:19:30> ({'r_t':  1316.2727, 'eps':     0.2002, 'len': 66558.0100, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  872000, Reward:   333.263 [ 152.376], Avg:   194.097 (0.400) <0-23:21:04> ({'r_t':  1002.0172, 'eps':     0.4002, 'len': 66615.0570, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  873000, Reward:   356.317 [ 107.201], Avg:   194.283 (0.600) <0-23:22:20> ({'r_t':   210.6405, 'eps':     0.6002, 'len': 66669.2310, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  874000, Reward:   214.185 [ 210.578], Avg:   194.306 (0.800) <0-23:23:23> ({'r_t':  -558.1308, 'eps':     0.8002, 'len': 66736.8200, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  875000, Reward:   148.908 [ 209.500], Avg:   194.254 (0.000) <0-23:25:49> ({'r_t': -1042.6606, 'eps':     0.0002, 'len': 66831.4580, 'dyn_loss':    10.3602, 'dot_loss':     1.7895, 'ddot_loss':     3.9123, 'rew_loss':   364.5132, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  876000, Reward:   323.852 [ 148.653], Avg:   194.401 (0.200) <0-23:27:41> ({'r_t':  1006.8070, 'eps':     0.2002, 'len': 66930.2880, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  877000, Reward:   356.429 [ 112.070], Avg:   194.586 (0.400) <0-23:29:17> ({'r_t':  1010.7732, 'eps':     0.4002, 'len': 66992.0910, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  878000, Reward:   284.545 [ 168.030], Avg:   194.688 (0.600) <0-23:30:41> ({'r_t':   108.2575, 'eps':     0.6002, 'len': 67045.2460, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  879000, Reward:   152.269 [ 205.200], Avg:   194.640 (0.800) <0-23:31:44> ({'r_t':  -569.9066, 'eps':     0.8002, 'len': 67116.3990, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  880000, Reward:   160.215 [ 218.031], Avg:   194.601 (0.000) <0-23:34:06> ({'r_t': -1104.6699, 'eps':     0.0002, 'len': 67209.9410, 'dyn_loss':    10.2717, 'dot_loss':     1.7764, 'ddot_loss':     3.8885, 'rew_loss':   360.6899, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  881000, Reward:   402.058 [  27.568], Avg:   194.836 (0.200) <0-23:35:56> ({'r_t':  1286.9535, 'eps':     0.2002, 'len': 67300.6350, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  882000, Reward:   346.060 [ 149.397], Avg:   195.008 (0.400) <0-23:37:29> ({'r_t':   998.3484, 'eps':     0.4002, 'len': 67358.8530, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  883000, Reward:   304.617 [ 179.592], Avg:   195.132 (0.600) <0-23:38:55> ({'r_t':   171.8155, 'eps':     0.6002, 'len': 67413.7620, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  884000, Reward:   177.352 [ 200.609], Avg:   195.111 (0.800) <0-23:40:06> ({'r_t':  -563.9979, 'eps':     0.8002, 'len': 67476.5920, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  885000, Reward:   363.643 [ 108.348], Avg:   195.302 (0.000) <0-23:42:30> ({'r_t': -1085.0777, 'eps':     0.0002, 'len': 67568.9630, 'dyn_loss':    10.1684, 'dot_loss':     1.7943, 'ddot_loss':     3.9415, 'rew_loss':   374.4487, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  886000, Reward:   403.435 [  26.220], Avg:   195.536 (0.200) <0-23:44:18> ({'r_t':  1428.9113, 'eps':     0.2002, 'len': 67654.3000, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  887000, Reward:   403.580 [  21.080], Avg:   195.771 (0.400) <0-23:45:50> ({'r_t':  1077.4509, 'eps':     0.4002, 'len': 67711.7880, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  888000, Reward:   373.254 [ 116.646], Avg:   195.970 (0.600) <0-23:47:08> ({'r_t':   197.7496, 'eps':     0.6002, 'len': 67767.2300, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  889000, Reward:   350.930 [ 106.910], Avg:   196.144 (0.800) <0-23:48:09> ({'r_t':  -582.1635, 'eps':     0.8002, 'len': 67835.5330, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  890000, Reward:    78.168 [ 200.067], Avg:   196.012 (0.000) <0-23:50:33> ({'r_t': -1065.2494, 'eps':     0.0002, 'len': 67929.5550, 'dyn_loss':    10.2634, 'dot_loss':     1.7917, 'ddot_loss':     3.9264, 'rew_loss':   373.1324, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  891000, Reward:   273.403 [ 200.090], Avg:   196.099 (0.200) <0-23:52:26> ({'r_t':  1077.2465, 'eps':     0.2002, 'len': 68016.8340, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  892000, Reward:   301.769 [ 175.580], Avg:   196.217 (0.400) <0-23:54:08> ({'r_t':   983.5828, 'eps':     0.4002, 'len': 68077.8470, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  893000, Reward:   215.886 [ 212.703], Avg:   196.239 (0.600) <0-23:55:25> ({'r_t':   165.0194, 'eps':     0.6002, 'len': 68128.9790, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  894000, Reward:   123.785 [ 207.679], Avg:   196.158 (0.800) <0-23:56:39> ({'r_t':  -608.2788, 'eps':     0.8002, 'len': 68191.8540, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  895000, Reward:   216.093 [ 184.529], Avg:   196.180 (0.000) <0-23:59:03> ({'r_t': -1072.1326, 'eps':     0.0002, 'len': 68281.8220, 'dyn_loss':     9.8540, 'dot_loss':     1.7633, 'ddot_loss':     3.8803, 'rew_loss':   358.8517, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  896000, Reward:   319.225 [ 142.288], Avg:   196.318 (0.200) <1-00:00:55> ({'r_t':  1119.1461, 'eps':     0.2002, 'len': 68361.0060, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  897000, Reward:   322.921 [ 105.086], Avg:   196.458 (0.400) <1-00:02:33> ({'r_t':   933.6655, 'eps':     0.4002, 'len': 68415.9790, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  898000, Reward:   334.866 [ 102.769], Avg:   196.612 (0.600) <1-00:03:52> ({'r_t':   206.4889, 'eps':     0.6002, 'len': 68469.4890, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  899000, Reward:   310.690 [ 100.072], Avg:   196.739 (0.800) <1-00:04:57> ({'r_t':  -624.4260, 'eps':     0.8002, 'len': 68533.8600, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  900000, Reward:   386.482 [  18.968], Avg:   196.950 (0.000) <1-00:07:16> ({'r_t': -1073.3944, 'eps':     0.0002, 'len': 68628.6670, 'dyn_loss':    10.0916, 'dot_loss':     1.7705, 'ddot_loss':     3.8945, 'rew_loss':   362.3868, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  901000, Reward:   382.784 [  59.130], Avg:   197.156 (0.200) <1-00:09:14> ({'r_t':  1343.3930, 'eps':     0.2002, 'len': 68710.0380, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  902000, Reward:   372.542 [  23.607], Avg:   197.350 (0.400) <1-00:10:49> ({'r_t':   788.2502, 'eps':     0.4002, 'len': 68763.0190, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  903000, Reward:   377.150 [  38.008], Avg:   197.549 (0.600) <1-00:12:11> ({'r_t':   183.1106, 'eps':     0.6002, 'len': 68812.0270, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  904000, Reward:   378.748 [  37.690], Avg:   197.749 (0.800) <1-00:13:15> ({'r_t':  -683.3657, 'eps':     0.8002, 'len': 68869.1210, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  905000, Reward:   293.215 [ 157.530], Avg:   197.855 (0.000) <1-00:15:35> ({'r_t': -1114.0362, 'eps':     0.0002, 'len': 68963.8000, 'dyn_loss':     9.7424, 'dot_loss':     1.7663, 'ddot_loss':     3.8998, 'rew_loss':   358.1591, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  906000, Reward:   333.331 [ 128.141], Avg:   198.004 (0.200) <1-00:17:28> ({'r_t':  1273.6099, 'eps':     0.2002, 'len': 69051.4210, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  907000, Reward:   349.161 [ 108.504], Avg:   198.170 (0.400) <1-00:19:02> ({'r_t':   996.0414, 'eps':     0.4002, 'len': 69106.7110, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  908000, Reward:   378.328 [  37.018], Avg:   198.369 (0.600) <1-00:20:20> ({'r_t':   181.2847, 'eps':     0.6002, 'len': 69157.8770, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  909000, Reward:   283.484 [ 168.800], Avg:   198.462 (0.800) <1-00:21:24> ({'r_t':  -557.4183, 'eps':     0.8002, 'len': 69217.5240, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  910000, Reward:   259.055 [ 135.047], Avg:   198.529 (0.000) <1-00:23:56> ({'r_t': -1098.7550, 'eps':     0.0002, 'len': 69306.2710, 'dyn_loss':    10.2323, 'dot_loss':     1.7704, 'ddot_loss':     3.8766, 'rew_loss':   369.9398, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  911000, Reward:   268.466 [ 131.794], Avg:   198.605 (0.200) <1-00:26:01> ({'r_t':   724.6820, 'eps':     0.2002, 'len': 69381.2090, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  912000, Reward:   297.893 [  73.303], Avg:   198.714 (0.400) <1-00:27:44> ({'r_t':   215.7317, 'eps':     0.4002, 'len': 69421.0910, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  913000, Reward:   313.294 [  91.058], Avg:   198.839 (0.600) <1-00:29:16> ({'r_t':   165.6840, 'eps':     0.6002, 'len': 69471.1280, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  914000, Reward:   285.580 [ 109.067], Avg:   198.934 (0.800) <1-00:30:27> ({'r_t':  -646.5858, 'eps':     0.8002, 'len': 69537.5780, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  915000, Reward:   305.152 [  60.197], Avg:   199.050 (0.000) <1-00:33:00> ({'r_t': -1134.0571, 'eps':     0.0002, 'len': 69626.7970, 'dyn_loss':    10.1229, 'dot_loss':     1.7818, 'ddot_loss':     3.9163, 'rew_loss':   372.0668, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  916000, Reward:   321.890 [ 116.021], Avg:   199.184 (0.200) <1-00:34:58> ({'r_t':  1063.6124, 'eps':     0.2002, 'len': 69704.6860, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  917000, Reward:   312.977 [  69.147], Avg:   199.308 (0.400) <1-00:36:47> ({'r_t':   911.7181, 'eps':     0.4002, 'len': 69756.8360, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  918000, Reward:   298.227 [ 111.813], Avg:   199.416 (0.600) <1-00:38:11> ({'r_t':   224.4072, 'eps':     0.6002, 'len': 69808.6000, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  919000, Reward:   310.776 [ 109.315], Avg:   199.537 (0.800) <1-00:39:18> ({'r_t':  -520.8045, 'eps':     0.8002, 'len': 69877.4290, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  920000, Reward:   131.440 [ 193.735], Avg:   199.463 (0.000) <1-00:41:43> ({'r_t': -1092.2810, 'eps':     0.0002, 'len': 69972.5220, 'dyn_loss':     9.7186, 'dot_loss':     1.7432, 'ddot_loss':     3.8319, 'rew_loss':   368.1004, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  921000, Reward:   302.827 [ 157.023], Avg:   199.575 (0.200) <1-00:43:41> ({'r_t':   979.9377, 'eps':     0.2002, 'len': 70059.4750, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  922000, Reward:   269.959 [ 172.018], Avg:   199.651 (0.400) <1-00:45:19> ({'r_t':   762.4092, 'eps':     0.4002, 'len': 70114.7020, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  923000, Reward:   319.261 [ 144.984], Avg:   199.781 (0.600) <1-00:46:37> ({'r_t':   197.1864, 'eps':     0.6002, 'len': 70167.1380, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  924000, Reward:    92.860 [ 197.501], Avg:   199.665 (0.800) <1-00:47:41> ({'r_t':  -597.2108, 'eps':     0.8002, 'len': 70227.1060, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  925000, Reward:   227.457 [ 181.887], Avg:   199.695 (0.000) <1-00:50:12> ({'r_t': -1031.6674, 'eps':     0.0002, 'len': 70320.1170, 'dyn_loss':    10.1928, 'dot_loss':     1.7566, 'ddot_loss':     3.8475, 'rew_loss':   367.1356, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  926000, Reward:   334.633 [  94.358], Avg:   199.841 (0.200) <1-00:52:19> ({'r_t':  1067.0443, 'eps':     0.2002, 'len': 70409.2000, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  927000, Reward:   333.875 [ 151.416], Avg:   199.985 (0.400) <1-00:53:54> ({'r_t':   941.5007, 'eps':     0.4002, 'len': 70463.8100, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  928000, Reward:   328.453 [ 105.395], Avg:   200.123 (0.600) <1-00:55:18> ({'r_t':   144.9432, 'eps':     0.6002, 'len': 70516.7010, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  929000, Reward:   300.334 [ 137.886], Avg:   200.231 (0.800) <1-00:56:26> ({'r_t':  -552.3061, 'eps':     0.8002, 'len': 70579.4890, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  930000, Reward:   253.681 [ 180.467], Avg:   200.288 (0.000) <1-00:58:51> ({'r_t': -1138.6526, 'eps':     0.0002, 'len': 70667.9250, 'dyn_loss':    10.0896, 'dot_loss':     1.7873, 'ddot_loss':     3.9188, 'rew_loss':   374.4274, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  931000, Reward:   355.686 [ 111.128], Avg:   200.455 (0.200) <1-01:00:40> ({'r_t':  1086.7934, 'eps':     0.2002, 'len': 70747.6530, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  932000, Reward:   363.294 [  45.025], Avg:   200.630 (0.400) <1-01:02:18> ({'r_t':   766.5855, 'eps':     0.4002, 'len': 70800.9550, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  933000, Reward:   254.058 [ 184.624], Avg:   200.687 (0.600) <1-01:03:38> ({'r_t':   203.1536, 'eps':     0.6002, 'len': 70851.9660, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  934000, Reward:   282.981 [ 162.489], Avg:   200.775 (0.800) <1-01:04:41> ({'r_t':  -558.8810, 'eps':     0.8002, 'len': 70915.0620, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  935000, Reward:   328.391 [ 145.636], Avg:   200.911 (0.000) <1-01:07:02> ({'r_t': -1129.5845, 'eps':     0.0002, 'len': 71004.4240, 'dyn_loss':     9.8144, 'dot_loss':     1.7399, 'ddot_loss':     3.8373, 'rew_loss':   363.5122, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  936000, Reward:   399.390 [  26.244], Avg:   201.123 (0.200) <1-01:08:53> ({'r_t':  1212.8851, 'eps':     0.2002, 'len': 71080.1990, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  937000, Reward:   322.960 [ 148.808], Avg:   201.253 (0.400) <1-01:10:28> ({'r_t':   977.4473, 'eps':     0.4002, 'len': 71136.0420, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  938000, Reward:   363.176 [ 113.603], Avg:   201.425 (0.600) <1-01:11:45> ({'r_t':   251.3624, 'eps':     0.6002, 'len': 71191.4660, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  939000, Reward:   368.014 [  29.136], Avg:   201.603 (0.800) <1-01:12:49> ({'r_t':  -506.1336, 'eps':     0.8002, 'len': 71257.8160, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  940000, Reward:   281.204 [  68.132], Avg:   201.687 (0.000) <1-01:15:26> ({'r_t': -1071.7759, 'eps':     0.0002, 'len': 71349.9280, 'dyn_loss':    10.2133, 'dot_loss':     1.8130, 'ddot_loss':     3.9897, 'rew_loss':   379.0946, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  941000, Reward:   293.939 [  85.015], Avg:   201.785 (0.200) <1-01:17:32> ({'r_t':   809.8259, 'eps':     0.2002, 'len': 71420.4340, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  942000, Reward:   267.801 [ 120.742], Avg:   201.855 (0.400) <1-01:19:21> ({'r_t':   504.1059, 'eps':     0.4002, 'len': 71462.9000, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  943000, Reward:   260.070 [ 101.690], Avg:   201.917 (0.600) <1-01:20:54> ({'r_t':   121.6484, 'eps':     0.6002, 'len': 71508.4720, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  944000, Reward:   269.429 [  82.192], Avg:   201.988 (0.800) <1-01:22:11> ({'r_t':  -621.4620, 'eps':     0.8002, 'len': 71561.9060, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  945000, Reward:   316.485 [ 138.910], Avg:   202.109 (0.000) <1-01:24:36> ({'r_t': -1132.9971, 'eps':     0.0002, 'len': 71647.0790, 'dyn_loss':    10.1490, 'dot_loss':     1.7646, 'ddot_loss':     3.8738, 'rew_loss':   367.9809, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  946000, Reward:   351.877 [ 115.869], Avg:   202.268 (0.200) <1-01:26:35> ({'r_t':  1161.8081, 'eps':     0.2002, 'len': 71732.0130, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  947000, Reward:   358.859 [ 117.797], Avg:   202.433 (0.400) <1-01:28:13> ({'r_t':   954.4031, 'eps':     0.4002, 'len': 71786.0700, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  948000, Reward:   390.364 [  19.355], Avg:   202.631 (0.600) <1-01:29:31> ({'r_t':   260.6431, 'eps':     0.6002, 'len': 71836.6920, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  949000, Reward:   347.425 [ 107.196], Avg:   202.783 (0.800) <1-01:30:36> ({'r_t':  -573.7168, 'eps':     0.8002, 'len': 71906.7290, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  950000, Reward:    47.640 [ 148.286], Avg:   202.620 (0.000) <1-01:33:15> ({'r_t': -1134.7902, 'eps':     0.0002, 'len': 71998.8470, 'dyn_loss':    10.2304, 'dot_loss':     1.7912, 'ddot_loss':     3.9234, 'rew_loss':   382.5172, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  951000, Reward:   151.532 [ 155.145], Avg:   202.566 (0.200) <1-01:35:21> ({'r_t':   496.0359, 'eps':     0.2002, 'len': 72082.2430, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  952000, Reward:    76.391 [ 116.983], Avg:   202.434 (0.400) <1-01:37:10> ({'r_t':   602.9576, 'eps':     0.4002, 'len': 72131.0230, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  953000, Reward:    90.397 [ 132.255], Avg:   202.317 (0.600) <1-01:38:43> ({'r_t':   156.3214, 'eps':     0.6002, 'len': 72179.4320, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  954000, Reward:    79.200 [ 119.610], Avg:   202.188 (0.800) <1-01:40:01> ({'r_t':  -562.2511, 'eps':     0.8002, 'len': 72244.1860, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  955000, Reward:   147.664 [ 187.738], Avg:   202.131 (0.000) <1-01:42:37> ({'r_t': -1089.4903, 'eps':     0.0002, 'len': 72330.6060, 'dyn_loss':    10.0548, 'dot_loss':     1.7755, 'ddot_loss':     3.8948, 'rew_loss':   376.1938, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  956000, Reward:   261.575 [ 193.064], Avg:   202.193 (0.200) <1-01:44:43> ({'r_t':   866.7443, 'eps':     0.2002, 'len': 72416.8540, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  957000, Reward:   283.358 [ 150.004], Avg:   202.277 (0.400) <1-01:46:32> ({'r_t':   763.5143, 'eps':     0.4002, 'len': 72471.7400, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  958000, Reward:   194.946 [ 175.899], Avg:   202.270 (0.600) <1-01:48:05> ({'r_t':   221.5933, 'eps':     0.6002, 'len': 72519.7350, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  959000, Reward:   165.505 [ 183.172], Avg:   202.231 (0.800) <1-01:49:22> ({'r_t':  -524.9205, 'eps':     0.8002, 'len': 72581.0520, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  960000, Reward:   148.517 [ 168.438], Avg:   202.176 (0.000) <1-01:51:58> ({'r_t': -1072.2920, 'eps':     0.0002, 'len': 72675.9090, 'dyn_loss':    10.0935, 'dot_loss':     1.7816, 'ddot_loss':     3.9024, 'rew_loss':   375.5860, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  961000, Reward:   224.174 [ 154.052], Avg:   202.198 (0.200) <1-01:54:04> ({'r_t':   701.7842, 'eps':     0.2002, 'len': 72772.3880, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  962000, Reward:   281.481 [ 147.952], Avg:   202.281 (0.400) <1-01:55:49> ({'r_t':   421.4900, 'eps':     0.4002, 'len': 72823.9360, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  963000, Reward:   241.790 [ 139.218], Avg:   202.322 (0.600) <1-01:57:23> ({'r_t':   174.8367, 'eps':     0.6002, 'len': 72872.4420, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  964000, Reward:   153.632 [ 194.433], Avg:   202.271 (0.800) <1-01:58:40> ({'r_t':  -647.5234, 'eps':     0.8002, 'len': 72932.4490, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  965000, Reward:   344.227 [ 108.660], Avg:   202.418 (0.000) <1-02:01:07> ({'r_t': -1162.8564, 'eps':     0.0002, 'len': 73020.7750, 'dyn_loss':    10.3120, 'dot_loss':     1.7836, 'ddot_loss':     3.8949, 'rew_loss':   374.6050, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  966000, Reward:   362.455 [  64.922], Avg:   202.584 (0.200) <1-02:03:07> ({'r_t':  1150.2940, 'eps':     0.2002, 'len': 73100.1480, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  967000, Reward:   372.189 [  43.431], Avg:   202.759 (0.400) <1-02:04:45> ({'r_t':   741.3507, 'eps':     0.4002, 'len': 73150.4870, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  968000, Reward:   376.309 [  46.329], Avg:   202.938 (0.600) <1-02:06:14> ({'r_t':   -15.1737, 'eps':     0.6002, 'len': 73200.4890, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  969000, Reward:   348.142 [  69.501], Avg:   203.088 (0.800) <1-02:07:30> ({'r_t':  -649.0182, 'eps':     0.8002, 'len': 73263.9010, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  970000, Reward:   295.823 [ 106.651], Avg:   203.183 (0.000) <1-02:10:06> ({'r_t': -1107.3654, 'eps':     0.0002, 'len': 73354.3540, 'dyn_loss':    10.0684, 'dot_loss':     1.7812, 'ddot_loss':     3.9270, 'rew_loss':   377.6832, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  971000, Reward:   275.135 [ 117.905], Avg:   203.257 (0.200) <1-02:12:11> ({'r_t':   839.7231, 'eps':     0.2002, 'len': 73430.1190, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  972000, Reward:   287.596 [ 110.828], Avg:   203.344 (0.400) <1-02:14:00> ({'r_t':   527.1746, 'eps':     0.4002, 'len': 73474.7030, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  973000, Reward:   303.784 [ 135.113], Avg:   203.447 (0.600) <1-02:15:33> ({'r_t':   101.6487, 'eps':     0.6002, 'len': 73519.8730, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  974000, Reward:   229.540 [ 132.515], Avg:   203.474 (0.800) <1-02:16:51> ({'r_t':  -629.6724, 'eps':     0.8002, 'len': 73579.3670, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  975000, Reward:   218.025 [ 210.853], Avg:   203.489 (0.000) <1-02:19:12> ({'r_t': -1103.0410, 'eps':     0.0002, 'len': 73667.6050, 'dyn_loss':    10.1339, 'dot_loss':     1.7979, 'ddot_loss':     3.9499, 'rew_loss':   374.4048, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  976000, Reward:   388.105 [  38.686], Avg:   203.678 (0.200) <1-02:21:05> ({'r_t':  1369.3757, 'eps':     0.2002, 'len': 73747.4180, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  977000, Reward:   368.199 [ 109.821], Avg:   203.846 (0.400) <1-02:22:37> ({'r_t':   895.0459, 'eps':     0.4002, 'len': 73803.8560, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  978000, Reward:   375.287 [ 115.949], Avg:   204.021 (0.600) <1-02:23:54> ({'r_t':   177.5637, 'eps':     0.6002, 'len': 73856.9530, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  979000, Reward:   330.222 [ 146.202], Avg:   204.150 (0.800) <1-02:24:57> ({'r_t':  -611.3862, 'eps':     0.8002, 'len': 73918.7250, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  980000, Reward:   276.360 [ 109.422], Avg:   204.223 (0.000) <1-02:27:33> ({'r_t': -1123.2237, 'eps':     0.0002, 'len': 74001.5680, 'dyn_loss':    10.3463, 'dot_loss':     1.8211, 'ddot_loss':     3.9944, 'rew_loss':   376.5880, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  981000, Reward:   260.713 [ 123.039], Avg:   204.281 (0.200) <1-02:29:39> ({'r_t':   862.3849, 'eps':     0.2002, 'len': 74074.9910, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  982000, Reward:   310.538 [  74.337], Avg:   204.389 (0.400) <1-02:31:24> ({'r_t':   658.5543, 'eps':     0.4002, 'len': 74121.2450, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  983000, Reward:   301.454 [  78.123], Avg:   204.488 (0.600) <1-02:32:57> ({'r_t':    84.2736, 'eps':     0.6002, 'len': 74171.1830, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  984000, Reward:   222.322 [ 154.381], Avg:   204.506 (0.800) <1-02:34:14> ({'r_t':  -603.6599, 'eps':     0.8002, 'len': 74243.2860, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  985000, Reward:   206.982 [ 181.921], Avg:   204.508 (0.000) <1-02:36:44> ({'r_t': -1128.8452, 'eps':     0.0002, 'len': 74333.8790, 'dyn_loss':    10.2620, 'dot_loss':     1.7992, 'ddot_loss':     3.9396, 'rew_loss':   379.7154, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  986000, Reward:   340.651 [ 111.315], Avg:   204.646 (0.200) <1-02:38:40> ({'r_t':   851.3969, 'eps':     0.2002, 'len': 74415.6020, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  987000, Reward:   284.631 [ 170.291], Avg:   204.727 (0.400) <1-02:40:18> ({'r_t':   564.5276, 'eps':     0.4002, 'len': 74461.3430, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  988000, Reward:   351.345 [  49.170], Avg:   204.875 (0.600) <1-02:41:39> ({'r_t':    26.6516, 'eps':     0.6002, 'len': 74505.9290, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  989000, Reward:   243.521 [ 187.413], Avg:   204.914 (0.800) <1-02:42:52> ({'r_t':  -570.9034, 'eps':     0.8002, 'len': 74563.1260, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  990000, Reward:   252.491 [ 136.411], Avg:   204.963 (0.000) <1-02:45:25> ({'r_t': -1120.1399, 'eps':     0.0002, 'len': 74639.5760, 'dyn_loss':    10.3346, 'dot_loss':     1.7858, 'ddot_loss':     3.9096, 'rew_loss':   371.5636, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  991000, Reward:   286.760 [ 134.962], Avg:   205.045 (0.200) <1-02:47:19> ({'r_t':   934.4445, 'eps':     0.2002, 'len': 74713.8120, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  992000, Reward:   322.557 [  42.879], Avg:   205.163 (0.400) <1-02:48:57> ({'r_t':   879.7099, 'eps':     0.4002, 'len': 74765.7050, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  993000, Reward:   286.290 [ 118.311], Avg:   205.245 (0.600) <1-02:50:28> ({'r_t':   238.6619, 'eps':     0.6002, 'len': 74818.5120, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  994000, Reward:   307.171 [  43.617], Avg:   205.347 (0.800) <1-02:51:37> ({'r_t':  -551.4163, 'eps':     0.8002, 'len': 74887.8170, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step:  995000, Reward:   207.256 [ 145.701], Avg:   205.349 (0.000) <1-02:54:15> ({'r_t': -1095.9112, 'eps':     0.0002, 'len': 74977.3680, 'dyn_loss':     9.7971, 'dot_loss':     1.7421, 'ddot_loss':     3.8368, 'rew_loss':   378.4875, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
Step:  996000, Reward:   257.239 [ 128.209], Avg:   205.401 (0.200) <1-02:56:20> ({'r_t':   824.0201, 'eps':     0.2002, 'len': 75053.0610, 'lr':   9.70e-05, 'eps_e':     0.2002, 'lr_e':   9.70e-05})
Step:  997000, Reward:   268.130 [ 123.201], Avg:   205.464 (0.400) <1-02:58:06> ({'r_t':   458.8929, 'eps':     0.4002, 'len': 75097.9360, 'lr':   9.70e-05, 'eps_e':     0.4002, 'lr_e':   9.70e-05})
Step:  998000, Reward:   248.877 [ 124.079], Avg:   205.508 (0.600) <1-02:59:39> ({'r_t':   200.0503, 'eps':     0.6002, 'len': 75151.3520, 'lr':   9.70e-05, 'eps_e':     0.6002, 'lr_e':   9.70e-05})
Step:  999000, Reward:   280.241 [ 116.452], Avg:   205.582 (0.800) <1-03:00:52> ({'r_t':  -561.6241, 'eps':     0.8002, 'len': 75219.0410, 'lr':   9.70e-05, 'eps_e':     0.8002, 'lr_e':   9.70e-05})
Step: 1000000, Reward:   336.403 [ 148.502], Avg:   205.713 (0.000) <1-03:03:22> ({'r_t': -1113.7092, 'eps':     0.0002, 'len': 75303.9410, 'dyn_loss':    10.0473, 'dot_loss':     1.7560, 'ddot_loss':     3.8447, 'rew_loss':   381.3112, 'lr':   9.70e-05, 'eps_e':     0.0002, 'lr_e':   9.70e-05})
