Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CarRacing-v1, Date: 05/06/2020 20:11:12
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: a607be52ca7148dfbaf2f88621c035e3cdff2f30
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.97
   NUM_STEPS = None
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 10000
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 250
   DYN_EPOCHS = 1
   TRAIN_EVERY = 10000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 40
      LAMBDA = 0.1
      COV = 0.5
   REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
   DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
   dynamics_size = 13
   state_size = (80,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 1000000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.8
      PATIENCE = 5
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fc399e17bd0> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7fc39a12b7d0>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7fc399d71950>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7fc399d6f9d0> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7fc399d6f850> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost
							# reward = progress + np.tanh(vy/self.vtarget) - cost
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_size = 13
			obs = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  2.000e-02  3.657e-01  4.017e-01  4.572e-01  5.260e-01  6.036e-01  2.700e-01  3.171e-01  3.850e-01  4.646e-01  5.509e-01  1.792e-01  2.444e-01  3.277e-01  4.184e-01  5.125e-01  1.063e-01  1.973e-01  2.942e-01  3.927e-01  4.918e-01  1.024e-01  1.953e-01  2.929e-01  3.917e-01  4.910e-01]
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 		return state
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.spec = next_spec
			
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7fc419d2f680>
					step = <function CarRacing.step at 0x7fc419d2f5f0>
					render = <function CarRacing.render at 0x7fc440173b90>
					dynamics_spec = <staticmethod object at 0x7fc419d30a50>
					track_spec = <function CarRacing.track_spec at 0x7fc440173cb0>
					observation = <function CarRacing.observation at 0x7fc440173d40>
					dynamics_keys = <staticmethod object at 0x7fc419d30950>
					observation_spec = <staticmethod object at 0x7fc419d30990>
					close = <function CarRacing.close at 0x7fc440173ef0>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(80,) 
			dtype = float32
			shape = (80,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fc399db3b50> 
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (80,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fc399d6f990> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=116, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48710), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=117, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58290), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=118, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 43978), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=119, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48482), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=120, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41536), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=121, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58292), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=122, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38142), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=123, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34714), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=124, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58918), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=125, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50846), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=126, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53032), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=127, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53156), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=128, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56336), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=129, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 42820), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=130, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55758), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=131, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50570), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fc399d6f750> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fc399d6fad0> 
		state_size = (80,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fc399d6fd50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fc399d6f8d0> 
			size = (3,)
			dt = 0.2
			action = [-0.463 -0.145 -1.000]
			daction_dt = [ 1.650 -0.739 -0.763]
		discrete = False
		action_size = (3,)
		state_size = (80,)
		config = <src.utils.config.Config object at 0x7fc39a2aec10> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.97
			NUM_STEPS = None
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 10000
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 250
			DYN_EPOCHS = 1
			TRAIN_EVERY = 10000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fc43fc8cb50> 
				NSAMPLES = 100
				HORIZON = 40
				LAMBDA = 0.1
				COV = 0.5
			REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
			DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
			dynamics_size = 13
			state_size = (80,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 1000000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fc39a2a0bd0> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.8
				PATIENCE = 5
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fc399d6fa10> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fc399d6ff10> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fc39a2aec10> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.97
				NUM_STEPS = None
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 10000
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 250
				DYN_EPOCHS = 1
				TRAIN_EVERY = 10000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fc43fc8cb50> 
					NSAMPLES = 100
					HORIZON = 40
					LAMBDA = 0.1
					COV = 0.5
				REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
				DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
				dynamics_size = 13
				state_size = (80,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 1000000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fc39a2a0bd0> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.8
					PATIENCE = 5
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fc399d6f6d0> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=29, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(29, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=13, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fc399d6fb10> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fc39a2aec10> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.97
						NUM_STEPS = None
						MAX_BUFFER_SIZE = 100000
						REPLAY_BATCH_SIZE = 10000
						TARGET_UPDATE_RATE = 0.0004
						BATCH_SIZE = 250
						DYN_EPOCHS = 1
						TRAIN_EVERY = 10000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fc43fc8cb50> 
							NSAMPLES = 100
							HORIZON = 40
							LAMBDA = 0.1
							COV = 0.5
						REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
						DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
						dynamics_size = 13
						state_size = (80,)
						action_size = (3,)
						env_name = CarRacing-v1
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 1000000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fc39a2a0bd0> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.8
							PATIENCE = 5
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (80,)
					action_size = (3,)
					discrete = False
					dyn_index = 13
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fc399da19d0>
				state_size = (80,)
				action_size = (3,)
			mu = [ 0.000  0.000  0.000]
			cov = [[ 0.500  0.000  0.000]
			 [ 0.000  0.500  0.000]
			 [ 0.000  0.000  0.500]]
			icov = [[ 2.000  0.000  0.000]
			 [ 0.000  2.000  0.000]
			 [ 0.000  0.000  2.000]]
			lamda = 0.1
			horizon = 40
			nsamples = 100
			action_size = (3,)
			control = [[[ 0.926 -0.739  0.705]
			  [ 0.712  0.812 -0.649]
			  [-0.119  0.576 -0.233]
			  [ 0.002 -0.928 -0.668]
			  [-0.741  0.425  0.200]
			  [ 0.981 -0.025  0.631]
			  [-0.064  0.355 -0.543]
			  [ 0.509  0.386  0.874]
			  [-0.032  0.939  0.211]
			  [-0.330 -0.351 -0.512]
			  [ 0.011  0.571 -0.183]
			  [-0.023  0.910  0.388]
			  [ 0.356 -0.227 -0.662]
			  [ 0.917 -0.118  0.139]
			  [-0.021 -0.893  0.366]
			  [-0.982 -0.765  0.712]
			  [-0.748  0.375  0.611]
			  [ 0.596 -0.371  0.107]
			  [-0.329 -0.375 -0.611]
			  [ 0.893  0.658  0.985]
			  [-0.508  0.012 -0.504]
			  [-0.683 -0.905  0.256]
			  [-0.184  0.153 -0.178]
			  [ 0.941 -0.257 -0.526]
			  [-0.746  0.280  0.079]
			  [ 0.971 -0.038 -0.325]
			  [ 0.424  0.023 -0.888]
			  [ 0.379  0.720 -0.402]
			  [ 0.947 -0.143  0.659]
			  [-0.421 -0.220  0.602]
			  [-0.315 -0.845  0.314]
			  [-0.789 -0.296 -0.810]
			  [ 0.313  0.073  0.179]
			  [ 0.124 -0.973 -0.563]
			  [-0.520  0.328 -0.145]
			  [ 0.710 -0.128  0.873]
			  [-0.192 -0.980  0.857]
			  [ 0.294  0.751 -0.545]
			  [-0.052 -0.780  0.727]
			  [ 0.052 -0.649 -0.940]]]
			noise = [[[[-0.518 -0.247  0.683]
			   [ 0.006  0.717  1.399]
			   [-0.502 -0.478 -0.309]
			   ...
			   [-0.381  0.771 -2.343]
			   [ 1.053 -0.069 -0.793]
			   [-0.508 -0.812 -0.139]]
			
			  [[ 0.377 -0.973 -0.656]
			   [ 2.639 -0.960 -0.441]
			   [-0.728  0.430  1.047]
			   ...
			   [ 0.785 -0.372  0.014]
			   [-0.126 -0.924 -0.033]
			   [ 0.404  0.645  0.333]]
			
			  [[ 0.437 -0.927  0.278]
			   [-0.137  0.527 -0.027]
			   [-0.439  0.439 -0.091]
			   ...
			   [ 0.325  0.597 -0.735]
			   [-0.857 -0.164  0.629]
			   [ 0.537 -0.175 -0.805]]
			
			  ...
			
			  [[-0.547  0.600  1.105]
			   [-0.324 -0.139  1.035]
			   [ 0.050  0.504  0.215]
			   ...
			   [-0.440 -0.694  0.431]
			   [ 0.588 -0.726  0.005]
			   [-0.134 -0.126 -1.636]]
			
			  [[ 0.863 -0.070  0.574]
			   [-0.090 -0.665  0.349]
			   [-0.346  0.548  0.967]
			   ...
			   [-1.167  0.250 -0.106]
			   [ 0.544  0.756  0.183]
			   [ 0.473  0.116 -0.505]]
			
			  [[ 0.865  0.038  1.219]
			   [ 0.413 -1.683 -0.262]
			   [ 0.070  1.216  0.045]
			   ...
			   [-0.104  0.617 -0.616]
			   [-0.459 -2.062  0.624]
			   [-0.720  0.150 -0.811]]]]
			init_cost = [[  0.131   5.823  13.393  -3.820   4.323  15.203   7.535  16.073  -6.420   1.789  -5.092  -4.552   1.911   1.248 -18.863 -13.653  -2.964  12.548  -2.068  10.075  14.471 -13.204  14.572   0.759  -9.118   8.549   5.247  11.274 -13.302  -0.122  -1.046   1.935  -1.955  -0.049  -5.510   2.275   8.538  -3.268   7.954  12.169 -10.718   7.601   5.516  13.066  -2.954  14.198  -2.732  -1.194  20.157   7.185   3.475 -14.575 -17.184  -0.680 -12.316  -1.275  -7.769   0.177   0.491  15.771 -12.865  13.375   1.019  11.103   2.254   8.514   0.441 -11.952   3.161  -8.295  -4.697  -3.986  -6.559   9.060   2.877  -5.379   3.076  -3.850  14.128   0.350   6.526  -0.726  -8.924  -0.081  -4.899  -7.313  -1.011   2.651   0.188 -17.940   0.738  -1.151   6.424  -3.812   7.160   1.714   4.388  -1.252   3.084  19.910]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fc399da1b50> 
			buffer = deque([], maxlen=100000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fc399d54150> 
		size = (3,)
		dt = 0.2
		action = [-1.000 -1.000  0.753]
		daction_dt = [-0.360  0.603 -0.287]
	discrete = False
	action_size = (3,)
	state_size = (80,)
	config = <src.utils.config.Config object at 0x7fc39a2aec10> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.97
		NUM_STEPS = None
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 10000
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 250
		DYN_EPOCHS = 1
		TRAIN_EVERY = 10000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fc43fc8cb50> 
			NSAMPLES = 100
			HORIZON = 40
			LAMBDA = 0.1
			COV = 0.5
		REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
		DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
		dynamics_size = 13
		state_size = (80,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 1000000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fc39a2a0bd0> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.8
			PATIENCE = 5
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fc3980cf2d0> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		controls = np.clip(self.control[:,None,:,:] + self.noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls[...,:horizon,:], x, numpy=True)
		costs = -np.sum(rewards, -1) #+ self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control += np.sum(weights[:,:,None,None]*self.noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[1, self.horizon, *self.action_size]).repeat(batch_size, 0)
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[1, self.nsamples, self.horizon]).repeat(batch_size, 0)
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def partition(self, x):
		if self.config.NUM_STEPS is None:
			return x[None,...]
		num_splits = x.shape[0]//self.config.NUM_STEPS
		if num_splits == 0:
			arr = np.zeros([self.config.NUM_STEPS, *x.shape[1:]])
			arr[-x.shape[0]:] = x
			num_splits = 1
			x = arr
		arr = x[:num_splits*self.config.NUM_STEPS].reshape(num_splits, self.config.NUM_STEPS, *x.shape[1:])
		return arr

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: np.stack(x)[None], zip(*buffer))
			buffer.clear()
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = 1-(self.time%self.config.TRAIN_EVERY)/self.config.TRAIN_EVERY if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:  -147.419 [ 104.993], Avg:  -147.419 (1.000) <0-00:00:00> ({'r_t':    -1.1339, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:  -141.764 [  31.098], Avg:  -144.592 (1.000) <0-00:00:35> ({'r_t': -2181.7333, 'eps':     1.0000, 'len':    42.6640, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward:  -200.061 [ 167.231], Avg:  -163.081 (1.000) <0-00:01:30> ({'r_t': -2222.6029, 'eps':     1.0000, 'len':   137.0140, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward:  -185.871 [  81.417], Avg:  -168.779 (1.000) <0-00:02:10> ({'r_t': -1844.9595, 'eps':     1.0000, 'len':   247.8970, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward:  -301.960 [ 372.405], Avg:  -195.415 (1.000) <0-00:03:09> ({'r_t': -1784.0085, 'eps':     1.0000, 'len':   358.3550, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward:  -312.537 [ 531.279], Avg:  -214.935 (1.000) <0-00:04:07> ({'r_t': -1528.7821, 'eps':     1.0000, 'len':   454.4150, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward:  -309.420 [ 272.976], Avg:  -228.433 (1.000) <0-00:05:05> ({'r_t': -2469.6473, 'eps':     1.0000, 'len':   553.8170, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward:  -221.769 [ 208.601], Avg:  -227.600 (1.000) <0-00:06:03> ({'r_t': -2116.0312, 'eps':     1.0000, 'len':   653.8950, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward:  -152.867 [  70.227], Avg:  -219.297 (1.000) <0-00:06:44> ({'r_t': -2425.2980, 'eps':     1.0000, 'len':   751.5200, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward:  -154.782 [  79.644], Avg:  -212.845 (1.000) <0-00:07:26> ({'r_t': -1812.1245, 'eps':     1.0000, 'len':   853.0780, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward:  -479.012 [1238.549], Avg:  -237.042 (1.000) <0-00:08:24> ({'r_t': -2322.9273, 'eps':     1.0000, 'len':   948.1610, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward:  -205.660 [ 175.197], Avg:  -234.427 (1.000) <0-00:09:22> ({'r_t': -1977.9037, 'eps':     1.0000, 'len':  1043.5660, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward:  -187.301 [ 167.377], Avg:  -230.802 (1.000) <0-00:09:59> ({'r_t': -2147.7310, 'eps':     1.0000, 'len':  1133.7450, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   13000, Reward:  -342.907 [ 640.425], Avg:  -238.809 (1.000) <0-00:10:57> ({'r_t': -2378.5102, 'eps':     1.0000, 'len':  1231.1800, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   14000, Reward:  -192.555 [ 177.958], Avg:  -235.726 (1.000) <0-00:11:55> ({'r_t': -2056.3644, 'eps':     1.0000, 'len':  1329.6040, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   15000, Reward:  -358.113 [ 872.603], Avg:  -243.375 (1.000) <0-00:12:28> ({'r_t': -2358.7845, 'eps':     1.0000, 'len':  1431.4070, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   16000, Reward:  -365.117 [ 885.395], Avg:  -250.536 (1.000) <0-00:13:26> ({'r_t': -2103.3346, 'eps':     1.0000, 'len':  1535.5140, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   17000, Reward:  -183.351 [ 105.544], Avg:  -246.804 (1.000) <0-00:14:13> ({'r_t': -2099.0154, 'eps':     1.0000, 'len':  1634.4980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   18000, Reward:  -158.524 [  49.224], Avg:  -242.157 (1.000) <0-00:14:49> ({'r_t': -2132.1782, 'eps':     1.0000, 'len':  1738.8190, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   19000, Reward:  -225.983 [ 234.442], Avg:  -241.349 (1.000) <0-00:15:47> ({'r_t': -2282.2750, 'eps':     1.0000, 'len':  1839.3080, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   20000, Reward:  -268.202 [ 255.117], Avg:  -242.627 (1.000) <0-00:16:45> ({'r_t': -1806.2186, 'eps':     1.0000, 'len':  1944.9620, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   21000, Reward:  -197.991 [ 173.933], Avg:  -240.598 (1.000) <0-00:17:43> ({'r_t': -1724.9957, 'eps':     1.0000, 'len':  2047.8340, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   22000, Reward:  -184.589 [ 183.237], Avg:  -238.163 (1.000) <0-00:18:41> ({'r_t': -2209.1257, 'eps':     1.0000, 'len':  2148.3820, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   23000, Reward:  -245.806 [ 273.266], Avg:  -238.482 (1.000) <0-00:19:39> ({'r_t': -1698.0116, 'eps':     1.0000, 'len':  2240.2630, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   24000, Reward:  -184.051 [ 141.278], Avg:  -236.305 (1.000) <0-00:20:31> ({'r_t': -2514.8593, 'eps':     1.0000, 'len':  2332.8970, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   25000, Reward:  -155.046 [  51.606], Avg:  -233.179 (1.000) <0-00:21:06> ({'r_t': -1787.7074, 'eps':     1.0000, 'len':  2434.8430, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   26000, Reward:  -167.024 [ 150.961], Avg:  -230.729 (1.000) <0-00:22:00> ({'r_t': -2203.1962, 'eps':     1.0000, 'len':  2540.6190, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   27000, Reward:  -183.815 [  83.710], Avg:  -229.054 (1.000) <0-00:22:42> ({'r_t': -2568.8288, 'eps':     1.0000, 'len':  2636.5180, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   28000, Reward:  -175.018 [  72.426], Avg:  -227.190 (1.000) <0-00:23:21> ({'r_t': -2338.3335, 'eps':     1.0000, 'len':  2730.6400, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   29000, Reward:  -161.480 [ 131.681], Avg:  -225.000 (1.000) <0-00:23:54> ({'r_t': -2020.3810, 'eps':     1.0000, 'len':  2834.4110, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   30000, Reward:  -335.395 [ 441.785], Avg:  -228.561 (1.000) <0-00:24:52> ({'r_t': -2366.6407, 'eps':     1.0000, 'len':  2936.2340, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   31000, Reward:  -405.567 [ 619.738], Avg:  -234.092 (1.000) <0-00:25:50> ({'r_t': -2121.2438, 'eps':     1.0000, 'len':  3034.8330, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   32000, Reward:  -423.619 [1138.063], Avg:  -239.836 (1.000) <0-00:26:28> ({'r_t': -2043.3627, 'eps':     1.0000, 'len':  3126.2990, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   33000, Reward:  -179.823 [ 102.580], Avg:  -238.071 (1.000) <0-00:27:11> ({'r_t': -1553.6930, 'eps':     1.0000, 'len':  3225.6470, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   34000, Reward:  -158.778 [  96.755], Avg:  -235.805 (1.000) <0-00:28:02> ({'r_t': -1784.0971, 'eps':     1.0000, 'len':  3320.3490, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   35000, Reward:  -437.056 [ 889.705], Avg:  -241.395 (1.000) <0-00:29:00> ({'r_t': -2432.4199, 'eps':     1.0000, 'len':  3414.1180, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   36000, Reward:  -242.972 [ 224.683], Avg:  -241.438 (1.000) <0-00:29:58> ({'r_t': -1725.1699, 'eps':     1.0000, 'len':  3505.2040, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   37000, Reward:  -163.681 [  68.346], Avg:  -239.392 (1.000) <0-00:30:38> ({'r_t': -1998.8379, 'eps':     1.0000, 'len':  3611.8070, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   38000, Reward:  -293.208 [ 291.273], Avg:  -240.772 (1.000) <0-00:31:36> ({'r_t': -1987.5774, 'eps':     1.0000, 'len':  3720.5030, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   39000, Reward:  -176.671 [ 166.746], Avg:  -239.169 (1.000) <0-00:32:34> ({'r_t': -1977.8458, 'eps':     1.0000, 'len':  3828.6780, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   40000, Reward:  -188.194 [ 129.605], Avg:  -237.926 (1.000) <0-00:33:22> ({'r_t': -2197.4648, 'eps':     1.0000, 'len':  3920.9980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   41000, Reward:  -222.865 [ 197.412], Avg:  -237.567 (1.000) <0-00:34:20> ({'r_t': -2017.8952, 'eps':     1.0000, 'len':  4015.0300, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   42000, Reward:  -153.548 [  68.109], Avg:  -235.613 (1.000) <0-00:34:58> ({'r_t': -1576.6197, 'eps':     1.0000, 'len':  4114.8780, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   43000, Reward:  -206.924 [ 153.803], Avg:  -234.961 (1.000) <0-00:35:56> ({'r_t': -2141.8563, 'eps':     1.0000, 'len':  4210.1810, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   44000, Reward:  -208.508 [ 187.225], Avg:  -234.373 (1.000) <0-00:36:54> ({'r_t': -1895.9234, 'eps':     1.0000, 'len':  4307.1580, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   45000, Reward:  -208.569 [ 175.187], Avg:  -233.812 (1.000) <0-00:37:52> ({'r_t': -1754.5229, 'eps':     1.0000, 'len':  4405.3130, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   46000, Reward:  -230.264 [ 239.941], Avg:  -233.737 (1.000) <0-00:38:50> ({'r_t': -2088.8713, 'eps':     1.0000, 'len':  4509.6300, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   47000, Reward:  -312.769 [ 297.040], Avg:  -235.383 (1.000) <0-00:39:49> ({'r_t': -2270.1964, 'eps':     1.0000, 'len':  4612.1420, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   48000, Reward:  -212.740 [ 167.887], Avg:  -234.921 (1.000) <0-00:40:41> ({'r_t': -1920.3447, 'eps':     1.0000, 'len':  4715.7880, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   49000, Reward:  -142.095 [  32.104], Avg:  -233.065 (1.000) <0-00:41:13> ({'r_t': -2149.5398, 'eps':     1.0000, 'len':  4815.3200, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   50000, Reward:  -132.733 [  32.963], Avg:  -231.098 (1.000) <0-00:41:48> ({'r_t': -1776.0202, 'eps':     1.0000, 'len':  4911.2450, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   51000, Reward:  -198.620 [ 220.534], Avg:  -230.473 (1.000) <0-00:42:32> ({'r_t': -1805.8044, 'eps':     1.0000, 'len':  5012.8290, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   52000, Reward:  -170.038 [ 105.206], Avg:  -229.333 (1.000) <0-00:43:22> ({'r_t': -1905.9506, 'eps':     1.0000, 'len':  5112.2210, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   53000, Reward:  -208.267 [ 173.772], Avg:  -228.943 (1.000) <0-00:44:20> ({'r_t': -1925.7341, 'eps':     1.0000, 'len':  5219.2840, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   54000, Reward:  -142.621 [  42.103], Avg:  -227.373 (1.000) <0-00:44:53> ({'r_t': -2829.9266, 'eps':     1.0000, 'len':  5313.8670, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   55000, Reward:  -353.843 [ 898.446], Avg:  -229.632 (1.000) <0-00:45:52> ({'r_t': -3347.3294, 'eps':     1.0000, 'len':  5409.5130, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   56000, Reward:  -156.115 [ 110.029], Avg:  -228.342 (1.000) <0-00:46:32> ({'r_t': -1471.2948, 'eps':     1.0000, 'len':  5500.7850, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   57000, Reward:  -182.125 [ 126.274], Avg:  -227.545 (1.000) <0-00:47:30> ({'r_t': -1974.9340, 'eps':     1.0000, 'len':  5607.1790, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   58000, Reward:  -178.253 [ 193.026], Avg:  -226.709 (1.000) <0-00:48:28> ({'r_t': -2453.3700, 'eps':     1.0000, 'len':  5710.8940, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   59000, Reward:  -312.426 [ 556.391], Avg:  -228.138 (1.000) <0-00:49:26> ({'r_t': -2275.6423, 'eps':     1.0000, 'len':  5813.6210, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   60000, Reward:  -239.482 [ 243.924], Avg:  -228.324 (1.000) <0-00:50:24> ({'r_t': -1974.9602, 'eps':     1.0000, 'len':  5915.2740, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   61000, Reward:  -232.892 [ 184.043], Avg:  -228.398 (1.000) <0-00:51:22> ({'r_t': -1749.3939, 'eps':     1.0000, 'len':  6018.6930, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   62000, Reward:  -201.319 [ 169.261], Avg:  -227.968 (1.000) <0-00:52:21> ({'r_t': -1990.4279, 'eps':     1.0000, 'len':  6121.9240, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   63000, Reward:  -310.580 [ 382.111], Avg:  -229.259 (1.000) <0-00:53:19> ({'r_t': -1843.5347, 'eps':     1.0000, 'len':  6226.2510, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   64000, Reward:  -149.545 [  77.625], Avg:  -228.032 (1.000) <0-00:54:00> ({'r_t': -1738.0926, 'eps':     1.0000, 'len':  6323.9890, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   65000, Reward:  -139.693 [  25.462], Avg:  -226.694 (1.000) <0-00:54:32> ({'r_t': -1677.2809, 'eps':     1.0000, 'len':  6428.2650, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   66000, Reward:  -140.260 [  33.348], Avg:  -225.404 (1.000) <0-00:55:05> ({'r_t': -2116.6808, 'eps':     1.0000, 'len':  6532.8630, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   67000, Reward:  -246.031 [ 271.861], Avg:  -225.707 (1.000) <0-00:56:03> ({'r_t': -1759.4935, 'eps':     1.0000, 'len':  6639.9290, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   68000, Reward:  -207.277 [ 267.461], Avg:  -225.440 (1.000) <0-00:56:59> ({'r_t': -1899.4269, 'eps':     1.0000, 'len':  6742.2350, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   69000, Reward:  -266.825 [ 526.078], Avg:  -226.031 (1.000) <0-00:57:57> ({'r_t': -1859.5120, 'eps':     1.0000, 'len':  6845.4270, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   70000, Reward:  -224.444 [ 245.193], Avg:  -226.009 (1.000) <0-00:58:42> ({'r_t': -2003.3716, 'eps':     1.0000, 'len':  6944.2040, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   71000, Reward:  -192.545 [ 197.980], Avg:  -225.544 (1.000) <0-00:59:40> ({'r_t': -2201.6777, 'eps':     1.0000, 'len':  7047.4480, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   72000, Reward:  -139.984 [  31.190], Avg:  -224.372 (1.000) <0-01:00:15> ({'r_t': -1756.5680, 'eps':     1.0000, 'len':  7147.5310, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   73000, Reward:  -179.117 [ 145.974], Avg:  -223.760 (1.000) <0-01:00:51> ({'r_t': -1790.5589, 'eps':     1.0000, 'len':  7249.2340, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   74000, Reward:  -172.575 [ 136.203], Avg:  -223.078 (1.000) <0-01:01:49> ({'r_t': -1852.5276, 'eps':     1.0000, 'len':  7349.2210, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   75000, Reward:  -168.242 [  91.232], Avg:  -222.356 (1.000) <0-01:02:33> ({'r_t': -1670.7064, 'eps':     1.0000, 'len':  7453.7230, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   76000, Reward:  -136.604 [  43.074], Avg:  -221.243 (1.000) <0-01:03:07> ({'r_t': -2004.0452, 'eps':     1.0000, 'len':  7558.4720, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   77000, Reward:  -180.443 [ 188.201], Avg:  -220.720 (1.000) <0-01:04:05> ({'r_t': -1892.4444, 'eps':     1.0000, 'len':  7658.4580, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   78000, Reward:  -230.195 [ 240.671], Avg:  -220.840 (1.000) <0-01:05:04> ({'r_t': -1728.4904, 'eps':     1.0000, 'len':  7761.0090, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   79000, Reward:  -412.085 [ 865.432], Avg:  -223.230 (1.000) <0-01:06:03> ({'r_t': -2385.4253, 'eps':     1.0000, 'len':  7855.3980, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   80000, Reward:  -339.698 [ 300.179], Avg:  -224.668 (1.000) <0-01:07:00> ({'r_t': -2699.6874, 'eps':     1.0000, 'len':  7956.5040, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   81000, Reward:  -236.471 [ 205.597], Avg:  -224.812 (1.000) <0-01:07:58> ({'r_t': -1904.1645, 'eps':     1.0000, 'len':  8053.9550, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   82000, Reward:  -237.387 [ 215.428], Avg:  -224.964 (1.000) <0-01:08:56> ({'r_t': -2264.9367, 'eps':     1.0000, 'len':  8151.6220, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   83000, Reward:  -226.083 [ 201.961], Avg:  -224.977 (1.000) <0-01:09:54> ({'r_t': -1883.8465, 'eps':     1.0000, 'len':  8242.6220, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   84000, Reward:  -266.406 [ 248.983], Avg:  -225.464 (1.000) <0-01:10:52> ({'r_t': -1539.6617, 'eps':     1.0000, 'len':  8346.4240, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   85000, Reward:  -268.392 [ 237.977], Avg:  -225.963 (1.000) <0-01:11:49> ({'r_t': -2842.6994, 'eps':     1.0000, 'len':  8448.5940, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   86000, Reward:  -175.338 [ 163.509], Avg:  -225.382 (1.000) <0-01:12:47> ({'r_t': -1815.5926, 'eps':     1.0000, 'len':  8548.7470, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   87000, Reward:  -203.554 [ 148.369], Avg:  -225.134 (1.000) <0-01:13:37> ({'r_t': -1922.3251, 'eps':     1.0000, 'len':  8643.0830, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   88000, Reward:  -141.569 [  41.572], Avg:  -224.195 (1.000) <0-01:14:10> ({'r_t': -2542.4428, 'eps':     1.0000, 'len':  8740.2600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   89000, Reward:  -233.003 [ 207.157], Avg:  -224.292 (1.000) <0-01:15:05> ({'r_t': -1419.2674, 'eps':     1.0000, 'len':  8847.7530, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   90000, Reward:  -151.667 [  38.761], Avg:  -223.494 (1.000) <0-01:15:40> ({'r_t': -1933.7228, 'eps':     1.0000, 'len':  8948.1580, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   91000, Reward:  -162.212 [  53.958], Avg:  -222.828 (1.000) <0-01:16:19> ({'r_t': -1982.1796, 'eps':     1.0000, 'len':  9045.8550, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   92000, Reward:  -192.356 [ 175.527], Avg:  -222.501 (1.000) <0-01:17:17> ({'r_t': -1631.9931, 'eps':     1.0000, 'len':  9146.4780, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   93000, Reward:  -139.701 [  34.577], Avg:  -221.620 (1.000) <0-01:17:52> ({'r_t': -1970.2900, 'eps':     1.0000, 'len':  9243.3670, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   94000, Reward:  -230.328 [ 217.952], Avg:  -221.711 (1.000) <0-01:18:41> ({'r_t': -2119.3405, 'eps':     1.0000, 'len':  9337.8580, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   95000, Reward:  -212.489 [ 194.182], Avg:  -221.615 (1.000) <0-01:19:39> ({'r_t': -1851.9697, 'eps':     1.0000, 'len':  9436.2790, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   96000, Reward:  -196.247 [ 141.530], Avg:  -221.354 (1.000) <0-01:20:30> ({'r_t': -2200.8990, 'eps':     1.0000, 'len':  9535.8170, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   97000, Reward:  -337.588 [ 539.153], Avg:  -222.540 (1.000) <0-01:21:28> ({'r_t': -2106.5712, 'eps':     1.0000, 'len':  9625.9610, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   98000, Reward:  -312.528 [ 310.478], Avg:  -223.449 (1.000) <0-01:22:26> ({'r_t': -1961.7667, 'eps':     1.0000, 'len':  9729.6800, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   99000, Reward:  -346.521 [ 618.138], Avg:  -224.680 (1.000) <0-01:23:24> ({'r_t': -2319.4516, 'eps':     1.0000, 'len':  9826.7660, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  100000, Reward:  -192.888 [ 162.782], Avg:  -224.365 (1.000) <0-01:24:17> ({'r_t': -1934.1132, 'eps':     1.0000, 'len':  9917.5700, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  101000, Reward:  -264.025 [ 246.545], Avg:  -224.754 (1.000) <0-01:25:15> ({'r_t': -2421.6133, 'eps':     1.0000, 'len': 10006.7910, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  102000, Reward:  -212.603 [ 203.110], Avg:  -224.636 (1.000) <0-01:26:13> ({'r_t': -1539.1635, 'eps':     1.0000, 'len': 10106.2130, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  103000, Reward:  -349.709 [ 499.646], Avg:  -225.838 (1.000) <0-01:27:11> ({'r_t': -2046.9032, 'eps':     1.0000, 'len': 10201.4480, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  104000, Reward:  -235.283 [ 229.976], Avg:  -225.928 (1.000) <0-01:28:09> ({'r_t': -1570.7115, 'eps':     1.0000, 'len': 10301.9700, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  105000, Reward:  -129.218 [  29.034], Avg:  -225.016 (1.000) <0-01:28:42> ({'r_t': -2051.2009, 'eps':     1.0000, 'len': 10401.1770, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  106000, Reward:  -229.087 [ 243.077], Avg:  -225.054 (1.000) <0-01:29:41> ({'r_t': -2338.9802, 'eps':     1.0000, 'len': 10496.9160, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  107000, Reward:  -441.853 [ 994.047], Avg:  -227.061 (1.000) <0-01:30:38> ({'r_t': -1643.2589, 'eps':     1.0000, 'len': 10595.6030, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  108000, Reward:  -278.537 [ 460.924], Avg:  -227.534 (1.000) <0-01:31:23> ({'r_t': -1940.7238, 'eps':     1.0000, 'len': 10703.7120, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  109000, Reward:  -214.235 [ 195.925], Avg:  -227.413 (1.000) <0-01:32:21> ({'r_t': -1700.8628, 'eps':     1.0000, 'len': 10808.6860, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  110000, Reward:  -102.101 [  36.503], Avg:  -226.284 (1.000) <0-01:38:03> ({'r_t': -2457.6121, 'eps':     0.9999, 'len': 10904.7480, 'dyn_loss': 10761.2002, 'dot_loss':   137.2029, 'ddot_loss':    31.8792, 'rew_loss':   566.8396, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  111000, Reward:  -147.357 [ 158.679], Avg:  -225.579 (0.900) <0-01:39:00> ({'r_t': -1854.1622, 'eps':     0.8999, 'len': 11003.6720, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  112000, Reward:  -974.252 [3382.664], Avg:  -232.204 (0.800) <0-01:40:03> ({'r_t': -1547.1153, 'eps':     0.7999, 'len': 11114.5710, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  113000, Reward:  -130.750 [ 152.498], Avg:  -231.315 (0.700) <0-01:40:45> ({'r_t': -1101.8261, 'eps':     0.6999, 'len': 11223.3720, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  114000, Reward:   -82.026 [  29.372], Avg:  -230.016 (0.600) <0-01:41:35> ({'r_t': -1104.4720, 'eps':     0.5999, 'len': 11355.8210, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  115000, Reward:  -176.307 [ 206.630], Avg:  -229.553 (0.500) <0-01:42:56> ({'r_t': -1186.1063, 'eps':     0.4999, 'len': 11527.6200, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  116000, Reward:  -102.961 [  42.731], Avg:  -228.471 (0.400) <0-01:44:03> ({'r_t': -1371.1419, 'eps':     0.3999, 'len': 11714.0600, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  117000, Reward:   -87.981 [  42.263], Avg:  -227.281 (0.300) <0-01:45:17> ({'r_t': -1332.0342, 'eps':     0.2999, 'len': 11909.6680, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  118000, Reward:   -80.362 [  28.389], Avg:  -226.046 (0.200) <0-01:46:36> ({'r_t': -1014.6908, 'eps':     0.1999, 'len': 12100.1180, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  119000, Reward:   -85.556 [  32.243], Avg:  -224.875 (0.100) <0-01:48:00> ({'r_t': -1307.4813, 'eps':     0.0999, 'len': 12275.4680, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  120000, Reward:  -188.435 [ 526.079], Avg:  -224.574 (1.000) <0-01:54:46> ({'r_t': -1070.9318, 'eps':     0.9999, 'len': 12448.5320, 'dyn_loss':   179.7003, 'dot_loss':    15.5040, 'ddot_loss':    14.9887, 'rew_loss':   572.6998, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  121000, Reward:   -51.384 [  31.476], Avg:  -223.155 (0.900) <0-01:55:17> ({'r_t': -1562.4156, 'eps':     0.8999, 'len': 12590.3630, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  122000, Reward:   -37.299 [  70.189], Avg:  -221.644 (0.800) <0-01:55:59> ({'r_t': -1419.0895, 'eps':     0.7999, 'len': 12694.1210, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  123000, Reward:   -76.411 [  69.668], Avg:  -220.472 (0.700) <0-01:56:47> ({'r_t': -1023.9008, 'eps':     0.6999, 'len': 12799.4970, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  124000, Reward:   -54.650 [  31.082], Avg:  -219.146 (0.600) <0-01:57:37> ({'r_t':  -565.2473, 'eps':     0.5999, 'len': 12928.5030, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  125000, Reward:   -53.638 [  32.320], Avg:  -217.832 (0.500) <0-01:58:38> ({'r_t':  -448.1087, 'eps':     0.4999, 'len': 13087.5890, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  126000, Reward:   -55.290 [  41.014], Avg:  -216.552 (0.400) <0-01:59:43> ({'r_t': -1088.6372, 'eps':     0.3999, 'len': 13228.4530, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  127000, Reward:   -47.907 [  16.873], Avg:  -215.235 (0.300) <0-02:00:55> ({'r_t':  -589.4691, 'eps':     0.2999, 'len': 13366.4840, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  128000, Reward:   -54.612 [  52.834], Avg:  -213.990 (0.200) <0-02:02:19> ({'r_t':  -918.5188, 'eps':     0.1999, 'len': 13522.8870, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  129000, Reward:   -39.481 [  34.041], Avg:  -212.647 (0.100) <0-02:03:48> ({'r_t':  -504.1738, 'eps':     0.0999, 'len': 13675.6370, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  130000, Reward:   -87.701 [  72.006], Avg:  -211.694 (1.000) <0-02:10:24> ({'r_t':  -714.4646, 'eps':     0.9999, 'len': 13830.0550, 'dyn_loss':    96.5764, 'dot_loss':     6.9110, 'ddot_loss':     9.1060, 'rew_loss':   526.1228, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  131000, Reward:  -138.576 [ 109.587], Avg:  -211.140 (0.900) <0-02:11:16> ({'r_t': -1816.7667, 'eps':     0.8999, 'len': 13960.9560, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  132000, Reward:   -70.660 [  46.202], Avg:  -210.083 (0.800) <0-02:12:02> ({'r_t': -1769.0416, 'eps':     0.7999, 'len': 14065.0260, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  133000, Reward:  -106.346 [  57.916], Avg:  -209.309 (0.700) <0-02:13:04> ({'r_t': -1063.8001, 'eps':     0.6999, 'len': 14149.3010, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  134000, Reward:  -156.432 [ 139.323], Avg:  -208.918 (0.600) <0-02:14:21> ({'r_t':  -794.3905, 'eps':     0.5999, 'len': 14228.0010, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  135000, Reward:  -168.402 [ 364.945], Avg:  -208.620 (0.500) <0-02:15:35> ({'r_t':  -503.1944, 'eps':     0.4999, 'len': 14318.6090, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  136000, Reward:   -98.053 [  71.716], Avg:  -207.813 (0.400) <0-02:17:04> ({'r_t':  -562.8822, 'eps':     0.3999, 'len': 14398.0110, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  137000, Reward:  -128.708 [ 122.631], Avg:  -207.239 (0.300) <0-02:18:42> ({'r_t':  -320.9563, 'eps':     0.2999, 'len': 14478.7370, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  138000, Reward:  -119.904 [  76.535], Avg:  -206.611 (0.200) <0-02:20:14> ({'r_t':  -437.3361, 'eps':     0.1999, 'len': 14559.5700, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  139000, Reward:  -101.460 [  57.160], Avg:  -205.860 (0.100) <0-02:21:51> ({'r_t':  -522.5084, 'eps':     0.0999, 'len': 14640.5190, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  140000, Reward:  -397.909 [ 861.978], Avg:  -207.222 (1.000) <0-02:28:36> ({'r_t':  -547.4733, 'eps':     0.9999, 'len': 14720.9860, 'dyn_loss':    61.6454, 'dot_loss':     4.5716, 'ddot_loss':     7.9798, 'rew_loss':   505.0399, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  141000, Reward:  -195.521 [ 491.463], Avg:  -207.140 (0.900) <0-02:29:29> ({'r_t': -1624.9592, 'eps':     0.8999, 'len': 14809.9960, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  142000, Reward:  -282.831 [ 629.542], Avg:  -207.669 (0.800) <0-02:30:23> ({'r_t': -1347.9456, 'eps':     0.7999, 'len': 14913.3540, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  143000, Reward:   -87.988 [ 390.474], Avg:  -206.838 (0.700) <0-02:31:27> ({'r_t':  -898.8401, 'eps':     0.6999, 'len': 15018.3110, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  144000, Reward:  -284.757 [ 648.140], Avg:  -207.375 (0.600) <0-02:32:34> ({'r_t':  -767.0164, 'eps':     0.5999, 'len': 15103.9620, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  145000, Reward:  -551.528 [ 961.992], Avg:  -209.732 (0.500) <0-02:33:44> ({'r_t':   -38.2793, 'eps':     0.4999, 'len': 15181.0740, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  146000, Reward:     1.411 [  75.871], Avg:  -208.296 (0.400) <0-02:35:04> ({'r_t':    22.0213, 'eps':     0.3999, 'len': 15250.0920, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  147000, Reward:  -221.124 [ 567.920], Avg:  -208.383 (0.300) <0-02:36:38> ({'r_t':  -758.8892, 'eps':     0.2999, 'len': 15316.2520, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  148000, Reward:  -413.353 [ 681.330], Avg:  -209.758 (0.200) <0-02:38:12> ({'r_t': -1158.2237, 'eps':     0.1999, 'len': 15385.6730, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  149000, Reward:  -347.616 [ 620.360], Avg:  -210.677 (0.100) <0-02:40:02> ({'r_t': -1023.5683, 'eps':     0.0999, 'len': 15455.2210, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  150000, Reward:     3.592 [ 127.299], Avg:  -209.258 (1.000) <0-02:46:56> ({'r_t':  -674.0181, 'eps':     0.9999, 'len': 15527.5110, 'dyn_loss':    48.7647, 'dot_loss':     4.5105, 'ddot_loss':     9.0664, 'rew_loss':   411.7847, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  151000, Reward:    -1.239 [  92.209], Avg:  -207.890 (0.900) <0-02:47:49> ({'r_t': -1981.4103, 'eps':     0.8999, 'len': 15609.8440, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  152000, Reward:   -23.053 [ 111.565], Avg:  -206.682 (0.800) <0-02:48:51> ({'r_t': -1542.3365, 'eps':     0.7999, 'len': 15714.9340, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  153000, Reward:   -77.448 [ 136.081], Avg:  -205.843 (0.700) <0-02:50:00> ({'r_t':  -976.0815, 'eps':     0.6999, 'len': 15816.4200, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  154000, Reward:   -44.587 [  78.034], Avg:  -204.802 (0.600) <0-02:51:13> ({'r_t':  -502.9535, 'eps':     0.5999, 'len': 15892.6540, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  155000, Reward:    -9.065 [  59.462], Avg:  -203.548 (0.500) <0-02:52:30> ({'r_t':  -215.5664, 'eps':     0.4999, 'len': 15950.8270, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  156000, Reward:   -52.740 [ 133.185], Avg:  -202.587 (0.400) <0-02:54:01> ({'r_t':  -178.4442, 'eps':     0.3999, 'len': 15997.9180, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  157000, Reward:     5.632 [  99.027], Avg:  -201.269 (0.300) <0-02:55:37> ({'r_t':  -208.5751, 'eps':     0.2999, 'len': 16041.3760, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  158000, Reward:   -51.383 [ 134.927], Avg:  -200.326 (0.200) <0-02:57:22> ({'r_t':   -90.1990, 'eps':     0.1999, 'len': 16089.4860, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  159000, Reward:   -42.576 [ 103.813], Avg:  -199.340 (0.100) <0-02:59:14> ({'r_t':  -145.6297, 'eps':     0.0999, 'len': 16137.6710, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  160000, Reward:   105.546 [  78.840], Avg:  -197.447 (1.000) <0-03:06:18> ({'r_t':  -124.8613, 'eps':     0.9999, 'len': 16188.6750, 'dyn_loss':    41.5599, 'dot_loss':     4.0728, 'ddot_loss':     8.4788, 'rew_loss':   433.6757, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  161000, Reward:    18.836 [ 156.515], Avg:  -196.112 (0.900) <0-03:07:17> ({'r_t': -1798.7691, 'eps':     0.8999, 'len': 16264.3360, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  162000, Reward:   103.149 [ 100.026], Avg:  -194.276 (0.800) <0-03:08:20> ({'r_t': -1609.1377, 'eps':     0.7999, 'len': 16361.8180, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  163000, Reward:    99.110 [ 118.813], Avg:  -192.487 (0.700) <0-03:09:30> ({'r_t':  -996.0404, 'eps':     0.6999, 'len': 16451.8380, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  164000, Reward:   132.260 [  52.492], Avg:  -190.519 (0.600) <0-03:10:34> ({'r_t':  -426.3681, 'eps':     0.5999, 'len': 16522.1590, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  165000, Reward:   115.929 [ 100.388], Avg:  -188.673 (0.500) <0-03:11:49> ({'r_t':  -330.1457, 'eps':     0.4999, 'len': 16587.5850, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  166000, Reward:    77.518 [  73.617], Avg:  -187.079 (0.400) <0-03:13:14> ({'r_t':    15.6261, 'eps':     0.3999, 'len': 16651.0850, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  167000, Reward:   111.036 [  78.466], Avg:  -185.304 (0.300) <0-03:14:41> ({'r_t':   123.8441, 'eps':     0.2999, 'len': 16714.3000, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  168000, Reward:   109.310 [  65.053], Avg:  -183.561 (0.200) <0-03:16:18> ({'r_t':   285.7310, 'eps':     0.1999, 'len': 16778.2270, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  169000, Reward:    99.812 [ 105.516], Avg:  -181.894 (0.100) <0-03:18:07> ({'r_t':   334.2748, 'eps':     0.0999, 'len': 16840.1240, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  170000, Reward:   173.803 [  77.986], Avg:  -179.814 (1.000) <0-03:25:17> ({'r_t':   486.2956, 'eps':     0.9999, 'len': 16903.9150, 'dyn_loss':    40.8916, 'dot_loss':     3.9295, 'ddot_loss':     8.2821, 'rew_loss':   388.9409, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  171000, Reward:   196.385 [  51.570], Avg:  -177.627 (0.900) <0-03:26:16> ({'r_t': -2024.9777, 'eps':     0.8999, 'len': 16985.8030, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  172000, Reward:   174.492 [  80.414], Avg:  -175.591 (0.800) <0-03:27:19> ({'r_t': -1408.5125, 'eps':     0.7999, 'len': 17086.8160, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  173000, Reward:   197.471 [  63.550], Avg:  -173.447 (0.700) <0-03:28:28> ({'r_t': -1008.6146, 'eps':     0.6999, 'len': 17183.9990, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  174000, Reward:   144.649 [ 127.334], Avg:  -171.630 (0.600) <0-03:29:44> ({'r_t':  -662.8663, 'eps':     0.5999, 'len': 17258.1440, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  175000, Reward:   187.511 [  79.514], Avg:  -169.589 (0.500) <0-03:31:06> ({'r_t':  -101.4538, 'eps':     0.4999, 'len': 17308.2420, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  176000, Reward:   185.701 [  59.571], Avg:  -167.582 (0.400) <0-03:32:35> ({'r_t':    95.6851, 'eps':     0.3999, 'len': 17349.2550, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  177000, Reward:   203.162 [  64.038], Avg:  -165.499 (0.300) <0-03:34:05> ({'r_t':   285.1372, 'eps':     0.2999, 'len': 17392.1550, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  178000, Reward:   215.196 [  69.262], Avg:  -163.372 (0.200) <0-03:35:49> ({'r_t':   308.4160, 'eps':     0.1999, 'len': 17435.5670, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  179000, Reward:   193.984 [  59.369], Avg:  -161.387 (0.100) <0-03:37:40> ({'r_t':   563.3573, 'eps':     0.0999, 'len': 17484.9620, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  180000, Reward:    84.483 [ 382.115], Avg:  -160.028 (1.000) <0-03:45:00> ({'r_t':   576.8252, 'eps':     0.9999, 'len': 17536.6720, 'dyn_loss':    38.6095, 'dot_loss':     3.7933, 'ddot_loss':     8.0704, 'rew_loss':   395.3106, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  181000, Reward:   -24.692 [ 864.997], Avg:  -159.285 (0.900) <0-03:45:59> ({'r_t': -1980.5488, 'eps':     0.8999, 'len': 17608.5840, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  182000, Reward:     5.661 [ 494.898], Avg:  -158.383 (0.800) <0-03:47:03> ({'r_t': -1435.7848, 'eps':     0.7999, 'len': 17705.2130, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  183000, Reward:   127.487 [ 185.031], Avg:  -156.830 (0.700) <0-03:48:12> ({'r_t': -1102.8392, 'eps':     0.6999, 'len': 17794.6250, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  184000, Reward:   180.441 [ 115.803], Avg:  -155.007 (0.600) <0-03:49:29> ({'r_t':  -539.6701, 'eps':     0.5999, 'len': 17865.9650, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  185000, Reward:   158.219 [ 142.089], Avg:  -153.323 (0.500) <0-03:50:52> ({'r_t':  -265.9810, 'eps':     0.4999, 'len': 17916.4120, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  186000, Reward:   -58.518 [ 739.042], Avg:  -152.816 (0.400) <0-03:52:23> ({'r_t':   290.8581, 'eps':     0.3999, 'len': 17958.4240, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  187000, Reward:    -5.577 [ 593.763], Avg:  -152.033 (0.300) <0-03:54:00> ({'r_t':   227.6234, 'eps':     0.2999, 'len': 17997.2220, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  188000, Reward:  -248.850 [1108.480], Avg:  -152.545 (0.200) <0-03:55:45> ({'r_t':   127.5469, 'eps':     0.1999, 'len': 18035.4970, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  189000, Reward:   -66.353 [ 805.547], Avg:  -152.091 (0.100) <0-03:57:36> ({'r_t':   229.5291, 'eps':     0.0999, 'len': 18075.4040, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  190000, Reward:   -22.073 [ 586.742], Avg:  -151.410 (1.000) <0-04:05:09> ({'r_t':    15.5665, 'eps':     0.9999, 'len': 18113.5610, 'dyn_loss':    34.9640, 'dot_loss':     3.5770, 'ddot_loss':     7.6923, 'rew_loss':   370.8784, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  191000, Reward:   291.681 [ 165.359], Avg:  -149.103 (0.900) <0-04:06:08> ({'r_t': -1748.4527, 'eps':     0.8999, 'len': 18184.8930, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  192000, Reward:   246.133 [ 212.579], Avg:  -147.055 (0.800) <0-04:07:12> ({'r_t': -1263.2355, 'eps':     0.7999, 'len': 18289.3720, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  193000, Reward:   -39.459 [ 577.712], Avg:  -146.500 (0.700) <0-04:08:22> ({'r_t': -1041.8992, 'eps':     0.6999, 'len': 18382.3720, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  194000, Reward:  -119.178 [ 632.795], Avg:  -146.360 (0.600) <0-04:09:38> ({'r_t':  -595.6618, 'eps':     0.5999, 'len': 18459.9430, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  195000, Reward:    60.661 [ 595.353], Avg:  -145.304 (0.500) <0-04:11:00> ({'r_t':  -129.2721, 'eps':     0.4999, 'len': 18508.2780, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  196000, Reward:   115.414 [ 499.168], Avg:  -143.980 (0.400) <0-04:12:30> ({'r_t':    93.0883, 'eps':     0.3999, 'len': 18546.1800, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  197000, Reward:   127.486 [ 556.777], Avg:  -142.609 (0.300) <0-04:14:08> ({'r_t':   107.0894, 'eps':     0.2999, 'len': 18581.9440, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  198000, Reward:    78.608 [ 491.976], Avg:  -141.498 (0.200) <0-04:15:52> ({'r_t':   -83.5722, 'eps':     0.1999, 'len': 18619.0500, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  199000, Reward:   113.728 [ 383.296], Avg:  -140.222 (0.100) <0-04:17:43> ({'r_t':   495.9001, 'eps':     0.0999, 'len': 18659.1740, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  200000, Reward:   222.728 [  65.843], Avg:  -138.416 (1.000) <0-04:25:23> ({'r_t':   383.9647, 'eps':     0.9999, 'len': 18703.2940, 'dyn_loss':    34.1743, 'dot_loss':     3.4763, 'ddot_loss':     7.5514, 'rew_loss':   351.1842, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  201000, Reward:  -271.589 [ 886.659], Avg:  -139.075 (0.900) <0-04:26:21> ({'r_t': -1560.0363, 'eps':     0.8999, 'len': 18779.6360, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  202000, Reward:     5.441 [ 564.367], Avg:  -138.363 (0.800) <0-04:27:25> ({'r_t': -1543.1336, 'eps':     0.7999, 'len': 18879.4590, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  203000, Reward:   114.376 [ 390.684], Avg:  -137.124 (0.700) <0-04:28:36> ({'r_t': -1073.1585, 'eps':     0.6999, 'len': 18967.9570, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  204000, Reward:  -234.973 [1447.179], Avg:  -137.602 (0.600) <0-04:29:53> ({'r_t':  -521.6196, 'eps':     0.5999, 'len': 19039.4910, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  205000, Reward:   129.060 [ 375.430], Avg:  -136.307 (0.500) <0-04:31:17> ({'r_t':  -275.7186, 'eps':     0.4999, 'len': 19089.4710, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  206000, Reward:   246.681 [  62.778], Avg:  -134.457 (0.400) <0-04:32:48> ({'r_t':  -151.6084, 'eps':     0.3999, 'len': 19128.4210, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  207000, Reward:   -97.474 [ 669.165], Avg:  -134.279 (0.300) <0-04:34:25> ({'r_t':   281.7028, 'eps':     0.2999, 'len': 19164.9180, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  208000, Reward:   143.089 [ 356.291], Avg:  -132.952 (0.200) <0-04:36:10> ({'r_t':   403.3182, 'eps':     0.1999, 'len': 19200.9020, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  209000, Reward:    24.014 [ 449.669], Avg:  -132.205 (0.100) <0-04:38:02> ({'r_t':    97.3262, 'eps':     0.0999, 'len': 19236.6030, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  210000, Reward:   121.662 [ 574.326], Avg:  -131.001 (1.000) <0-04:45:53> ({'r_t':    59.6193, 'eps':     0.9999, 'len': 19272.6070, 'dyn_loss':    32.4475, 'dot_loss':     3.3341, 'ddot_loss':     7.3347, 'rew_loss':   286.1378, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  211000, Reward:   -12.572 [ 639.958], Avg:  -130.443 (0.900) <0-04:46:52> ({'r_t': -1671.3684, 'eps':     0.8999, 'len': 19336.2550, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  212000, Reward:   267.434 [ 383.142], Avg:  -128.575 (0.800) <0-04:47:55> ({'r_t': -1342.6495, 'eps':     0.7999, 'len': 19437.4740, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  213000, Reward:   264.918 [ 357.045], Avg:  -126.736 (0.700) <0-04:49:05> ({'r_t': -1114.2633, 'eps':     0.6999, 'len': 19528.4640, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  214000, Reward:   102.834 [ 582.663], Avg:  -125.668 (0.600) <0-04:50:22> ({'r_t':  -766.8240, 'eps':     0.5999, 'len': 19607.6880, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  215000, Reward:   -53.916 [ 618.614], Avg:  -125.336 (0.500) <0-04:51:45> ({'r_t':  -216.1402, 'eps':     0.4999, 'len': 19665.5950, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  216000, Reward:    14.769 [ 565.489], Avg:  -124.690 (0.400) <0-04:53:16> ({'r_t':   316.4058, 'eps':     0.3999, 'len': 19704.3850, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  217000, Reward:   270.801 [ 375.058], Avg:  -122.876 (0.300) <0-04:54:53> ({'r_t':   148.9520, 'eps':     0.2999, 'len': 19738.8310, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  218000, Reward:   -18.148 [ 778.504], Avg:  -122.398 (0.200) <0-04:56:38> ({'r_t':   372.8162, 'eps':     0.1999, 'len': 19775.2480, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  219000, Reward:   -37.474 [ 656.282], Avg:  -122.012 (0.100) <0-04:58:30> ({'r_t':   474.0950, 'eps':     0.0999, 'len': 19813.2870, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  220000, Reward:   442.424 [  44.085], Avg:  -119.458 (1.000) <0-05:06:30> ({'r_t':   -56.3676, 'eps':     0.9999, 'len': 19854.4850, 'dyn_loss':    32.1488, 'dot_loss':     3.2311, 'ddot_loss':     7.1170, 'rew_loss':   356.8611, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  221000, Reward:   417.281 [  50.544], Avg:  -117.040 (0.900) <0-05:07:28> ({'r_t': -1513.8744, 'eps':     0.8999, 'len': 19924.1610, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  222000, Reward:   128.429 [ 486.471], Avg:  -115.940 (0.800) <0-05:08:32> ({'r_t': -1345.5435, 'eps':     0.7999, 'len': 20026.8580, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  223000, Reward:   386.440 [  99.902], Avg:  -113.697 (0.700) <0-05:09:42> ({'r_t': -1128.9237, 'eps':     0.6999, 'len': 20119.1810, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  224000, Reward:   328.278 [ 375.168], Avg:  -111.732 (0.600) <0-05:10:59> ({'r_t':  -797.6599, 'eps':     0.5999, 'len': 20204.5080, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  225000, Reward:   193.481 [ 522.799], Avg:  -110.382 (0.500) <0-05:12:22> ({'r_t':  -265.8798, 'eps':     0.4999, 'len': 20262.0090, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  226000, Reward:   367.951 [ 128.480], Avg:  -108.275 (0.400) <0-05:13:52> ({'r_t':   146.8517, 'eps':     0.3999, 'len': 20303.2740, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  227000, Reward:  -126.781 [ 857.854], Avg:  -108.356 (0.300) <0-05:15:30> ({'r_t':   370.8136, 'eps':     0.2999, 'len': 20338.3050, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  228000, Reward:   400.737 [ 120.247], Avg:  -106.133 (0.200) <0-05:17:14> ({'r_t':   545.6532, 'eps':     0.1999, 'len': 20375.3090, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  229000, Reward:   283.734 [ 383.366], Avg:  -104.438 (0.100) <0-05:19:06> ({'r_t':   565.3253, 'eps':     0.0999, 'len': 20413.5440, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  230000, Reward:   400.894 [ 137.027], Avg:  -102.250 (1.000) <0-05:27:06> ({'r_t':   854.6145, 'eps':     0.9999, 'len': 20453.7140, 'dyn_loss':    30.5913, 'dot_loss':     3.1503, 'ddot_loss':     7.0073, 'rew_loss':   305.1223, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  231000, Reward:   410.333 [ 144.368], Avg:  -100.041 (0.900) <0-05:28:04> ({'r_t': -1625.1163, 'eps':     0.8999, 'len': 20526.0480, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  232000, Reward:   373.503 [ 159.780], Avg:   -98.008 (0.800) <0-05:29:08> ({'r_t': -1398.6368, 'eps':     0.7999, 'len': 20622.3160, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  233000, Reward:   242.618 [ 514.922], Avg:   -96.553 (0.700) <0-05:30:18> ({'r_t': -1274.8792, 'eps':     0.6999, 'len': 20709.1100, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  234000, Reward:   390.711 [ 172.738], Avg:   -94.479 (0.600) <0-05:31:35> ({'r_t':  -652.0870, 'eps':     0.5999, 'len': 20788.5100, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  235000, Reward:   305.472 [ 390.713], Avg:   -92.785 (0.500) <0-05:32:58> ({'r_t':  -165.0031, 'eps':     0.4999, 'len': 20840.7880, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  236000, Reward:   409.464 [ 120.899], Avg:   -90.665 (0.400) <0-05:34:28> ({'r_t':   301.2664, 'eps':     0.3999, 'len': 20881.0300, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  237000, Reward:   195.965 [ 406.149], Avg:   -89.461 (0.300) <0-05:36:06> ({'r_t':   690.1447, 'eps':     0.2999, 'len': 20915.2570, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  238000, Reward:   317.492 [ 368.277], Avg:   -87.758 (0.200) <0-05:37:50> ({'r_t':   908.2565, 'eps':     0.1999, 'len': 20949.1830, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  239000, Reward:   259.855 [ 495.977], Avg:   -86.310 (0.100) <0-05:39:42> ({'r_t':   741.4085, 'eps':     0.0999, 'len': 20984.2210, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  240000, Reward:   380.999 [ 175.003], Avg:   -84.371 (1.000) <0-05:47:58> ({'r_t':   724.0357, 'eps':     0.9999, 'len': 21020.3530, 'dyn_loss':    30.3087, 'dot_loss':     3.1826, 'ddot_loss':     7.1472, 'rew_loss':   309.1055, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  241000, Reward:   399.244 [ 181.178], Avg:   -82.372 (0.900) <0-05:48:56> ({'r_t': -1776.6896, 'eps':     0.8999, 'len': 21087.6930, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  242000, Reward:   454.551 [  40.895], Avg:   -80.163 (0.800) <0-05:50:00> ({'r_t': -1466.3079, 'eps':     0.7999, 'len': 21183.9140, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  243000, Reward:   376.607 [ 209.686], Avg:   -78.291 (0.700) <0-05:51:10> ({'r_t': -1088.2702, 'eps':     0.6999, 'len': 21268.9350, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  244000, Reward:   469.215 [  23.137], Avg:   -76.056 (0.600) <0-05:52:27> ({'r_t':  -805.7731, 'eps':     0.5999, 'len': 21340.4130, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  245000, Reward:   241.455 [ 485.361], Avg:   -74.765 (0.500) <0-05:53:50> ({'r_t':  -279.1125, 'eps':     0.4999, 'len': 21394.6160, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  246000, Reward:   330.683 [ 354.151], Avg:   -73.124 (0.400) <0-05:55:20> ({'r_t':   377.2300, 'eps':     0.3999, 'len': 21431.4590, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  247000, Reward:   433.749 [  49.105], Avg:   -71.080 (0.300) <0-05:56:58> ({'r_t':   764.3587, 'eps':     0.2999, 'len': 21464.6970, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  248000, Reward:   373.508 [ 361.831], Avg:   -69.295 (0.200) <0-05:58:42> ({'r_t':   884.1191, 'eps':     0.1999, 'len': 21499.0530, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  249000, Reward:   357.486 [ 366.572], Avg:   -67.588 (0.100) <0-06:00:34> ({'r_t':   935.4786, 'eps':     0.0999, 'len': 21533.6960, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  250000, Reward:   246.798 [ 473.955], Avg:   -66.335 (1.000) <0-06:08:52> ({'r_t':   942.7220, 'eps':     0.9999, 'len': 21568.8690, 'dyn_loss':    28.6836, 'dot_loss':     3.0661, 'ddot_loss':     6.9204, 'rew_loss':   302.4195, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  251000, Reward:   214.899 [ 503.465], Avg:   -65.219 (0.900) <0-06:09:50> ({'r_t': -1721.8883, 'eps':     0.8999, 'len': 21631.5730, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  252000, Reward:   271.612 [ 478.862], Avg:   -63.888 (0.800) <0-06:10:54> ({'r_t': -1242.3754, 'eps':     0.7999, 'len': 21737.5580, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  253000, Reward:   353.065 [ 384.956], Avg:   -62.246 (0.700) <0-06:12:04> ({'r_t': -1121.9749, 'eps':     0.6999, 'len': 21829.3660, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  254000, Reward:   226.879 [ 633.755], Avg:   -61.112 (0.600) <0-06:13:20> ({'r_t':  -804.5688, 'eps':     0.5999, 'len': 21895.1850, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  255000, Reward:   386.122 [ 175.869], Avg:   -59.365 (0.500) <0-06:14:44> ({'r_t':   -76.6700, 'eps':     0.4999, 'len': 21944.1260, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  256000, Reward:   204.731 [ 514.839], Avg:   -58.338 (0.400) <0-06:16:14> ({'r_t':   333.6788, 'eps':     0.3999, 'len': 21981.9980, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  257000, Reward:   447.431 [  59.067], Avg:   -56.377 (0.300) <0-06:17:51> ({'r_t':   728.0038, 'eps':     0.2999, 'len': 22015.1020, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  258000, Reward:   277.167 [ 517.391], Avg:   -55.089 (0.200) <0-06:19:36> ({'r_t':   855.8127, 'eps':     0.1999, 'len': 22048.0020, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  259000, Reward:   456.997 [  69.816], Avg:   -53.120 (0.100) <0-06:21:28> ({'r_t':   457.9190, 'eps':     0.0999, 'len': 22082.4280, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  260000, Reward:   327.629 [ 378.433], Avg:   -51.661 (1.000) <0-06:29:57> ({'r_t':   534.3850, 'eps':     0.9999, 'len': 22116.4760, 'dyn_loss':    27.4810, 'dot_loss':     3.0073, 'ddot_loss':     6.8170, 'rew_loss':   307.8230, 'lr':     0.0001, 'eps_e':     0.9999, 'lr_e':     0.0001})
Step:  261000, Reward:   448.514 [  77.884], Avg:   -49.752 (0.900) <0-06:30:56> ({'r_t': -1627.0861, 'eps':     0.8999, 'len': 22185.9490, 'lr':     0.0001, 'eps_e':     0.8999, 'lr_e':     0.0001})
Step:  262000, Reward:   352.674 [ 384.131], Avg:   -48.222 (0.800) <0-06:32:00> ({'r_t': -1404.6196, 'eps':     0.7999, 'len': 22284.4870, 'lr':     0.0001, 'eps_e':     0.7999, 'lr_e':     0.0001})
Step:  263000, Reward:   438.075 [  69.041], Avg:   -46.380 (0.700) <0-06:33:09> ({'r_t': -1172.3900, 'eps':     0.6999, 'len': 22370.5380, 'lr':     0.0001, 'eps_e':     0.6999, 'lr_e':     0.0001})
Step:  264000, Reward:   362.280 [ 366.171], Avg:   -44.838 (0.600) <0-06:34:26> ({'r_t':  -775.9436, 'eps':     0.5999, 'len': 22439.8390, 'lr':     0.0001, 'eps_e':     0.5999, 'lr_e':     0.0001})
Step:  265000, Reward:   352.101 [ 356.667], Avg:   -43.346 (0.500) <0-06:35:49> ({'r_t':   -67.9298, 'eps':     0.4999, 'len': 22492.8770, 'lr':     0.0001, 'eps_e':     0.4999, 'lr_e':     0.0001})
Step:  266000, Reward:   391.732 [ 223.456], Avg:   -41.716 (0.400) <0-06:37:19> ({'r_t':   224.3486, 'eps':     0.3999, 'len': 22531.7940, 'lr':     0.0001, 'eps_e':     0.3999, 'lr_e':     0.0001})
Step:  267000, Reward:   466.750 [  57.894], Avg:   -39.819 (0.300) <0-06:38:57> ({'r_t':   388.0024, 'eps':     0.2999, 'len': 22565.8950, 'lr':     0.0001, 'eps_e':     0.2999, 'lr_e':     0.0001})
Step:  268000, Reward:   158.288 [1090.933], Avg:   -39.082 (0.200) <0-06:40:41> ({'r_t':   834.9336, 'eps':     0.1999, 'len': 22599.6590, 'lr':     0.0001, 'eps_e':     0.1999, 'lr_e':     0.0001})
Step:  269000, Reward:   365.215 [ 349.324], Avg:   -37.585 (0.100) <0-06:42:33> ({'r_t':   654.1621, 'eps':     0.0999, 'len': 22634.1280, 'lr':     0.0001, 'eps_e':     0.0999, 'lr_e':     0.0001})
Step:  270000, Reward:   323.307 [ 369.007], Avg:   -36.253 (1.000) <0-06:51:00> ({'r_t':   805.9706, 'eps':     0.9999, 'len': 22670.4390, 'dyn_loss':    26.8291, 'dot_loss':     2.9270, 'ddot_loss':     6.6491, 'rew_loss':   322.4980, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  271000, Reward:   332.104 [ 378.831], Avg:   -34.899 (0.900) <0-06:51:59> ({'r_t': -1861.7441, 'eps':     0.8999, 'len': 22743.1010, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  272000, Reward:   434.439 [  95.100], Avg:   -33.180 (0.800) <0-06:53:02> ({'r_t': -1572.6456, 'eps':     0.7999, 'len': 22845.5430, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  273000, Reward:   339.649 [ 385.017], Avg:   -31.819 (0.700) <0-06:54:12> ({'r_t': -1159.9534, 'eps':     0.6999, 'len': 22927.1420, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  274000, Reward:   225.341 [ 383.853], Avg:   -30.884 (0.600) <0-06:55:29> ({'r_t':  -801.1302, 'eps':     0.5999, 'len': 23001.4680, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  275000, Reward:   391.893 [ 145.950], Avg:   -29.352 (0.500) <0-06:56:52> ({'r_t':  -207.9088, 'eps':     0.4999, 'len': 23048.4120, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  276000, Reward:   234.609 [ 493.864], Avg:   -28.399 (0.400) <0-06:58:22> ({'r_t':   244.4199, 'eps':     0.3999, 'len': 23085.4040, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  277000, Reward:    93.235 [ 599.432], Avg:   -27.962 (0.300) <0-06:59:59> ({'r_t':   760.2132, 'eps':     0.2999, 'len': 23119.6430, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  278000, Reward:   431.234 [  86.437], Avg:   -26.316 (0.200) <0-07:01:44> ({'r_t':   557.6659, 'eps':     0.1999, 'len': 23153.6640, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  279000, Reward:   407.264 [  97.313], Avg:   -24.767 (0.100) <0-07:03:35> ({'r_t':  1026.2675, 'eps':     0.0999, 'len': 23187.1410, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  280000, Reward:   329.184 [ 733.241], Avg:   -23.508 (1.000) <0-07:12:08> ({'r_t':   690.6184, 'eps':     0.9999, 'len': 23221.0720, 'dyn_loss':    26.4714, 'dot_loss':     2.9399, 'ddot_loss':     6.7043, 'rew_loss':   262.2106, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  281000, Reward:   380.896 [ 377.825], Avg:   -22.074 (0.900) <0-07:13:07> ({'r_t': -1672.5906, 'eps':     0.8999, 'len': 23287.6400, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  282000, Reward:   313.940 [ 496.285], Avg:   -20.886 (0.800) <0-07:14:11> ({'r_t': -1375.8756, 'eps':     0.7999, 'len': 23393.1740, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  283000, Reward:   515.973 [  41.004], Avg:   -18.996 (0.700) <0-07:15:20> ({'r_t': -1263.6683, 'eps':     0.6999, 'len': 23486.7020, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  284000, Reward:   471.200 [ 132.747], Avg:   -17.276 (0.600) <0-07:16:37> ({'r_t':  -717.0910, 'eps':     0.5999, 'len': 23554.9670, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  285000, Reward:   414.867 [ 396.405], Avg:   -15.765 (0.500) <0-07:18:00> ({'r_t':  -163.6010, 'eps':     0.4999, 'len': 23606.7060, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  286000, Reward:   488.102 [  49.864], Avg:   -14.009 (0.400) <0-07:19:30> ({'r_t':   232.5295, 'eps':     0.3999, 'len': 23643.3670, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  287000, Reward:   305.645 [ 491.985], Avg:   -12.899 (0.300) <0-07:21:07> ({'r_t':   538.6486, 'eps':     0.2999, 'len': 23676.1410, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  288000, Reward:   321.634 [ 398.486], Avg:   -11.742 (0.200) <0-07:22:52> ({'r_t':   784.7554, 'eps':     0.1999, 'len': 23708.8040, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  289000, Reward:   518.224 [  42.791], Avg:    -9.914 (0.100) <0-07:24:43> ({'r_t':   872.4226, 'eps':     0.0999, 'len': 23742.1160, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  290000, Reward:   540.963 [  35.501], Avg:    -8.021 (1.000) <0-07:33:28> ({'r_t':   313.0169, 'eps':     0.9999, 'len': 23776.1180, 'dyn_loss':    24.8733, 'dot_loss':     2.8219, 'ddot_loss':     6.4636, 'rew_loss':   262.4459, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  291000, Reward:   257.008 [ 587.815], Avg:    -7.114 (0.900) <0-07:34:27> ({'r_t': -1676.6939, 'eps':     0.8999, 'len': 23839.8980, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  292000, Reward:   464.538 [ 174.601], Avg:    -5.504 (0.800) <0-07:35:31> ({'r_t': -1529.5951, 'eps':     0.7999, 'len': 23939.6390, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  293000, Reward:   279.310 [ 478.524], Avg:    -4.535 (0.700) <0-07:36:40> ({'r_t': -1129.0701, 'eps':     0.6999, 'len': 24026.6870, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  294000, Reward:   309.439 [ 498.453], Avg:    -3.471 (0.600) <0-07:37:57> ({'r_t':  -800.5977, 'eps':     0.5999, 'len': 24095.8140, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  295000, Reward:   468.246 [ 202.839], Avg:    -1.877 (0.500) <0-07:39:20> ({'r_t':   -95.5041, 'eps':     0.4999, 'len': 24143.5460, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  296000, Reward:   511.143 [ 109.921], Avg:    -0.150 (0.400) <0-07:40:50> ({'r_t':   269.8139, 'eps':     0.3999, 'len': 24180.1900, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  297000, Reward:   457.904 [ 146.039], Avg:     1.387 (0.300) <0-07:42:27> ({'r_t':   632.1116, 'eps':     0.2999, 'len': 24215.2000, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  298000, Reward:   532.166 [  81.266], Avg:     3.162 (0.200) <0-07:44:12> ({'r_t':   811.7799, 'eps':     0.1999, 'len': 24249.8380, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  299000, Reward:   494.066 [ 119.345], Avg:     4.799 (0.100) <0-07:46:03> ({'r_t':  1077.5131, 'eps':     0.0999, 'len': 24283.4390, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  300000, Reward:   527.109 [ 176.767], Avg:     6.534 (1.000) <0-07:54:50> ({'r_t':  1043.4990, 'eps':     0.9999, 'len': 24320.3720, 'dyn_loss':    24.3537, 'dot_loss':     2.7672, 'ddot_loss':     6.3355, 'rew_loss':   244.2697, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  301000, Reward:   410.257 [ 503.178], Avg:     7.871 (0.900) <0-07:55:49> ({'r_t': -1710.8613, 'eps':     0.8999, 'len': 24390.6270, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  302000, Reward:   333.465 [ 597.171], Avg:     8.945 (0.800) <0-07:56:52> ({'r_t': -1292.2214, 'eps':     0.7999, 'len': 24491.4240, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  303000, Reward:   356.524 [ 508.391], Avg:    10.089 (0.700) <0-07:58:02> ({'r_t': -1174.4747, 'eps':     0.6999, 'len': 24577.3540, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  304000, Reward:   440.479 [ 347.932], Avg:    11.500 (0.600) <0-07:59:18> ({'r_t':  -721.0832, 'eps':     0.5999, 'len': 24645.8720, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  305000, Reward:   333.946 [ 498.794], Avg:    12.554 (0.500) <0-08:00:41> ({'r_t':   -70.5053, 'eps':     0.4999, 'len': 24694.5900, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  306000, Reward:   244.731 [ 579.606], Avg:    13.310 (0.400) <0-08:02:12> ({'r_t':    67.3507, 'eps':     0.3999, 'len': 24730.6350, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  307000, Reward:   514.506 [ 185.391], Avg:    14.937 (0.300) <0-08:03:49> ({'r_t':   270.7741, 'eps':     0.2999, 'len': 24763.3020, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  308000, Reward:   447.366 [ 260.031], Avg:    16.337 (0.200) <0-08:05:33> ({'r_t':   651.1796, 'eps':     0.1999, 'len': 24795.6440, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  309000, Reward:   469.329 [ 383.723], Avg:    17.798 (0.100) <0-08:07:25> ({'r_t':   817.6335, 'eps':     0.0999, 'len': 24829.3360, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  310000, Reward:   545.383 [ 343.661], Avg:    19.494 (1.000) <0-08:16:17> ({'r_t':  1115.3648, 'eps':     0.9999, 'len': 24864.4610, 'dyn_loss':    24.0789, 'dot_loss':     2.7379, 'ddot_loss':     6.2786, 'rew_loss':   268.1083, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  311000, Reward:   504.517 [ 413.521], Avg:    21.049 (0.900) <0-08:17:15> ({'r_t': -1802.8119, 'eps':     0.8999, 'len': 24932.6300, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  312000, Reward:   158.683 [ 661.985], Avg:    21.488 (0.800) <0-08:18:19> ({'r_t': -2082.9200, 'eps':     0.7999, 'len': 25032.5840, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  313000, Reward:   548.781 [ 402.116], Avg:    23.168 (0.700) <0-08:19:29> ({'r_t': -1153.9755, 'eps':     0.6999, 'len': 25120.9210, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  314000, Reward:   439.123 [ 475.834], Avg:    24.488 (0.600) <0-08:20:45> ({'r_t':  -585.6568, 'eps':     0.5999, 'len': 25189.4940, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  315000, Reward:   523.596 [ 358.725], Avg:    26.068 (0.500) <0-08:22:08> ({'r_t':   -99.1250, 'eps':     0.4999, 'len': 25233.3850, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  316000, Reward:   276.179 [ 646.880], Avg:    26.857 (0.400) <0-08:23:38> ({'r_t':   397.3045, 'eps':     0.3999, 'len': 25268.2710, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  317000, Reward:   454.963 [ 504.909], Avg:    28.203 (0.300) <0-08:25:16> ({'r_t':   659.9690, 'eps':     0.2999, 'len': 25301.5590, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  318000, Reward:   427.392 [ 545.687], Avg:    29.454 (0.200) <0-08:27:00> ({'r_t':   879.9812, 'eps':     0.1999, 'len': 25334.2410, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  319000, Reward:   678.520 [  48.247], Avg:    31.483 (0.100) <0-08:28:52> ({'r_t':  1189.4041, 'eps':     0.0999, 'len': 25366.6910, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  320000, Reward:   429.693 [ 364.309], Avg:    32.723 (1.000) <0-08:37:51> ({'r_t':  1051.0891, 'eps':     0.9999, 'len': 25401.6420, 'dyn_loss':    24.4895, 'dot_loss':     2.7224, 'ddot_loss':     6.2444, 'rew_loss':   246.5585, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  321000, Reward:   106.538 [ 672.508], Avg:    32.952 (0.900) <0-08:38:49> ({'r_t': -1938.2557, 'eps':     0.8999, 'len': 25463.1250, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  322000, Reward:   439.075 [ 486.203], Avg:    34.210 (0.800) <0-08:39:53> ({'r_t': -1506.7338, 'eps':     0.7999, 'len': 25557.1430, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  323000, Reward:   228.696 [ 506.430], Avg:    34.810 (0.700) <0-08:41:03> ({'r_t': -1180.4508, 'eps':     0.6999, 'len': 25642.6820, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  324000, Reward:   440.424 [ 434.406], Avg:    36.058 (0.600) <0-08:42:19> ({'r_t':  -681.0483, 'eps':     0.5999, 'len': 25706.0660, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  325000, Reward:   463.468 [ 381.191], Avg:    37.369 (0.500) <0-08:43:43> ({'r_t':  -165.4572, 'eps':     0.4999, 'len': 25756.0250, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  326000, Reward:   263.494 [ 601.431], Avg:    38.061 (0.400) <0-08:45:13> ({'r_t':   287.5493, 'eps':     0.3999, 'len': 25792.3180, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  327000, Reward:   445.643 [ 407.771], Avg:    39.303 (0.300) <0-08:46:50> ({'r_t':   524.0786, 'eps':     0.2999, 'len': 25825.3120, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  328000, Reward:   522.137 [ 366.484], Avg:    40.771 (0.200) <0-08:48:35> ({'r_t':   600.2707, 'eps':     0.1999, 'len': 25859.3870, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  329000, Reward:   477.688 [ 370.336], Avg:    42.095 (0.100) <0-08:50:26> ({'r_t':   818.5115, 'eps':     0.0999, 'len': 25895.3640, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  330000, Reward:   559.326 [ 174.708], Avg:    43.658 (1.000) <0-08:59:37> ({'r_t':  1079.5596, 'eps':     0.9999, 'len': 25931.7770, 'dyn_loss':    24.3116, 'dot_loss':     2.6903, 'ddot_loss':     6.1594, 'rew_loss':   259.2026, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  331000, Reward:   628.390 [ 387.435], Avg:    45.419 (0.900) <0-09:00:36> ({'r_t': -1834.5539, 'eps':     0.8999, 'len': 25998.6520, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  332000, Reward:   639.100 [ 165.116], Avg:    47.202 (0.800) <0-09:01:40> ({'r_t': -1623.5690, 'eps':     0.7999, 'len': 26094.5400, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  333000, Reward:   529.842 [ 487.069], Avg:    48.647 (0.700) <0-09:02:49> ({'r_t': -1302.1057, 'eps':     0.6999, 'len': 26178.8850, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  334000, Reward:   678.796 [ 186.398], Avg:    50.528 (0.600) <0-09:04:06> ({'r_t':  -831.5628, 'eps':     0.5999, 'len': 26245.2720, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  335000, Reward:   602.096 [ 208.896], Avg:    52.169 (0.500) <0-09:05:29> ({'r_t':  -258.6547, 'eps':     0.4999, 'len': 26298.3190, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  336000, Reward:   592.277 [ 220.303], Avg:    53.772 (0.400) <0-09:06:59> ({'r_t':    66.7218, 'eps':     0.3999, 'len': 26338.6010, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  337000, Reward:   634.898 [ 110.351], Avg:    55.491 (0.300) <0-09:08:37> ({'r_t':   589.5345, 'eps':     0.2999, 'len': 26371.1190, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  338000, Reward:   667.194 [ 160.125], Avg:    57.296 (0.200) <0-09:10:21> ({'r_t':  1108.4281, 'eps':     0.1999, 'len': 26403.4190, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  339000, Reward:   706.026 [  68.921], Avg:    59.204 (0.100) <0-09:12:13> ({'r_t':  1140.1288, 'eps':     0.0999, 'len': 26435.8080, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  340000, Reward:   588.714 [ 273.377], Avg:    60.757 (1.000) <0-09:21:19> ({'r_t':  1203.6945, 'eps':     0.9999, 'len': 26469.3060, 'dyn_loss':    23.8405, 'dot_loss':     2.6683, 'ddot_loss':     6.1078, 'rew_loss':   233.9071, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  341000, Reward:   564.473 [ 382.911], Avg:    62.229 (0.900) <0-09:22:18> ({'r_t': -1445.9811, 'eps':     0.8999, 'len': 26532.6750, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  342000, Reward:   540.546 [ 394.049], Avg:    63.624 (0.800) <0-09:23:21> ({'r_t': -1304.7119, 'eps':     0.7999, 'len': 26637.7570, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  343000, Reward:   491.720 [ 483.593], Avg:    64.868 (0.700) <0-09:24:31> ({'r_t': -1100.8718, 'eps':     0.6999, 'len': 26726.7050, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  344000, Reward:   631.919 [ 118.124], Avg:    66.512 (0.600) <0-09:25:47> ({'r_t':  -715.7806, 'eps':     0.5999, 'len': 26793.7450, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  345000, Reward:   642.507 [ 183.411], Avg:    68.177 (0.500) <0-09:27:11> ({'r_t':  -210.7822, 'eps':     0.4999, 'len': 26839.6390, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  346000, Reward:   333.230 [ 584.673], Avg:    68.941 (0.400) <0-09:28:41> ({'r_t':    93.1424, 'eps':     0.3999, 'len': 26876.4900, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  347000, Reward:   471.765 [ 560.485], Avg:    70.098 (0.300) <0-09:30:18> ({'r_t':   696.3887, 'eps':     0.2999, 'len': 26910.5790, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  348000, Reward:   519.992 [ 409.781], Avg:    71.387 (0.200) <0-09:32:02> ({'r_t':   973.5159, 'eps':     0.1999, 'len': 26942.8030, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  349000, Reward:   661.984 [ 159.630], Avg:    73.075 (0.100) <0-09:33:53> ({'r_t':  1112.4693, 'eps':     0.0999, 'len': 26976.3800, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  350000, Reward:   435.128 [ 485.864], Avg:    74.106 (1.000) <0-09:43:01> ({'r_t':  1159.7480, 'eps':     0.9999, 'len': 27009.2450, 'dyn_loss':    22.5657, 'dot_loss':     2.6056, 'ddot_loss':     5.9907, 'rew_loss':   235.4902, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  351000, Reward:   488.339 [ 421.322], Avg:    75.283 (0.900) <0-09:43:59> ({'r_t': -1623.6675, 'eps':     0.8999, 'len': 27071.3980, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  352000, Reward:   618.579 [ 166.229], Avg:    76.822 (0.800) <0-09:45:03> ({'r_t': -1595.3429, 'eps':     0.7999, 'len': 27174.5980, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  353000, Reward:   464.392 [ 497.778], Avg:    77.917 (0.700) <0-09:46:13> ({'r_t': -1133.7829, 'eps':     0.6999, 'len': 27260.8000, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  354000, Reward:   436.819 [ 488.022], Avg:    78.928 (0.600) <0-09:47:29> ({'r_t':  -747.7649, 'eps':     0.5999, 'len': 27330.3100, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  355000, Reward:   535.599 [ 371.746], Avg:    80.211 (0.500) <0-09:48:52> ({'r_t':  -193.3549, 'eps':     0.4999, 'len': 27381.5880, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  356000, Reward:   558.025 [ 367.879], Avg:    81.549 (0.400) <0-09:50:22> ({'r_t':   326.5720, 'eps':     0.3999, 'len': 27421.1950, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  357000, Reward:   473.909 [ 471.086], Avg:    82.645 (0.300) <0-09:52:00> ({'r_t':   566.2646, 'eps':     0.2999, 'len': 27453.6900, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  358000, Reward:   534.094 [ 379.552], Avg:    83.902 (0.200) <0-09:53:44> ({'r_t':   879.2999, 'eps':     0.1999, 'len': 27486.1810, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  359000, Reward:   615.332 [ 372.522], Avg:    85.379 (0.100) <0-09:55:36> ({'r_t':  1164.2456, 'eps':     0.0999, 'len': 27519.4230, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  360000, Reward:   639.721 [  95.908], Avg:    86.914 (1.000) <0-10:04:54> ({'r_t':  1361.8173, 'eps':     0.9999, 'len': 27553.8580, 'dyn_loss':    22.7076, 'dot_loss':     2.5856, 'ddot_loss':     5.9517, 'rew_loss':   240.3220, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  361000, Reward:   599.030 [ 186.447], Avg:    88.329 (0.900) <0-10:05:52> ({'r_t': -2173.8690, 'eps':     0.8999, 'len': 27620.8890, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  362000, Reward:   508.472 [ 497.718], Avg:    89.486 (0.800) <0-10:06:56> ({'r_t': -1466.5307, 'eps':     0.7999, 'len': 27727.7280, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  363000, Reward:   657.340 [ 113.433], Avg:    91.046 (0.700) <0-10:08:06> ({'r_t': -1181.8244, 'eps':     0.6999, 'len': 27817.2640, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  364000, Reward:   461.858 [ 529.566], Avg:    92.062 (0.600) <0-10:09:22> ({'r_t':  -793.6995, 'eps':     0.5999, 'len': 27886.0640, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  365000, Reward:   649.159 [  96.527], Avg:    93.584 (0.500) <0-10:10:45> ({'r_t':  -445.6206, 'eps':     0.4999, 'len': 27930.9500, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  366000, Reward:   654.533 [  84.169], Avg:    95.113 (0.400) <0-10:12:16> ({'r_t':    17.3249, 'eps':     0.3999, 'len': 27967.4400, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  367000, Reward:   620.176 [ 214.526], Avg:    96.540 (0.300) <0-10:13:53> ({'r_t':   535.5125, 'eps':     0.2999, 'len': 28000.2980, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  368000, Reward:   577.641 [ 364.370], Avg:    97.843 (0.200) <0-10:15:37> ({'r_t':   737.3474, 'eps':     0.1999, 'len': 28033.8530, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  369000, Reward:   559.264 [ 198.185], Avg:    99.091 (0.100) <0-10:17:28> ({'r_t':  1233.4579, 'eps':     0.0999, 'len': 28066.5480, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  370000, Reward:   580.983 [ 395.203], Avg:   100.389 (1.000) <0-10:26:49> ({'r_t':  1422.9271, 'eps':     0.9999, 'len': 28099.2190, 'dyn_loss':    22.3521, 'dot_loss':     2.5238, 'ddot_loss':     5.7967, 'rew_loss':   211.8140, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  371000, Reward:   543.411 [ 342.294], Avg:   101.580 (0.900) <0-10:27:48> ({'r_t': -1753.6434, 'eps':     0.8999, 'len': 28164.8700, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  372000, Reward:   541.517 [ 568.998], Avg:   102.760 (0.800) <0-10:28:51> ({'r_t': -1260.7626, 'eps':     0.7999, 'len': 28270.0360, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  373000, Reward:   629.365 [ 205.260], Avg:   104.168 (0.700) <0-10:30:01> ({'r_t': -1120.7290, 'eps':     0.6999, 'len': 28349.5590, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  374000, Reward:   570.973 [ 363.110], Avg:   105.413 (0.600) <0-10:31:17> ({'r_t':  -722.0511, 'eps':     0.5999, 'len': 28414.1160, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  375000, Reward:   591.439 [ 422.077], Avg:   106.705 (0.500) <0-10:32:40> ({'r_t':  -301.9230, 'eps':     0.4999, 'len': 28464.8950, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  376000, Reward:   671.657 [ 107.669], Avg:   108.204 (0.400) <0-10:34:10> ({'r_t':   323.1488, 'eps':     0.3999, 'len': 28501.2660, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  377000, Reward:   617.931 [ 135.371], Avg:   109.552 (0.300) <0-10:35:47> ({'r_t':   573.4412, 'eps':     0.2999, 'len': 28533.5920, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  378000, Reward:   550.837 [ 374.927], Avg:   110.717 (0.200) <0-10:37:32> ({'r_t':   761.9204, 'eps':     0.1999, 'len': 28565.7780, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  379000, Reward:   455.508 [ 480.518], Avg:   111.624 (0.100) <0-10:39:23> ({'r_t':  1301.6425, 'eps':     0.0999, 'len': 28598.4760, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  380000, Reward:   689.874 [ 125.565], Avg:   113.142 (1.000) <0-10:48:56> ({'r_t':  1026.7949, 'eps':     0.9999, 'len': 28632.0350, 'dyn_loss':    22.3453, 'dot_loss':     2.5412, 'ddot_loss':     5.8540, 'rew_loss':   214.8544, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  381000, Reward:   650.340 [ 343.773], Avg:   114.548 (0.900) <0-10:49:54> ({'r_t': -1858.9640, 'eps':     0.8999, 'len': 28695.6000, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  382000, Reward:   757.301 [  70.663], Avg:   116.226 (0.800) <0-10:50:58> ({'r_t': -1537.3657, 'eps':     0.7999, 'len': 28800.6600, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  383000, Reward:   739.122 [ 198.429], Avg:   117.848 (0.700) <0-10:52:08> ({'r_t': -1111.0090, 'eps':     0.6999, 'len': 28892.0440, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  384000, Reward:   639.951 [ 200.907], Avg:   119.204 (0.600) <0-10:53:24> ({'r_t':  -785.1160, 'eps':     0.5999, 'len': 28958.4430, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  385000, Reward:   676.924 [ 127.392], Avg:   120.649 (0.500) <0-10:54:47> ({'r_t':  -136.1981, 'eps':     0.4999, 'len': 29005.4990, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  386000, Reward:   708.816 [  90.795], Avg:   122.169 (0.400) <0-10:56:17> ({'r_t':   181.5131, 'eps':     0.3999, 'len': 29042.1430, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  387000, Reward:   703.082 [  65.330], Avg:   123.666 (0.300) <0-10:57:55> ({'r_t':   687.7968, 'eps':     0.2999, 'len': 29076.2160, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  388000, Reward:   715.312 [  99.698], Avg:   125.187 (0.200) <0-10:59:39> ({'r_t':   911.4535, 'eps':     0.1999, 'len': 29109.5420, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  389000, Reward:   691.242 [  97.857], Avg:   126.639 (0.100) <0-11:01:31> ({'r_t':  1174.4776, 'eps':     0.0999, 'len': 29141.6180, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  390000, Reward:   619.573 [ 290.752], Avg:   127.899 (1.000) <0-11:10:59> ({'r_t':  1296.9046, 'eps':     0.9999, 'len': 29174.6710, 'dyn_loss':    21.5951, 'dot_loss':     2.4950, 'ddot_loss':     5.7549, 'rew_loss':   233.9699, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  391000, Reward:   661.462 [ 108.558], Avg:   129.261 (0.900) <0-11:11:58> ({'r_t': -1611.2045, 'eps':     0.8999, 'len': 29241.0990, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  392000, Reward:   666.252 [ 172.154], Avg:   130.627 (0.800) <0-11:13:01> ({'r_t': -1255.8355, 'eps':     0.7999, 'len': 29339.2240, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  393000, Reward:   492.037 [ 531.249], Avg:   131.544 (0.700) <0-11:14:11> ({'r_t': -1143.6740, 'eps':     0.6999, 'len': 29425.0810, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  394000, Reward:   733.310 [  90.996], Avg:   133.068 (0.600) <0-11:15:27> ({'r_t':  -931.7371, 'eps':     0.5999, 'len': 29483.8140, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  395000, Reward:   685.348 [  74.968], Avg:   134.462 (0.500) <0-11:16:50> ({'r_t':  -211.2257, 'eps':     0.4999, 'len': 29526.5790, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  396000, Reward:   670.438 [  97.340], Avg:   135.812 (0.400) <0-11:18:21> ({'r_t':   298.8717, 'eps':     0.3999, 'len': 29562.4390, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  397000, Reward:   628.464 [ 213.127], Avg:   137.050 (0.300) <0-11:19:58> ({'r_t':   514.0806, 'eps':     0.2999, 'len': 29595.2560, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  398000, Reward:   611.973 [ 211.286], Avg:   138.240 (0.200) <0-11:21:42> ({'r_t':  1044.1220, 'eps':     0.1999, 'len': 29627.4590, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  399000, Reward:   560.169 [ 361.902], Avg:   139.295 (0.100) <0-11:23:34> ({'r_t':  1058.7724, 'eps':     0.0999, 'len': 29659.7910, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  400000, Reward:   603.803 [ 224.924], Avg:   140.454 (1.000) <0-11:33:13> ({'r_t':  1315.4164, 'eps':     0.9999, 'len': 29692.9460, 'dyn_loss':    21.5898, 'dot_loss':     2.4817, 'ddot_loss':     5.7196, 'rew_loss':   230.8585, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  401000, Reward:   463.180 [ 432.515], Avg:   141.256 (0.900) <0-11:34:11> ({'r_t': -1589.1666, 'eps':     0.8999, 'len': 29756.3030, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  402000, Reward:   552.825 [ 397.901], Avg:   142.278 (0.800) <0-11:35:15> ({'r_t': -1328.1583, 'eps':     0.7999, 'len': 29861.1900, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  403000, Reward:   664.424 [ 112.223], Avg:   143.570 (0.700) <0-11:36:24> ({'r_t': -1175.2293, 'eps':     0.6999, 'len': 29952.3390, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  404000, Reward:   607.702 [ 111.413], Avg:   144.716 (0.600) <0-11:37:41> ({'r_t':  -869.4825, 'eps':     0.5999, 'len': 30021.6830, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  405000, Reward:   583.793 [ 342.317], Avg:   145.798 (0.500) <0-11:39:04> ({'r_t':  -272.9199, 'eps':     0.4999, 'len': 30073.4540, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  406000, Reward:   684.569 [ 119.792], Avg:   147.121 (0.400) <0-11:40:34> ({'r_t':   277.8161, 'eps':     0.3999, 'len': 30111.3790, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  407000, Reward:   587.383 [ 278.157], Avg:   148.201 (0.300) <0-11:42:11> ({'r_t':   500.6117, 'eps':     0.2999, 'len': 30144.1290, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  408000, Reward:   609.141 [ 209.654], Avg:   149.328 (0.200) <0-11:43:56> ({'r_t':  1035.8543, 'eps':     0.1999, 'len': 30177.0580, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  409000, Reward:   621.083 [ 318.993], Avg:   150.478 (0.100) <0-11:45:47> ({'r_t':  1273.6571, 'eps':     0.0999, 'len': 30209.9210, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  410000, Reward:   527.037 [ 414.756], Avg:   151.394 (1.000) <0-11:55:21> ({'r_t':  1312.0394, 'eps':     0.9999, 'len': 30243.2520, 'dyn_loss':    21.3744, 'dot_loss':     2.4695, 'ddot_loss':     5.6936, 'rew_loss':   196.3318, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  411000, Reward:   710.543 [  61.756], Avg:   152.751 (0.900) <0-11:56:20> ({'r_t': -1572.8956, 'eps':     0.8999, 'len': 30308.3680, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  412000, Reward:   612.363 [ 340.337], Avg:   153.864 (0.800) <0-11:57:24> ({'r_t': -1496.8954, 'eps':     0.7999, 'len': 30413.7900, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  413000, Reward:   546.096 [ 275.362], Avg:   154.812 (0.700) <0-11:58:33> ({'r_t': -1131.0652, 'eps':     0.6999, 'len': 30496.1130, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  414000, Reward:   614.982 [ 127.432], Avg:   155.921 (0.600) <0-11:59:50> ({'r_t':  -885.6021, 'eps':     0.5999, 'len': 30558.1120, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  415000, Reward:   407.702 [ 532.704], Avg:   156.526 (0.500) <0-12:01:13> ({'r_t':  -334.0136, 'eps':     0.4999, 'len': 30610.2060, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  416000, Reward:   579.825 [ 216.123], Avg:   157.541 (0.400) <0-12:02:43> ({'r_t':   269.2591, 'eps':     0.3999, 'len': 30648.5030, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  417000, Reward:   529.342 [ 376.817], Avg:   158.430 (0.300) <0-12:04:20> ({'r_t':   588.8954, 'eps':     0.2999, 'len': 30680.9930, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  418000, Reward:   651.525 [ 130.444], Avg:   159.607 (0.200) <0-12:06:04> ({'r_t':   994.9695, 'eps':     0.1999, 'len': 30713.4350, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  419000, Reward:   451.770 [ 514.989], Avg:   160.303 (0.100) <0-12:07:55> ({'r_t':  1148.4742, 'eps':     0.0999, 'len': 30746.2730, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  420000, Reward:   646.862 [ 157.864], Avg:   161.459 (1.000) <0-12:17:32> ({'r_t':  1341.1013, 'eps':     0.9999, 'len': 30779.1040, 'dyn_loss':    21.0418, 'dot_loss':     2.4400, 'ddot_loss':     5.6232, 'rew_loss':   205.1496, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  421000, Reward:   611.216 [ 191.576], Avg:   162.524 (0.900) <0-12:18:31> ({'r_t': -1874.2568, 'eps':     0.8999, 'len': 30848.1430, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  422000, Reward:   613.623 [ 109.367], Avg:   163.591 (0.800) <0-12:19:34> ({'r_t': -1376.4104, 'eps':     0.7999, 'len': 30946.5010, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  423000, Reward:   684.794 [ 143.934], Avg:   164.820 (0.700) <0-12:20:44> ({'r_t': -1140.5866, 'eps':     0.6999, 'len': 31037.4420, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  424000, Reward:   682.153 [ 104.753], Avg:   166.037 (0.600) <0-12:22:00> ({'r_t':  -862.6619, 'eps':     0.5999, 'len': 31102.8060, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  425000, Reward:   683.247 [ 100.772], Avg:   167.251 (0.500) <0-12:23:23> ({'r_t':  -216.4628, 'eps':     0.4999, 'len': 31150.5170, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  426000, Reward:   546.817 [ 404.251], Avg:   168.140 (0.400) <0-12:24:53> ({'r_t':   263.1325, 'eps':     0.3999, 'len': 31186.5670, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  427000, Reward:   638.215 [  87.538], Avg:   169.239 (0.300) <0-12:26:31> ({'r_t':   472.4280, 'eps':     0.2999, 'len': 31219.0220, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  428000, Reward:   454.444 [ 427.042], Avg:   169.903 (0.200) <0-12:28:15> ({'r_t':   824.6075, 'eps':     0.1999, 'len': 31251.1060, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  429000, Reward:   597.363 [ 213.538], Avg:   170.898 (0.100) <0-12:30:06> ({'r_t':  1164.5436, 'eps':     0.0999, 'len': 31283.6970, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  430000, Reward:   430.592 [ 564.993], Avg:   171.500 (1.000) <0-12:39:54> ({'r_t':  1448.9626, 'eps':     0.9999, 'len': 31315.9540, 'dyn_loss':    20.6549, 'dot_loss':     2.4032, 'ddot_loss':     5.5509, 'rew_loss':   203.7764, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  431000, Reward:   635.113 [ 124.005], Avg:   172.573 (0.900) <0-12:40:53> ({'r_t': -1698.8168, 'eps':     0.8999, 'len': 31385.7820, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  432000, Reward:   485.273 [ 412.149], Avg:   173.295 (0.800) <0-12:41:56> ({'r_t': -1383.3020, 'eps':     0.7999, 'len': 31484.9130, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  433000, Reward:   146.563 [ 728.204], Avg:   173.234 (0.700) <0-12:43:06> ({'r_t': -1135.4154, 'eps':     0.6999, 'len': 31572.7110, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  434000, Reward:   435.523 [ 786.703], Avg:   173.837 (0.600) <0-12:44:22> ({'r_t':  -698.5322, 'eps':     0.5999, 'len': 31637.9310, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  435000, Reward:   476.391 [ 404.335], Avg:   174.531 (0.500) <0-12:45:45> ({'r_t':  -222.3370, 'eps':     0.4999, 'len': 31689.8140, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  436000, Reward:   380.349 [ 592.571], Avg:   175.002 (0.400) <0-12:47:15> ({'r_t':   173.0261, 'eps':     0.3999, 'len': 31725.5620, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  437000, Reward:   453.955 [ 517.201], Avg:   175.639 (0.300) <0-12:48:53> ({'r_t':   510.7826, 'eps':     0.2999, 'len': 31758.0020, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  438000, Reward:   468.115 [ 532.087], Avg:   176.305 (0.200) <0-12:50:37> ({'r_t':   758.6183, 'eps':     0.1999, 'len': 31790.1890, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  439000, Reward:   594.253 [ 381.300], Avg:   177.255 (0.100) <0-12:52:29> ({'r_t':   824.3188, 'eps':     0.0999, 'len': 31823.2430, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  440000, Reward:   693.224 [ 101.212], Avg:   178.425 (1.000) <0-13:02:24> ({'r_t':   574.6915, 'eps':     0.9999, 'len': 31855.9550, 'dyn_loss':    20.9823, 'dot_loss':     2.4053, 'ddot_loss':     5.5427, 'rew_loss':   211.9607, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  441000, Reward:   558.498 [ 262.882], Avg:   179.285 (0.900) <0-13:03:22> ({'r_t': -1576.6948, 'eps':     0.8999, 'len': 31914.1610, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  442000, Reward:   501.270 [ 271.242], Avg:   180.011 (0.800) <0-13:04:26> ({'r_t': -1534.2721, 'eps':     0.7999, 'len': 32010.5750, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  443000, Reward:   590.255 [ 164.365], Avg:   180.935 (0.700) <0-13:05:35> ({'r_t': -1147.4526, 'eps':     0.6999, 'len': 32093.2090, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  444000, Reward:   605.974 [ 379.576], Avg:   181.891 (0.600) <0-13:06:52> ({'r_t':  -818.1657, 'eps':     0.5999, 'len': 32160.2240, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  445000, Reward:   548.648 [ 213.135], Avg:   182.713 (0.500) <0-13:08:15> ({'r_t':  -343.8709, 'eps':     0.4999, 'len': 32212.8120, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  446000, Reward:   624.350 [ 137.483], Avg:   183.701 (0.400) <0-13:09:45> ({'r_t':   153.6900, 'eps':     0.3999, 'len': 32248.6730, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  447000, Reward:   502.569 [ 362.613], Avg:   184.413 (0.300) <0-13:11:22> ({'r_t':   477.2911, 'eps':     0.2999, 'len': 32282.8220, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  448000, Reward:   590.333 [ 187.298], Avg:   185.317 (0.200) <0-13:13:07> ({'r_t':   962.9595, 'eps':     0.1999, 'len': 32315.7710, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  449000, Reward:   707.881 [ 102.676], Avg:   186.478 (0.100) <0-13:14:58> ({'r_t':  1061.6149, 'eps':     0.0999, 'len': 32348.0690, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  450000, Reward:   669.353 [ 105.789], Avg:   187.549 (1.000) <0-13:24:51> ({'r_t':  1076.3351, 'eps':     0.9999, 'len': 32381.2820, 'dyn_loss':    20.7637, 'dot_loss':     2.4082, 'ddot_loss':     5.5657, 'rew_loss':   197.2321, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  451000, Reward:   345.290 [ 581.275], Avg:   187.898 (0.900) <0-13:25:49> ({'r_t': -2124.2966, 'eps':     0.8999, 'len': 32448.9090, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  452000, Reward:   685.224 [ 130.440], Avg:   188.995 (0.800) <0-13:26:53> ({'r_t': -1310.8815, 'eps':     0.7999, 'len': 32545.3680, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  453000, Reward:   566.553 [ 377.038], Avg:   189.827 (0.700) <0-13:28:03> ({'r_t': -1155.2725, 'eps':     0.6999, 'len': 32631.4080, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  454000, Reward:   496.273 [ 418.465], Avg:   190.501 (0.600) <0-13:29:19> ({'r_t':  -794.9993, 'eps':     0.5999, 'len': 32687.2570, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  455000, Reward:   579.689 [ 373.278], Avg:   191.354 (0.500) <0-13:30:42> ({'r_t':  -215.1089, 'eps':     0.4999, 'len': 32737.2770, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  456000, Reward:   539.235 [ 245.454], Avg:   192.115 (0.400) <0-13:32:12> ({'r_t':   202.0871, 'eps':     0.3999, 'len': 32772.2910, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  457000, Reward:   641.889 [  91.098], Avg:   193.097 (0.300) <0-13:33:50> ({'r_t':   556.1815, 'eps':     0.2999, 'len': 32805.2240, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  458000, Reward:   557.905 [ 382.411], Avg:   193.892 (0.200) <0-13:35:34> ({'r_t':   692.1702, 'eps':     0.1999, 'len': 32838.5830, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  459000, Reward:   560.351 [ 368.925], Avg:   194.689 (0.100) <0-13:37:26> ({'r_t':  1151.0599, 'eps':     0.0999, 'len': 32870.8520, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  460000, Reward:   531.728 [ 380.760], Avg:   195.420 (1.000) <0-13:47:26> ({'r_t':  1140.0497, 'eps':     0.9999, 'len': 32903.8930, 'dyn_loss':    20.0851, 'dot_loss':     2.3711, 'ddot_loss':     5.4950, 'rew_loss':   221.0894, 'lr':   8.00e-05, 'eps_e':     0.9999, 'lr_e':   8.00e-05})
Step:  461000, Reward:   454.269 [ 503.694], Avg:   195.980 (0.900) <0-13:48:24> ({'r_t': -1740.6133, 'eps':     0.8999, 'len': 32967.8720, 'lr':   8.00e-05, 'eps_e':     0.8999, 'lr_e':   8.00e-05})
Step:  462000, Reward:   570.722 [ 335.212], Avg:   196.790 (0.800) <0-13:49:28> ({'r_t': -1448.4779, 'eps':     0.7999, 'len': 33072.6520, 'lr':   8.00e-05, 'eps_e':     0.7999, 'lr_e':   8.00e-05})
Step:  463000, Reward:   677.146 [  81.215], Avg:   197.825 (0.700) <0-13:50:38> ({'r_t': -1126.0583, 'eps':     0.6999, 'len': 33163.3080, 'lr':   8.00e-05, 'eps_e':     0.6999, 'lr_e':   8.00e-05})
Step:  464000, Reward:   633.420 [ 214.015], Avg:   198.762 (0.600) <0-13:51:54> ({'r_t':  -787.7559, 'eps':     0.5999, 'len': 33226.8250, 'lr':   8.00e-05, 'eps_e':     0.5999, 'lr_e':   8.00e-05})
Step:  465000, Reward:   672.068 [  67.244], Avg:   199.777 (0.500) <0-13:53:17> ({'r_t':  -317.9427, 'eps':     0.4999, 'len': 33275.8160, 'lr':   8.00e-05, 'eps_e':     0.4999, 'lr_e':   8.00e-05})
Step:  466000, Reward:   635.801 [ 155.752], Avg:   200.711 (0.400) <0-13:54:48> ({'r_t':   196.3687, 'eps':     0.3999, 'len': 33313.4960, 'lr':   8.00e-05, 'eps_e':     0.3999, 'lr_e':   8.00e-05})
Step:  467000, Reward:   628.431 [ 151.314], Avg:   201.625 (0.300) <0-13:56:25> ({'r_t':   666.3654, 'eps':     0.2999, 'len': 33346.7610, 'lr':   8.00e-05, 'eps_e':     0.2999, 'lr_e':   8.00e-05})
Step:  468000, Reward:   525.005 [ 435.426], Avg:   202.314 (0.200) <0-13:58:10> ({'r_t':   796.4822, 'eps':     0.1999, 'len': 33379.3100, 'lr':   8.00e-05, 'eps_e':     0.1999, 'lr_e':   8.00e-05})
Step:  469000, Reward:   678.178 [ 107.755], Avg:   203.327 (0.100) <0-14:00:01> ({'r_t':  1100.1661, 'eps':     0.0999, 'len': 33411.6610, 'lr':   8.00e-05, 'eps_e':     0.0999, 'lr_e':   8.00e-05})
Step:  470000, Reward:   613.943 [ 242.548], Avg:   204.199 (1.000) <0-14:10:00> ({'r_t':  1237.6780, 'eps':     0.9999, 'len': 33445.1800, 'dyn_loss':    20.3660, 'dot_loss':     2.3744, 'ddot_loss':     5.4994, 'rew_loss':   222.2339, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  471000, Reward:   530.154 [ 366.189], Avg:   204.889 (0.900) <0-14:10:59> ({'r_t': -2641.0732, 'eps':     0.8999, 'len': 33507.8480, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  472000, Reward:   670.663 [  62.383], Avg:   205.874 (0.800) <0-14:12:03> ({'r_t': -1348.2295, 'eps':     0.7999, 'len': 33608.9250, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  473000, Reward:   639.352 [ 112.755], Avg:   206.788 (0.700) <0-14:13:12> ({'r_t': -1157.3874, 'eps':     0.6999, 'len': 33700.2360, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  474000, Reward:   663.698 [  64.369], Avg:   207.750 (0.600) <0-14:14:29> ({'r_t':  -766.0083, 'eps':     0.5999, 'len': 33761.1470, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  475000, Reward:   584.956 [ 191.938], Avg:   208.543 (0.500) <0-14:15:52> ({'r_t':  -270.2301, 'eps':     0.4999, 'len': 33806.8750, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  476000, Reward:   646.926 [ 100.934], Avg:   209.462 (0.400) <0-14:17:23> ({'r_t':   141.8652, 'eps':     0.3999, 'len': 33842.2250, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  477000, Reward:   664.157 [  87.031], Avg:   210.413 (0.300) <0-14:19:00> ({'r_t':   582.5353, 'eps':     0.2999, 'len': 33875.2660, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  478000, Reward:   577.745 [ 170.934], Avg:   211.180 (0.200) <0-14:20:45> ({'r_t':   926.3643, 'eps':     0.1999, 'len': 33907.4810, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  479000, Reward:   589.854 [ 266.607], Avg:   211.969 (0.100) <0-14:22:37> ({'r_t':  1151.7662, 'eps':     0.0999, 'len': 33940.1620, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  480000, Reward:   579.285 [ 373.768], Avg:   212.733 (1.000) <0-14:32:44> ({'r_t':  1322.1879, 'eps':     0.9999, 'len': 33972.6390, 'dyn_loss':    19.6325, 'dot_loss':     2.3280, 'ddot_loss':     5.4014, 'rew_loss':   192.6517, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  481000, Reward:   514.015 [ 275.884], Avg:   213.358 (0.900) <0-14:33:43> ({'r_t': -2080.6259, 'eps':     0.8999, 'len': 34033.7820, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  482000, Reward:   637.987 [  56.200], Avg:   214.237 (0.800) <0-14:34:46> ({'r_t': -1844.3867, 'eps':     0.7999, 'len': 34135.7980, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  483000, Reward:   566.958 [ 359.073], Avg:   214.965 (0.700) <0-14:35:56> ({'r_t': -1166.1818, 'eps':     0.6999, 'len': 34222.9040, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  484000, Reward:   564.287 [ 387.395], Avg:   215.686 (0.600) <0-14:37:13> ({'r_t':  -845.1281, 'eps':     0.5999, 'len': 34283.1700, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  485000, Reward:   416.343 [ 819.303], Avg:   216.099 (0.500) <0-14:38:36> ({'r_t':  -197.3841, 'eps':     0.4999, 'len': 34333.2650, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  486000, Reward:   563.012 [ 240.810], Avg:   216.811 (0.400) <0-14:40:06> ({'r_t':   291.5253, 'eps':     0.3999, 'len': 34369.6950, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  487000, Reward:   627.927 [ 111.463], Avg:   217.653 (0.300) <0-14:41:44> ({'r_t':   585.2909, 'eps':     0.2999, 'len': 34402.7720, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  488000, Reward:   309.715 [ 583.060], Avg:   217.842 (0.200) <0-14:43:29> ({'r_t':   997.4055, 'eps':     0.1999, 'len': 34435.5540, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  489000, Reward:   631.859 [ 217.017], Avg:   218.687 (0.100) <0-14:45:20> ({'r_t':   983.6309, 'eps':     0.0999, 'len': 34468.2040, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  490000, Reward:   639.440 [ 130.176], Avg:   219.544 (1.000) <0-14:55:33> ({'r_t':  1170.4122, 'eps':     0.9999, 'len': 34501.0930, 'dyn_loss':    19.2768, 'dot_loss':     2.2869, 'ddot_loss':     5.3080, 'rew_loss':   197.9402, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  491000, Reward:   551.996 [ 404.123], Avg:   220.219 (0.900) <0-14:56:32> ({'r_t': -1712.4633, 'eps':     0.8999, 'len': 34567.6010, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  492000, Reward:   633.782 [  74.854], Avg:   221.058 (0.800) <0-14:57:36> ({'r_t': -1578.0727, 'eps':     0.7999, 'len': 34672.8800, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  493000, Reward:   655.391 [ 135.150], Avg:   221.937 (0.700) <0-14:58:45> ({'r_t': -1165.6979, 'eps':     0.6999, 'len': 34764.8180, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  494000, Reward:   544.260 [ 388.606], Avg:   222.589 (0.600) <0-15:00:02> ({'r_t':  -725.9285, 'eps':     0.5999, 'len': 34832.5920, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  495000, Reward:   623.774 [  86.602], Avg:   223.397 (0.500) <0-15:01:25> ({'r_t':  -309.5461, 'eps':     0.4999, 'len': 34884.2570, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  496000, Reward:   668.025 [  93.213], Avg:   224.292 (0.400) <0-15:02:55> ({'r_t':   296.7842, 'eps':     0.3999, 'len': 34923.0460, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  497000, Reward:   663.105 [  76.684], Avg:   225.173 (0.300) <0-15:04:33> ({'r_t':   511.6635, 'eps':     0.2999, 'len': 34955.0590, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  498000, Reward:   603.966 [ 257.788], Avg:   225.932 (0.200) <0-15:06:17> ({'r_t':   944.5038, 'eps':     0.1999, 'len': 34987.8850, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  499000, Reward:   654.369 [ 127.362], Avg:   226.789 (0.100) <0-15:08:09> ({'r_t':  1099.4335, 'eps':     0.0999, 'len': 35020.6920, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  500000, Reward:   415.706 [ 540.038], Avg:   227.166 (1.000) <0-15:18:26> ({'r_t':  1186.7261, 'eps':     0.9999, 'len': 35053.0140, 'dyn_loss':    19.2073, 'dot_loss':     2.2802, 'ddot_loss':     5.3084, 'rew_loss':   204.7075, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  501000, Reward:   476.254 [ 473.667], Avg:   227.662 (0.900) <0-15:19:24> ({'r_t': -2174.6899, 'eps':     0.8999, 'len': 35110.6570, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  502000, Reward:   654.933 [  95.302], Avg:   228.512 (0.800) <0-15:20:28> ({'r_t': -1366.6319, 'eps':     0.7999, 'len': 35206.9110, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  503000, Reward:   676.786 [  59.557], Avg:   229.401 (0.700) <0-15:21:37> ({'r_t': -1101.0743, 'eps':     0.6999, 'len': 35291.2200, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  504000, Reward:   494.874 [ 500.517], Avg:   229.927 (0.600) <0-15:22:54> ({'r_t':  -811.9580, 'eps':     0.5999, 'len': 35356.5040, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  505000, Reward:   401.142 [ 582.352], Avg:   230.265 (0.500) <0-15:24:17> ({'r_t':  -283.5232, 'eps':     0.4999, 'len': 35401.2410, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  506000, Reward:   631.584 [ 223.778], Avg:   231.057 (0.400) <0-15:25:47> ({'r_t':   162.0425, 'eps':     0.3999, 'len': 35435.6610, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  507000, Reward:   644.216 [ 133.922], Avg:   231.870 (0.300) <0-15:27:25> ({'r_t':   423.5638, 'eps':     0.2999, 'len': 35467.7920, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  508000, Reward:   584.417 [ 362.235], Avg:   232.563 (0.200) <0-15:29:09> ({'r_t':   721.2485, 'eps':     0.1999, 'len': 35502.5750, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  509000, Reward:   476.630 [ 409.370], Avg:   233.041 (0.100) <0-15:31:01> ({'r_t':  1199.2642, 'eps':     0.0999, 'len': 35535.2170, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  510000, Reward:   640.067 [ 197.713], Avg:   233.838 (1.000) <0-15:41:25> ({'r_t':  1247.8561, 'eps':     0.9999, 'len': 35568.0010, 'dyn_loss':    19.2576, 'dot_loss':     2.2725, 'ddot_loss':     5.2909, 'rew_loss':   192.2584, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  511000, Reward:   594.535 [ 202.572], Avg:   234.542 (0.900) <0-15:42:24> ({'r_t': -1444.9677, 'eps':     0.8999, 'len': 35636.5260, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  512000, Reward:   642.446 [  79.751], Avg:   235.338 (0.800) <0-15:43:28> ({'r_t': -1463.0262, 'eps':     0.7999, 'len': 35740.9790, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  513000, Reward:   651.224 [  90.001], Avg:   236.147 (0.700) <0-15:44:38> ({'r_t': -1122.8745, 'eps':     0.6999, 'len': 35831.0480, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  514000, Reward:   640.430 [  66.227], Avg:   236.932 (0.600) <0-15:45:55> ({'r_t':  -806.3763, 'eps':     0.5999, 'len': 35897.5810, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  515000, Reward:   434.238 [ 485.919], Avg:   237.314 (0.500) <0-15:47:19> ({'r_t':  -299.0799, 'eps':     0.4999, 'len': 35945.5210, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  516000, Reward:   598.848 [ 192.762], Avg:   238.013 (0.400) <0-15:48:50> ({'r_t':   228.9192, 'eps':     0.3999, 'len': 35981.4880, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  517000, Reward:   671.597 [  72.383], Avg:   238.850 (0.300) <0-15:50:29> ({'r_t':   565.6047, 'eps':     0.2999, 'len': 36014.5920, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  518000, Reward:   636.512 [  81.560], Avg:   239.617 (0.200) <0-15:52:14> ({'r_t':   844.3925, 'eps':     0.1999, 'len': 36047.0990, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  519000, Reward:   574.321 [ 265.600], Avg:   240.260 (0.100) <0-15:54:07> ({'r_t':   966.2354, 'eps':     0.0999, 'len': 36079.2840, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  520000, Reward:   468.093 [ 498.158], Avg:   240.698 (1.000) <0-16:04:34> ({'r_t':  1269.6547, 'eps':     0.9999, 'len': 36111.9390, 'dyn_loss':    19.0794, 'dot_loss':     2.2626, 'ddot_loss':     5.2588, 'rew_loss':   195.0428, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  521000, Reward:   565.491 [ 447.177], Avg:   241.320 (0.900) <0-16:05:33> ({'r_t': -1521.8633, 'eps':     0.8999, 'len': 36172.5360, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  522000, Reward:   654.440 [  86.292], Avg:   242.110 (0.800) <0-16:06:37> ({'r_t': -1324.3463, 'eps':     0.7999, 'len': 36268.1180, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  523000, Reward:   482.231 [ 384.058], Avg:   242.568 (0.700) <0-16:07:47> ({'r_t': -1187.2676, 'eps':     0.6999, 'len': 36351.5760, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  524000, Reward:   624.486 [ 123.667], Avg:   243.295 (0.600) <0-16:09:04> ({'r_t':  -783.7089, 'eps':     0.5999, 'len': 36416.9900, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  525000, Reward:   633.577 [  59.350], Avg:   244.037 (0.500) <0-16:10:29> ({'r_t':  -223.9569, 'eps':     0.4999, 'len': 36464.8070, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  526000, Reward:   512.780 [ 395.119], Avg:   244.547 (0.400) <0-16:12:01> ({'r_t':     4.9975, 'eps':     0.3999, 'len': 36500.9950, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  527000, Reward:   572.593 [ 351.555], Avg:   245.169 (0.300) <0-16:13:39> ({'r_t':   539.8620, 'eps':     0.2999, 'len': 36535.1040, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  528000, Reward:   507.359 [ 395.472], Avg:   245.664 (0.200) <0-16:15:25> ({'r_t':   950.7367, 'eps':     0.1999, 'len': 36567.0400, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  529000, Reward:   580.859 [ 246.744], Avg:   246.297 (0.100) <0-16:17:18> ({'r_t':  1097.0980, 'eps':     0.0999, 'len': 36599.2660, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  530000, Reward:   590.189 [ 364.726], Avg:   246.944 (1.000) <0-16:27:36> ({'r_t':  1258.2320, 'eps':     0.9999, 'len': 36632.4280, 'dyn_loss':    18.4697, 'dot_loss':     2.2281, 'ddot_loss':     5.1807, 'rew_loss':   195.0562, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  531000, Reward:   444.562 [ 501.614], Avg:   247.316 (0.900) <0-16:28:35> ({'r_t': -1412.0625, 'eps':     0.8999, 'len': 36696.9790, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  532000, Reward:   693.903 [  98.119], Avg:   248.154 (0.800) <0-16:29:39> ({'r_t': -1425.6724, 'eps':     0.7999, 'len': 36789.5180, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  533000, Reward:   528.870 [ 383.898], Avg:   248.679 (0.700) <0-16:30:49> ({'r_t': -1115.3234, 'eps':     0.6999, 'len': 36869.2530, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  534000, Reward:   439.090 [ 493.034], Avg:   249.035 (0.600) <0-16:32:06> ({'r_t':  -906.2382, 'eps':     0.5999, 'len': 36939.3550, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  535000, Reward:   633.260 [  85.744], Avg:   249.752 (0.500) <0-16:33:29> ({'r_t':  -309.4816, 'eps':     0.4999, 'len': 36990.2170, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  536000, Reward:   566.963 [ 339.855], Avg:   250.343 (0.400) <0-16:35:00> ({'r_t':   222.1154, 'eps':     0.3999, 'len': 37027.8460, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  537000, Reward:   490.644 [ 374.079], Avg:   250.789 (0.300) <0-16:36:38> ({'r_t':   480.5335, 'eps':     0.2999, 'len': 37061.3730, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  538000, Reward:   526.288 [ 299.388], Avg:   251.301 (0.200) <0-16:38:24> ({'r_t':   922.8310, 'eps':     0.1999, 'len': 37093.5120, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  539000, Reward:   654.030 [  81.791], Avg:   252.046 (0.100) <0-16:40:16> ({'r_t':  1041.9928, 'eps':     0.0999, 'len': 37125.4970, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  540000, Reward:   623.682 [ 288.944], Avg:   252.733 (1.000) <0-16:50:45> ({'r_t':  1103.9030, 'eps':     0.9999, 'len': 37157.5690, 'dyn_loss':    18.1722, 'dot_loss':     2.2213, 'ddot_loss':     5.1774, 'rew_loss':   188.6060, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  541000, Reward:   554.436 [ 418.523], Avg:   253.290 (0.900) <0-16:51:44> ({'r_t': -1995.6172, 'eps':     0.8999, 'len': 37221.8800, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  542000, Reward:   594.123 [ 388.272], Avg:   253.918 (0.800) <0-16:52:47> ({'r_t': -1300.8222, 'eps':     0.7999, 'len': 37329.3710, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  543000, Reward:   694.609 [  53.417], Avg:   254.728 (0.700) <0-16:53:57> ({'r_t': -1186.5669, 'eps':     0.6999, 'len': 37418.5770, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  544000, Reward:   590.363 [ 175.248], Avg:   255.344 (0.600) <0-16:55:14> ({'r_t':  -957.3677, 'eps':     0.5999, 'len': 37484.0810, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  545000, Reward:   671.484 [ 184.155], Avg:   256.106 (0.500) <0-16:56:39> ({'r_t':  -366.5683, 'eps':     0.4999, 'len': 37529.2820, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  546000, Reward:   623.633 [ 191.195], Avg:   256.778 (0.400) <0-16:58:10> ({'r_t':   240.7970, 'eps':     0.3999, 'len': 37566.7160, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  547000, Reward:   697.256 [  88.235], Avg:   257.581 (0.300) <0-16:59:49> ({'r_t':   632.8764, 'eps':     0.2999, 'len': 37599.0890, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  548000, Reward:   669.097 [  92.045], Avg:   258.331 (0.200) <0-17:01:34> ({'r_t':   896.0493, 'eps':     0.1999, 'len': 37631.2150, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  549000, Reward:   595.946 [ 256.016], Avg:   258.945 (0.100) <0-17:03:27> ({'r_t':  1153.1404, 'eps':     0.0999, 'len': 37663.4180, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  550000, Reward:   602.605 [ 394.325], Avg:   259.569 (1.000) <0-17:14:06> ({'r_t':  1181.3365, 'eps':     0.9999, 'len': 37697.1440, 'dyn_loss':    18.5863, 'dot_loss':     2.2371, 'ddot_loss':     5.2101, 'rew_loss':   195.1810, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  551000, Reward:   599.244 [ 185.631], Avg:   260.184 (0.900) <0-17:15:05> ({'r_t': -1617.4972, 'eps':     0.8999, 'len': 37761.4210, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  552000, Reward:   603.357 [ 392.385], Avg:   260.804 (0.800) <0-17:16:09> ({'r_t': -1441.7995, 'eps':     0.7999, 'len': 37859.5810, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  553000, Reward:   448.091 [ 759.064], Avg:   261.142 (0.700) <0-17:17:19> ({'r_t': -1143.2545, 'eps':     0.6999, 'len': 37940.8690, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  554000, Reward:   512.215 [ 351.894], Avg:   261.595 (0.600) <0-17:18:36> ({'r_t':  -942.9227, 'eps':     0.5999, 'len': 38002.9670, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  555000, Reward:   464.140 [ 690.419], Avg:   261.959 (0.500) <0-17:20:00> ({'r_t':  -214.8911, 'eps':     0.4999, 'len': 38051.7630, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  556000, Reward:   622.756 [ 343.458], Avg:   262.607 (0.400) <0-17:21:31> ({'r_t':   172.4598, 'eps':     0.3999, 'len': 38087.8540, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  557000, Reward:   538.770 [ 408.550], Avg:   263.102 (0.300) <0-17:23:09> ({'r_t':   588.8265, 'eps':     0.2999, 'len': 38121.9860, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  558000, Reward:   479.417 [ 366.260], Avg:   263.489 (0.200) <0-17:24:55> ({'r_t':   956.2178, 'eps':     0.1999, 'len': 38154.3900, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  559000, Reward:   620.160 [ 207.575], Avg:   264.126 (0.100) <0-17:26:48> ({'r_t':  1107.5587, 'eps':     0.0999, 'len': 38186.6190, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  560000, Reward:   697.388 [  59.924], Avg:   264.898 (1.000) <0-17:37:15> ({'r_t':  1228.6970, 'eps':     0.9999, 'len': 38219.2000, 'dyn_loss':    18.2114, 'dot_loss':     2.2133, 'ddot_loss':     5.1554, 'rew_loss':   175.1476, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  561000, Reward:   713.933 [  71.833], Avg:   265.697 (0.900) <0-17:38:14> ({'r_t': -1448.1877, 'eps':     0.8999, 'len': 38279.8360, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  562000, Reward:   451.954 [ 499.264], Avg:   266.028 (0.800) <0-17:39:17> ({'r_t': -1460.2245, 'eps':     0.7999, 'len': 38378.3550, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  563000, Reward:   653.802 [  85.845], Avg:   266.715 (0.700) <0-17:40:27> ({'r_t': -1251.0929, 'eps':     0.6999, 'len': 38466.5150, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  564000, Reward:   528.328 [ 403.344], Avg:   267.178 (0.600) <0-17:41:44> ({'r_t':  -759.8194, 'eps':     0.5999, 'len': 38530.8280, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  565000, Reward:   662.934 [ 109.116], Avg:   267.878 (0.500) <0-17:43:09> ({'r_t':  -284.5126, 'eps':     0.4999, 'len': 38579.7520, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  566000, Reward:   603.710 [ 114.483], Avg:   268.470 (0.400) <0-17:44:40> ({'r_t':   180.7954, 'eps':     0.3999, 'len': 38613.9200, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  567000, Reward:   679.604 [  94.963], Avg:   269.194 (0.300) <0-17:46:18> ({'r_t':   592.1059, 'eps':     0.2999, 'len': 38646.3740, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  568000, Reward:   690.655 [  78.143], Avg:   269.934 (0.200) <0-17:48:04> ({'r_t':   967.0240, 'eps':     0.1999, 'len': 38679.0660, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  569000, Reward:   526.120 [ 347.774], Avg:   270.384 (0.100) <0-17:49:57> ({'r_t':   964.2113, 'eps':     0.0999, 'len': 38711.2030, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  570000, Reward:   674.454 [  83.326], Avg:   271.092 (1.000) <0-18:00:35> ({'r_t':  1343.1883, 'eps':     0.9999, 'len': 38743.8640, 'dyn_loss':    18.1154, 'dot_loss':     2.1976, 'ddot_loss':     5.1342, 'rew_loss':   186.1295, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  571000, Reward:   580.845 [ 198.294], Avg:   271.633 (0.900) <0-18:01:34> ({'r_t': -1778.1891, 'eps':     0.8999, 'len': 38802.3450, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  572000, Reward:   527.170 [ 233.102], Avg:   272.079 (0.800) <0-18:02:38> ({'r_t': -1569.9177, 'eps':     0.7999, 'len': 38893.6910, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  573000, Reward:   641.652 [ 116.564], Avg:   272.723 (0.700) <0-18:03:48> ({'r_t': -1163.6778, 'eps':     0.6999, 'len': 38985.5080, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  574000, Reward:   687.606 [  89.868], Avg:   273.444 (0.600) <0-18:05:04> ({'r_t':  -789.8367, 'eps':     0.5999, 'len': 39059.4130, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  575000, Reward:   575.895 [ 395.117], Avg:   273.970 (0.500) <0-18:06:28> ({'r_t':  -262.2810, 'eps':     0.4999, 'len': 39112.1160, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  576000, Reward:   565.030 [ 175.898], Avg:   274.474 (0.400) <0-18:07:59> ({'r_t':   215.1535, 'eps':     0.3999, 'len': 39147.0160, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  577000, Reward:   680.511 [ 109.014], Avg:   275.176 (0.300) <0-18:09:37> ({'r_t':   497.1334, 'eps':     0.2999, 'len': 39180.0800, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  578000, Reward:   407.476 [ 578.903], Avg:   275.405 (0.200) <0-18:11:23> ({'r_t':   929.5778, 'eps':     0.1999, 'len': 39212.3780, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  579000, Reward:   480.377 [ 500.018], Avg:   275.758 (0.100) <0-18:13:15> ({'r_t':  1074.5830, 'eps':     0.0999, 'len': 39244.9640, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  580000, Reward:   612.907 [ 193.974], Avg:   276.339 (1.000) <0-18:23:51> ({'r_t':  1389.2583, 'eps':     0.9999, 'len': 39277.7260, 'dyn_loss':    18.3022, 'dot_loss':     2.2079, 'ddot_loss':     5.1535, 'rew_loss':   162.7020, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  581000, Reward:   643.331 [ 129.681], Avg:   276.969 (0.900) <0-18:24:50> ({'r_t': -1951.3387, 'eps':     0.8999, 'len': 39338.6140, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  582000, Reward:   572.244 [ 205.769], Avg:   277.476 (0.800) <0-18:25:54> ({'r_t': -1513.9427, 'eps':     0.7999, 'len': 39442.9680, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  583000, Reward:   614.287 [ 191.450], Avg:   278.052 (0.700) <0-18:27:04> ({'r_t': -1258.3378, 'eps':     0.6999, 'len': 39531.7780, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  584000, Reward:   577.218 [ 131.994], Avg:   278.564 (0.600) <0-18:28:22> ({'r_t':  -747.9002, 'eps':     0.5999, 'len': 39597.0180, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  585000, Reward:   578.948 [ 207.414], Avg:   279.076 (0.500) <0-18:29:46> ({'r_t':  -288.1275, 'eps':     0.4999, 'len': 39644.7250, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  586000, Reward:   606.795 [ 127.634], Avg:   279.635 (0.400) <0-18:31:17> ({'r_t':    20.2635, 'eps':     0.3999, 'len': 39683.5700, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  587000, Reward:   672.092 [  85.547], Avg:   280.302 (0.300) <0-18:32:55> ({'r_t':   503.8960, 'eps':     0.2999, 'len': 39717.0470, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  588000, Reward:   665.826 [  73.751], Avg:   280.957 (0.200) <0-18:34:41> ({'r_t':   838.8699, 'eps':     0.1999, 'len': 39750.0020, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  589000, Reward:   601.722 [ 192.907], Avg:   281.500 (0.100) <0-18:36:34> ({'r_t':  1126.4124, 'eps':     0.0999, 'len': 39783.4150, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  590000, Reward:   713.525 [  58.405], Avg:   282.231 (1.000) <0-18:47:21> ({'r_t':  1340.2951, 'eps':     0.9999, 'len': 39816.5550, 'dyn_loss':    18.1623, 'dot_loss':     2.1982, 'ddot_loss':     5.1330, 'rew_loss':   169.1323, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  591000, Reward:   479.051 [ 421.077], Avg:   282.564 (0.900) <0-18:48:20> ({'r_t': -1436.6315, 'eps':     0.8999, 'len': 39881.1700, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  592000, Reward:   641.253 [  91.597], Avg:   283.169 (0.800) <0-18:49:24> ({'r_t': -1261.3766, 'eps':     0.7999, 'len': 39979.0770, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  593000, Reward:   691.171 [  71.688], Avg:   283.856 (0.700) <0-18:50:34> ({'r_t': -1159.5537, 'eps':     0.6999, 'len': 40066.3390, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  594000, Reward:   546.250 [ 397.587], Avg:   284.297 (0.600) <0-18:51:51> ({'r_t':  -912.2032, 'eps':     0.5999, 'len': 40135.9690, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  595000, Reward:   631.653 [ 152.405], Avg:   284.879 (0.500) <0-18:53:15> ({'r_t':  -300.2568, 'eps':     0.4999, 'len': 40188.0030, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  596000, Reward:   541.140 [ 368.808], Avg:   285.309 (0.400) <0-18:54:46> ({'r_t':   248.9024, 'eps':     0.3999, 'len': 40223.9690, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  597000, Reward:   356.249 [ 570.334], Avg:   285.427 (0.300) <0-18:56:24> ({'r_t':   576.0941, 'eps':     0.2999, 'len': 40256.7400, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  598000, Reward:   640.297 [ 200.122], Avg:   286.020 (0.200) <0-18:58:10> ({'r_t':   849.2228, 'eps':     0.1999, 'len': 40288.7520, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  599000, Reward:   468.201 [ 432.133], Avg:   286.323 (0.100) <0-19:00:02> ({'r_t':  1159.5850, 'eps':     0.0999, 'len': 40321.9000, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  600000, Reward:   716.279 [ 107.006], Avg:   287.039 (1.000) <0-19:10:52> ({'r_t':  1367.9125, 'eps':     0.9999, 'len': 40354.6160, 'dyn_loss':    18.1153, 'dot_loss':     2.1747, 'ddot_loss':     5.0869, 'rew_loss':   168.2424, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  601000, Reward:   709.306 [  94.895], Avg:   287.740 (0.900) <0-19:11:51> ({'r_t': -2103.5127, 'eps':     0.8999, 'len': 40419.9460, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  602000, Reward:   654.374 [ 172.921], Avg:   288.348 (0.800) <0-19:12:55> ({'r_t': -1331.3016, 'eps':     0.7999, 'len': 40525.6410, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  603000, Reward:   672.493 [ 111.100], Avg:   288.984 (0.700) <0-19:14:05> ({'r_t': -1081.3579, 'eps':     0.6999, 'len': 40608.1410, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  604000, Reward:   656.272 [ 108.139], Avg:   289.591 (0.600) <0-19:15:22> ({'r_t':  -739.8123, 'eps':     0.5999, 'len': 40664.1250, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  605000, Reward:   667.965 [ 115.805], Avg:   290.216 (0.500) <0-19:16:46> ({'r_t':  -205.0820, 'eps':     0.4999, 'len': 40708.5590, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  606000, Reward:   529.312 [ 382.190], Avg:   290.610 (0.400) <0-19:18:17> ({'r_t':   304.4615, 'eps':     0.3999, 'len': 40744.9760, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  607000, Reward:   633.503 [  92.054], Avg:   291.174 (0.300) <0-19:19:55> ({'r_t':   340.2814, 'eps':     0.2999, 'len': 40777.0850, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  608000, Reward:   703.870 [  84.967], Avg:   291.851 (0.200) <0-19:21:41> ({'r_t':   926.2080, 'eps':     0.1999, 'len': 40809.7780, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  609000, Reward:   524.810 [ 380.659], Avg:   292.233 (0.100) <0-19:23:34> ({'r_t':  1197.0093, 'eps':     0.0999, 'len': 40842.2180, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  610000, Reward:   679.857 [ 142.808], Avg:   292.868 (1.000) <0-19:34:17> ({'r_t':  1394.1359, 'eps':     0.9999, 'len': 40875.4880, 'dyn_loss':    17.5930, 'dot_loss':     2.1432, 'ddot_loss':     5.0078, 'rew_loss':   170.7676, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  611000, Reward:   523.515 [ 480.661], Avg:   293.244 (0.900) <0-19:35:15> ({'r_t': -1335.2353, 'eps':     0.8999, 'len': 40941.0040, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  612000, Reward:   593.355 [ 377.537], Avg:   293.734 (0.800) <0-19:36:19> ({'r_t': -1305.6588, 'eps':     0.7999, 'len': 41041.7950, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  613000, Reward:   537.453 [ 407.702], Avg:   294.131 (0.700) <0-19:37:30> ({'r_t': -1167.9714, 'eps':     0.6999, 'len': 41135.6640, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  614000, Reward:   649.602 [  81.885], Avg:   294.709 (0.600) <0-19:38:47> ({'r_t':  -807.7569, 'eps':     0.5999, 'len': 41202.4750, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  615000, Reward:   617.999 [ 220.626], Avg:   295.234 (0.500) <0-19:40:11> ({'r_t':  -228.0106, 'eps':     0.4999, 'len': 41248.9450, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  616000, Reward:   661.009 [ 114.244], Avg:   295.827 (0.400) <0-19:41:43> ({'r_t':   228.0495, 'eps':     0.3999, 'len': 41283.2510, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  617000, Reward:   652.882 [ 105.305], Avg:   296.404 (0.300) <0-19:43:22> ({'r_t':   615.9564, 'eps':     0.2999, 'len': 41315.4250, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  618000, Reward:   678.134 [  75.322], Avg:   297.021 (0.200) <0-19:45:08> ({'r_t':   981.2367, 'eps':     0.1999, 'len': 41347.6460, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  619000, Reward:   540.758 [ 397.319], Avg:   297.414 (0.100) <0-19:47:01> ({'r_t':  1196.7874, 'eps':     0.0999, 'len': 41380.1700, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  620000, Reward:   486.487 [ 403.101], Avg:   297.719 (1.000) <0-19:57:54> ({'r_t':  1369.7146, 'eps':     0.9999, 'len': 41412.7880, 'dyn_loss':    17.7268, 'dot_loss':     2.1531, 'ddot_loss':     5.0214, 'rew_loss':   138.0322, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  621000, Reward:   394.426 [ 513.103], Avg:   297.874 (0.900) <0-19:58:54> ({'r_t': -1719.5980, 'eps':     0.8999, 'len': 41478.5320, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  622000, Reward:   499.495 [ 263.562], Avg:   298.198 (0.800) <0-19:59:58> ({'r_t': -1513.3723, 'eps':     0.7999, 'len': 41580.5520, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  623000, Reward:   454.994 [ 397.179], Avg:   298.449 (0.700) <0-20:01:08> ({'r_t': -1150.0934, 'eps':     0.6999, 'len': 41669.9670, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  624000, Reward:   373.443 [ 724.716], Avg:   298.569 (0.600) <0-20:02:26> ({'r_t':  -777.7594, 'eps':     0.5999, 'len': 41737.3810, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  625000, Reward:   496.279 [ 414.177], Avg:   298.885 (0.500) <0-20:03:50> ({'r_t':  -255.4789, 'eps':     0.4999, 'len': 41780.7320, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  626000, Reward:   456.806 [ 383.399], Avg:   299.137 (0.400) <0-20:05:22> ({'r_t':   153.8993, 'eps':     0.3999, 'len': 41818.7490, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  627000, Reward:   553.705 [ 257.167], Avg:   299.542 (0.300) <0-20:07:00> ({'r_t':   417.7115, 'eps':     0.2999, 'len': 41852.1280, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  628000, Reward:   560.766 [ 217.633], Avg:   299.957 (0.200) <0-20:08:46> ({'r_t':   665.9995, 'eps':     0.1999, 'len': 41885.6810, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  629000, Reward:   484.901 [ 376.008], Avg:   300.251 (0.100) <0-20:10:40> ({'r_t':   668.9160, 'eps':     0.0999, 'len': 41918.1100, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  630000, Reward:   729.875 [ 114.734], Avg:   300.932 (1.000) <0-20:21:29> ({'r_t':  1161.4181, 'eps':     0.9999, 'len': 41952.1000, 'dyn_loss':    17.5281, 'dot_loss':     2.1470, 'ddot_loss':     5.0215, 'rew_loss':   180.5907, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  631000, Reward:   656.167 [ 205.297], Avg:   301.494 (0.900) <0-20:22:28> ({'r_t': -1442.5418, 'eps':     0.8999, 'len': 42020.3050, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  632000, Reward:   668.499 [ 104.999], Avg:   302.074 (0.800) <0-20:23:31> ({'r_t': -1249.8302, 'eps':     0.7999, 'len': 42120.1570, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  633000, Reward:   625.384 [ 210.985], Avg:   302.584 (0.700) <0-20:24:42> ({'r_t': -1223.1671, 'eps':     0.6999, 'len': 42202.6600, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  634000, Reward:   559.915 [ 374.664], Avg:   302.989 (0.600) <0-20:25:59> ({'r_t':  -854.7339, 'eps':     0.5999, 'len': 42269.8110, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  635000, Reward:   638.270 [ 202.970], Avg:   303.516 (0.500) <0-20:27:23> ({'r_t':  -207.2541, 'eps':     0.4999, 'len': 42320.6630, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  636000, Reward:   691.984 [  49.329], Avg:   304.126 (0.400) <0-20:28:55> ({'r_t':   299.9296, 'eps':     0.3999, 'len': 42356.0810, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  637000, Reward:   634.360 [ 106.714], Avg:   304.643 (0.300) <0-20:30:33> ({'r_t':   696.3848, 'eps':     0.2999, 'len': 42388.1580, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  638000, Reward:   466.314 [ 398.830], Avg:   304.896 (0.200) <0-20:32:20> ({'r_t':   909.8134, 'eps':     0.1999, 'len': 42420.3090, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  639000, Reward:   644.634 [ 176.541], Avg:   305.427 (0.100) <0-20:34:13> ({'r_t':  1209.8429, 'eps':     0.0999, 'len': 42452.4670, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  640000, Reward:   598.740 [ 375.786], Avg:   305.885 (1.000) <0-20:45:04> ({'r_t':  1280.5555, 'eps':     0.9999, 'len': 42485.6770, 'dyn_loss':    17.5497, 'dot_loss':     2.1416, 'ddot_loss':     5.0192, 'rew_loss':   163.6031, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  641000, Reward:   670.924 [  82.199], Avg:   306.453 (0.900) <0-20:46:03> ({'r_t': -1828.3865, 'eps':     0.8999, 'len': 42548.5620, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  642000, Reward:   647.899 [ 140.148], Avg:   306.984 (0.800) <0-20:47:07> ({'r_t': -1390.8516, 'eps':     0.7999, 'len': 42651.1500, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  643000, Reward:   619.808 [ 132.017], Avg:   307.470 (0.700) <0-20:48:17> ({'r_t': -1096.0215, 'eps':     0.6999, 'len': 42738.0290, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  644000, Reward:   560.250 [ 341.439], Avg:   307.862 (0.600) <0-20:49:34> ({'r_t':  -746.1778, 'eps':     0.5999, 'len': 42812.0710, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  645000, Reward:   541.335 [ 397.739], Avg:   308.224 (0.500) <0-20:50:58> ({'r_t':  -296.6339, 'eps':     0.4999, 'len': 42862.2580, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  646000, Reward:   669.368 [ 116.175], Avg:   308.782 (0.400) <0-20:52:30> ({'r_t':   259.4958, 'eps':     0.3999, 'len': 42898.2390, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  647000, Reward:   663.632 [  99.806], Avg:   309.329 (0.300) <0-20:54:09> ({'r_t':   439.9250, 'eps':     0.2999, 'len': 42930.9280, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  648000, Reward:   574.978 [ 355.165], Avg:   309.739 (0.200) <0-20:55:54> ({'r_t':   827.0792, 'eps':     0.1999, 'len': 42963.0070, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  649000, Reward:   422.806 [ 548.471], Avg:   309.913 (0.100) <0-20:57:48> ({'r_t':   949.9039, 'eps':     0.0999, 'len': 42996.4840, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  650000, Reward:   622.796 [ 364.587], Avg:   310.393 (1.000) <0-21:08:41> ({'r_t':  1129.2991, 'eps':     0.9999, 'len': 43028.9500, 'dyn_loss':    17.6881, 'dot_loss':     2.1511, 'ddot_loss':     5.0320, 'rew_loss':   164.8884, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  651000, Reward:   504.800 [ 516.504], Avg:   310.691 (0.900) <0-21:09:40> ({'r_t': -1753.8513, 'eps':     0.8999, 'len': 43095.1810, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  652000, Reward:   660.554 [  62.386], Avg:   311.227 (0.800) <0-21:10:44> ({'r_t': -1487.9584, 'eps':     0.7999, 'len': 43194.6190, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  653000, Reward:   664.689 [ 101.008], Avg:   311.768 (0.700) <0-21:11:54> ({'r_t': -1188.8119, 'eps':     0.6999, 'len': 43286.2380, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  654000, Reward:   685.751 [  78.984], Avg:   312.339 (0.600) <0-21:13:11> ({'r_t':  -874.6733, 'eps':     0.5999, 'len': 43350.5090, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  655000, Reward:   656.842 [  79.704], Avg:   312.864 (0.500) <0-21:14:35> ({'r_t':  -195.2134, 'eps':     0.4999, 'len': 43396.2840, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  656000, Reward:   666.648 [  49.422], Avg:   313.402 (0.400) <0-21:16:07> ({'r_t':   288.0375, 'eps':     0.3999, 'len': 43431.1700, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  657000, Reward:   684.830 [ 106.117], Avg:   313.967 (0.300) <0-21:17:46> ({'r_t':   482.6991, 'eps':     0.2999, 'len': 43465.4810, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  658000, Reward:   661.937 [  67.270], Avg:   314.495 (0.200) <0-21:19:32> ({'r_t':   978.0130, 'eps':     0.1999, 'len': 43498.1010, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  659000, Reward:   628.920 [ 199.784], Avg:   314.971 (0.100) <0-21:21:25> ({'r_t':   810.0873, 'eps':     0.0999, 'len': 43530.9270, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  660000, Reward:   628.825 [ 185.239], Avg:   315.446 (1.000) <0-21:32:15> ({'r_t':  1329.2363, 'eps':     0.9999, 'len': 43563.6870, 'dyn_loss':    17.3103, 'dot_loss':     2.1257, 'ddot_loss':     4.9759, 'rew_loss':   167.3907, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  661000, Reward:   673.938 [  62.097], Avg:   315.987 (0.900) <0-21:33:14> ({'r_t': -1535.8927, 'eps':     0.8999, 'len': 43626.0870, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  662000, Reward:   679.718 [  75.183], Avg:   316.536 (0.800) <0-21:34:17> ({'r_t': -1531.2407, 'eps':     0.7999, 'len': 43719.1650, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  663000, Reward:   666.112 [  72.481], Avg:   317.063 (0.700) <0-21:35:27> ({'r_t': -1172.0772, 'eps':     0.6999, 'len': 43809.3870, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  664000, Reward:   652.305 [  68.112], Avg:   317.567 (0.600) <0-21:36:45> ({'r_t':  -815.6906, 'eps':     0.5999, 'len': 43875.5500, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  665000, Reward:   680.612 [ 116.840], Avg:   318.112 (0.500) <0-21:38:09> ({'r_t':  -215.9063, 'eps':     0.4999, 'len': 43922.1960, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  666000, Reward:   655.258 [  71.703], Avg:   318.617 (0.400) <0-21:39:40> ({'r_t':   194.6331, 'eps':     0.3999, 'len': 43958.8550, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  667000, Reward:   623.213 [ 199.912], Avg:   319.073 (0.300) <0-21:41:19> ({'r_t':   744.7039, 'eps':     0.2999, 'len': 43991.2520, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  668000, Reward:   621.854 [ 185.231], Avg:   319.526 (0.200) <0-21:43:05> ({'r_t':   844.3596, 'eps':     0.1999, 'len': 44023.1880, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  669000, Reward:   664.836 [  85.174], Avg:   320.041 (0.100) <0-21:44:58> ({'r_t':  1145.3969, 'eps':     0.0999, 'len': 44056.0920, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  670000, Reward:   682.808 [  85.896], Avg:   320.582 (1.000) <0-21:55:57> ({'r_t':  1317.7153, 'eps':     0.9999, 'len': 44089.0660, 'dyn_loss':    17.3569, 'dot_loss':     2.1121, 'ddot_loss':     4.9511, 'rew_loss':   156.6023, 'lr':   6.40e-05, 'eps_e':     0.9999, 'lr_e':   6.40e-05})
Step:  671000, Reward:   680.643 [  68.305], Avg:   321.118 (0.900) <0-21:56:56> ({'r_t': -2160.9647, 'eps':     0.8999, 'len': 44154.1320, 'lr':   6.40e-05, 'eps_e':     0.8999, 'lr_e':   6.40e-05})
Step:  672000, Reward:   546.921 [ 399.171], Avg:   321.453 (0.800) <0-21:57:59> ({'r_t': -1457.5939, 'eps':     0.7999, 'len': 44258.0380, 'lr':   6.40e-05, 'eps_e':     0.7999, 'lr_e':   6.40e-05})
Step:  673000, Reward:   689.849 [  84.616], Avg:   322.000 (0.700) <0-21:59:10> ({'r_t': -1268.6884, 'eps':     0.6999, 'len': 44340.7130, 'lr':   6.40e-05, 'eps_e':     0.6999, 'lr_e':   6.40e-05})
Step:  674000, Reward:   465.502 [ 468.312], Avg:   322.212 (0.600) <0-22:00:27> ({'r_t':  -769.4890, 'eps':     0.5999, 'len': 44403.3950, 'lr':   6.40e-05, 'eps_e':     0.5999, 'lr_e':   6.40e-05})
Step:  675000, Reward:   500.012 [ 389.931], Avg:   322.475 (0.500) <0-22:01:51> ({'r_t':  -279.4132, 'eps':     0.4999, 'len': 44447.0360, 'lr':   6.40e-05, 'eps_e':     0.4999, 'lr_e':   6.40e-05})
Step:  676000, Reward:   615.315 [ 194.869], Avg:   322.908 (0.400) <0-22:03:22> ({'r_t':   273.9666, 'eps':     0.3999, 'len': 44482.8650, 'lr':   6.40e-05, 'eps_e':     0.3999, 'lr_e':   6.40e-05})
Step:  677000, Reward:   447.182 [ 432.922], Avg:   323.091 (0.300) <0-22:05:01> ({'r_t':   641.7997, 'eps':     0.2999, 'len': 44514.8580, 'lr':   6.40e-05, 'eps_e':     0.2999, 'lr_e':   6.40e-05})
Step:  678000, Reward:   636.033 [  57.568], Avg:   323.552 (0.200) <0-22:06:47> ({'r_t':   760.3892, 'eps':     0.1999, 'len': 44546.9280, 'lr':   6.40e-05, 'eps_e':     0.1999, 'lr_e':   6.40e-05})
Step:  679000, Reward:   630.619 [ 144.686], Avg:   324.004 (0.100) <0-22:08:40> ({'r_t':  1204.0860, 'eps':     0.0999, 'len': 44578.9570, 'lr':   6.40e-05, 'eps_e':     0.0999, 'lr_e':   6.40e-05})
Step:  680000, Reward:   422.993 [  96.358], Avg:   324.149 (1.000) <0-22:19:36> ({'r_t':  1301.1820, 'eps':     0.9999, 'len': 44610.9080, 'dyn_loss':    17.1240, 'dot_loss':     2.1118, 'ddot_loss':     4.9534, 'rew_loss':   163.8264, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  681000, Reward:   439.128 [  92.112], Avg:   324.318 (0.900) <0-22:20:35> ({'r_t': -1371.4672, 'eps':     0.8999, 'len': 44679.0340, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  682000, Reward:   303.534 [ 425.148], Avg:   324.287 (0.800) <0-22:21:40> ({'r_t': -1529.7494, 'eps':     0.7999, 'len': 44781.8440, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  683000, Reward:   393.807 [ 198.511], Avg:   324.389 (0.700) <0-22:22:50> ({'r_t': -1139.7055, 'eps':     0.6999, 'len': 44870.1390, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  684000, Reward:   465.658 [ 112.018], Avg:   324.595 (0.600) <0-22:24:08> ({'r_t':  -930.3494, 'eps':     0.5999, 'len': 44933.0670, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  685000, Reward:   321.748 [ 342.612], Avg:   324.591 (0.500) <0-22:25:32> ({'r_t':  -281.5426, 'eps':     0.4999, 'len': 44977.3980, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  686000, Reward:   435.115 [  72.651], Avg:   324.752 (0.400) <0-22:27:04> ({'r_t':    39.9411, 'eps':     0.3999, 'len': 45014.3570, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  687000, Reward:   480.379 [ 148.004], Avg:   324.978 (0.300) <0-22:28:43> ({'r_t':   668.7466, 'eps':     0.2999, 'len': 45047.3790, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  688000, Reward:   412.473 [  58.485], Avg:   325.105 (0.200) <0-22:30:29> ({'r_t':   626.1477, 'eps':     0.1999, 'len': 45080.9590, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  689000, Reward:   381.573 [ 160.749], Avg:   325.187 (0.100) <0-22:32:22> ({'r_t':   548.0041, 'eps':     0.0999, 'len': 45114.2170, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  690000, Reward:   666.726 [  88.613], Avg:   325.681 (1.000) <0-22:43:29> ({'r_t':   882.3665, 'eps':     0.9999, 'len': 45149.2780, 'dyn_loss':    17.0022, 'dot_loss':     2.0902, 'ddot_loss':     4.8942, 'rew_loss':   159.9911, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  691000, Reward:   634.358 [ 127.750], Avg:   326.127 (0.900) <0-22:44:28> ({'r_t': -2251.7329, 'eps':     0.8999, 'len': 45213.4380, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  692000, Reward:   653.659 [ 147.440], Avg:   326.600 (0.800) <0-22:45:32> ({'r_t': -1553.6994, 'eps':     0.7999, 'len': 45310.3090, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  693000, Reward:   552.682 [ 386.501], Avg:   326.926 (0.700) <0-22:46:42> ({'r_t': -1188.6889, 'eps':     0.6999, 'len': 45394.5290, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  694000, Reward:   636.804 [ 196.610], Avg:   327.371 (0.600) <0-22:47:59> ({'r_t':  -818.5966, 'eps':     0.5999, 'len': 45460.1970, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  695000, Reward:   504.137 [ 333.370], Avg:   327.625 (0.500) <0-22:49:23> ({'r_t':  -194.0240, 'eps':     0.4999, 'len': 45509.7440, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  696000, Reward:   521.964 [ 383.271], Avg:   327.904 (0.400) <0-22:50:55> ({'r_t':   264.0885, 'eps':     0.3999, 'len': 45545.8350, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  697000, Reward:   576.995 [ 188.501], Avg:   328.261 (0.300) <0-22:52:33> ({'r_t':   429.5807, 'eps':     0.2999, 'len': 45578.5460, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  698000, Reward:   621.062 [ 151.190], Avg:   328.680 (0.200) <0-22:54:19> ({'r_t':   914.3823, 'eps':     0.1999, 'len': 45611.3980, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  699000, Reward:   678.066 [ 109.789], Avg:   329.179 (0.100) <0-22:56:12> ({'r_t':  1042.5564, 'eps':     0.0999, 'len': 45643.3900, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  700000, Reward:   306.353 [ 630.018], Avg:   329.147 (1.000) <0-23:07:11> ({'r_t':  1118.6925, 'eps':     0.9999, 'len': 45676.2710, 'dyn_loss':    16.6535, 'dot_loss':     2.0634, 'ddot_loss':     4.8475, 'rew_loss':   148.9712, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  701000, Reward:   592.177 [ 191.499], Avg:   329.521 (0.900) <0-23:08:10> ({'r_t': -1792.8445, 'eps':     0.8999, 'len': 45744.6090, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  702000, Reward:   614.076 [ 178.381], Avg:   329.926 (0.800) <0-23:09:14> ({'r_t': -1517.8954, 'eps':     0.7999, 'len': 45851.8280, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  703000, Reward:   619.398 [ 194.343], Avg:   330.337 (0.700) <0-23:10:24> ({'r_t': -1141.3071, 'eps':     0.6999, 'len': 45936.4530, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  704000, Reward:   557.146 [ 411.210], Avg:   330.659 (0.600) <0-23:11:41> ({'r_t':  -808.5129, 'eps':     0.5999, 'len': 46003.4990, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  705000, Reward:   641.400 [ 112.186], Avg:   331.099 (0.500) <0-23:13:05> ({'r_t':  -204.7321, 'eps':     0.4999, 'len': 46051.3040, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  706000, Reward:   541.772 [ 366.020], Avg:   331.397 (0.400) <0-23:14:36> ({'r_t':   155.3039, 'eps':     0.3999, 'len': 46088.6960, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  707000, Reward:   606.609 [ 117.964], Avg:   331.786 (0.300) <0-23:16:15> ({'r_t':   367.9513, 'eps':     0.2999, 'len': 46121.5290, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  708000, Reward:   714.864 [  82.101], Avg:   332.326 (0.200) <0-23:18:01> ({'r_t':   858.1734, 'eps':     0.1999, 'len': 46153.9020, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  709000, Reward:   636.411 [ 103.272], Avg:   332.754 (0.100) <0-23:19:54> ({'r_t':   888.8037, 'eps':     0.0999, 'len': 46185.8500, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  710000, Reward:   524.046 [ 365.632], Avg:   333.023 (1.000) <0-23:31:08> ({'r_t':  1374.5813, 'eps':     0.9999, 'len': 46217.7860, 'dyn_loss':    17.1621, 'dot_loss':     2.0796, 'ddot_loss':     4.8731, 'rew_loss':   165.7700, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  711000, Reward:   636.935 [  67.751], Avg:   333.450 (0.900) <0-23:32:07> ({'r_t': -1633.1186, 'eps':     0.8999, 'len': 46283.5070, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  712000, Reward:   661.427 [ 104.692], Avg:   333.910 (0.800) <0-23:33:10> ({'r_t': -1299.1144, 'eps':     0.7999, 'len': 46383.0730, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  713000, Reward:   620.281 [ 120.197], Avg:   334.311 (0.700) <0-23:34:21> ({'r_t': -1285.9406, 'eps':     0.6999, 'len': 46465.7970, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  714000, Reward:   502.323 [ 378.985], Avg:   334.546 (0.600) <0-23:35:38> ({'r_t':  -799.3427, 'eps':     0.5999, 'len': 46530.3860, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  715000, Reward:   632.383 [ 249.186], Avg:   334.962 (0.500) <0-23:37:02> ({'r_t':  -176.7381, 'eps':     0.4999, 'len': 46574.6410, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  716000, Reward:   607.406 [ 247.031], Avg:   335.342 (0.400) <0-23:38:33> ({'r_t':    70.3370, 'eps':     0.3999, 'len': 46610.8910, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  717000, Reward:   553.747 [ 312.170], Avg:   335.646 (0.300) <0-23:40:12> ({'r_t':   585.6666, 'eps':     0.2999, 'len': 46643.9540, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  718000, Reward:   559.128 [ 253.947], Avg:   335.957 (0.200) <0-23:41:58> ({'r_t':   868.1180, 'eps':     0.1999, 'len': 46676.0170, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  719000, Reward:   529.122 [ 353.512], Avg:   336.226 (0.100) <0-23:43:51> ({'r_t':  1135.1056, 'eps':     0.0999, 'len': 46709.1070, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  720000, Reward:   639.770 [  71.353], Avg:   336.647 (1.000) <0-23:55:03> ({'r_t':  1329.0085, 'eps':     0.9999, 'len': 46741.3770, 'dyn_loss':    16.6253, 'dot_loss':     2.0438, 'ddot_loss':     4.8017, 'rew_loss':   147.8871, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  721000, Reward:   664.319 [  86.799], Avg:   337.100 (0.900) <0-23:56:02> ({'r_t': -2231.0017, 'eps':     0.8999, 'len': 46808.8530, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  722000, Reward:   630.767 [  81.027], Avg:   337.507 (0.800) <0-23:57:05> ({'r_t': -1626.7724, 'eps':     0.7999, 'len': 46908.7850, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  723000, Reward:   360.284 [ 587.981], Avg:   337.538 (0.700) <0-23:58:15> ({'r_t': -1126.9349, 'eps':     0.6999, 'len': 46991.3630, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  724000, Reward:   594.601 [ 175.228], Avg:   337.893 (0.600) <0-23:59:32> ({'r_t':  -847.4814, 'eps':     0.5999, 'len': 47060.9470, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  725000, Reward:   603.912 [ 192.448], Avg:   338.259 (0.500) <1-00:00:56> ({'r_t':  -179.0690, 'eps':     0.4999, 'len': 47107.0500, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  726000, Reward:   656.098 [  97.779], Avg:   338.696 (0.400) <1-00:02:28> ({'r_t':   216.9671, 'eps':     0.3999, 'len': 47143.4060, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  727000, Reward:   642.490 [ 169.525], Avg:   339.113 (0.300) <1-00:04:06> ({'r_t':   476.2339, 'eps':     0.2999, 'len': 47176.2760, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  728000, Reward:   650.682 [  78.946], Avg:   339.541 (0.200) <1-00:05:52> ({'r_t':   931.3645, 'eps':     0.1999, 'len': 47208.3550, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  729000, Reward:   560.539 [ 245.408], Avg:   339.844 (0.100) <1-00:07:45> ({'r_t':  1073.2552, 'eps':     0.0999, 'len': 47240.3910, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  730000, Reward:   583.901 [ 368.399], Avg:   340.177 (1.000) <1-00:18:53> ({'r_t':  1157.2290, 'eps':     0.9999, 'len': 47273.1830, 'dyn_loss':    16.8223, 'dot_loss':     2.0597, 'ddot_loss':     4.8289, 'rew_loss':   154.3170, 'lr':   5.12e-05, 'eps_e':     0.9999, 'lr_e':   5.12e-05})
Step:  731000, Reward:   585.652 [ 131.215], Avg:   340.513 (0.900) <1-00:19:52> ({'r_t': -1532.7922, 'eps':     0.8999, 'len': 47339.9910, 'lr':   5.12e-05, 'eps_e':     0.8999, 'lr_e':   5.12e-05})
Step:  732000, Reward:   634.679 [  82.571], Avg:   340.914 (0.800) <1-00:20:55> ({'r_t': -1284.1454, 'eps':     0.7999, 'len': 47442.5090, 'lr':   5.12e-05, 'eps_e':     0.7999, 'lr_e':   5.12e-05})
Step:  733000, Reward:   569.922 [ 185.246], Avg:   341.226 (0.700) <1-00:22:05> ({'r_t': -1589.5246, 'eps':     0.6999, 'len': 47523.5580, 'lr':   5.12e-05, 'eps_e':     0.6999, 'lr_e':   5.12e-05})
Step:  734000, Reward:   572.820 [ 376.206], Avg:   341.541 (0.600) <1-00:23:22> ({'r_t':  -829.0756, 'eps':     0.5999, 'len': 47584.3850, 'lr':   5.12e-05, 'eps_e':     0.5999, 'lr_e':   5.12e-05})
Step:  735000, Reward:   598.881 [  91.137], Avg:   341.891 (0.500) <1-00:24:46> ({'r_t':  -180.7357, 'eps':     0.4999, 'len': 47633.3220, 'lr':   5.12e-05, 'eps_e':     0.4999, 'lr_e':   5.12e-05})
Step:  736000, Reward:   567.842 [ 378.031], Avg:   342.197 (0.400) <1-00:26:17> ({'r_t':   278.3756, 'eps':     0.3999, 'len': 47668.8480, 'lr':   5.12e-05, 'eps_e':     0.3999, 'lr_e':   5.12e-05})
Step:  737000, Reward:   664.462 [  84.220], Avg:   342.634 (0.300) <1-00:27:56> ({'r_t':   429.3882, 'eps':     0.2999, 'len': 47701.4240, 'lr':   5.12e-05, 'eps_e':     0.2999, 'lr_e':   5.12e-05})
Step:  738000, Reward:   664.522 [  83.363], Avg:   343.070 (0.200) <1-00:29:42> ({'r_t':   861.1198, 'eps':     0.1999, 'len': 47733.3880, 'lr':   5.12e-05, 'eps_e':     0.1999, 'lr_e':   5.12e-05})
Step:  739000, Reward:   564.210 [ 351.445], Avg:   343.369 (0.100) <1-00:31:34> ({'r_t':   926.0035, 'eps':     0.0999, 'len': 47765.3240, 'lr':   5.12e-05, 'eps_e':     0.0999, 'lr_e':   5.12e-05})
Step:  740000, Reward:   626.137 [  88.561], Avg:   343.750 (1.000) <1-00:42:48> ({'r_t':  1336.4321, 'eps':     0.9999, 'len': 47798.1370, 'dyn_loss':    16.6334, 'dot_loss':     2.0575, 'ddot_loss':     4.8421, 'rew_loss':   153.1931, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  741000, Reward:   526.991 [ 444.643], Avg:   343.997 (0.900) <1-00:43:47> ({'r_t': -1449.2576, 'eps':     0.8999, 'len': 47859.5450, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  742000, Reward:   568.193 [ 157.172], Avg:   344.299 (0.800) <1-00:44:51> ({'r_t': -1417.3542, 'eps':     0.7999, 'len': 47954.4150, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  743000, Reward:   618.206 [ 173.230], Avg:   344.667 (0.700) <1-00:46:01> ({'r_t': -1114.3829, 'eps':     0.6999, 'len': 48040.8150, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  744000, Reward:   513.494 [ 217.234], Avg:   344.894 (0.600) <1-00:47:18> ({'r_t':  -735.6318, 'eps':     0.5999, 'len': 48103.5990, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  745000, Reward:   392.304 [ 373.491], Avg:   344.957 (0.500) <1-00:48:42> ({'r_t':  -242.4748, 'eps':     0.4999, 'len': 48150.9320, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  746000, Reward:   663.888 [  81.239], Avg:   345.384 (0.400) <1-00:50:13> ({'r_t':   253.4649, 'eps':     0.3999, 'len': 48187.5940, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  747000, Reward:   423.699 [ 420.793], Avg:   345.489 (0.300) <1-00:51:51> ({'r_t':   613.4758, 'eps':     0.2999, 'len': 48220.1760, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  748000, Reward:   586.967 [ 194.940], Avg:   345.811 (0.200) <1-00:53:37> ({'r_t':   912.2091, 'eps':     0.1999, 'len': 48252.7220, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  749000, Reward:   668.077 [  87.623], Avg:   346.241 (0.100) <1-00:55:30> ({'r_t':   990.9537, 'eps':     0.0999, 'len': 48284.8940, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  750000, Reward:   614.457 [  67.146], Avg:   346.598 (1.000) <1-01:06:33> ({'r_t':  1347.5682, 'eps':     0.9999, 'len': 48317.4820, 'dyn_loss':    16.4176, 'dot_loss':     2.0081, 'ddot_loss':     4.7098, 'rew_loss':   159.4350, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  751000, Reward:   670.923 [  91.596], Avg:   347.029 (0.900) <1-01:07:32> ({'r_t': -1591.3562, 'eps':     0.8999, 'len': 48378.3810, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  752000, Reward:   624.332 [ 186.334], Avg:   347.398 (0.800) <1-01:08:36> ({'r_t': -1451.6737, 'eps':     0.7999, 'len': 48479.2230, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  753000, Reward:   552.664 [ 180.243], Avg:   347.670 (0.700) <1-01:09:46> ({'r_t': -1175.9218, 'eps':     0.6999, 'len': 48566.8020, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  754000, Reward:   627.956 [  64.770], Avg:   348.041 (0.600) <1-01:11:03> ({'r_t':  -772.0415, 'eps':     0.5999, 'len': 48631.4200, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  755000, Reward:   561.696 [ 339.924], Avg:   348.324 (0.500) <1-01:12:27> ({'r_t':  -295.3403, 'eps':     0.4999, 'len': 48679.5890, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  756000, Reward:   556.597 [ 173.754], Avg:   348.599 (0.400) <1-01:13:58> ({'r_t':   275.1737, 'eps':     0.3999, 'len': 48714.4320, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  757000, Reward:   586.290 [ 154.976], Avg:   348.912 (0.300) <1-01:15:36> ({'r_t':   491.7993, 'eps':     0.2999, 'len': 48746.8080, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  758000, Reward:   685.020 [  97.198], Avg:   349.355 (0.200) <1-01:17:22> ({'r_t':   802.2931, 'eps':     0.1999, 'len': 48778.8120, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  759000, Reward:   605.082 [ 167.738], Avg:   349.692 (0.100) <1-01:19:15> ({'r_t':  1105.6349, 'eps':     0.0999, 'len': 48811.1260, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  760000, Reward:   662.656 [  82.007], Avg:   350.103 (1.000) <1-01:30:29> ({'r_t':  1201.5677, 'eps':     0.9999, 'len': 48843.8300, 'dyn_loss':    16.4259, 'dot_loss':     2.0206, 'ddot_loss':     4.7422, 'rew_loss':   148.6340, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  761000, Reward:   353.614 [ 627.469], Avg:   350.108 (0.900) <1-01:31:28> ({'r_t': -1674.2194, 'eps':     0.8999, 'len': 48908.9080, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  762000, Reward:   531.274 [ 399.298], Avg:   350.345 (0.800) <1-01:32:31> ({'r_t': -1572.0728, 'eps':     0.7999, 'len': 49013.6170, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  763000, Reward:   524.186 [ 398.962], Avg:   350.573 (0.700) <1-01:33:41> ({'r_t': -1236.0204, 'eps':     0.6999, 'len': 49101.7500, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  764000, Reward:   633.457 [  88.568], Avg:   350.942 (0.600) <1-01:34:58> ({'r_t':  -847.6949, 'eps':     0.5999, 'len': 49166.6610, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  765000, Reward:   451.629 [ 480.983], Avg:   351.074 (0.500) <1-01:36:23> ({'r_t':  -280.0475, 'eps':     0.4999, 'len': 49212.2240, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  766000, Reward:   445.737 [ 479.540], Avg:   351.197 (0.400) <1-01:37:54> ({'r_t':   211.1660, 'eps':     0.3999, 'len': 49248.7460, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  767000, Reward:   587.174 [ 225.528], Avg:   351.504 (0.300) <1-01:39:32> ({'r_t':   641.1452, 'eps':     0.2999, 'len': 49281.4240, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  768000, Reward:   666.872 [  90.698], Avg:   351.915 (0.200) <1-01:41:18> ({'r_t':   765.0644, 'eps':     0.1999, 'len': 49313.6620, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  769000, Reward:   556.192 [ 399.047], Avg:   352.180 (0.100) <1-01:43:10> ({'r_t':  1067.2562, 'eps':     0.0999, 'len': 49345.9740, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  770000, Reward:   516.138 [ 353.158], Avg:   352.393 (1.000) <1-01:54:26> ({'r_t':  1250.3018, 'eps':     0.9999, 'len': 49378.2770, 'dyn_loss':    16.3956, 'dot_loss':     2.0073, 'ddot_loss':     4.7075, 'rew_loss':   148.7814, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  771000, Reward:   653.755 [  93.972], Avg:   352.783 (0.900) <1-01:55:25> ({'r_t': -1512.7772, 'eps':     0.8999, 'len': 49446.8640, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  772000, Reward:   717.937 [  73.905], Avg:   353.255 (0.800) <1-01:56:29> ({'r_t': -1722.0554, 'eps':     0.7999, 'len': 49555.1800, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  773000, Reward:   644.490 [ 125.119], Avg:   353.632 (0.700) <1-01:57:39> ({'r_t': -1188.5511, 'eps':     0.6999, 'len': 49639.9890, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  774000, Reward:   580.222 [ 155.078], Avg:   353.924 (0.600) <1-01:58:56> ({'r_t':  -858.0010, 'eps':     0.5999, 'len': 49700.6390, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  775000, Reward:   413.595 [ 528.304], Avg:   354.001 (0.500) <1-02:00:20> ({'r_t':  -239.9244, 'eps':     0.4999, 'len': 49749.4690, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  776000, Reward:   593.805 [ 173.393], Avg:   354.309 (0.400) <1-02:01:51> ({'r_t':   184.4920, 'eps':     0.3999, 'len': 49785.8800, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  777000, Reward:   570.512 [ 372.216], Avg:   354.587 (0.300) <1-02:03:30> ({'r_t':   682.1646, 'eps':     0.2999, 'len': 49818.0500, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  778000, Reward:   454.485 [ 517.660], Avg:   354.716 (0.200) <1-02:05:16> ({'r_t':   607.7701, 'eps':     0.1999, 'len': 49850.2520, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  779000, Reward:   627.696 [ 135.423], Avg:   355.066 (0.100) <1-02:07:09> ({'r_t':  1154.1197, 'eps':     0.0999, 'len': 49882.2490, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  780000, Reward:   632.033 [  80.238], Avg:   355.420 (1.000) <1-02:18:31> ({'r_t':  1197.4730, 'eps':     0.9999, 'len': 49914.5990, 'dyn_loss':    16.1460, 'dot_loss':     1.9830, 'ddot_loss':     4.6646, 'rew_loss':   152.8670, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  781000, Reward:   592.477 [ 392.197], Avg:   355.723 (0.900) <1-02:19:30> ({'r_t': -1519.8279, 'eps':     0.8999, 'len': 49979.5530, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  782000, Reward:   644.779 [  92.184], Avg:   356.092 (0.800) <1-02:20:33> ({'r_t': -1441.3664, 'eps':     0.7999, 'len': 50080.6860, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  783000, Reward:   648.323 [ 100.121], Avg:   356.465 (0.700) <1-02:21:44> ({'r_t': -1271.3367, 'eps':     0.6999, 'len': 50167.6710, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  784000, Reward:   681.217 [  73.906], Avg:   356.879 (0.600) <1-02:23:01> ({'r_t':  -799.3087, 'eps':     0.5999, 'len': 50227.3870, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  785000, Reward:   641.767 [  88.324], Avg:   357.241 (0.500) <1-02:24:25> ({'r_t':  -231.0292, 'eps':     0.4999, 'len': 50271.2540, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  786000, Reward:   561.640 [ 250.408], Avg:   357.501 (0.400) <1-02:25:56> ({'r_t':   248.9287, 'eps':     0.3999, 'len': 50306.0620, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  787000, Reward:   502.785 [ 401.233], Avg:   357.685 (0.300) <1-02:27:34> ({'r_t':   676.3296, 'eps':     0.2999, 'len': 50338.4230, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  788000, Reward:   574.323 [ 367.661], Avg:   357.960 (0.200) <1-02:29:20> ({'r_t':   883.8861, 'eps':     0.1999, 'len': 50370.5600, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  789000, Reward:   615.035 [ 205.499], Avg:   358.285 (0.100) <1-02:31:13> ({'r_t':  1123.6572, 'eps':     0.0999, 'len': 50402.4960, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  790000, Reward:   633.937 [  70.832], Avg:   358.634 (1.000) <1-02:42:29> ({'r_t':  1282.5357, 'eps':     0.9999, 'len': 50434.9600, 'dyn_loss':    16.1657, 'dot_loss':     2.0124, 'ddot_loss':     4.7366, 'rew_loss':   148.8453, 'lr':   4.10e-05, 'eps_e':     0.9999, 'lr_e':   4.10e-05})
Step:  791000, Reward:   692.210 [  61.645], Avg:   359.055 (0.900) <1-02:43:28> ({'r_t': -1801.7889, 'eps':     0.8999, 'len': 50499.8050, 'lr':   4.10e-05, 'eps_e':     0.8999, 'lr_e':   4.10e-05})
Step:  792000, Reward:   651.304 [ 115.498], Avg:   359.424 (0.800) <1-02:44:32> ({'r_t': -1457.4147, 'eps':     0.7999, 'len': 50602.6920, 'lr':   4.10e-05, 'eps_e':     0.7999, 'lr_e':   4.10e-05})
Step:  793000, Reward:   598.481 [ 381.749], Avg:   359.725 (0.700) <1-02:45:42> ({'r_t': -1161.1094, 'eps':     0.6999, 'len': 50683.5380, 'lr':   4.10e-05, 'eps_e':     0.6999, 'lr_e':   4.10e-05})
Step:  794000, Reward:   662.355 [  91.926], Avg:   360.105 (0.600) <1-02:46:59> ({'r_t':  -791.6319, 'eps':     0.5999, 'len': 50747.0460, 'lr':   4.10e-05, 'eps_e':     0.5999, 'lr_e':   4.10e-05})
Step:  795000, Reward:   630.276 [  73.360], Avg:   360.445 (0.500) <1-02:48:23> ({'r_t':  -237.9303, 'eps':     0.4999, 'len': 50792.3210, 'lr':   4.10e-05, 'eps_e':     0.4999, 'lr_e':   4.10e-05})
Step:  796000, Reward:   631.331 [ 107.573], Avg:   360.785 (0.400) <1-02:49:54> ({'r_t':   152.8631, 'eps':     0.3999, 'len': 50829.1640, 'lr':   4.10e-05, 'eps_e':     0.3999, 'lr_e':   4.10e-05})
Step:  797000, Reward:   620.327 [  83.514], Avg:   361.110 (0.300) <1-02:51:32> ({'r_t':   558.7467, 'eps':     0.2999, 'len': 50861.8040, 'lr':   4.10e-05, 'eps_e':     0.2999, 'lr_e':   4.10e-05})
Step:  798000, Reward:   652.865 [ 107.110], Avg:   361.475 (0.200) <1-02:53:18> ({'r_t':   949.5648, 'eps':     0.1999, 'len': 50893.9040, 'lr':   4.10e-05, 'eps_e':     0.1999, 'lr_e':   4.10e-05})
Step:  799000, Reward:   682.417 [  59.595], Avg:   361.876 (0.100) <1-02:55:11> ({'r_t':  1205.8105, 'eps':     0.0999, 'len': 50925.9510, 'lr':   4.10e-05, 'eps_e':     0.0999, 'lr_e':   4.10e-05})
Step:  800000, Reward:   681.898 [  76.016], Avg:   362.276 (1.000) <1-03:06:22> ({'r_t':  1257.4225, 'eps':     0.9999, 'len': 50957.9980, 'dyn_loss':    15.9639, 'dot_loss':     1.9795, 'ddot_loss':     4.6606, 'rew_loss':   151.9257, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  801000, Reward:   705.638 [  82.641], Avg:   362.704 (0.900) <1-03:07:21> ({'r_t': -1709.3762, 'eps':     0.8999, 'len': 51023.4780, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  802000, Reward:   662.485 [  79.958], Avg:   363.077 (0.800) <1-03:08:25> ({'r_t': -1705.8842, 'eps':     0.7999, 'len': 51121.6540, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  803000, Reward:   604.617 [ 355.437], Avg:   363.378 (0.700) <1-03:09:35> ({'r_t': -1112.5175, 'eps':     0.6999, 'len': 51202.2010, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  804000, Reward:   537.013 [ 379.906], Avg:   363.593 (0.600) <1-03:10:52> ({'r_t':  -890.2014, 'eps':     0.5999, 'len': 51262.0210, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  805000, Reward:   609.553 [ 130.777], Avg:   363.899 (0.500) <1-03:12:16> ({'r_t':  -248.3487, 'eps':     0.4999, 'len': 51310.3030, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  806000, Reward:   666.089 [  77.697], Avg:   364.273 (0.400) <1-03:13:48> ({'r_t':   237.2207, 'eps':     0.3999, 'len': 51345.4300, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  807000, Reward:   673.184 [  65.357], Avg:   364.655 (0.300) <1-03:15:27> ({'r_t':   595.2541, 'eps':     0.2999, 'len': 51377.6700, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  808000, Reward:   572.926 [ 367.988], Avg:   364.913 (0.200) <1-03:17:13> ({'r_t':   928.7553, 'eps':     0.1999, 'len': 51409.7690, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  809000, Reward:   664.951 [ 131.284], Avg:   365.283 (0.100) <1-03:19:06> ({'r_t':  1212.4069, 'eps':     0.0999, 'len': 51442.0510, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  810000, Reward:   669.336 [  71.948], Avg:   365.658 (1.000) <1-03:30:34> ({'r_t':  1375.9346, 'eps':     0.9999, 'len': 51474.5190, 'dyn_loss':    15.7703, 'dot_loss':     1.9466, 'ddot_loss':     4.5843, 'rew_loss':   139.8675, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  811000, Reward:   633.469 [ 185.702], Avg:   365.988 (0.900) <1-03:31:34> ({'r_t': -1682.3082, 'eps':     0.8999, 'len': 51543.2050, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  812000, Reward:   515.782 [ 355.461], Avg:   366.172 (0.800) <1-03:32:38> ({'r_t': -1563.8661, 'eps':     0.7999, 'len': 51645.9330, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  813000, Reward:   589.423 [ 286.465], Avg:   366.446 (0.700) <1-03:33:48> ({'r_t': -1134.0734, 'eps':     0.6999, 'len': 51728.7820, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  814000, Reward:   630.495 [  88.808], Avg:   366.770 (0.600) <1-03:35:05> ({'r_t':  -942.7424, 'eps':     0.5999, 'len': 51789.1020, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  815000, Reward:   647.874 [  73.805], Avg:   367.115 (0.500) <1-03:36:29> ({'r_t':  -320.7705, 'eps':     0.4999, 'len': 51834.2180, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  816000, Reward:   437.976 [ 389.955], Avg:   367.202 (0.400) <1-03:38:01> ({'r_t':   201.0264, 'eps':     0.3999, 'len': 51870.0970, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  817000, Reward:   593.335 [ 368.798], Avg:   367.478 (0.300) <1-03:39:39> ({'r_t':   518.0716, 'eps':     0.2999, 'len': 51903.6780, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  818000, Reward:   650.380 [ 102.578], Avg:   367.823 (0.200) <1-03:41:25> ({'r_t':   901.5723, 'eps':     0.1999, 'len': 51936.4440, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  819000, Reward:   659.886 [ 141.840], Avg:   368.180 (0.100) <1-03:43:19> ({'r_t':   898.5407, 'eps':     0.0999, 'len': 51968.3800, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  820000, Reward:   720.240 [  77.997], Avg:   368.608 (1.000) <1-03:54:43> ({'r_t':  1355.7473, 'eps':     0.9999, 'len': 52000.7420, 'dyn_loss':    15.7071, 'dot_loss':     1.9425, 'ddot_loss':     4.5696, 'rew_loss':   153.5361, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  821000, Reward:   620.329 [ 100.430], Avg:   368.915 (0.900) <1-03:55:42> ({'r_t': -1694.6113, 'eps':     0.8999, 'len': 52069.9720, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  822000, Reward:   679.791 [  67.090], Avg:   369.292 (0.800) <1-03:56:46> ({'r_t': -1481.1003, 'eps':     0.7999, 'len': 52171.3040, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  823000, Reward:   649.081 [  58.369], Avg:   369.632 (0.700) <1-03:57:56> ({'r_t': -1179.2586, 'eps':     0.6999, 'len': 52255.0330, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  824000, Reward:   647.561 [  86.693], Avg:   369.969 (0.600) <1-03:59:14> ({'r_t':  -753.1022, 'eps':     0.5999, 'len': 52318.0320, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  825000, Reward:   630.073 [  94.497], Avg:   370.284 (0.500) <1-04:00:38> ({'r_t':  -375.9977, 'eps':     0.4999, 'len': 52369.2930, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  826000, Reward:   638.847 [  85.577], Avg:   370.609 (0.400) <1-04:02:09> ({'r_t':   224.8602, 'eps':     0.3999, 'len': 52405.0210, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  827000, Reward:   526.183 [ 341.965], Avg:   370.796 (0.300) <1-04:03:48> ({'r_t':   650.6987, 'eps':     0.2999, 'len': 52438.0170, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  828000, Reward:   647.776 [ 114.582], Avg:   371.131 (0.200) <1-04:05:34> ({'r_t':   865.0878, 'eps':     0.1999, 'len': 52470.4800, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  829000, Reward:   680.871 [ 100.457], Avg:   371.504 (0.100) <1-04:07:28> ({'r_t':  1076.2287, 'eps':     0.0999, 'len': 52502.5470, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  830000, Reward:   664.600 [ 138.618], Avg:   371.856 (1.000) <1-04:19:02> ({'r_t':  1332.0889, 'eps':     0.9999, 'len': 52534.7820, 'dyn_loss':    15.7668, 'dot_loss':     1.9507, 'ddot_loss':     4.5902, 'rew_loss':   123.2508, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  831000, Reward:   546.244 [ 423.932], Avg:   372.066 (0.900) <1-04:20:01> ({'r_t': -1562.4221, 'eps':     0.8999, 'len': 52598.4250, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  832000, Reward:   651.387 [ 194.132], Avg:   372.401 (0.800) <1-04:21:05> ({'r_t': -1429.4321, 'eps':     0.7999, 'len': 52696.4940, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  833000, Reward:   692.710 [  87.867], Avg:   372.785 (0.700) <1-04:22:15> ({'r_t': -1096.1821, 'eps':     0.6999, 'len': 52783.7890, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  834000, Reward:   685.290 [  76.126], Avg:   373.160 (0.600) <1-04:23:32> ({'r_t':  -882.4467, 'eps':     0.5999, 'len': 52848.2000, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  835000, Reward:   537.799 [ 344.949], Avg:   373.357 (0.500) <1-04:24:57> ({'r_t':  -347.0207, 'eps':     0.4999, 'len': 52897.6050, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  836000, Reward:   642.390 [ 101.892], Avg:   373.678 (0.400) <1-04:26:28> ({'r_t':   160.7956, 'eps':     0.3999, 'len': 52933.7760, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  837000, Reward:   605.724 [ 214.676], Avg:   373.955 (0.300) <1-04:28:07> ({'r_t':   593.5933, 'eps':     0.2999, 'len': 52966.5010, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  838000, Reward:   659.318 [ 114.418], Avg:   374.295 (0.200) <1-04:29:53> ({'r_t':   891.4271, 'eps':     0.1999, 'len': 52998.9300, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  839000, Reward:   533.134 [ 250.283], Avg:   374.484 (0.100) <1-04:31:46> ({'r_t':  1157.2649, 'eps':     0.0999, 'len': 53031.1980, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  840000, Reward:   629.173 [ 253.367], Avg:   374.787 (1.000) <1-04:43:12> ({'r_t':  1324.2877, 'eps':     0.9999, 'len': 53063.4680, 'dyn_loss':    15.5489, 'dot_loss':     1.9307, 'ddot_loss':     4.5483, 'rew_loss':   149.0477, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  841000, Reward:   531.552 [ 352.022], Avg:   374.973 (0.900) <1-04:44:11> ({'r_t': -1978.3502, 'eps':     0.8999, 'len': 53127.4190, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  842000, Reward:   590.936 [ 364.229], Avg:   375.229 (0.800) <1-04:45:14> ({'r_t': -1481.9061, 'eps':     0.7999, 'len': 53226.4140, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  843000, Reward:   542.621 [ 379.971], Avg:   375.428 (0.700) <1-04:46:24> ({'r_t': -1203.8763, 'eps':     0.6999, 'len': 53309.8660, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  844000, Reward:   652.528 [  97.713], Avg:   375.756 (0.600) <1-04:47:41> ({'r_t':  -783.8853, 'eps':     0.5999, 'len': 53375.9390, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  845000, Reward:   666.127 [  99.258], Avg:   376.099 (0.500) <1-04:49:05> ({'r_t':  -377.2671, 'eps':     0.4999, 'len': 53426.7670, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  846000, Reward:   671.972 [ 113.267], Avg:   376.448 (0.400) <1-04:50:37> ({'r_t':    77.4670, 'eps':     0.3999, 'len': 53463.6950, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  847000, Reward:   652.977 [  82.127], Avg:   376.774 (0.300) <1-04:52:15> ({'r_t':   478.5550, 'eps':     0.2999, 'len': 53497.6070, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  848000, Reward:   648.372 [  84.672], Avg:   377.094 (0.200) <1-04:54:01> ({'r_t':   829.6069, 'eps':     0.1999, 'len': 53530.3320, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  849000, Reward:   565.422 [ 387.347], Avg:   377.316 (0.100) <1-04:55:54> ({'r_t':  1147.2018, 'eps':     0.0999, 'len': 53562.3340, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  850000, Reward:   675.183 [ 121.423], Avg:   377.666 (1.000) <1-05:07:26> ({'r_t':  1348.5825, 'eps':     0.9999, 'len': 53594.6590, 'dyn_loss':    15.7751, 'dot_loss':     1.9447, 'ddot_loss':     4.5661, 'rew_loss':   125.1541, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  851000, Reward:   540.979 [ 353.614], Avg:   377.857 (0.900) <1-05:08:25> ({'r_t': -1766.1893, 'eps':     0.8999, 'len': 53660.6100, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  852000, Reward:   549.024 [ 351.959], Avg:   378.058 (0.800) <1-05:09:29> ({'r_t': -1304.6423, 'eps':     0.7999, 'len': 53761.2220, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  853000, Reward:   690.222 [  75.733], Avg:   378.424 (0.700) <1-05:10:39> ({'r_t': -1253.5120, 'eps':     0.6999, 'len': 53842.4760, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  854000, Reward:   552.670 [ 192.971], Avg:   378.627 (0.600) <1-05:11:56> ({'r_t':  -895.4995, 'eps':     0.5999, 'len': 53910.4410, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  855000, Reward:   639.127 [ 103.336], Avg:   378.932 (0.500) <1-05:13:20> ({'r_t':  -218.5566, 'eps':     0.4999, 'len': 53957.6900, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  856000, Reward:   652.702 [  70.165], Avg:   379.251 (0.400) <1-05:14:52> ({'r_t':   211.9710, 'eps':     0.3999, 'len': 53994.0490, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  857000, Reward:   594.897 [ 355.569], Avg:   379.503 (0.300) <1-05:16:30> ({'r_t':   438.9083, 'eps':     0.2999, 'len': 54026.5500, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  858000, Reward:   617.178 [ 165.425], Avg:   379.779 (0.200) <1-05:18:16> ({'r_t':   788.0315, 'eps':     0.1999, 'len': 54059.1830, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  859000, Reward:   606.487 [ 200.225], Avg:   380.043 (0.100) <1-05:20:09> ({'r_t':   975.4399, 'eps':     0.0999, 'len': 54091.8860, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  860000, Reward:   628.863 [ 203.506], Avg:   380.332 (1.000) <1-05:31:32> ({'r_t':  1226.7324, 'eps':     0.9999, 'len': 54125.4270, 'dyn_loss':    15.4382, 'dot_loss':     1.9175, 'ddot_loss':     4.5134, 'rew_loss':   132.2921, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  861000, Reward:   678.953 [ 103.194], Avg:   380.678 (0.900) <1-05:32:31> ({'r_t': -1506.3580, 'eps':     0.8999, 'len': 54193.9550, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  862000, Reward:   681.451 [  79.095], Avg:   381.027 (0.800) <1-05:33:35> ({'r_t': -1333.8471, 'eps':     0.7999, 'len': 54290.6480, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  863000, Reward:   707.237 [  74.613], Avg:   381.404 (0.700) <1-05:34:45> ({'r_t': -1307.2313, 'eps':     0.6999, 'len': 54370.5060, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  864000, Reward:   675.778 [  85.655], Avg:   381.745 (0.600) <1-05:36:02> ({'r_t':  -902.0511, 'eps':     0.5999, 'len': 54434.7060, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  865000, Reward:   609.450 [ 152.964], Avg:   382.008 (0.500) <1-05:37:26> ({'r_t':  -198.9114, 'eps':     0.4999, 'len': 54479.0340, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  866000, Reward:   447.394 [ 459.418], Avg:   382.083 (0.400) <1-05:38:57> ({'r_t':   266.3771, 'eps':     0.3999, 'len': 54514.3380, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  867000, Reward:   690.940 [  73.860], Avg:   382.439 (0.300) <1-05:40:35> ({'r_t':   500.4288, 'eps':     0.2999, 'len': 54547.5500, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  868000, Reward:   608.937 [ 198.534], Avg:   382.699 (0.200) <1-05:42:21> ({'r_t':   938.2023, 'eps':     0.1999, 'len': 54579.7210, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  869000, Reward:   636.014 [ 170.959], Avg:   382.991 (0.100) <1-05:44:14> ({'r_t':  1105.8064, 'eps':     0.0999, 'len': 54611.8200, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  870000, Reward:   444.444 [ 410.288], Avg:   383.061 (1.000) <1-05:55:47> ({'r_t':  1389.9938, 'eps':     0.9999, 'len': 54643.9760, 'dyn_loss':    15.7535, 'dot_loss':     1.9312, 'ddot_loss':     4.5523, 'rew_loss':   128.1856, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  871000, Reward:   664.954 [  99.196], Avg:   383.384 (0.900) <1-05:56:46> ({'r_t': -1733.0633, 'eps':     0.8999, 'len': 54709.5720, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  872000, Reward:   573.771 [ 252.295], Avg:   383.603 (0.800) <1-05:57:50> ({'r_t': -1365.8312, 'eps':     0.7999, 'len': 54815.5570, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  873000, Reward:   620.320 [ 160.665], Avg:   383.873 (0.700) <1-05:59:00> ({'r_t': -1250.4144, 'eps':     0.6999, 'len': 54902.0580, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  874000, Reward:   578.449 [ 193.756], Avg:   384.096 (0.600) <1-06:00:17> ({'r_t':  -851.5432, 'eps':     0.5999, 'len': 54964.0120, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  875000, Reward:   523.936 [ 389.529], Avg:   384.255 (0.500) <1-06:01:41> ({'r_t':  -212.1646, 'eps':     0.4999, 'len': 55003.8520, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  876000, Reward:   592.639 [ 216.180], Avg:   384.493 (0.400) <1-06:03:12> ({'r_t':   155.0834, 'eps':     0.3999, 'len': 55038.4210, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  877000, Reward:   666.832 [  84.227], Avg:   384.815 (0.300) <1-06:04:51> ({'r_t':   517.2168, 'eps':     0.2999, 'len': 55070.5420, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  878000, Reward:   649.595 [  68.683], Avg:   385.116 (0.200) <1-06:06:37> ({'r_t':   696.6395, 'eps':     0.1999, 'len': 55102.4780, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  879000, Reward:   534.116 [ 349.230], Avg:   385.285 (0.100) <1-06:08:29> ({'r_t':  1211.6647, 'eps':     0.0999, 'len': 55134.5320, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  880000, Reward:   531.010 [ 386.786], Avg:   385.451 (1.000) <1-06:19:58> ({'r_t':  1226.7179, 'eps':     0.9999, 'len': 55166.6920, 'dyn_loss':    15.6003, 'dot_loss':     1.9288, 'ddot_loss':     4.5418, 'rew_loss':   149.6866, 'lr':   3.28e-05, 'eps_e':     0.9999, 'lr_e':   3.28e-05})
Step:  881000, Reward:   690.083 [  63.227], Avg:   385.796 (0.900) <1-06:20:57> ({'r_t': -1562.9946, 'eps':     0.8999, 'len': 55232.4310, 'lr':   3.28e-05, 'eps_e':     0.8999, 'lr_e':   3.28e-05})
Step:  882000, Reward:   622.063 [ 177.872], Avg:   386.063 (0.800) <1-06:22:01> ({'r_t': -1319.5055, 'eps':     0.7999, 'len': 55329.6360, 'lr':   3.28e-05, 'eps_e':     0.7999, 'lr_e':   3.28e-05})
Step:  883000, Reward:   663.682 [ 155.619], Avg:   386.378 (0.700) <1-06:23:11> ({'r_t': -1189.4655, 'eps':     0.6999, 'len': 55417.0110, 'lr':   3.28e-05, 'eps_e':     0.6999, 'lr_e':   3.28e-05})
Step:  884000, Reward:   574.495 [ 195.143], Avg:   386.590 (0.600) <1-06:24:28> ({'r_t':  -938.0463, 'eps':     0.5999, 'len': 55480.7750, 'lr':   3.28e-05, 'eps_e':     0.5999, 'lr_e':   3.28e-05})
Step:  885000, Reward:   649.966 [ 123.859], Avg:   386.887 (0.500) <1-06:25:52> ({'r_t':  -210.6591, 'eps':     0.4999, 'len': 55524.4120, 'lr':   3.28e-05, 'eps_e':     0.4999, 'lr_e':   3.28e-05})
Step:  886000, Reward:   658.370 [  86.906], Avg:   387.193 (0.400) <1-06:27:23> ({'r_t':   235.2357, 'eps':     0.3999, 'len': 55560.4670, 'lr':   3.28e-05, 'eps_e':     0.3999, 'lr_e':   3.28e-05})
Step:  887000, Reward:   629.722 [ 180.853], Avg:   387.467 (0.300) <1-06:29:01> ({'r_t':   683.1375, 'eps':     0.2999, 'len': 55592.7440, 'lr':   3.28e-05, 'eps_e':     0.2999, 'lr_e':   3.28e-05})
Step:  888000, Reward:   661.403 [ 116.536], Avg:   387.775 (0.200) <1-06:30:47> ({'r_t':  1000.7237, 'eps':     0.1999, 'len': 55625.0640, 'lr':   3.28e-05, 'eps_e':     0.1999, 'lr_e':   3.28e-05})
Step:  889000, Reward:   614.752 [ 216.596], Avg:   388.030 (0.100) <1-06:32:40> ({'r_t':  1177.9935, 'eps':     0.0999, 'len': 55658.1840, 'lr':   3.28e-05, 'eps_e':     0.0999, 'lr_e':   3.28e-05})
Step:  890000, Reward:   673.256 [  98.656], Avg:   388.350 (1.000) <1-06:44:22> ({'r_t':  1090.7937, 'eps':     0.9999, 'len': 55690.9050, 'dyn_loss':    15.7209, 'dot_loss':     1.9209, 'ddot_loss':     4.5127, 'rew_loss':   126.4202, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  891000, Reward:   644.133 [ 188.342], Avg:   388.637 (0.900) <1-06:45:21> ({'r_t': -1981.7248, 'eps':     0.8999, 'len': 55755.7700, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  892000, Reward:   557.275 [ 395.823], Avg:   388.825 (0.800) <1-06:46:25> ({'r_t': -1362.4754, 'eps':     0.7999, 'len': 55845.1820, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  893000, Reward:   488.842 [ 402.935], Avg:   388.937 (0.700) <1-06:47:35> ({'r_t': -1179.3169, 'eps':     0.6999, 'len': 55922.4470, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  894000, Reward:   610.507 [ 143.290], Avg:   389.185 (0.600) <1-06:48:52> ({'r_t':  -766.7270, 'eps':     0.5999, 'len': 55982.8380, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  895000, Reward:   622.870 [ 131.251], Avg:   389.446 (0.500) <1-06:50:16> ({'r_t':  -274.9915, 'eps':     0.4999, 'len': 56028.5810, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  896000, Reward:   577.738 [ 253.829], Avg:   389.656 (0.400) <1-06:51:47> ({'r_t':   192.7527, 'eps':     0.3999, 'len': 56063.1840, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  897000, Reward:   558.991 [ 399.840], Avg:   389.844 (0.300) <1-06:53:25> ({'r_t':   602.4010, 'eps':     0.2999, 'len': 56095.6260, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  898000, Reward:   675.206 [  80.512], Avg:   390.162 (0.200) <1-06:55:11> ({'r_t':   882.5134, 'eps':     0.1999, 'len': 56128.5130, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  899000, Reward:   680.222 [ 190.612], Avg:   390.484 (0.100) <1-06:57:03> ({'r_t':  1028.6421, 'eps':     0.0999, 'len': 56160.9420, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  900000, Reward:   485.052 [ 469.650], Avg:   390.589 (1.000) <1-07:08:30> ({'r_t':  1295.9330, 'eps':     0.9999, 'len': 56193.2270, 'dyn_loss':    15.4882, 'dot_loss':     1.9047, 'ddot_loss':     4.4707, 'rew_loss':   131.7702, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  901000, Reward:   670.965 [ 110.017], Avg:   390.900 (0.900) <1-07:09:29> ({'r_t': -1696.3034, 'eps':     0.8999, 'len': 56260.1310, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  902000, Reward:   665.332 [  93.471], Avg:   391.204 (0.800) <1-07:10:33> ({'r_t': -1611.0210, 'eps':     0.7999, 'len': 56355.4190, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  903000, Reward:   567.338 [ 336.001], Avg:   391.398 (0.700) <1-07:11:43> ({'r_t': -1152.2029, 'eps':     0.6999, 'len': 56437.4490, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  904000, Reward:   632.217 [ 148.204], Avg:   391.665 (0.600) <1-07:13:00> ({'r_t':  -919.5584, 'eps':     0.5999, 'len': 56503.6150, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  905000, Reward:   618.935 [ 179.877], Avg:   391.915 (0.500) <1-07:14:24> ({'r_t':  -172.9551, 'eps':     0.4999, 'len': 56551.2280, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  906000, Reward:   622.604 [ 180.953], Avg:   392.170 (0.400) <1-07:15:55> ({'r_t':   281.0311, 'eps':     0.3999, 'len': 56586.4140, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  907000, Reward:   708.539 [  86.360], Avg:   392.518 (0.300) <1-07:17:33> ({'r_t':   599.5680, 'eps':     0.2999, 'len': 56618.3860, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  908000, Reward:   614.950 [ 209.291], Avg:   392.763 (0.200) <1-07:19:18> ({'r_t':   931.4045, 'eps':     0.1999, 'len': 56651.9100, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  909000, Reward:   602.794 [ 367.181], Avg:   392.994 (0.100) <1-07:21:11> ({'r_t':  1163.4496, 'eps':     0.0999, 'len': 56685.5130, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  910000, Reward:   581.191 [ 373.730], Avg:   393.200 (1.000) <1-07:32:45> ({'r_t':  1358.1775, 'eps':     0.9999, 'len': 56718.0740, 'dyn_loss':    15.3554, 'dot_loss':     1.8965, 'ddot_loss':     4.4719, 'rew_loss':   127.8801, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  911000, Reward:   719.093 [  62.860], Avg:   393.558 (0.900) <1-07:33:43> ({'r_t': -2034.9525, 'eps':     0.8999, 'len': 56780.4490, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  912000, Reward:   652.433 [  78.897], Avg:   393.841 (0.800) <1-07:34:47> ({'r_t': -1489.4936, 'eps':     0.7999, 'len': 56878.9860, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  913000, Reward:   616.169 [ 148.553], Avg:   394.084 (0.700) <1-07:35:57> ({'r_t': -1203.7086, 'eps':     0.6999, 'len': 56959.1510, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  914000, Reward:   660.503 [  75.546], Avg:   394.376 (0.600) <1-07:37:14> ({'r_t':  -741.5585, 'eps':     0.5999, 'len': 57022.8590, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  915000, Reward:   667.352 [  62.924], Avg:   394.674 (0.500) <1-07:38:38> ({'r_t':  -196.0669, 'eps':     0.4999, 'len': 57064.8660, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  916000, Reward:   561.550 [ 354.264], Avg:   394.856 (0.400) <1-07:40:09> ({'r_t':   253.8931, 'eps':     0.3999, 'len': 57099.6890, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  917000, Reward:   585.216 [ 217.021], Avg:   395.063 (0.300) <1-07:41:48> ({'r_t':   711.7713, 'eps':     0.2999, 'len': 57132.1690, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  918000, Reward:   642.140 [  80.264], Avg:   395.332 (0.200) <1-07:43:33> ({'r_t':   876.8321, 'eps':     0.1999, 'len': 57164.8160, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  919000, Reward:   624.901 [ 190.661], Avg:   395.581 (0.100) <1-07:45:26> ({'r_t':  1209.4785, 'eps':     0.0999, 'len': 57197.6540, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  920000, Reward:   612.918 [ 196.032], Avg:   395.817 (1.000) <1-07:57:06> ({'r_t':  1162.3691, 'eps':     0.9999, 'len': 57230.3430, 'dyn_loss':    15.2475, 'dot_loss':     1.8791, 'ddot_loss':     4.4234, 'rew_loss':   148.4161, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  921000, Reward:   647.115 [ 204.224], Avg:   396.090 (0.900) <1-07:58:05> ({'r_t': -1782.1926, 'eps':     0.8999, 'len': 57296.8220, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  922000, Reward:   572.957 [ 418.778], Avg:   396.281 (0.800) <1-07:59:09> ({'r_t': -1422.4845, 'eps':     0.7999, 'len': 57394.4570, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  923000, Reward:   601.301 [ 120.778], Avg:   396.503 (0.700) <1-08:00:18> ({'r_t': -1195.5785, 'eps':     0.6999, 'len': 57480.8890, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  924000, Reward:   637.097 [  94.822], Avg:   396.763 (0.600) <1-08:01:35> ({'r_t':  -930.9575, 'eps':     0.5999, 'len': 57544.1540, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  925000, Reward:   637.171 [  68.977], Avg:   397.023 (0.500) <1-08:02:59> ({'r_t':  -162.3467, 'eps':     0.4999, 'len': 57588.3170, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  926000, Reward:   575.112 [ 239.408], Avg:   397.215 (0.400) <1-08:04:30> ({'r_t':   221.5522, 'eps':     0.3999, 'len': 57622.6640, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  927000, Reward:   623.504 [  89.037], Avg:   397.459 (0.300) <1-08:06:08> ({'r_t':   633.3354, 'eps':     0.2999, 'len': 57654.6880, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  928000, Reward:   556.219 [ 362.480], Avg:   397.630 (0.200) <1-08:07:54> ({'r_t':   981.4188, 'eps':     0.1999, 'len': 57686.7090, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  929000, Reward:   470.105 [ 509.246], Avg:   397.708 (0.100) <1-08:09:47> ({'r_t':  1130.0080, 'eps':     0.0999, 'len': 57718.7460, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  930000, Reward:   638.081 [  79.385], Avg:   397.966 (1.000) <1-08:21:28> ({'r_t':  1296.0355, 'eps':     0.9999, 'len': 57750.7150, 'dyn_loss':    15.3009, 'dot_loss':     1.8778, 'ddot_loss':     4.4216, 'rew_loss':   137.5632, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  931000, Reward:   687.114 [  65.825], Avg:   398.276 (0.900) <1-08:22:26> ({'r_t': -1645.9499, 'eps':     0.8999, 'len': 57810.9060, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  932000, Reward:   511.426 [ 484.950], Avg:   398.398 (0.800) <1-08:23:30> ({'r_t': -1395.5418, 'eps':     0.7999, 'len': 57900.1150, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  933000, Reward:   705.795 [  74.861], Avg:   398.727 (0.700) <1-08:24:40> ({'r_t': -1154.9583, 'eps':     0.6999, 'len': 57991.5010, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  934000, Reward:   579.513 [ 224.869], Avg:   398.920 (0.600) <1-08:25:57> ({'r_t':  -813.7560, 'eps':     0.5999, 'len': 58054.5450, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  935000, Reward:   581.646 [ 179.681], Avg:   399.115 (0.500) <1-08:27:21> ({'r_t':  -208.2775, 'eps':     0.4999, 'len': 58100.9690, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  936000, Reward:   644.408 [  60.539], Avg:   399.377 (0.400) <1-08:28:52> ({'r_t':   271.5994, 'eps':     0.3999, 'len': 58134.5280, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  937000, Reward:   659.573 [  81.440], Avg:   399.654 (0.300) <1-08:30:30> ({'r_t':   724.7113, 'eps':     0.2999, 'len': 58166.5000, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  938000, Reward:   663.479 [  92.886], Avg:   399.935 (0.200) <1-08:32:16> ({'r_t':   896.9225, 'eps':     0.1999, 'len': 58198.5630, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  939000, Reward:   674.877 [ 103.161], Avg:   400.228 (0.100) <1-08:34:09> ({'r_t':  1087.1862, 'eps':     0.0999, 'len': 58230.9610, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  940000, Reward:   712.015 [ 120.296], Avg:   400.559 (1.000) <1-08:45:49> ({'r_t':  1343.0070, 'eps':     0.9999, 'len': 58263.2770, 'dyn_loss':    14.9433, 'dot_loss':     1.8500, 'ddot_loss':     4.3599, 'rew_loss':   132.3199, 'lr':   2.62e-05, 'eps_e':     0.9999, 'lr_e':   2.62e-05})
Step:  941000, Reward:   619.304 [ 188.076], Avg:   400.791 (0.900) <1-08:46:48> ({'r_t': -1628.1739, 'eps':     0.8999, 'len': 58329.4730, 'lr':   2.62e-05, 'eps_e':     0.8999, 'lr_e':   2.62e-05})
Step:  942000, Reward:   682.397 [  90.702], Avg:   401.090 (0.800) <1-08:47:52> ({'r_t': -1310.0983, 'eps':     0.7999, 'len': 58431.0310, 'lr':   2.62e-05, 'eps_e':     0.7999, 'lr_e':   2.62e-05})
Step:  943000, Reward:   665.998 [  68.298], Avg:   401.371 (0.700) <1-08:49:02> ({'r_t': -1225.2337, 'eps':     0.6999, 'len': 58521.0390, 'lr':   2.62e-05, 'eps_e':     0.6999, 'lr_e':   2.62e-05})
Step:  944000, Reward:   562.614 [ 363.620], Avg:   401.541 (0.600) <1-08:50:19> ({'r_t':  -822.8495, 'eps':     0.5999, 'len': 58584.9950, 'lr':   2.62e-05, 'eps_e':     0.5999, 'lr_e':   2.62e-05})
Step:  945000, Reward:   660.602 [ 106.757], Avg:   401.815 (0.500) <1-08:51:43> ({'r_t':  -206.2029, 'eps':     0.4999, 'len': 58631.1030, 'lr':   2.62e-05, 'eps_e':     0.4999, 'lr_e':   2.62e-05})
Step:  946000, Reward:   663.099 [  85.608], Avg:   402.091 (0.400) <1-08:53:14> ({'r_t':   297.0715, 'eps':     0.3999, 'len': 58666.9350, 'lr':   2.62e-05, 'eps_e':     0.3999, 'lr_e':   2.62e-05})
Step:  947000, Reward:   679.558 [ 107.500], Avg:   402.384 (0.300) <1-08:54:52> ({'r_t':   659.1309, 'eps':     0.2999, 'len': 58699.2460, 'lr':   2.62e-05, 'eps_e':     0.2999, 'lr_e':   2.62e-05})
Step:  948000, Reward:   625.166 [ 177.862], Avg:   402.618 (0.200) <1-08:56:38> ({'r_t':   957.1334, 'eps':     0.1999, 'len': 58731.1820, 'lr':   2.62e-05, 'eps_e':     0.1999, 'lr_e':   2.62e-05})
Step:  949000, Reward:   660.907 [  77.155], Avg:   402.890 (0.100) <1-08:58:31> ({'r_t':  1101.1250, 'eps':     0.0999, 'len': 58763.5450, 'lr':   2.62e-05, 'eps_e':     0.0999, 'lr_e':   2.62e-05})
Step:  950000, Reward:   643.049 [  65.362], Avg:   403.143 (1.000) <1-09:10:13> ({'r_t':  1338.2029, 'eps':     0.9999, 'len': 58796.8990, 'dyn_loss':    15.3717, 'dot_loss':     1.8710, 'ddot_loss':     4.4032, 'rew_loss':   146.0104, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
Step:  951000, Reward:   670.222 [  79.520], Avg:   403.423 (0.900) <1-09:11:12> ({'r_t': -1605.7817, 'eps':     0.8999, 'len': 58860.3960, 'lr':   2.10e-05, 'eps_e':     0.8999, 'lr_e':   2.10e-05})
Step:  952000, Reward:   432.864 [ 521.586], Avg:   403.454 (0.800) <1-09:12:16> ({'r_t': -1302.9119, 'eps':     0.7999, 'len': 58961.0620, 'lr':   2.10e-05, 'eps_e':     0.7999, 'lr_e':   2.10e-05})
Step:  953000, Reward:   597.756 [ 139.109], Avg:   403.658 (0.700) <1-09:13:26> ({'r_t': -1142.2402, 'eps':     0.6999, 'len': 59049.8770, 'lr':   2.10e-05, 'eps_e':     0.6999, 'lr_e':   2.10e-05})
Step:  954000, Reward:   673.092 [ 109.012], Avg:   403.940 (0.600) <1-09:14:42> ({'r_t':  -866.7271, 'eps':     0.5999, 'len': 59112.5340, 'lr':   2.10e-05, 'eps_e':     0.5999, 'lr_e':   2.10e-05})
Step:  955000, Reward:   616.530 [ 186.329], Avg:   404.162 (0.500) <1-09:16:06> ({'r_t':  -203.2086, 'eps':     0.4999, 'len': 59159.5190, 'lr':   2.10e-05, 'eps_e':     0.4999, 'lr_e':   2.10e-05})
Step:  956000, Reward:   614.124 [  84.916], Avg:   404.382 (0.400) <1-09:17:37> ({'r_t':   147.3482, 'eps':     0.3999, 'len': 59195.2360, 'lr':   2.10e-05, 'eps_e':     0.3999, 'lr_e':   2.10e-05})
Step:  957000, Reward:   652.067 [  91.795], Avg:   404.640 (0.300) <1-09:19:16> ({'r_t':   633.8831, 'eps':     0.2999, 'len': 59227.5740, 'lr':   2.10e-05, 'eps_e':     0.2999, 'lr_e':   2.10e-05})
Step:  958000, Reward:   635.534 [  68.191], Avg:   404.881 (0.200) <1-09:21:01> ({'r_t':  1003.8993, 'eps':     0.1999, 'len': 59259.5100, 'lr':   2.10e-05, 'eps_e':     0.1999, 'lr_e':   2.10e-05})
Step:  959000, Reward:   646.419 [  83.084], Avg:   405.133 (0.100) <1-09:22:54> ({'r_t':  1177.3534, 'eps':     0.0999, 'len': 59292.3370, 'lr':   2.10e-05, 'eps_e':     0.0999, 'lr_e':   2.10e-05})
Step:  960000, Reward:   646.613 [ 207.816], Avg:   405.384 (1.000) <1-09:34:36> ({'r_t':  1305.2846, 'eps':     0.9999, 'len': 59324.8260, 'dyn_loss':    15.1801, 'dot_loss':     1.8595, 'ddot_loss':     4.3851, 'rew_loss':   131.7893, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
Step:  961000, Reward:   534.650 [ 402.816], Avg:   405.518 (0.900) <1-09:35:35> ({'r_t': -1650.5138, 'eps':     0.8999, 'len': 59388.8840, 'lr':   2.10e-05, 'eps_e':     0.8999, 'lr_e':   2.10e-05})
Step:  962000, Reward:   616.597 [  62.753], Avg:   405.738 (0.800) <1-09:36:38> ({'r_t': -1533.5243, 'eps':     0.7999, 'len': 59488.2410, 'lr':   2.10e-05, 'eps_e':     0.7999, 'lr_e':   2.10e-05})
Step:  963000, Reward:   608.676 [ 185.715], Avg:   405.948 (0.700) <1-09:37:48> ({'r_t': -1240.9031, 'eps':     0.6999, 'len': 59570.9990, 'lr':   2.10e-05, 'eps_e':     0.6999, 'lr_e':   2.10e-05})
Step:  964000, Reward:   689.253 [  86.954], Avg:   406.242 (0.600) <1-09:39:05> ({'r_t':  -741.5739, 'eps':     0.5999, 'len': 59635.2070, 'lr':   2.10e-05, 'eps_e':     0.5999, 'lr_e':   2.10e-05})
Step:  965000, Reward:   648.613 [ 111.236], Avg:   406.493 (0.500) <1-09:40:29> ({'r_t':  -142.7437, 'eps':     0.4999, 'len': 59681.3320, 'lr':   2.10e-05, 'eps_e':     0.4999, 'lr_e':   2.10e-05})
Step:  966000, Reward:   523.599 [ 390.512], Avg:   406.614 (0.400) <1-09:42:00> ({'r_t':   200.9086, 'eps':     0.3999, 'len': 59714.8150, 'lr':   2.10e-05, 'eps_e':     0.3999, 'lr_e':   2.10e-05})
Step:  967000, Reward:   671.959 [  75.208], Avg:   406.888 (0.300) <1-09:43:38> ({'r_t':   494.4065, 'eps':     0.2999, 'len': 59747.4400, 'lr':   2.10e-05, 'eps_e':     0.2999, 'lr_e':   2.10e-05})
Step:  968000, Reward:   560.889 [ 252.849], Avg:   407.047 (0.200) <1-09:45:23> ({'r_t':   978.2478, 'eps':     0.1999, 'len': 59780.2920, 'lr':   2.10e-05, 'eps_e':     0.1999, 'lr_e':   2.10e-05})
Step:  969000, Reward:   556.725 [ 364.835], Avg:   407.201 (0.100) <1-09:47:16> ({'r_t':  1097.7260, 'eps':     0.0999, 'len': 59812.2550, 'lr':   2.10e-05, 'eps_e':     0.0999, 'lr_e':   2.10e-05})
Step:  970000, Reward:   652.129 [  92.237], Avg:   407.453 (1.000) <1-09:58:48> ({'r_t':  1363.4420, 'eps':     0.9999, 'len': 59844.2780, 'dyn_loss':    15.1384, 'dot_loss':     1.8607, 'ddot_loss':     4.3826, 'rew_loss':   123.4771, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
Step:  971000, Reward:   659.585 [  76.418], Avg:   407.713 (0.900) <1-09:59:47> ({'r_t': -1730.5074, 'eps':     0.8999, 'len': 59909.1250, 'lr':   2.10e-05, 'eps_e':     0.8999, 'lr_e':   2.10e-05})
Step:  972000, Reward:   649.218 [  67.296], Avg:   407.961 (0.800) <1-10:00:51> ({'r_t': -1281.1215, 'eps':     0.7999, 'len': 60008.9750, 'lr':   2.10e-05, 'eps_e':     0.7999, 'lr_e':   2.10e-05})
Step:  973000, Reward:   562.583 [ 433.365], Avg:   408.120 (0.700) <1-10:02:00> ({'r_t': -1106.6186, 'eps':     0.6999, 'len': 60092.1930, 'lr':   2.10e-05, 'eps_e':     0.6999, 'lr_e':   2.10e-05})
Step:  974000, Reward:   617.878 [  88.764], Avg:   408.335 (0.600) <1-10:03:17> ({'r_t':  -929.5625, 'eps':     0.5999, 'len': 60155.3620, 'lr':   2.10e-05, 'eps_e':     0.5999, 'lr_e':   2.10e-05})
Step:  975000, Reward:   586.986 [ 219.909], Avg:   408.518 (0.500) <1-10:04:41> ({'r_t':  -295.2029, 'eps':     0.4999, 'len': 60196.1640, 'lr':   2.10e-05, 'eps_e':     0.4999, 'lr_e':   2.10e-05})
Step:  976000, Reward:   701.288 [  78.133], Avg:   408.818 (0.400) <1-10:06:12> ({'r_t':   290.7582, 'eps':     0.3999, 'len': 60229.7740, 'lr':   2.10e-05, 'eps_e':     0.3999, 'lr_e':   2.10e-05})
Step:  977000, Reward:   698.389 [  67.269], Avg:   409.114 (0.300) <1-10:07:50> ({'r_t':   371.1600, 'eps':     0.2999, 'len': 60262.3920, 'lr':   2.10e-05, 'eps_e':     0.2999, 'lr_e':   2.10e-05})
Step:  978000, Reward:   597.753 [ 181.019], Avg:   409.306 (0.200) <1-10:09:35> ({'r_t':   898.4650, 'eps':     0.1999, 'len': 60294.9160, 'lr':   2.10e-05, 'eps_e':     0.1999, 'lr_e':   2.10e-05})
Step:  979000, Reward:   534.365 [ 347.344], Avg:   409.434 (0.100) <1-10:11:28> ({'r_t':   975.0719, 'eps':     0.0999, 'len': 60327.1240, 'lr':   2.10e-05, 'eps_e':     0.0999, 'lr_e':   2.10e-05})
Step:  980000, Reward:   644.348 [ 137.636], Avg:   409.673 (1.000) <1-10:23:02> ({'r_t':  1389.3826, 'eps':     0.9999, 'len': 60359.1020, 'dyn_loss':    15.0060, 'dot_loss':     1.8453, 'ddot_loss':     4.3463, 'rew_loss':   138.4486, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
Step:  981000, Reward:   605.586 [ 173.463], Avg:   409.873 (0.900) <1-10:24:00> ({'r_t': -1830.3352, 'eps':     0.8999, 'len': 60421.8150, 'lr':   2.10e-05, 'eps_e':     0.8999, 'lr_e':   2.10e-05})
Step:  982000, Reward:   540.050 [ 420.907], Avg:   410.005 (0.800) <1-10:25:04> ({'r_t': -1613.1799, 'eps':     0.7999, 'len': 60525.5550, 'lr':   2.10e-05, 'eps_e':     0.7999, 'lr_e':   2.10e-05})
Step:  983000, Reward:   639.077 [  85.740], Avg:   410.238 (0.700) <1-10:26:14> ({'r_t': -1108.5884, 'eps':     0.6999, 'len': 60610.3400, 'lr':   2.10e-05, 'eps_e':     0.6999, 'lr_e':   2.10e-05})
Step:  984000, Reward:   644.221 [  86.594], Avg:   410.476 (0.600) <1-10:27:31> ({'r_t':  -743.0850, 'eps':     0.5999, 'len': 60671.2690, 'lr':   2.10e-05, 'eps_e':     0.5999, 'lr_e':   2.10e-05})
Step:  985000, Reward:   649.983 [ 151.595], Avg:   410.719 (0.500) <1-10:28:55> ({'r_t':  -250.2252, 'eps':     0.4999, 'len': 60720.5720, 'lr':   2.10e-05, 'eps_e':     0.4999, 'lr_e':   2.10e-05})
Step:  986000, Reward:   288.209 [ 599.055], Avg:   410.594 (0.400) <1-10:30:25> ({'r_t':    23.3185, 'eps':     0.3999, 'len': 60755.5650, 'lr':   2.10e-05, 'eps_e':     0.3999, 'lr_e':   2.10e-05})
Step:  987000, Reward:   618.581 [ 110.465], Avg:   410.805 (0.300) <1-10:32:04> ({'r_t':   620.6710, 'eps':     0.2999, 'len': 60788.8920, 'lr':   2.10e-05, 'eps_e':     0.2999, 'lr_e':   2.10e-05})
Step:  988000, Reward:   653.427 [ 100.075], Avg:   411.050 (0.200) <1-10:33:49> ({'r_t':   902.1008, 'eps':     0.1999, 'len': 60821.6390, 'lr':   2.10e-05, 'eps_e':     0.1999, 'lr_e':   2.10e-05})
Step:  989000, Reward:   683.050 [  79.118], Avg:   411.325 (0.100) <1-10:35:42> ({'r_t':  1167.6596, 'eps':     0.0999, 'len': 60853.5900, 'lr':   2.10e-05, 'eps_e':     0.0999, 'lr_e':   2.10e-05})
Step:  990000, Reward:   622.769 [ 201.429], Avg:   411.538 (1.000) <1-10:47:24> ({'r_t':  1237.5949, 'eps':     0.9999, 'len': 60885.6440, 'dyn_loss':    14.9894, 'dot_loss':     1.8454, 'ddot_loss':     4.3430, 'rew_loss':   125.1192, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
Step:  991000, Reward:   682.903 [ 101.966], Avg:   411.812 (0.900) <1-10:48:23> ({'r_t': -1679.7520, 'eps':     0.8999, 'len': 60956.0080, 'lr':   2.10e-05, 'eps_e':     0.8999, 'lr_e':   2.10e-05})
Step:  992000, Reward:   550.851 [ 211.911], Avg:   411.952 (0.800) <1-10:49:27> ({'r_t': -1506.7063, 'eps':     0.7999, 'len': 61052.9490, 'lr':   2.10e-05, 'eps_e':     0.7999, 'lr_e':   2.10e-05})
Step:  993000, Reward:   642.879 [ 192.769], Avg:   412.184 (0.700) <1-10:50:37> ({'r_t': -1198.0115, 'eps':     0.6999, 'len': 61135.0040, 'lr':   2.10e-05, 'eps_e':     0.6999, 'lr_e':   2.10e-05})
Step:  994000, Reward:   621.415 [ 180.404], Avg:   412.395 (0.600) <1-10:51:54> ({'r_t':  -822.2458, 'eps':     0.5999, 'len': 61202.2610, 'lr':   2.10e-05, 'eps_e':     0.5999, 'lr_e':   2.10e-05})
Step:  995000, Reward:   655.662 [  69.057], Avg:   412.639 (0.500) <1-10:53:18> ({'r_t':  -178.4826, 'eps':     0.4999, 'len': 61248.5660, 'lr':   2.10e-05, 'eps_e':     0.4999, 'lr_e':   2.10e-05})
Step:  996000, Reward:   690.939 [  84.081], Avg:   412.918 (0.400) <1-10:54:49> ({'r_t':   276.4344, 'eps':     0.3999, 'len': 61283.6280, 'lr':   2.10e-05, 'eps_e':     0.3999, 'lr_e':   2.10e-05})
Step:  997000, Reward:   651.320 [  65.516], Avg:   413.157 (0.300) <1-10:56:27> ({'r_t':   655.3324, 'eps':     0.2999, 'len': 61317.5670, 'lr':   2.10e-05, 'eps_e':     0.2999, 'lr_e':   2.10e-05})
Step:  998000, Reward:   619.838 [ 145.975], Avg:   413.364 (0.200) <1-10:58:12> ({'r_t':   908.6857, 'eps':     0.1999, 'len': 61349.6680, 'lr':   2.10e-05, 'eps_e':     0.1999, 'lr_e':   2.10e-05})
Step:  999000, Reward:   676.297 [ 213.802], Avg:   413.627 (0.100) <1-11:00:05> ({'r_t':  1037.5584, 'eps':     0.0999, 'len': 61382.2150, 'lr':   2.10e-05, 'eps_e':     0.0999, 'lr_e':   2.10e-05})
Step: 1000000, Reward:   637.651 [  76.013], Avg:   413.850 (1.000) <1-11:11:48> ({'r_t':  1328.8339, 'eps':     0.9999, 'len': 61415.2820, 'dyn_loss':    14.8480, 'dot_loss':     1.8306, 'ddot_loss':     4.3110, 'rew_loss':   130.5957, 'lr':   2.10e-05, 'eps_e':     0.9999, 'lr_e':   2.10e-05})
