Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CarRacing-v1, Date: 09/06/2020 00:30:39
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 2527c6a0132ec31ed7f8b1a38fedd8f27861491c
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.9
   ADVANTAGE_DECAY = 0.9
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = None
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 10000
   TARGET_UPDATE_RATE = 0.0004
   TRAIN_EVERY = 10000
   BATCH_SIZE = 500
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 20
      LAMBDA = 0.1
      COV = 1
   REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
   DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
   dynamics_size = 13
   state_size = (80,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 1000000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.97
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fa166ab7810> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7fa1fbe99ad0>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7fa166a249e0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7fa166a23b10> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7fa166a23790> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost
							# reward = progress + np.tanh(vy/self.vtarget) - cost
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_size = 13
			obs = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  2.000e-02  3.657e-01  4.017e-01  4.572e-01  5.260e-01  6.036e-01  2.700e-01  3.171e-01  3.850e-01  4.646e-01  5.509e-01  1.792e-01  2.444e-01  3.277e-01  4.184e-01  5.125e-01  1.063e-01  1.973e-01  2.942e-01  3.927e-01  4.918e-01  1.024e-01  1.953e-01  2.929e-01  3.917e-01  4.910e-01]
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 		return state
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.spec = next_spec
			
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7fa1e69e6680>
					step = <function CarRacing.step at 0x7fa1e69e65f0>
					render = <function CarRacing.render at 0x7fa210e4cb90>
					dynamics_spec = <staticmethod object at 0x7fa1e69e4dd0>
					track_spec = <function CarRacing.track_spec at 0x7fa210e4ccb0>
					observation = <function CarRacing.observation at 0x7fa210e4cd40>
					dynamics_keys = <staticmethod object at 0x7fa1e69e4cd0>
					observation_spec = <staticmethod object at 0x7fa1e69e4d10>
					close = <function CarRacing.close at 0x7fa210e4cef0>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(80,) 
			dtype = float32
			shape = (80,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fa166a97d50> 
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (80,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fa166a97850> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=131, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56752), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=132, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38890), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=133, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36834), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=134, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 46028), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=135, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57340), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=136, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56326), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=137, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49556), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=138, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57430), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=139, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 39540), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=140, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49846), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=141, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33376), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=142, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51018), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=143, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50830), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=144, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59712), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=145, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38390), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=146, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41978), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fa166a23ad0> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fa166a23190> 
		state_size = (80,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fa166a23c50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fa166a23810> 
			size = (3,)
			dt = 0.2
			action = [ 0.389  0.217 -0.622]
			daction_dt = [ 0.707  0.391  1.992]
		discrete = False
		action_size = (3,)
		state_size = (80,)
		config = <src.utils.config.Config object at 0x7fa166f64690> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.9
			ADVANTAGE_DECAY = 0.9
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = None
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 10000
			TARGET_UPDATE_RATE = 0.0004
			TRAIN_EVERY = 10000
			BATCH_SIZE = 500
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fa210ddc8d0> 
				NSAMPLES = 100
				HORIZON = 20
				LAMBDA = 0.1
				COV = 1
			REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
			DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
			dynamics_size = 13
			state_size = (80,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 1000000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fa166f50c90> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.97
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fa166a23950> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fa166a55150> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fa166f64690> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.9
				ADVANTAGE_DECAY = 0.9
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = None
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 10000
				TARGET_UPDATE_RATE = 0.0004
				TRAIN_EVERY = 10000
				BATCH_SIZE = 500
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fa210ddc8d0> 
					NSAMPLES = 100
					HORIZON = 20
					LAMBDA = 0.1
					COV = 1
				REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
				DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
				dynamics_size = 13
				state_size = (80,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 1000000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fa166f50c90> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.97
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fa166a55250> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=29, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(29, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=13, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fa166a553d0> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fa166f64690> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.9
						ADVANTAGE_DECAY = 0.9
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = None
						MAX_BUFFER_SIZE = 100000
						REPLAY_BATCH_SIZE = 10000
						TARGET_UPDATE_RATE = 0.0004
						TRAIN_EVERY = 10000
						BATCH_SIZE = 500
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fa210ddc8d0> 
							NSAMPLES = 100
							HORIZON = 20
							LAMBDA = 0.1
							COV = 1
						REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
						DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
						dynamics_size = 13
						state_size = (80,)
						action_size = (3,)
						env_name = CarRacing-v1
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 1000000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fa166f50c90> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.97
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (80,)
					action_size = (3,)
					discrete = False
					dyn_index = 13
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa166a55c50>
				state_size = (80,)
				action_size = (3,)
			mu = [ 0.000  0.000  0.000]
			cov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			icov = [[ 1.000  0.000  0.000]
			 [ 0.000  1.000  0.000]
			 [ 0.000  0.000  1.000]]
			lamda = 0.1
			horizon = 20
			nsamples = 100
			action_size = (3,)
			control = [[[-4.894e-01  6.504e-01  9.166e-01]
			  [ 5.955e-01  5.999e-01  9.956e-01]
			  [ 3.754e-01 -5.160e-01 -7.760e-01]
			  [-7.363e-01 -6.335e-01 -2.167e-01]
			  [ 7.307e-01  2.928e-01  9.544e-01]
			  [ 9.402e-01 -5.026e-01  4.431e-01]
			  [-9.180e-01 -2.453e-01 -8.984e-04]
			  [-9.387e-02 -6.570e-01  1.616e-01]
			  [-4.453e-01 -8.551e-01  8.843e-01]
			  [ 4.254e-01  8.930e-01 -4.114e-01]
			  [ 2.400e-01  7.778e-01 -4.052e-02]
			  [-8.494e-01 -1.434e-01 -2.750e-01]
			  [ 7.305e-01 -8.157e-01 -7.418e-01]
			  [-1.828e-01  8.175e-01  6.011e-01]
			  [-3.071e-02 -7.328e-01 -2.966e-01]
			  [ 8.960e-01  6.382e-01 -5.098e-01]
			  [-9.473e-01  1.893e-01  3.174e-01]
			  [ 2.730e-01  7.682e-01  4.655e-01]
			  [ 6.605e-01 -3.109e-01 -4.766e-01]
			  [ 6.068e-01 -6.840e-01  3.179e-01]]]
			noise = [[[[ 0.137 -1.176  0.230]
			   [ 0.097  1.458 -0.894]
			   [-0.677 -0.025 -0.082]
			   ...
			   [ 0.960 -1.827 -0.648]
			   [ 0.913 -0.789  0.068]
			   [-1.384 -0.321 -0.605]]
			
			  [[ 0.710  0.766 -0.535]
			   [-0.519  0.111 -0.054]
			   [-1.168  1.600 -2.559]
			   ...
			   [-0.467 -0.431 -0.067]
			   [-1.108 -0.079  1.388]
			   [-0.401  2.091 -0.485]]
			
			  [[ 0.092 -1.449  0.532]
			   [-0.364 -1.027 -1.545]
			   [-1.949 -1.075  0.110]
			   ...
			   [-0.125  1.086  1.177]
			   [ 0.147 -1.367  1.215]
			   [ 0.508  1.668 -1.083]]
			
			  ...
			
			  [[ 0.389 -0.770 -0.851]
			   [ 0.165  0.037  1.573]
			   [-0.493 -0.006 -1.438]
			   ...
			   [-0.535  1.290 -0.750]
			   [-1.028 -1.257 -0.159]
			   [-0.727  0.063  0.751]]
			
			  [[-1.357 -0.678 -0.460]
			   [ 0.772 -0.169 -0.937]
			   [-1.098 -0.104 -0.216]
			   ...
			   [ 1.358 -0.218 -0.803]
			   [-0.927 -0.172 -0.891]
			   [-0.423  0.277 -0.787]]
			
			  [[-0.814  0.699  1.932]
			   [-0.372  0.129  0.093]
			   [ 1.694  0.602 -1.563]
			   ...
			   [-0.855 -1.463 -0.215]
			   [ 1.440  2.149 -0.803]
			   [ 0.301  0.510  0.138]]]]
			init_cost = [[-0.223 -0.440 -0.334  0.374  0.063 -0.292 -0.257 -0.113 -0.071 -0.217 -0.341  0.060 -0.007 -0.033  0.182 -0.112  0.134 -0.231 -0.219  0.555 -0.010  0.159  0.096 -0.070  0.061 -0.105  0.106  0.010 -0.068 -0.108 -0.060 -0.250  0.205 -0.161 -0.067 -0.161 -0.053 -0.339  0.068 -0.051  0.309 -0.207 -0.007 -0.286 -0.105 -0.481 -0.077 -0.053 -0.208 -0.072 -0.167 -0.461 -0.125 -0.268  0.193 -0.082 -0.293  0.167 -0.195 -0.176  0.151  0.333  0.206  0.144  0.170  0.272  0.041  0.158  0.475 -0.184 -0.040 -0.055  0.348  0.410 -0.353  0.303 -0.066  0.075 -0.130  0.311 -0.506 -0.101  0.382 -0.230 -0.090 -0.209  0.087 -0.302  0.130 -0.059  0.027  0.280  0.299  0.061  0.174 -0.255  0.128  0.121 -0.123  0.232]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fa166e48d90> 
			buffer = deque([], maxlen=100000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fa166a55d90> 
		size = (3,)
		dt = 0.2
		action = [-0.161 -1.000 -1.000]
		daction_dt = [-1.424 -0.292  1.750]
	discrete = False
	action_size = (3,)
	state_size = (80,)
	config = <src.utils.config.Config object at 0x7fa166f64690> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.9
		ADVANTAGE_DECAY = 0.9
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = None
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 10000
		TARGET_UPDATE_RATE = 0.0004
		TRAIN_EVERY = 10000
		BATCH_SIZE = 500
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fa210ddc8d0> 
			NSAMPLES = 100
			HORIZON = 20
			LAMBDA = 0.1
			COV = 1
		REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
		DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
		dynamics_size = 13
		state_size = (80,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 1000000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fa166f50c90> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.97
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fa164167890> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		noise = self.noise[...,:horizon,:] * max(eps if eps else 0, 0.1)
		controls = np.clip(self.control[:,None,:horizon,:] + noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1) + self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control[...,:horizon,:] += np.sum(weights[:,:,None,None]*noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))/self.horizon

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: self.to_tensor(x)[None], zip(*buffer))
			buffer.clear()
			values = self.network.envmodel.network.reward(actions, states, next_states)[0]
			rewards = self.compute_gae(0*values[-1], rewards.transpose(0,1), dones.transpose(0,1), values)[0].transpose(0,1)
			states, actions, next_states, rewards, dones = map(lambda x: x.cpu().numpy(), [states, actions, next_states, rewards, dones])
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.TRAIN_EVERY)/self.config.TRAIN_EVERY if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:   -84.496 [  28.584], Avg:   -84.496 (1.000) <0-00:00:00> ({'r_t':    -1.0359, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:   -73.160 [  16.453], Avg:   -78.828 (1.000) <0-00:00:25> ({'r_t': -1209.9443, 'eps':     1.0000, 'len':    43.8060, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward:   -64.123 [  18.257], Avg:   -73.926 (1.000) <0-00:00:51> ({'r_t': -1234.3525, 'eps':     1.0000, 'len':   146.0860, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward:   -72.673 [  20.267], Avg:   -73.613 (1.000) <0-00:01:16> ({'r_t': -1192.6981, 'eps':     1.0000, 'len':   256.4800, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward:   -95.124 [  64.263], Avg:   -77.915 (1.000) <0-00:01:51> ({'r_t': -1265.4595, 'eps':     1.0000, 'len':   366.0600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward:   -67.380 [  28.791], Avg:   -76.159 (1.000) <0-00:02:19> ({'r_t': -1262.5284, 'eps':     1.0000, 'len':   464.7330, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward:   -83.977 [  33.273], Avg:   -77.276 (1.000) <0-00:02:47> ({'r_t': -1288.0606, 'eps':     1.0000, 'len':   553.0680, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward:   -74.008 [  22.663], Avg:   -76.868 (1.000) <0-00:03:12> ({'r_t': -1263.0715, 'eps':     1.0000, 'len':   653.2860, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward:   -88.767 [  44.176], Avg:   -78.190 (1.000) <0-00:03:43> ({'r_t': -1280.6493, 'eps':     1.0000, 'len':   753.3610, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward:   -78.429 [  29.052], Avg:   -78.214 (1.000) <0-00:04:10> ({'r_t': -1237.1394, 'eps':     1.0000, 'len':   861.6710, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward:  -106.742 [  78.209], Avg:   -80.807 (1.000) <0-00:04:44> ({'r_t': -1286.0523, 'eps':     1.0000, 'len':   963.0900, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward:   -78.900 [  34.292], Avg:   -80.648 (1.000) <0-00:05:11> ({'r_t': -1289.8482, 'eps':     1.0000, 'len':  1057.7990, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward:   -75.276 [  28.983], Avg:   -80.235 (1.000) <0-00:05:38> ({'r_t': -1265.0455, 'eps':     1.0000, 'len':  1152.0730, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   13000, Reward:  -105.480 [  56.379], Avg:   -82.038 (1.000) <0-00:06:10> ({'r_t': -1280.4289, 'eps':     1.0000, 'len':  1245.1320, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   14000, Reward:   -76.785 [  30.759], Avg:   -81.688 (1.000) <0-00:06:38> ({'r_t': -1247.8455, 'eps':     1.0000, 'len':  1341.7700, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   15000, Reward:   -75.830 [  26.002], Avg:   -81.322 (1.000) <0-00:07:05> ({'r_t': -1266.6541, 'eps':     1.0000, 'len':  1445.0210, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   16000, Reward:   -71.229 [  19.802], Avg:   -80.728 (1.000) <0-00:07:32> ({'r_t': -1227.9524, 'eps':     1.0000, 'len':  1549.4580, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   17000, Reward:   -79.260 [  26.305], Avg:   -80.647 (1.000) <0-00:07:59> ({'r_t': -1212.3596, 'eps':     1.0000, 'len':  1648.1350, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   18000, Reward:   -70.127 [  21.975], Avg:   -80.093 (1.000) <0-00:08:24> ({'r_t': -1306.8895, 'eps':     1.0000, 'len':  1743.0270, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   19000, Reward:   -71.780 [  31.635], Avg:   -79.677 (1.000) <0-00:08:52> ({'r_t': -1240.8059, 'eps':     1.0000, 'len':  1835.4560, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   20000, Reward:   -68.858 [  21.584], Avg:   -79.162 (1.000) <0-00:09:18> ({'r_t': -1294.0155, 'eps':     1.0000, 'len':  1932.5150, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   21000, Reward:   -70.759 [  19.191], Avg:   -78.780 (1.000) <0-00:09:43> ({'r_t': -1282.5469, 'eps':     1.0000, 'len':  2020.9420, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   22000, Reward:   -67.667 [  21.990], Avg:   -78.297 (1.000) <0-00:10:09> ({'r_t': -1252.7833, 'eps':     1.0000, 'len':  2119.8890, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   23000, Reward:   -74.128 [  19.493], Avg:   -78.123 (1.000) <0-00:10:35> ({'r_t': -1221.8040, 'eps':     1.0000, 'len':  2222.4860, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   24000, Reward:   -77.286 [  27.627], Avg:   -78.090 (1.000) <0-00:11:03> ({'r_t': -1237.1987, 'eps':     1.0000, 'len':  2321.0100, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   25000, Reward:   -71.506 [  25.188], Avg:   -77.836 (1.000) <0-00:11:29> ({'r_t': -1242.3671, 'eps':     1.0000, 'len':  2425.2960, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   26000, Reward:   -76.081 [  29.082], Avg:   -77.771 (1.000) <0-00:11:56> ({'r_t': -1207.6048, 'eps':     1.0000, 'len':  2529.5990, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   27000, Reward:   -72.122 [  19.379], Avg:   -77.570 (1.000) <0-00:12:22> ({'r_t': -1283.6916, 'eps':     1.0000, 'len':  2629.8960, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   28000, Reward:   -77.545 [  41.524], Avg:   -77.569 (1.000) <0-00:12:51> ({'r_t': -1230.1385, 'eps':     1.0000, 'len':  2729.4430, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   29000, Reward:   -68.867 [  19.678], Avg:   -77.279 (1.000) <0-00:13:18> ({'r_t': -1222.9371, 'eps':     1.0000, 'len':  2832.8410, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   30000, Reward:   -68.824 [  16.455], Avg:   -77.006 (1.000) <0-00:13:43> ({'r_t': -1200.7898, 'eps':     1.0000, 'len':  2939.6900, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   31000, Reward:   -66.445 [  16.385], Avg:   -76.676 (1.000) <0-00:14:07> ({'r_t': -1273.4793, 'eps':     1.0000, 'len':  3037.9500, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   32000, Reward:   -71.816 [  19.510], Avg:   -76.529 (1.000) <0-00:14:32> ({'r_t': -1225.1370, 'eps':     1.0000, 'len':  3132.2920, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   33000, Reward:   -67.555 [  18.278], Avg:   -76.265 (1.000) <0-00:14:58> ({'r_t': -1316.4141, 'eps':     1.0000, 'len':  3225.4840, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   34000, Reward:   -88.877 [  40.556], Avg:   -76.625 (1.000) <0-00:15:28> ({'r_t': -1237.3807, 'eps':     1.0000, 'len':  3324.6670, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   35000, Reward:   -76.641 [  40.835], Avg:   -76.626 (1.000) <0-00:15:58> ({'r_t': -1261.3207, 'eps':     1.0000, 'len':  3428.2380, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   36000, Reward:   -70.256 [  20.359], Avg:   -76.453 (1.000) <0-00:16:24> ({'r_t': -1265.9064, 'eps':     1.0000, 'len':  3527.2620, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   37000, Reward:   -82.995 [  24.241], Avg:   -76.626 (1.000) <0-00:16:51> ({'r_t': -1205.7306, 'eps':     1.0000, 'len':  3625.4200, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   38000, Reward:   -70.959 [  30.124], Avg:   -76.480 (1.000) <0-00:17:20> ({'r_t': -1225.7591, 'eps':     1.0000, 'len':  3727.2970, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   39000, Reward:   -65.006 [  17.993], Avg:   -76.193 (1.000) <0-00:17:45> ({'r_t': -1255.8903, 'eps':     1.0000, 'len':  3830.7430, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   40000, Reward:   -70.768 [  22.123], Avg:   -76.061 (1.000) <0-00:18:11> ({'r_t': -1276.8203, 'eps':     1.0000, 'len':  3927.1530, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   41000, Reward:   -66.558 [  21.387], Avg:   -75.835 (1.000) <0-00:18:36> ({'r_t': -1228.6341, 'eps':     1.0000, 'len':  4030.4230, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   42000, Reward:   -69.567 [  17.872], Avg:   -75.689 (1.000) <0-00:19:02> ({'r_t': -1245.7444, 'eps':     1.0000, 'len':  4125.7620, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   43000, Reward:   -83.737 [  32.688], Avg:   -75.872 (1.000) <0-00:19:29> ({'r_t': -1216.6335, 'eps':     1.0000, 'len':  4217.2230, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   44000, Reward:   -74.037 [  21.102], Avg:   -75.831 (1.000) <0-00:19:55> ({'r_t': -1261.2695, 'eps':     1.0000, 'len':  4319.0140, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   45000, Reward:   -71.342 [  18.264], Avg:   -75.734 (1.000) <0-00:20:21> ({'r_t': -1217.7810, 'eps':     1.0000, 'len':  4418.0830, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   46000, Reward:   -76.935 [  26.213], Avg:   -75.759 (1.000) <0-00:20:47> ({'r_t': -1252.9828, 'eps':     1.0000, 'len':  4517.3660, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   47000, Reward:   -68.146 [  15.716], Avg:   -75.601 (1.000) <0-00:21:12> ({'r_t': -1197.3083, 'eps':     1.0000, 'len':  4619.5820, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   48000, Reward:   -86.538 [  44.795], Avg:   -75.824 (1.000) <0-00:21:41> ({'r_t': -1217.8568, 'eps':     1.0000, 'len':  4726.7620, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   49000, Reward:   -77.074 [  29.649], Avg:   -75.849 (1.000) <0-00:22:09> ({'r_t': -1238.1382, 'eps':     1.0000, 'len':  4825.9890, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   50000, Reward:   -79.143 [  45.431], Avg:   -75.913 (1.000) <0-00:22:40> ({'r_t': -1253.8049, 'eps':     1.0000, 'len':  4929.2790, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   51000, Reward:   -71.521 [  33.086], Avg:   -75.829 (1.000) <0-00:23:08> ({'r_t': -1224.6343, 'eps':     1.0000, 'len':  5027.5690, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   52000, Reward:   -82.971 [  31.757], Avg:   -75.964 (1.000) <0-00:23:36> ({'r_t': -1270.5488, 'eps':     1.0000, 'len':  5124.0420, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   53000, Reward:   -71.938 [  21.225], Avg:   -75.889 (1.000) <0-00:24:02> ({'r_t': -1229.6539, 'eps':     1.0000, 'len':  5226.0220, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   54000, Reward:   -66.781 [  24.129], Avg:   -75.724 (1.000) <0-00:24:27> ({'r_t': -1249.8647, 'eps':     1.0000, 'len':  5333.5280, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   55000, Reward:   -77.807 [  25.008], Avg:   -75.761 (1.000) <0-00:24:53> ({'r_t': -1223.8853, 'eps':     1.0000, 'len':  5432.4850, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   56000, Reward:   -82.744 [  26.615], Avg:   -75.883 (1.000) <0-00:25:20> ({'r_t': -1213.6599, 'eps':     1.0000, 'len':  5539.1940, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   57000, Reward:   -78.253 [  47.686], Avg:   -75.924 (1.000) <0-00:25:52> ({'r_t': -1219.5239, 'eps':     1.0000, 'len':  5638.0540, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   58000, Reward:   -75.287 [  26.704], Avg:   -75.913 (1.000) <0-00:26:18> ({'r_t': -1236.6732, 'eps':     1.0000, 'len':  5739.4050, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   59000, Reward:   -77.064 [  18.327], Avg:   -75.932 (1.000) <0-00:26:44> ({'r_t': -1210.1097, 'eps':     1.0000, 'len':  5841.6380, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   60000, Reward:   -74.755 [  16.151], Avg:   -75.913 (1.000) <0-00:27:09> ({'r_t': -1235.1868, 'eps':     1.0000, 'len':  5945.6670, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   61000, Reward:   -63.749 [  15.080], Avg:   -75.717 (1.000) <0-00:27:34> ({'r_t': -1186.9651, 'eps':     1.0000, 'len':  6048.0910, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   62000, Reward:   -67.255 [  20.931], Avg:   -75.583 (1.000) <0-00:27:59> ({'r_t': -1226.9257, 'eps':     1.0000, 'len':  6142.5690, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   63000, Reward:   -71.586 [  14.560], Avg:   -75.520 (1.000) <0-00:28:23> ({'r_t': -1269.5541, 'eps':     1.0000, 'len':  6242.9620, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   64000, Reward:   -74.484 [  20.955], Avg:   -75.504 (1.000) <0-00:28:49> ({'r_t': -1250.1593, 'eps':     1.0000, 'len':  6345.1750, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   65000, Reward:   -58.429 [   7.646], Avg:   -75.246 (1.000) <0-00:29:12> ({'r_t': -1198.0479, 'eps':     1.0000, 'len':  6446.0720, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   66000, Reward:   -74.046 [  30.605], Avg:   -75.228 (1.000) <0-00:29:40> ({'r_t': -1222.2929, 'eps':     1.0000, 'len':  6549.7960, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   67000, Reward:   -72.489 [  27.589], Avg:   -75.187 (1.000) <0-00:30:07> ({'r_t': -1192.8817, 'eps':     1.0000, 'len':  6649.8510, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   68000, Reward:   -82.043 [  31.783], Avg:   -75.287 (1.000) <0-00:30:35> ({'r_t': -1202.9188, 'eps':     1.0000, 'len':  6751.8640, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   69000, Reward:   -65.511 [  13.495], Avg:   -75.147 (1.000) <0-00:31:00> ({'r_t': -1168.5208, 'eps':     1.0000, 'len':  6858.2880, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   70000, Reward:   -88.516 [  39.252], Avg:   -75.335 (1.000) <0-00:31:28> ({'r_t': -1191.0944, 'eps':     1.0000, 'len':  6974.1100, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   71000, Reward:   -87.559 [  36.805], Avg:   -75.505 (1.000) <0-00:31:57> ({'r_t': -1292.3570, 'eps':     1.0000, 'len':  7081.6350, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   72000, Reward:   -87.975 [  37.122], Avg:   -75.676 (1.000) <0-00:32:26> ({'r_t': -1295.1062, 'eps':     1.0000, 'len':  7173.6380, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   73000, Reward:   -66.895 [  14.785], Avg:   -75.557 (1.000) <0-00:32:51> ({'r_t': -1176.9551, 'eps':     1.0000, 'len':  7274.8000, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   74000, Reward:   -67.713 [  28.362], Avg:   -75.453 (1.000) <0-00:33:19> ({'r_t': -1248.9487, 'eps':     1.0000, 'len':  7371.2900, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   75000, Reward:   -72.039 [  22.447], Avg:   -75.408 (1.000) <0-00:33:45> ({'r_t': -1270.2090, 'eps':     1.0000, 'len':  7467.3750, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   76000, Reward:   -71.702 [  19.158], Avg:   -75.360 (1.000) <0-00:34:10> ({'r_t': -1177.8641, 'eps':     1.0000, 'len':  7568.8720, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   77000, Reward:   -81.836 [  38.671], Avg:   -75.443 (1.000) <0-00:34:41> ({'r_t': -1240.7946, 'eps':     1.0000, 'len':  7666.0950, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   78000, Reward:   -86.291 [  32.116], Avg:   -75.580 (1.000) <0-00:35:08> ({'r_t': -1252.6767, 'eps':     1.0000, 'len':  7767.1750, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   79000, Reward:   -62.974 [  11.818], Avg:   -75.422 (1.000) <0-00:35:32> ({'r_t': -1241.2456, 'eps':     1.0000, 'len':  7871.5200, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   80000, Reward:   -68.073 [  15.278], Avg:   -75.332 (1.000) <0-00:35:57> ({'r_t': -1260.7514, 'eps':     1.0000, 'len':  7967.8680, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   81000, Reward:   -82.330 [  37.974], Avg:   -75.417 (1.000) <0-00:36:25> ({'r_t': -1262.8778, 'eps':     1.0000, 'len':  8062.7490, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   82000, Reward:   -75.634 [  29.634], Avg:   -75.420 (1.000) <0-00:36:52> ({'r_t': -1244.9864, 'eps':     1.0000, 'len':  8162.3840, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   83000, Reward:   -68.808 [  17.694], Avg:   -75.341 (1.000) <0-00:37:17> ({'r_t': -1295.4763, 'eps':     1.0000, 'len':  8263.4730, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   84000, Reward:   -77.226 [  24.311], Avg:   -75.363 (1.000) <0-00:37:44> ({'r_t': -1259.8599, 'eps':     1.0000, 'len':  8353.9360, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   85000, Reward:   -74.737 [  20.654], Avg:   -75.356 (1.000) <0-00:38:10> ({'r_t': -1149.1701, 'eps':     1.0000, 'len':  8446.3100, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   86000, Reward:   -71.161 [  14.060], Avg:   -75.308 (1.000) <0-00:38:35> ({'r_t': -1265.0463, 'eps':     1.0000, 'len':  8545.6320, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   87000, Reward:   -65.414 [  14.554], Avg:   -75.195 (1.000) <0-00:39:00> ({'r_t': -1278.5643, 'eps':     1.0000, 'len':  8644.8440, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   88000, Reward:   -89.105 [  29.293], Avg:   -75.351 (1.000) <0-00:39:27> ({'r_t': -1189.3777, 'eps':     1.0000, 'len':  8752.9700, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   89000, Reward:   -75.330 [  25.925], Avg:   -75.351 (1.000) <0-00:39:54> ({'r_t': -1315.7409, 'eps':     1.0000, 'len':  8852.4070, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   90000, Reward:   -82.475 [  24.093], Avg:   -75.430 (1.000) <0-00:40:20> ({'r_t': -1277.8778, 'eps':     1.0000, 'len':  8948.2050, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   91000, Reward:   -70.329 [  21.692], Avg:   -75.374 (1.000) <0-00:40:47> ({'r_t': -1258.8296, 'eps':     1.0000, 'len':  9049.2960, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   92000, Reward:   -79.091 [  22.729], Avg:   -75.414 (1.000) <0-00:41:12> ({'r_t': -1191.3168, 'eps':     1.0000, 'len':  9145.5340, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   93000, Reward:   -76.024 [  21.761], Avg:   -75.421 (1.000) <0-00:41:38> ({'r_t': -1233.4853, 'eps':     1.0000, 'len':  9243.8760, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   94000, Reward:   -72.662 [  20.926], Avg:   -75.392 (1.000) <0-00:42:05> ({'r_t': -1224.1754, 'eps':     1.0000, 'len':  9340.1510, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   95000, Reward:   -77.792 [  25.417], Avg:   -75.417 (1.000) <0-00:42:31> ({'r_t': -1264.5090, 'eps':     1.0000, 'len':  9432.5720, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   96000, Reward:   -80.445 [  27.829], Avg:   -75.468 (1.000) <0-00:42:57> ({'r_t': -1228.6443, 'eps':     1.0000, 'len':  9531.3650, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   97000, Reward:   -73.251 [  30.590], Avg:   -75.446 (1.000) <0-00:43:25> ({'r_t': -1283.3894, 'eps':     1.0000, 'len':  9635.5750, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   98000, Reward:   -60.672 [  10.341], Avg:   -75.296 (1.000) <0-00:43:50> ({'r_t': -1229.1738, 'eps':     1.0000, 'len':  9740.6740, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   99000, Reward:   -79.209 [  32.658], Avg:   -75.336 (1.000) <0-00:44:17> ({'r_t': -1204.1028, 'eps':     1.0000, 'len':  9841.9780, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  100000, Reward:   -84.207 [  30.564], Avg:   -75.423 (1.000) <0-00:44:44> ({'r_t': -1280.5294, 'eps':     1.0000, 'len':  9939.3450, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  101000, Reward:   -82.127 [  23.607], Avg:   -75.489 (1.000) <0-00:45:10> ({'r_t': -1160.3179, 'eps':     1.0000, 'len': 10036.8690, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  102000, Reward:   -80.198 [  28.586], Avg:   -75.535 (1.000) <0-00:45:36> ({'r_t': -1211.9831, 'eps':     1.0000, 'len': 10139.5570, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  103000, Reward:   -82.209 [  28.380], Avg:   -75.599 (1.000) <0-00:46:03> ({'r_t': -1224.7327, 'eps':     1.0000, 'len': 10233.9590, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  104000, Reward:   -83.810 [  42.528], Avg:   -75.677 (1.000) <0-00:46:33> ({'r_t': -1213.9261, 'eps':     1.0000, 'len': 10336.4050, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  105000, Reward:   -69.782 [  19.423], Avg:   -75.622 (1.000) <0-00:46:59> ({'r_t': -1228.1075, 'eps':     1.0000, 'len': 10436.1230, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  106000, Reward:   -74.742 [  21.398], Avg:   -75.613 (1.000) <0-00:47:24> ({'r_t': -1239.1110, 'eps':     1.0000, 'len': 10534.8220, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  107000, Reward:   -78.098 [  27.279], Avg:   -75.636 (1.000) <0-00:47:51> ({'r_t': -1237.5431, 'eps':     1.0000, 'len': 10633.7140, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  108000, Reward:   -67.923 [  17.284], Avg:   -75.566 (1.000) <0-00:48:17> ({'r_t': -1175.8513, 'eps':     1.0000, 'len': 10735.4500, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  109000, Reward:   -73.965 [  23.430], Avg:   -75.551 (1.000) <0-00:48:43> ({'r_t': -1228.8125, 'eps':     1.0000, 'len': 10841.7600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:  110000, Reward:   -38.708 [  45.617], Avg:   -75.219 (0.000) <0-00:51:24> ({'r_t': -1213.4657, 'eps':     0.0001, 'len': 10937.2170, 'dyn_loss':   714.8326, 'dot_loss':    41.1257, 'ddot_loss':    19.7262, 'rew_loss':    12.7517, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  111000, Reward:   -21.723 [  26.854], Avg:   -74.742 (0.100) <0-00:52:20> ({'r_t':  -167.8998, 'eps':     0.1001, 'len': 11066.4950, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  112000, Reward:    -9.995 [  31.571], Avg:   -74.169 (0.200) <0-00:53:14> ({'r_t':  -188.3619, 'eps':     0.2001, 'len': 11219.9530, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  113000, Reward:   -30.483 [  64.549], Avg:   -73.785 (0.300) <0-00:54:09> ({'r_t':  -277.6448, 'eps':     0.3001, 'len': 11406.0430, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  114000, Reward:   -27.781 [  51.902], Avg:   -73.385 (0.400) <0-00:54:56> ({'r_t':  -367.0105, 'eps':     0.4001, 'len': 11594.1400, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  115000, Reward:   -16.173 [  28.178], Avg:   -72.892 (0.500) <0-00:55:38> ({'r_t':  -370.0332, 'eps':     0.5001, 'len': 11780.8060, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  116000, Reward:   -26.044 [  82.178], Avg:   -72.492 (0.600) <0-00:56:22> ({'r_t':  -484.1865, 'eps':     0.6001, 'len': 11956.7010, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  117000, Reward:   -20.570 [  36.835], Avg:   -72.052 (0.700) <0-00:56:59> ({'r_t':  -772.9713, 'eps':     0.7001, 'len': 12110.0440, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  118000, Reward:   -48.683 [ 126.310], Avg:   -71.855 (0.800) <0-00:57:43> ({'r_t': -1020.7795, 'eps':     0.8001, 'len': 12243.3080, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  119000, Reward:   -35.868 [  36.090], Avg:   -71.555 (0.900) <0-00:58:14> ({'r_t': -1154.8606, 'eps':     0.9001, 'len': 12354.4270, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  120000, Reward:   -32.465 [ 172.572], Avg:   -71.232 (0.000) <0-01:01:02> ({'r_t': -1184.3810, 'eps':     0.0001, 'len': 12463.8740, 'dyn_loss':    56.0607, 'dot_loss':     7.8149, 'ddot_loss':     9.2845, 'rew_loss':     7.8887, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  121000, Reward:    12.580 [  46.498], Avg:   -70.545 (0.100) <0-01:02:01> ({'r_t':   212.8244, 'eps':     0.1001, 'len': 12577.8540, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  122000, Reward:    25.294 [  42.930], Avg:   -69.766 (0.200) <0-01:02:54> ({'r_t':   249.8918, 'eps':     0.2001, 'len': 12706.8650, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  123000, Reward:     6.398 [  68.693], Avg:   -69.152 (0.300) <0-01:03:44> ({'r_t':   324.3520, 'eps':     0.3001, 'len': 12853.6690, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  124000, Reward:    -3.717 [  92.973], Avg:   -68.629 (0.400) <0-01:04:38> ({'r_t':   156.9093, 'eps':     0.4001, 'len': 13007.2540, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  125000, Reward:     9.495 [  42.324], Avg:   -68.008 (0.500) <0-01:05:21> ({'r_t':   -36.5524, 'eps':     0.5001, 'len': 13159.6020, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  126000, Reward:     2.694 [  99.856], Avg:   -67.452 (0.600) <0-01:06:07> ({'r_t':  -232.9135, 'eps':     0.6001, 'len': 13311.7410, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  127000, Reward:    -2.991 [  69.725], Avg:   -66.948 (0.700) <0-01:06:49> ({'r_t':  -712.4334, 'eps':     0.7001, 'len': 13448.9210, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  128000, Reward:    30.032 [  50.476], Avg:   -66.196 (0.800) <0-01:07:20> ({'r_t':  -979.6495, 'eps':     0.8001, 'len': 13570.3770, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  129000, Reward:     3.529 [  47.124], Avg:   -65.660 (0.900) <0-01:08:01> ({'r_t': -1188.8918, 'eps':     0.9001, 'len': 13679.2620, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  130000, Reward:    56.699 [  49.613], Avg:   -64.726 (0.000) <0-01:10:33> ({'r_t': -1229.3682, 'eps':     0.0001, 'len': 13782.0760, 'dyn_loss':    38.1431, 'dot_loss':     5.0490, 'ddot_loss':     7.4975, 'rew_loss':     7.4772, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  131000, Reward:    55.990 [  43.723], Avg:   -63.811 (0.100) <0-01:11:29> ({'r_t':   317.3788, 'eps':     0.1001, 'len': 13890.9720, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  132000, Reward:    41.797 [  56.892], Avg:   -63.017 (0.200) <0-01:12:23> ({'r_t':   448.3279, 'eps':     0.2001, 'len': 14011.3340, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  133000, Reward:    32.159 [  75.287], Avg:   -62.307 (0.300) <0-01:13:14> ({'r_t':   611.4958, 'eps':     0.3001, 'len': 14140.7950, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  134000, Reward:    28.100 [  74.127], Avg:   -61.637 (0.400) <0-01:14:02> ({'r_t':   625.3325, 'eps':     0.4001, 'len': 14275.9360, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  135000, Reward:    25.732 [  64.996], Avg:   -60.995 (0.500) <0-01:14:46> ({'r_t':   404.0850, 'eps':     0.5001, 'len': 14411.9750, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  136000, Reward:    39.438 [  47.490], Avg:   -60.262 (0.600) <0-01:15:26> ({'r_t':   -29.0189, 'eps':     0.6001, 'len': 14550.0480, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  137000, Reward:    24.042 [  70.505], Avg:   -59.651 (0.700) <0-01:16:02> ({'r_t':  -506.7016, 'eps':     0.7001, 'len': 14682.8280, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  138000, Reward:    25.211 [  65.200], Avg:   -59.041 (0.800) <0-01:16:36> ({'r_t':  -935.7478, 'eps':     0.8001, 'len': 14799.7200, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  139000, Reward:    25.659 [  80.211], Avg:   -58.436 (0.900) <0-01:17:10> ({'r_t': -1185.6045, 'eps':     0.9001, 'len': 14907.8930, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  140000, Reward:    85.933 [  31.592], Avg:   -57.412 (0.000) <0-01:19:43> ({'r_t': -1178.0400, 'eps':     0.0001, 'len': 15015.7400, 'dyn_loss':    27.0703, 'dot_loss':     3.9829, 'ddot_loss':     6.9194, 'rew_loss':     7.2779, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  141000, Reward:    64.301 [  45.887], Avg:   -56.555 (0.100) <0-01:20:45> ({'r_t':   503.5018, 'eps':     0.1001, 'len': 15117.6620, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  142000, Reward:    35.740 [  73.649], Avg:   -55.909 (0.200) <0-01:21:49> ({'r_t':   449.0519, 'eps':     0.2001, 'len': 15208.7770, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  143000, Reward:    -8.662 [ 166.285], Avg:   -55.581 (0.300) <0-01:22:52> ({'r_t':   588.6478, 'eps':     0.3001, 'len': 15297.4870, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  144000, Reward:    82.296 [  80.732], Avg:   -54.630 (0.400) <0-01:23:49> ({'r_t':   762.7563, 'eps':     0.4001, 'len': 15394.1240, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  145000, Reward:    49.623 [  69.435], Avg:   -53.916 (0.500) <0-01:24:40> ({'r_t':   718.3948, 'eps':     0.5001, 'len': 15504.1770, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  146000, Reward:    95.540 [  33.578], Avg:   -52.899 (0.600) <0-01:25:27> ({'r_t':   346.2255, 'eps':     0.6001, 'len': 15615.8250, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  147000, Reward:    36.598 [  75.285], Avg:   -52.295 (0.700) <0-01:26:17> ({'r_t':  -284.9912, 'eps':     0.7001, 'len': 15732.3450, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  148000, Reward:    41.858 [  77.810], Avg:   -51.663 (0.800) <0-01:27:03> ({'r_t':  -850.3784, 'eps':     0.8001, 'len': 15851.5250, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  149000, Reward:    66.803 [  43.076], Avg:   -50.873 (0.900) <0-01:27:34> ({'r_t': -1153.5988, 'eps':     0.9001, 'len': 15960.2670, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  150000, Reward:    94.937 [  62.148], Avg:   -49.907 (0.000) <0-01:30:12> ({'r_t': -1201.2637, 'eps':     0.0001, 'len': 16061.0020, 'dyn_loss':    24.1298, 'dot_loss':     3.8028, 'ddot_loss':     7.0871, 'rew_loss':     7.5359, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  151000, Reward:    90.876 [ 115.137], Avg:   -48.981 (0.100) <0-01:31:24> ({'r_t':   694.5700, 'eps':     0.1001, 'len': 16146.9720, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  152000, Reward:   122.281 [  64.333], Avg:   -47.862 (0.200) <0-01:32:29> ({'r_t':   769.4502, 'eps':     0.2001, 'len': 16219.4020, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  153000, Reward:   130.457 [  91.954], Avg:   -46.704 (0.300) <0-01:33:29> ({'r_t':  1047.0107, 'eps':     0.3001, 'len': 16305.9560, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  154000, Reward:   136.059 [  69.269], Avg:   -45.525 (0.400) <0-01:34:24> ({'r_t':  1122.2161, 'eps':     0.4001, 'len': 16399.9650, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  155000, Reward:   150.135 [  76.459], Avg:   -44.271 (0.500) <0-01:35:16> ({'r_t':   833.7992, 'eps':     0.5001, 'len': 16494.8040, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  156000, Reward:    86.377 [ 100.474], Avg:   -43.438 (0.600) <0-01:36:05> ({'r_t':   508.5926, 'eps':     0.6001, 'len': 16591.1060, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  157000, Reward:   141.641 [  75.610], Avg:   -42.267 (0.700) <0-01:36:49> ({'r_t':  -223.4541, 'eps':     0.7001, 'len': 16688.8970, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  158000, Reward:   126.993 [  58.868], Avg:   -41.202 (0.800) <0-01:37:28> ({'r_t':  -850.6488, 'eps':     0.8001, 'len': 16792.6620, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  159000, Reward:   114.774 [  53.761], Avg:   -40.228 (0.900) <0-01:38:05> ({'r_t': -1141.8612, 'eps':     0.9001, 'len': 16904.2350, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  160000, Reward:    40.941 [ 128.944], Avg:   -39.723 (0.000) <0-01:40:46> ({'r_t': -1225.4223, 'eps':     0.0001, 'len': 17015.2100, 'dyn_loss':    24.7551, 'dot_loss':     3.7809, 'ddot_loss':     7.2089, 'rew_loss':     8.2831, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  161000, Reward:    45.490 [ 134.354], Avg:   -39.197 (0.100) <0-01:41:54> ({'r_t':   176.0645, 'eps':     0.1001, 'len': 17109.0940, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  162000, Reward:    13.852 [ 165.285], Avg:   -38.872 (0.200) <0-01:43:02> ({'r_t':    42.0896, 'eps':     0.2001, 'len': 17175.2910, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  163000, Reward:    16.451 [ 103.174], Avg:   -38.535 (0.300) <0-01:44:01> ({'r_t':   509.0791, 'eps':     0.3001, 'len': 17249.8680, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  164000, Reward:   -16.908 [ 137.778], Avg:   -38.404 (0.400) <0-01:44:57> ({'r_t':   396.8664, 'eps':     0.4001, 'len': 17330.2190, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  165000, Reward:    10.925 [ 136.765], Avg:   -38.106 (0.500) <0-01:45:51> ({'r_t':   332.6533, 'eps':     0.5001, 'len': 17408.4310, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  166000, Reward:    12.645 [ 140.286], Avg:   -37.803 (0.600) <0-01:46:45> ({'r_t':   293.9807, 'eps':     0.6001, 'len': 17495.4980, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  167000, Reward:    -3.617 [ 158.646], Avg:   -37.599 (0.700) <0-01:47:35> ({'r_t':  -238.9426, 'eps':     0.7001, 'len': 17598.9350, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  168000, Reward:    65.783 [ 109.481], Avg:   -36.987 (0.800) <0-01:48:17> ({'r_t':  -818.5259, 'eps':     0.8001, 'len': 17712.5350, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  169000, Reward:    -2.542 [ 169.950], Avg:   -36.785 (0.900) <0-01:49:00> ({'r_t': -1098.0339, 'eps':     0.9001, 'len': 17825.5030, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  170000, Reward:   317.643 [ 103.786], Avg:   -34.712 (0.000) <0-01:51:36> ({'r_t': -1263.7398, 'eps':     0.0001, 'len': 17922.9550, 'dyn_loss':    21.5958, 'dot_loss':     3.4833, 'ddot_loss':     6.7315, 'rew_loss':     8.4887, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  171000, Reward:   361.521 [  26.157], Avg:   -32.408 (0.100) <0-01:52:36> ({'r_t':  1750.9309, 'eps':     0.1001, 'len': 18009.1080, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  172000, Reward:   342.194 [  77.643], Avg:   -30.243 (0.200) <0-01:53:37> ({'r_t':  1717.3766, 'eps':     0.2001, 'len': 18085.5700, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  173000, Reward:   333.160 [  46.615], Avg:   -28.154 (0.300) <0-01:54:32> ({'r_t':  1702.5243, 'eps':     0.3001, 'len': 18164.5590, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  174000, Reward:   348.808 [  32.516], Avg:   -26.000 (0.400) <0-01:55:21> ({'r_t':  1718.1116, 'eps':     0.4001, 'len': 18245.5930, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  175000, Reward:   317.091 [ 123.027], Avg:   -24.051 (0.500) <0-01:56:13> ({'r_t':  1297.7323, 'eps':     0.5001, 'len': 18322.6920, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  176000, Reward:   297.643 [ 141.603], Avg:   -22.234 (0.600) <0-01:56:57> ({'r_t':   645.4637, 'eps':     0.6001, 'len': 18399.0030, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  177000, Reward:   358.809 [  29.090], Avg:   -20.093 (0.700) <0-01:57:36> ({'r_t':  -193.3340, 'eps':     0.7001, 'len': 18484.7950, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  178000, Reward:   273.918 [ 138.002], Avg:   -18.450 (0.800) <0-01:58:17> ({'r_t':  -867.4698, 'eps':     0.8001, 'len': 18584.9250, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  179000, Reward:   329.927 [  95.358], Avg:   -16.515 (0.900) <0-01:58:50> ({'r_t': -1196.5812, 'eps':     0.9001, 'len': 18689.7360, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  180000, Reward:   401.465 [  52.231], Avg:   -14.206 (0.000) <0-02:01:27> ({'r_t': -1215.0862, 'eps':     0.0001, 'len': 18791.4840, 'dyn_loss':    20.0453, 'dot_loss':     3.2820, 'ddot_loss':     6.3862, 'rew_loss':     8.9175, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  181000, Reward:   378.751 [  78.997], Avg:   -12.047 (0.100) <0-02:02:36> ({'r_t':  1738.1137, 'eps':     0.1001, 'len': 18874.8160, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  182000, Reward:   382.535 [  61.398], Avg:    -9.890 (0.200) <0-02:03:36> ({'r_t':  1815.3774, 'eps':     0.2001, 'len': 18944.9740, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  183000, Reward:   365.983 [ 115.468], Avg:    -7.848 (0.300) <0-02:04:36> ({'r_t':  1738.8320, 'eps':     0.3001, 'len': 19023.3370, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  184000, Reward:   392.514 [  50.260], Avg:    -5.683 (0.400) <0-02:05:29> ({'r_t':  1671.3390, 'eps':     0.4001, 'len': 19103.1450, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  185000, Reward:   398.982 [  62.230], Avg:    -3.508 (0.500) <0-02:06:17> ({'r_t':  1407.5303, 'eps':     0.5001, 'len': 19183.3400, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  186000, Reward:   389.723 [  53.206], Avg:    -1.405 (0.600) <0-02:07:04> ({'r_t':   835.7319, 'eps':     0.6001, 'len': 19263.5760, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  187000, Reward:   359.201 [  88.021], Avg:     0.513 (0.700) <0-02:07:53> ({'r_t':  -169.0890, 'eps':     0.7001, 'len': 19358.7200, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  188000, Reward:   386.206 [  57.968], Avg:     2.554 (0.800) <0-02:08:37> ({'r_t':  -775.8678, 'eps':     0.8001, 'len': 19467.7920, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  189000, Reward:   358.768 [ 106.269], Avg:     4.429 (0.900) <0-02:09:18> ({'r_t': -1117.1198, 'eps':     0.9001, 'len': 19577.1910, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  190000, Reward:   335.510 [ 101.365], Avg:     6.162 (0.000) <0-02:12:04> ({'r_t': -1242.0121, 'eps':     0.0001, 'len': 19681.2110, 'dyn_loss':    20.1821, 'dot_loss':     3.1748, 'ddot_loss':     6.2234, 'rew_loss':     9.2495, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  191000, Reward:   386.392 [  79.753], Avg:     8.142 (0.100) <0-02:13:05> ({'r_t':  1735.6164, 'eps':     0.1001, 'len': 19764.8350, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  192000, Reward:   398.913 [  58.144], Avg:    10.167 (0.200) <0-02:14:06> ({'r_t':  1906.2454, 'eps':     0.2001, 'len': 19835.3800, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  193000, Reward:   370.837 [  79.190], Avg:    12.026 (0.300) <0-02:15:03> ({'r_t':  1935.6767, 'eps':     0.3001, 'len': 19911.7390, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  194000, Reward:   349.877 [ 112.651], Avg:    13.759 (0.400) <0-02:16:02> ({'r_t':  1806.9819, 'eps':     0.4001, 'len': 19991.2870, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  195000, Reward:   395.723 [  73.854], Avg:    15.708 (0.500) <0-02:16:49> ({'r_t':  1429.1309, 'eps':     0.5001, 'len': 20069.3130, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  196000, Reward:   392.504 [  52.837], Avg:    17.620 (0.600) <0-02:17:35> ({'r_t':   880.2829, 'eps':     0.6001, 'len': 20149.1920, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  197000, Reward:   390.101 [  88.230], Avg:    19.502 (0.700) <0-02:18:16> ({'r_t':  -238.1694, 'eps':     0.7001, 'len': 20243.3740, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  198000, Reward:   365.245 [ 106.474], Avg:    21.239 (0.800) <0-02:18:54> ({'r_t':  -832.2868, 'eps':     0.8001, 'len': 20348.9120, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  199000, Reward:   359.513 [  69.398], Avg:    22.930 (0.900) <0-02:19:31> ({'r_t': -1106.8063, 'eps':     0.9001, 'len': 20457.8510, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  200000, Reward:   479.827 [  46.477], Avg:    25.203 (0.000) <0-02:22:13> ({'r_t': -1246.4379, 'eps':     0.0001, 'len': 20561.3400, 'dyn_loss':    20.9371, 'dot_loss':     3.1717, 'ddot_loss':     6.2552, 'rew_loss':     9.8724, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  201000, Reward:   472.933 [  62.462], Avg:    27.420 (0.100) <0-02:23:14> ({'r_t':  2016.3464, 'eps':     0.1001, 'len': 20639.0420, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  202000, Reward:   488.639 [  47.811], Avg:    29.692 (0.200) <0-02:24:15> ({'r_t':  2060.2313, 'eps':     0.2001, 'len': 20706.2660, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  203000, Reward:   476.954 [  50.442], Avg:    31.884 (0.300) <0-02:25:14> ({'r_t':  2065.8299, 'eps':     0.3001, 'len': 20782.0890, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  204000, Reward:   444.291 [  89.459], Avg:    33.896 (0.400) <0-02:26:07> ({'r_t':  1980.5951, 'eps':     0.4001, 'len': 20860.1590, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  205000, Reward:   464.162 [  81.931], Avg:    35.985 (0.500) <0-02:26:59> ({'r_t':  1441.4581, 'eps':     0.5001, 'len': 20932.5040, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  206000, Reward:   500.273 [  42.692], Avg:    38.228 (0.600) <0-02:27:46> ({'r_t':   707.2390, 'eps':     0.6001, 'len': 21012.6720, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  207000, Reward:   482.228 [  49.586], Avg:    40.362 (0.700) <0-02:28:30> ({'r_t':  -244.5138, 'eps':     0.7001, 'len': 21112.6500, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  208000, Reward:   471.267 [  55.622], Avg:    42.424 (0.800) <0-02:29:09> ({'r_t':  -918.5332, 'eps':     0.8001, 'len': 21219.2510, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  209000, Reward:   491.017 [  52.960], Avg:    44.560 (0.900) <0-02:29:49> ({'r_t': -1097.0946, 'eps':     0.9001, 'len': 21329.3230, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  210000, Reward:   519.767 [  50.474], Avg:    46.812 (0.000) <0-02:32:35> ({'r_t': -1188.4166, 'eps':     0.0001, 'len': 21434.3350, 'dyn_loss':    20.0153, 'dot_loss':     3.0969, 'ddot_loss':     6.1725, 'rew_loss':     9.9984, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  211000, Reward:   526.862 [  27.729], Avg:    49.077 (0.100) <0-02:33:37> ({'r_t':  2307.6227, 'eps':     0.1001, 'len': 21516.6600, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  212000, Reward:   507.368 [  53.488], Avg:    51.228 (0.200) <0-02:34:41> ({'r_t':  2157.3690, 'eps':     0.2001, 'len': 21583.0710, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  213000, Reward:   511.767 [  46.766], Avg:    53.380 (0.300) <0-02:35:42> ({'r_t':  2100.6579, 'eps':     0.3001, 'len': 21650.7660, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  214000, Reward:   515.065 [  35.879], Avg:    55.528 (0.400) <0-02:36:36> ({'r_t':  2124.3865, 'eps':     0.4001, 'len': 21717.0330, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  215000, Reward:   524.929 [  25.155], Avg:    57.701 (0.500) <0-02:37:24> ({'r_t':  1678.1769, 'eps':     0.5001, 'len': 21783.2730, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  216000, Reward:   516.160 [  51.858], Avg:    59.814 (0.600) <0-02:38:12> ({'r_t':   732.4389, 'eps':     0.6001, 'len': 21853.2670, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  217000, Reward:   515.830 [  55.314], Avg:    61.906 (0.700) <0-02:38:57> ({'r_t':  -219.8890, 'eps':     0.7001, 'len': 21941.7530, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  218000, Reward:   509.447 [  53.168], Avg:    63.949 (0.800) <0-02:39:40> ({'r_t':  -961.2619, 'eps':     0.8001, 'len': 22043.0670, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  219000, Reward:   524.512 [  54.222], Avg:    66.043 (0.900) <0-02:40:20> ({'r_t': -1129.3573, 'eps':     0.9001, 'len': 22150.4850, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  220000, Reward:   611.412 [ 113.523], Avg:    68.510 (0.000) <0-02:43:09> ({'r_t': -1187.7745, 'eps':     0.0001, 'len': 22260.5200, 'dyn_loss':    20.7901, 'dot_loss':     3.1781, 'ddot_loss':     6.3527, 'rew_loss':    10.5902, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  221000, Reward:   646.972 [  71.863], Avg:    71.116 (0.100) <0-02:44:13> ({'r_t':  2521.8488, 'eps':     0.1001, 'len': 22341.8240, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  222000, Reward:   608.969 [ 121.223], Avg:    73.528 (0.200) <0-02:45:13> ({'r_t':  2488.9311, 'eps':     0.2001, 'len': 22403.4590, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  223000, Reward:   654.188 [  66.406], Avg:    76.120 (0.300) <0-02:46:10> ({'r_t':  2413.2631, 'eps':     0.3001, 'len': 22474.2950, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  224000, Reward:   598.987 [ 121.032], Avg:    78.444 (0.400) <0-02:47:03> ({'r_t':  2112.7169, 'eps':     0.4001, 'len': 22543.4370, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  225000, Reward:   640.152 [  85.181], Avg:    80.929 (0.500) <0-02:47:54> ({'r_t':  1632.3410, 'eps':     0.5001, 'len': 22610.8410, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  226000, Reward:   629.215 [ 110.791], Avg:    83.345 (0.600) <0-02:48:41> ({'r_t':   808.8210, 'eps':     0.6001, 'len': 22687.1010, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  227000, Reward:   600.180 [ 125.707], Avg:    85.612 (0.700) <0-02:49:28> ({'r_t':  -249.2917, 'eps':     0.7001, 'len': 22775.0560, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  228000, Reward:   622.302 [ 104.565], Avg:    87.955 (0.800) <0-02:50:09> ({'r_t':  -901.5963, 'eps':     0.8001, 'len': 22881.2100, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  229000, Reward:   625.854 [  78.818], Avg:    90.294 (0.900) <0-02:50:45> ({'r_t': -1197.4388, 'eps':     0.9001, 'len': 22986.9690, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  230000, Reward:   652.955 [  68.086], Avg:    92.730 (0.000) <0-02:53:39> ({'r_t': -1215.3647, 'eps':     0.0001, 'len': 23092.4950, 'dyn_loss':    20.5436, 'dot_loss':     3.1880, 'ddot_loss':     6.4095, 'rew_loss':    10.9882, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  231000, Reward:   679.075 [  58.495], Avg:    95.257 (0.100) <0-02:54:44> ({'r_t':  2492.8807, 'eps':     0.1001, 'len': 23175.8330, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  232000, Reward:   658.639 [  89.623], Avg:    97.675 (0.200) <0-02:55:44> ({'r_t':  2478.5353, 'eps':     0.2001, 'len': 23236.0970, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  233000, Reward:   666.671 [  63.251], Avg:   100.107 (0.300) <0-02:56:42> ({'r_t':  2610.7266, 'eps':     0.3001, 'len': 23302.4400, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  234000, Reward:   659.796 [  60.165], Avg:   102.488 (0.400) <0-02:57:34> ({'r_t':  2049.7024, 'eps':     0.4001, 'len': 23369.3490, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  235000, Reward:   628.610 [  78.505], Avg:   104.718 (0.500) <0-02:58:27> ({'r_t':  1723.1744, 'eps':     0.5001, 'len': 23438.3400, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  236000, Reward:   673.222 [  81.617], Avg:   107.116 (0.600) <0-02:59:12> ({'r_t':   732.0772, 'eps':     0.6001, 'len': 23515.6370, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  237000, Reward:   638.668 [  91.129], Avg:   109.350 (0.700) <0-02:59:57> ({'r_t':  -201.7047, 'eps':     0.7001, 'len': 23611.4140, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  238000, Reward:   670.897 [  70.458], Avg:   111.699 (0.800) <0-03:00:42> ({'r_t':  -804.5695, 'eps':     0.8001, 'len': 23712.0390, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  239000, Reward:   667.913 [  76.030], Avg:   114.017 (0.900) <0-03:01:20> ({'r_t': -1168.8971, 'eps':     0.9001, 'len': 23818.8300, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  240000, Reward:   655.323 [  93.386], Avg:   116.263 (0.000) <0-03:04:12> ({'r_t': -1163.2467, 'eps':     0.0001, 'len': 23927.1990, 'dyn_loss':    20.1260, 'dot_loss':     3.1249, 'ddot_loss':     6.3178, 'rew_loss':    11.0513, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  241000, Reward:   672.914 [  52.777], Avg:   118.563 (0.100) <0-03:05:17> ({'r_t':  2530.7493, 'eps':     0.1001, 'len': 24012.5510, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  242000, Reward:   690.401 [  53.202], Avg:   120.916 (0.200) <0-03:06:19> ({'r_t':  2342.4875, 'eps':     0.2001, 'len': 24067.5160, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  243000, Reward:   652.887 [ 104.156], Avg:   123.097 (0.300) <0-03:07:23> ({'r_t':  2483.4462, 'eps':     0.3001, 'len': 24129.8900, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  244000, Reward:   664.703 [  71.007], Avg:   125.307 (0.400) <0-03:08:17> ({'r_t':  2151.0751, 'eps':     0.4001, 'len': 24192.9490, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  245000, Reward:   628.759 [  75.685], Avg:   127.354 (0.500) <0-03:09:09> ({'r_t':  1808.1305, 'eps':     0.5001, 'len': 24257.9670, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  246000, Reward:   700.835 [  48.262], Avg:   129.676 (0.600) <0-03:09:58> ({'r_t':   733.3838, 'eps':     0.6001, 'len': 24329.1890, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  247000, Reward:   664.728 [  74.399], Avg:   131.833 (0.700) <0-03:10:48> ({'r_t':  -312.6668, 'eps':     0.7001, 'len': 24414.4280, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  248000, Reward:   620.922 [ 153.539], Avg:   133.797 (0.800) <0-03:11:28> ({'r_t':  -948.2768, 'eps':     0.8001, 'len': 24513.0230, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  249000, Reward:   684.193 [  54.380], Avg:   135.999 (0.900) <0-03:12:04> ({'r_t': -1173.1344, 'eps':     0.9001, 'len': 24615.4650, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  250000, Reward:   755.443 [ 100.116], Avg:   138.467 (0.000) <0-03:15:00> ({'r_t': -1233.6352, 'eps':     0.0001, 'len': 24712.7630, 'dyn_loss':    20.1755, 'dot_loss':     3.1157, 'ddot_loss':     6.3162, 'rew_loss':    11.2924, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  251000, Reward:   712.294 [ 187.913], Avg:   140.744 (0.100) <0-03:16:12> ({'r_t':  2592.9754, 'eps':     0.1001, 'len': 24786.7470, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  252000, Reward:   791.538 [  86.847], Avg:   143.316 (0.200) <0-03:17:16> ({'r_t':  2397.1440, 'eps':     0.2001, 'len': 24839.6210, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  253000, Reward:   765.133 [  84.964], Avg:   145.764 (0.300) <0-03:18:20> ({'r_t':  2490.2162, 'eps':     0.3001, 'len': 24899.4570, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  254000, Reward:   738.803 [ 103.993], Avg:   148.090 (0.400) <0-03:19:21> ({'r_t':  2252.7882, 'eps':     0.4001, 'len': 24960.4120, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  255000, Reward:   723.433 [ 103.591], Avg:   150.337 (0.500) <0-03:20:13> ({'r_t':  1566.1725, 'eps':     0.5001, 'len': 25023.5300, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  256000, Reward:   695.753 [ 191.247], Avg:   152.460 (0.600) <0-03:21:01> ({'r_t':   742.3699, 'eps':     0.6001, 'len': 25094.8660, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  257000, Reward:   734.401 [  88.668], Avg:   154.715 (0.700) <0-03:21:52> ({'r_t':  -337.4476, 'eps':     0.7001, 'len': 25180.9530, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  258000, Reward:   765.678 [  71.449], Avg:   157.074 (0.800) <0-03:22:37> ({'r_t':  -835.5348, 'eps':     0.8001, 'len': 25286.0040, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  259000, Reward:   732.678 [  89.551], Avg:   159.288 (0.900) <0-03:23:20> ({'r_t': -1178.1635, 'eps':     0.9001, 'len': 25397.4370, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  260000, Reward:   719.514 [ 189.484], Avg:   161.434 (0.000) <0-03:26:18> ({'r_t': -1226.4937, 'eps':     0.0001, 'len': 25498.4020, 'dyn_loss':    20.8315, 'dot_loss':     3.1722, 'ddot_loss':     6.4264, 'rew_loss':    11.6193, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  261000, Reward:   773.650 [ 188.623], Avg:   163.771 (0.100) <0-03:27:30> ({'r_t':  2645.5767, 'eps':     0.1001, 'len': 25580.8080, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  262000, Reward:   702.732 [ 168.183], Avg:   165.820 (0.200) <0-03:28:38> ({'r_t':  2522.9739, 'eps':     0.2001, 'len': 25640.6620, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  263000, Reward:   727.079 [ 157.466], Avg:   167.946 (0.300) <0-03:29:41> ({'r_t':  2585.5397, 'eps':     0.3001, 'len': 25702.9790, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  264000, Reward:   631.341 [ 199.015], Avg:   169.695 (0.400) <0-03:30:42> ({'r_t':  2328.1761, 'eps':     0.4001, 'len': 25762.2290, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  265000, Reward:   636.688 [ 133.692], Avg:   171.451 (0.500) <0-03:31:39> ({'r_t':  1787.6473, 'eps':     0.5001, 'len': 25826.9850, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  266000, Reward:   726.569 [ 192.475], Avg:   173.530 (0.600) <0-03:32:33> ({'r_t':   838.0965, 'eps':     0.6001, 'len': 25899.5930, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  267000, Reward:   717.589 [ 187.197], Avg:   175.560 (0.700) <0-03:33:23> ({'r_t':  -298.0742, 'eps':     0.7001, 'len': 25986.4190, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  268000, Reward:   722.300 [ 178.456], Avg:   177.592 (0.800) <0-03:34:11> ({'r_t':  -948.9859, 'eps':     0.8001, 'len': 26091.1770, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  269000, Reward:   681.738 [ 140.240], Avg:   179.459 (0.900) <0-03:34:51> ({'r_t': -1108.1774, 'eps':     0.9001, 'len': 26207.2200, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  270000, Reward:   936.300 [ 293.562], Avg:   182.252 (0.000) <0-03:37:51> ({'r_t': -1203.1181, 'eps':     0.0001, 'len': 26311.0610, 'dyn_loss':    21.1086, 'dot_loss':     3.2003, 'ddot_loss':     6.5025, 'rew_loss':    11.8992, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  271000, Reward:   883.897 [ 318.262], Avg:   184.832 (0.100) <0-03:39:02> ({'r_t':  2763.2998, 'eps':     0.1001, 'len': 26382.3150, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  272000, Reward:   827.668 [ 406.705], Avg:   187.187 (0.200) <0-03:40:10> ({'r_t':  2760.2183, 'eps':     0.2001, 'len': 26432.0650, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  273000, Reward:   782.760 [ 372.825], Avg:   189.360 (0.300) <0-03:41:14> ({'r_t':  2540.3065, 'eps':     0.3001, 'len': 26486.5400, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  274000, Reward:   941.389 [ 374.586], Avg:   192.095 (0.400) <0-03:42:15> ({'r_t':  2263.9271, 'eps':     0.4001, 'len': 26543.6770, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  275000, Reward:   913.252 [ 305.846], Avg:   194.708 (0.500) <0-03:43:12> ({'r_t':  1783.6036, 'eps':     0.5001, 'len': 26603.1450, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  276000, Reward:   914.709 [ 393.994], Avg:   197.307 (0.600) <0-03:44:06> ({'r_t':   731.1206, 'eps':     0.6001, 'len': 26673.7460, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  277000, Reward:   877.953 [ 404.509], Avg:   199.755 (0.700) <0-03:44:57> ({'r_t':  -389.6833, 'eps':     0.7001, 'len': 26766.5570, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  278000, Reward:   878.827 [ 404.381], Avg:   202.189 (0.800) <0-03:45:44> ({'r_t':  -857.7431, 'eps':     0.8001, 'len': 26867.1510, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  279000, Reward:   987.863 [ 342.373], Avg:   204.995 (0.900) <0-03:46:27> ({'r_t': -1149.8208, 'eps':     0.9001, 'len': 26972.5440, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  280000, Reward:  1314.410 [  90.280], Avg:   208.943 (0.000) <0-03:49:28> ({'r_t': -1201.0260, 'eps':     0.0001, 'len': 27075.0680, 'dyn_loss':    20.2864, 'dot_loss':     3.1314, 'ddot_loss':     6.3808, 'rew_loss':    11.7022, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:  281000, Reward:  1272.545 [ 141.392], Avg:   212.715 (0.100) <0-03:50:39> ({'r_t':  3120.4374, 'eps':     0.1001, 'len': 27142.2740, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:  282000, Reward:  1182.070 [ 308.003], Avg:   216.140 (0.200) <0-03:51:47> ({'r_t':  3029.2535, 'eps':     0.2001, 'len': 27181.1270, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:  283000, Reward:  1241.952 [ 202.335], Avg:   219.752 (0.300) <0-03:52:51> ({'r_t':  2779.8769, 'eps':     0.3001, 'len': 27226.9700, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:  284000, Reward:  1314.681 [  75.724], Avg:   223.594 (0.400) <0-03:53:52> ({'r_t':  2531.6611, 'eps':     0.4001, 'len': 27281.4170, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:  285000, Reward:  1278.341 [ 119.609], Avg:   227.282 (0.500) <0-03:54:49> ({'r_t':  1713.7137, 'eps':     0.5001, 'len': 27346.5990, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:  286000, Reward:  1328.356 [  91.928], Avg:   231.119 (0.600) <0-03:55:42> ({'r_t':   642.3348, 'eps':     0.6001, 'len': 27425.2000, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:  287000, Reward:  1223.188 [ 239.505], Avg:   234.563 (0.700) <0-03:56:33> ({'r_t':  -217.5168, 'eps':     0.7001, 'len': 27518.4620, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:  288000, Reward:  1156.358 [ 293.512], Avg:   237.753 (0.800) <0-03:57:20> ({'r_t':  -907.1982, 'eps':     0.8001, 'len': 27617.6390, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:  289000, Reward:  1261.821 [ 189.719], Avg:   241.284 (0.900) <0-03:58:03> ({'r_t': -1136.0761, 'eps':     0.9001, 'len': 27721.1890, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:  290000, Reward:  1261.943 [ 412.599], Avg:   244.792 (0.000) <0-04:01:07> ({'r_t': -1209.1301, 'eps':     0.0001, 'len': 27824.7190, 'dyn_loss':    21.4078, 'dot_loss':     3.2356, 'ddot_loss':     6.5634, 'rew_loss':    12.3059, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  291000, Reward:   954.542 [ 515.247], Avg:   247.222 (0.100) <0-04:02:19> ({'r_t':  3214.5641, 'eps':     0.1001, 'len': 27897.4940, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  292000, Reward:  1225.946 [ 468.619], Avg:   250.563 (0.200) <0-04:03:26> ({'r_t':  3140.9761, 'eps':     0.2001, 'len': 27942.7280, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  293000, Reward:   957.787 [ 484.002], Avg:   252.968 (0.300) <0-04:04:31> ({'r_t':  2922.1677, 'eps':     0.3001, 'len': 27996.5390, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  294000, Reward:  1113.118 [ 497.791], Avg:   255.884 (0.400) <0-04:05:32> ({'r_t':  2532.7015, 'eps':     0.4001, 'len': 28045.8230, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  295000, Reward:  1021.097 [ 475.667], Avg:   258.469 (0.500) <0-04:06:29> ({'r_t':  1743.1358, 'eps':     0.5001, 'len': 28100.7440, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  296000, Reward:  1216.353 [ 467.098], Avg:   261.694 (0.600) <0-04:07:23> ({'r_t':   574.1296, 'eps':     0.6001, 'len': 28179.2360, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  297000, Reward:   985.506 [ 458.082], Avg:   264.123 (0.700) <0-04:08:13> ({'r_t':  -206.6440, 'eps':     0.7001, 'len': 28274.5880, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  298000, Reward:  1156.010 [ 448.186], Avg:   267.106 (0.800) <0-04:09:00> ({'r_t':  -943.9802, 'eps':     0.8001, 'len': 28379.0540, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  299000, Reward:  1146.381 [ 477.585], Avg:   270.037 (0.900) <0-04:09:44> ({'r_t': -1157.7652, 'eps':     0.9001, 'len': 28485.4700, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  300000, Reward:  1270.486 [ 363.526], Avg:   273.361 (0.000) <0-04:12:47> ({'r_t': -1237.2951, 'eps':     0.0001, 'len': 28585.7470, 'dyn_loss':    21.7144, 'dot_loss':     3.2644, 'ddot_loss':     6.6225, 'rew_loss':    12.3974, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  301000, Reward:  1280.642 [ 365.279], Avg:   276.696 (0.100) <0-04:13:59> ({'r_t':  3138.1933, 'eps':     0.1001, 'len': 28653.1360, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  302000, Reward:  1221.655 [ 416.136], Avg:   279.815 (0.200) <0-04:15:06> ({'r_t':  3155.7208, 'eps':     0.2001, 'len': 28693.6510, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  303000, Reward:  1010.391 [ 375.305], Avg:   282.218 (0.300) <0-04:16:11> ({'r_t':  3015.4178, 'eps':     0.3001, 'len': 28737.3340, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  304000, Reward:  1330.773 [ 355.403], Avg:   285.656 (0.400) <0-04:17:11> ({'r_t':  2638.0628, 'eps':     0.4001, 'len': 28786.7060, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  305000, Reward:  1004.866 [ 519.875], Avg:   288.006 (0.500) <0-04:18:08> ({'r_t':  1886.1307, 'eps':     0.5001, 'len': 28843.2760, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  306000, Reward:  1178.519 [ 450.831], Avg:   290.907 (0.600) <0-04:19:02> ({'r_t':   757.2030, 'eps':     0.6001, 'len': 28917.3090, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  307000, Reward:  1290.758 [ 386.627], Avg:   294.153 (0.700) <0-04:19:53> ({'r_t':  -389.6831, 'eps':     0.7001, 'len': 29018.9290, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  308000, Reward:  1320.178 [ 297.837], Avg:   297.474 (0.800) <0-04:20:40> ({'r_t':  -965.3866, 'eps':     0.8001, 'len': 29126.2490, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  309000, Reward:  1246.816 [ 414.307], Avg:   300.536 (0.900) <0-04:21:23> ({'r_t': -1163.2369, 'eps':     0.9001, 'len': 29233.4560, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  310000, Reward:  1237.263 [ 467.797], Avg:   303.548 (0.000) <0-04:24:28> ({'r_t': -1234.3502, 'eps':     0.0001, 'len': 29334.2420, 'dyn_loss':    21.3737, 'dot_loss':     3.2660, 'ddot_loss':     6.6454, 'rew_loss':    12.5540, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  311000, Reward:  1313.708 [ 385.645], Avg:   306.786 (0.100) <0-04:25:40> ({'r_t':  3181.1399, 'eps':     0.1001, 'len': 29403.2610, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  312000, Reward:  1260.685 [ 370.124], Avg:   309.833 (0.200) <0-04:26:48> ({'r_t':  3068.0015, 'eps':     0.2001, 'len': 29446.5480, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  313000, Reward:  1190.234 [ 474.713], Avg:   312.637 (0.300) <0-04:27:52> ({'r_t':  2997.4996, 'eps':     0.3001, 'len': 29490.8970, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  314000, Reward:  1025.919 [ 472.296], Avg:   314.901 (0.400) <0-04:28:53> ({'r_t':  2588.7239, 'eps':     0.4001, 'len': 29538.1600, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  315000, Reward:  1129.991 [ 393.681], Avg:   317.481 (0.500) <0-04:29:50> ({'r_t':  1761.0984, 'eps':     0.5001, 'len': 29590.3180, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  316000, Reward:  1012.608 [ 500.011], Avg:   319.674 (0.600) <0-04:30:43> ({'r_t':   484.2477, 'eps':     0.6001, 'len': 29664.9980, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  317000, Reward:  1329.808 [ 502.820], Avg:   322.850 (0.700) <0-04:31:34> ({'r_t':  -385.1852, 'eps':     0.7001, 'len': 29758.7850, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  318000, Reward:  1283.757 [ 431.283], Avg:   325.862 (0.800) <0-04:32:21> ({'r_t':  -929.0674, 'eps':     0.8001, 'len': 29862.9540, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  319000, Reward:  1320.227 [ 411.290], Avg:   328.970 (0.900) <0-04:33:04> ({'r_t': -1116.4644, 'eps':     0.9001, 'len': 29973.8270, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  320000, Reward:  1464.040 [ 349.924], Avg:   332.506 (0.000) <0-04:36:08> ({'r_t': -1250.5048, 'eps':     0.0001, 'len': 30086.5950, 'dyn_loss':    21.4806, 'dot_loss':     3.2524, 'ddot_loss':     6.6136, 'rew_loss':    12.6203, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  321000, Reward:  1528.771 [ 254.130], Avg:   336.221 (0.100) <0-04:37:19> ({'r_t':  3452.8424, 'eps':     0.1001, 'len': 30154.7070, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  322000, Reward:  1506.662 [ 304.816], Avg:   339.845 (0.200) <0-04:38:27> ({'r_t':  3420.1148, 'eps':     0.2001, 'len': 30192.5290, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  323000, Reward:  1480.941 [ 336.655], Avg:   343.367 (0.300) <0-04:39:31> ({'r_t':  3034.5624, 'eps':     0.3001, 'len': 30239.6580, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  324000, Reward:  1501.101 [ 310.074], Avg:   346.929 (0.400) <0-04:40:32> ({'r_t':  2537.0547, 'eps':     0.4001, 'len': 30291.6820, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  325000, Reward:  1383.980 [ 455.336], Avg:   350.110 (0.500) <0-04:41:29> ({'r_t':  1791.7935, 'eps':     0.5001, 'len': 30351.2820, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  326000, Reward:  1512.900 [ 308.422], Avg:   353.666 (0.600) <0-04:42:23> ({'r_t':   539.0605, 'eps':     0.6001, 'len': 30426.5580, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  327000, Reward:  1317.469 [ 499.770], Avg:   356.604 (0.700) <0-04:43:13> ({'r_t':  -342.9934, 'eps':     0.7001, 'len': 30521.0020, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  328000, Reward:  1471.029 [ 385.763], Avg:   359.992 (0.800) <0-04:44:00> ({'r_t':  -929.9973, 'eps':     0.8001, 'len': 30622.3260, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  329000, Reward:  1384.995 [ 412.142], Avg:   363.098 (0.900) <0-04:44:44> ({'r_t': -1174.6251, 'eps':     0.9001, 'len': 30720.7680, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  330000, Reward:  1627.723 [  56.206], Avg:   366.918 (0.000) <0-04:47:50> ({'r_t': -1227.9034, 'eps':     0.0001, 'len': 30821.5800, 'dyn_loss':    22.2209, 'dot_loss':     3.3579, 'ddot_loss':     6.8112, 'rew_loss':    12.8046, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  331000, Reward:  1444.473 [ 493.573], Avg:   370.164 (0.100) <0-04:49:01> ({'r_t':  3483.3996, 'eps':     0.1001, 'len': 30885.5910, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  332000, Reward:  1495.902 [ 391.915], Avg:   373.545 (0.200) <0-04:50:09> ({'r_t':  3358.5080, 'eps':     0.2001, 'len': 30921.7840, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  333000, Reward:  1427.553 [ 428.026], Avg:   376.700 (0.300) <0-04:51:13> ({'r_t':  3079.1164, 'eps':     0.3001, 'len': 30966.8010, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  334000, Reward:  1551.532 [ 266.312], Avg:   380.207 (0.400) <0-04:52:14> ({'r_t':  2738.3899, 'eps':     0.4001, 'len': 31016.3560, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  335000, Reward:  1519.101 [ 347.260], Avg:   383.597 (0.500) <0-04:53:11> ({'r_t':  1719.3742, 'eps':     0.5001, 'len': 31072.8850, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  336000, Reward:  1632.640 [  50.969], Avg:   387.303 (0.600) <0-04:54:04> ({'r_t':   579.4218, 'eps':     0.6001, 'len': 31151.6970, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  337000, Reward:  1560.671 [ 300.217], Avg:   390.775 (0.700) <0-04:54:55> ({'r_t':  -295.5485, 'eps':     0.7001, 'len': 31244.2790, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  338000, Reward:  1591.291 [ 269.312], Avg:   394.316 (0.800) <0-04:55:42> ({'r_t':  -931.3308, 'eps':     0.8001, 'len': 31355.0190, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  339000, Reward:  1497.008 [ 384.388], Avg:   397.559 (0.900) <0-04:56:25> ({'r_t': -1175.5333, 'eps':     0.9001, 'len': 31460.7940, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  340000, Reward:  1371.045 [ 499.927], Avg:   400.414 (0.000) <0-04:59:31> ({'r_t': -1201.8537, 'eps':     0.0001, 'len': 31565.3320, 'dyn_loss':    21.9785, 'dot_loss':     3.3586, 'ddot_loss':     6.8406, 'rew_loss':    12.9589, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  341000, Reward:  1371.553 [ 502.524], Avg:   403.254 (0.100) <0-05:00:43> ({'r_t':  3381.8120, 'eps':     0.1001, 'len': 31635.8030, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  342000, Reward:  1289.546 [ 557.282], Avg:   405.838 (0.200) <0-05:01:51> ({'r_t':  3208.3082, 'eps':     0.2001, 'len': 31677.0360, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  343000, Reward:  1400.127 [ 512.224], Avg:   408.728 (0.300) <0-05:02:55> ({'r_t':  3092.8925, 'eps':     0.3001, 'len': 31726.1110, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  344000, Reward:  1289.390 [ 562.653], Avg:   411.281 (0.400) <0-05:03:56> ({'r_t':  2722.0435, 'eps':     0.4001, 'len': 31778.5380, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  345000, Reward:  1406.738 [ 515.868], Avg:   414.158 (0.500) <0-05:04:53> ({'r_t':  1822.1882, 'eps':     0.5001, 'len': 31834.9100, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  346000, Reward:  1513.873 [ 367.345], Avg:   417.327 (0.600) <0-05:05:46> ({'r_t':   616.5913, 'eps':     0.6001, 'len': 31907.1050, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  347000, Reward:  1603.696 [ 145.474], Avg:   420.736 (0.700) <0-05:06:37> ({'r_t':  -464.1344, 'eps':     0.7001, 'len': 32003.7740, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  348000, Reward:  1320.293 [ 537.667], Avg:   423.313 (0.800) <0-05:07:24> ({'r_t':  -973.2930, 'eps':     0.8001, 'len': 32106.6230, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  349000, Reward:  1255.297 [ 548.940], Avg:   425.691 (0.900) <0-05:08:07> ({'r_t': -1189.3988, 'eps':     0.9001, 'len': 32205.4800, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  350000, Reward:  1582.607 [ 436.669], Avg:   428.987 (0.000) <0-05:11:15> ({'r_t': -1211.1343, 'eps':     0.0001, 'len': 32313.5360, 'dyn_loss':    20.8419, 'dot_loss':     3.2708, 'ddot_loss':     6.7059, 'rew_loss':    12.6663, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  351000, Reward:  1609.247 [ 438.761], Avg:   432.340 (0.100) <0-05:12:26> ({'r_t':  3541.7182, 'eps':     0.1001, 'len': 32381.5300, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  352000, Reward:  1673.863 [ 295.015], Avg:   435.857 (0.200) <0-05:13:33> ({'r_t':  3421.7710, 'eps':     0.2001, 'len': 32419.4370, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  353000, Reward:  1648.378 [ 299.882], Avg:   439.282 (0.300) <0-05:14:38> ({'r_t':  3017.1779, 'eps':     0.3001, 'len': 32467.3090, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  354000, Reward:  1437.067 [ 497.360], Avg:   442.093 (0.400) <0-05:15:38> ({'r_t':  2659.7287, 'eps':     0.4001, 'len': 32519.8220, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  355000, Reward:  1632.118 [ 313.161], Avg:   445.435 (0.500) <0-05:16:36> ({'r_t':  1857.8872, 'eps':     0.5001, 'len': 32575.5950, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  356000, Reward:  1645.678 [ 437.482], Avg:   448.797 (0.600) <0-05:17:29> ({'r_t':   487.5546, 'eps':     0.6001, 'len': 32653.7020, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  357000, Reward:  1754.625 [  87.782], Avg:   452.445 (0.700) <0-05:18:19> ({'r_t':  -325.9126, 'eps':     0.7001, 'len': 32751.1150, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  358000, Reward:  1439.601 [ 590.785], Avg:   455.195 (0.800) <0-05:19:07> ({'r_t':  -946.1717, 'eps':     0.8001, 'len': 32852.1020, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  359000, Reward:  1658.326 [ 285.030], Avg:   458.537 (0.900) <0-05:19:50> ({'r_t': -1058.8228, 'eps':     0.9001, 'len': 32966.6300, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  360000, Reward:  1703.435 [ 341.236], Avg:   461.985 (0.000) <0-05:22:59> ({'r_t': -1183.7280, 'eps':     0.0001, 'len': 33077.4990, 'dyn_loss':    21.7410, 'dot_loss':     3.3477, 'ddot_loss':     6.8501, 'rew_loss':    13.1042, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  361000, Reward:  1792.248 [  96.629], Avg:   465.660 (0.100) <0-05:24:11> ({'r_t':  3475.3574, 'eps':     0.1001, 'len': 33147.0310, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  362000, Reward:  1610.695 [ 385.359], Avg:   468.814 (0.200) <0-05:25:18> ({'r_t':  3479.7420, 'eps':     0.2001, 'len': 33182.9680, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  363000, Reward:  1528.899 [ 508.582], Avg:   471.727 (0.300) <0-05:26:23> ({'r_t':  3174.8613, 'eps':     0.3001, 'len': 33226.7250, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  364000, Reward:  1419.050 [ 574.640], Avg:   474.322 (0.400) <0-05:27:23> ({'r_t':  2762.8650, 'eps':     0.4001, 'len': 33271.6370, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  365000, Reward:  1392.065 [ 590.818], Avg:   476.830 (0.500) <0-05:28:20> ({'r_t':  1818.7251, 'eps':     0.5001, 'len': 33327.5940, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  366000, Reward:  1521.675 [ 470.711], Avg:   479.677 (0.600) <0-05:29:14> ({'r_t':   638.2512, 'eps':     0.6001, 'len': 33403.6040, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  367000, Reward:  1461.825 [ 576.932], Avg:   482.345 (0.700) <0-05:30:05> ({'r_t':  -398.1519, 'eps':     0.7001, 'len': 33499.3100, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  368000, Reward:  1617.390 [ 454.860], Avg:   485.421 (0.800) <0-05:30:52> ({'r_t':  -954.7423, 'eps':     0.8001, 'len': 33617.4070, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  369000, Reward:  1622.257 [ 419.773], Avg:   488.494 (0.900) <0-05:31:35> ({'r_t': -1082.0334, 'eps':     0.9001, 'len': 33731.0400, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  370000, Reward:  1668.498 [ 382.966], Avg:   491.675 (0.000) <0-05:34:46> ({'r_t': -1223.2204, 'eps':     0.0001, 'len': 33828.4800, 'dyn_loss':    21.1356, 'dot_loss':     3.2694, 'ddot_loss':     6.6925, 'rew_loss':    12.9428, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  371000, Reward:  1489.615 [ 565.058], Avg:   494.357 (0.100) <0-05:35:57> ({'r_t':  3605.9014, 'eps':     0.1001, 'len': 33896.4080, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  372000, Reward:  1525.211 [ 596.226], Avg:   497.121 (0.200) <0-05:37:05> ({'r_t':  3333.7144, 'eps':     0.2001, 'len': 33940.2420, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  373000, Reward:  1479.347 [ 570.528], Avg:   499.747 (0.300) <0-05:38:09> ({'r_t':  3055.1939, 'eps':     0.3001, 'len': 33987.8210, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  374000, Reward:  1620.330 [ 469.779], Avg:   502.735 (0.400) <0-05:39:10> ({'r_t':  2694.8342, 'eps':     0.4001, 'len': 34035.6410, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  375000, Reward:  1666.981 [ 411.656], Avg:   505.832 (0.500) <0-05:40:07> ({'r_t':  1654.8202, 'eps':     0.5001, 'len': 34098.0710, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  376000, Reward:  1488.960 [ 594.826], Avg:   508.440 (0.600) <0-05:41:01> ({'r_t':   616.1865, 'eps':     0.6001, 'len': 34174.5840, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  377000, Reward:  1393.236 [ 622.483], Avg:   510.780 (0.700) <0-05:41:51> ({'r_t':  -270.2410, 'eps':     0.7001, 'len': 34272.2560, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  378000, Reward:  1344.899 [ 638.835], Avg:   512.981 (0.800) <0-05:42:38> ({'r_t':  -976.1134, 'eps':     0.8001, 'len': 34376.6480, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  379000, Reward:  1460.129 [ 528.601], Avg:   515.474 (0.900) <0-05:43:22> ({'r_t': -1093.6164, 'eps':     0.9001, 'len': 34487.2230, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  380000, Reward:  1749.010 [ 312.221], Avg:   518.711 (0.000) <0-05:46:32> ({'r_t': -1257.4605, 'eps':     0.0001, 'len': 34589.3540, 'dyn_loss':    21.8103, 'dot_loss':     3.3352, 'ddot_loss':     6.8257, 'rew_loss':    12.9385, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  381000, Reward:  1697.854 [ 322.716], Avg:   521.798 (0.100) <0-05:47:44> ({'r_t':  3800.6486, 'eps':     0.1001, 'len': 34649.4580, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  382000, Reward:  1829.435 [ 115.800], Avg:   525.212 (0.200) <0-05:48:51> ({'r_t':  3678.0340, 'eps':     0.2001, 'len': 34684.0400, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  383000, Reward:  1818.951 [ 127.113], Avg:   528.581 (0.300) <0-05:49:55> ({'r_t':  3428.2286, 'eps':     0.3001, 'len': 34724.1530, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  384000, Reward:  1798.039 [ 160.560], Avg:   531.879 (0.400) <0-05:50:56> ({'r_t':  2691.4428, 'eps':     0.4001, 'len': 34766.7930, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  385000, Reward:  1633.346 [ 473.087], Avg:   534.732 (0.500) <0-05:51:53> ({'r_t':  2031.5681, 'eps':     0.5001, 'len': 34820.9510, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  386000, Reward:  1751.734 [ 329.586], Avg:   537.877 (0.600) <0-05:52:46> ({'r_t':   520.9268, 'eps':     0.6001, 'len': 34890.6340, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  387000, Reward:  1723.638 [ 281.370], Avg:   540.933 (0.700) <0-05:53:37> ({'r_t':  -329.9235, 'eps':     0.7001, 'len': 34983.7860, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  388000, Reward:  1758.959 [ 330.010], Avg:   544.064 (0.800) <0-05:54:24> ({'r_t':  -916.1262, 'eps':     0.8001, 'len': 35088.0890, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  389000, Reward:  1558.796 [ 500.043], Avg:   546.666 (0.900) <0-05:55:08> ({'r_t': -1090.9892, 'eps':     0.9001, 'len': 35198.7530, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  390000, Reward:  1874.234 [ 105.997], Avg:   550.061 (0.000) <0-05:58:18> ({'r_t': -1297.8536, 'eps':     0.0001, 'len': 35304.9370, 'dyn_loss':    21.6868, 'dot_loss':     3.3489, 'ddot_loss':     6.8746, 'rew_loss':    12.9287, 'lr':   9.70e-05, 'eps_e':     0.0001, 'lr_e':   9.70e-05})
Step:  391000, Reward:  1684.403 [ 420.565], Avg:   552.955 (0.100) <0-05:59:29> ({'r_t':  3686.7327, 'eps':     0.1001, 'len': 35373.8030, 'lr':   9.70e-05, 'eps_e':     0.1001, 'lr_e':   9.70e-05})
Step:  392000, Reward:  1540.436 [ 638.209], Avg:   555.468 (0.200) <0-06:00:37> ({'r_t':  3595.3090, 'eps':     0.2001, 'len': 35411.7690, 'lr':   9.70e-05, 'eps_e':     0.2001, 'lr_e':   9.70e-05})
Step:  393000, Reward:  1597.493 [ 585.348], Avg:   558.112 (0.300) <0-06:01:41> ({'r_t':  3440.4435, 'eps':     0.3001, 'len': 35448.7540, 'lr':   9.70e-05, 'eps_e':     0.3001, 'lr_e':   9.70e-05})
Step:  394000, Reward:  1663.561 [ 520.394], Avg:   560.911 (0.400) <0-06:02:42> ({'r_t':  2826.5914, 'eps':     0.4001, 'len': 35493.4880, 'lr':   9.70e-05, 'eps_e':     0.4001, 'lr_e':   9.70e-05})
Step:  395000, Reward:  1419.223 [ 659.097], Avg:   563.078 (0.500) <0-06:03:39> ({'r_t':  1796.9359, 'eps':     0.5001, 'len': 35550.6920, 'lr':   9.70e-05, 'eps_e':     0.5001, 'lr_e':   9.70e-05})
Step:  396000, Reward:  1822.319 [ 309.180], Avg:   566.250 (0.600) <0-06:04:33> ({'r_t':   706.9070, 'eps':     0.6001, 'len': 35621.4100, 'lr':   9.70e-05, 'eps_e':     0.6001, 'lr_e':   9.70e-05})
Step:  397000, Reward:  1552.734 [ 461.865], Avg:   568.729 (0.700) <0-06:05:23> ({'r_t':  -287.3056, 'eps':     0.7001, 'len': 35705.4460, 'lr':   9.70e-05, 'eps_e':     0.7001, 'lr_e':   9.70e-05})
Step:  398000, Reward:  1655.219 [ 538.077], Avg:   571.452 (0.800) <0-06:06:11> ({'r_t':  -929.5040, 'eps':     0.8001, 'len': 35800.9630, 'lr':   9.70e-05, 'eps_e':     0.8001, 'lr_e':   9.70e-05})
Step:  399000, Reward:  1650.309 [ 425.687], Avg:   574.149 (0.900) <0-06:06:54> ({'r_t': -1140.3087, 'eps':     0.9001, 'len': 35911.2020, 'lr':   9.70e-05, 'eps_e':     0.9001, 'lr_e':   9.70e-05})
Step:  400000, Reward:  1631.833 [ 532.166], Avg:   576.787 (0.000) <0-06:10:07> ({'r_t': -1245.4480, 'eps':     0.0001, 'len': 36007.3700, 'dyn_loss':    22.2738, 'dot_loss':     3.4086, 'ddot_loss':     6.9769, 'rew_loss':    13.2863, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  401000, Reward:  1411.556 [ 625.629], Avg:   578.863 (0.100) <0-06:11:19> ({'r_t':  3775.7675, 'eps':     0.1001, 'len': 36075.7510, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  402000, Reward:  1793.436 [ 348.519], Avg:   581.877 (0.200) <0-06:12:26> ({'r_t':  3693.7291, 'eps':     0.2001, 'len': 36110.7520, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  403000, Reward:  1626.310 [ 602.378], Avg:   584.462 (0.300) <0-06:13:31> ({'r_t':  3390.9365, 'eps':     0.3001, 'len': 36149.9120, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  404000, Reward:  1852.727 [ 336.177], Avg:   587.594 (0.400) <0-06:14:31> ({'r_t':  2991.0887, 'eps':     0.4001, 'len': 36193.2950, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  405000, Reward:  1879.237 [ 140.633], Avg:   590.775 (0.500) <0-06:15:28> ({'r_t':  1961.6962, 'eps':     0.5001, 'len': 36241.4140, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  406000, Reward:  1505.233 [ 539.259], Avg:   593.022 (0.600) <0-06:16:22> ({'r_t':   634.0594, 'eps':     0.6001, 'len': 36309.3080, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  407000, Reward:  1838.136 [ 345.622], Avg:   596.074 (0.700) <0-06:17:13> ({'r_t':  -374.8012, 'eps':     0.7001, 'len': 36403.7210, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  408000, Reward:  1884.698 [ 106.150], Avg:   599.224 (0.800) <0-06:17:59> ({'r_t': -1006.5338, 'eps':     0.8001, 'len': 36505.4450, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  409000, Reward:  1836.839 [ 333.229], Avg:   602.243 (0.900) <0-06:18:43> ({'r_t': -1130.2790, 'eps':     0.9001, 'len': 36613.8020, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  410000, Reward:  1656.705 [ 517.719], Avg:   604.809 (0.000) <0-06:21:55> ({'r_t': -1223.3785, 'eps':     0.0001, 'len': 36719.0740, 'dyn_loss':    21.6630, 'dot_loss':     3.3593, 'ddot_loss':     6.8981, 'rew_loss':    12.9374, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  411000, Reward:  1532.539 [ 600.158], Avg:   607.060 (0.100) <0-06:23:06> ({'r_t':  3785.2940, 'eps':     0.1001, 'len': 36788.9880, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  412000, Reward:  1471.907 [ 593.138], Avg:   609.154 (0.200) <0-06:24:14> ({'r_t':  3594.7082, 'eps':     0.2001, 'len': 36827.3310, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  413000, Reward:  1681.210 [ 506.448], Avg:   611.744 (0.300) <0-06:25:18> ({'r_t':  3285.9225, 'eps':     0.3001, 'len': 36871.2860, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  414000, Reward:  1463.542 [ 646.097], Avg:   613.797 (0.400) <0-06:26:19> ({'r_t':  2834.9593, 'eps':     0.4001, 'len': 36921.4680, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  415000, Reward:  1493.103 [ 614.848], Avg:   615.910 (0.500) <0-06:27:16> ({'r_t':  1566.4204, 'eps':     0.5001, 'len': 36985.0990, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  416000, Reward:  1795.954 [ 336.358], Avg:   618.740 (0.600) <0-06:28:10> ({'r_t':   460.0796, 'eps':     0.6001, 'len': 37065.3520, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  417000, Reward:  1793.023 [ 373.009], Avg:   621.549 (0.700) <0-06:29:00> ({'r_t':  -415.4576, 'eps':     0.7001, 'len': 37158.6230, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  418000, Reward:  1374.765 [ 653.869], Avg:   623.347 (0.800) <0-06:29:47> ({'r_t':  -883.8673, 'eps':     0.8001, 'len': 37271.8750, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  419000, Reward:  1409.342 [ 588.428], Avg:   625.218 (0.900) <0-06:30:31> ({'r_t': -1162.7947, 'eps':     0.9001, 'len': 37388.4880, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  420000, Reward:  1804.936 [ 441.008], Avg:   628.021 (0.000) <0-06:33:43> ({'r_t': -1209.3592, 'eps':     0.0001, 'len': 37495.0440, 'dyn_loss':    21.7587, 'dot_loss':     3.3863, 'ddot_loss':     6.9654, 'rew_loss':    12.9803, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  421000, Reward:  1714.085 [ 525.822], Avg:   630.594 (0.100) <0-06:34:54> ({'r_t':  4019.8193, 'eps':     0.1001, 'len': 37565.3000, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  422000, Reward:  1904.886 [ 373.525], Avg:   633.607 (0.200) <0-06:36:02> ({'r_t':  3917.6307, 'eps':     0.2001, 'len': 37598.9790, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  423000, Reward:  1925.249 [ 157.938], Avg:   636.653 (0.300) <0-06:37:06> ({'r_t':  3495.4347, 'eps':     0.3001, 'len': 37641.2740, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  424000, Reward:  2000.297 [ 149.194], Avg:   639.862 (0.400) <0-06:38:06> ({'r_t':  3027.0598, 'eps':     0.4001, 'len': 37685.2750, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  425000, Reward:  1971.028 [ 170.988], Avg:   642.986 (0.500) <0-06:39:03> ({'r_t':  1773.3237, 'eps':     0.5001, 'len': 37736.9470, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  426000, Reward:  1786.309 [ 365.929], Avg:   645.664 (0.600) <0-06:39:57> ({'r_t':   444.7224, 'eps':     0.6001, 'len': 37813.0720, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  427000, Reward:  1982.454 [ 186.517], Avg:   648.787 (0.700) <0-06:40:47> ({'r_t':  -406.5665, 'eps':     0.7001, 'len': 37911.1880, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  428000, Reward:  1839.087 [ 356.903], Avg:   651.562 (0.800) <0-06:41:34> ({'r_t':  -983.4268, 'eps':     0.8001, 'len': 38010.3090, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  429000, Reward:  1931.192 [ 151.053], Avg:   654.538 (0.900) <0-06:42:17> ({'r_t': -1133.7877, 'eps':     0.9001, 'len': 38118.7480, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  430000, Reward:  1295.963 [ 552.207], Avg:   656.026 (0.000) <0-06:45:32> ({'r_t': -1168.6147, 'eps':     0.0001, 'len': 38226.3120, 'dyn_loss':    22.1459, 'dot_loss':     3.3942, 'ddot_loss':     6.9697, 'rew_loss':    13.1678, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  431000, Reward:  1719.977 [ 309.736], Avg:   658.489 (0.100) <0-06:46:43> ({'r_t':  3445.4744, 'eps':     0.1001, 'len': 38295.1520, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  432000, Reward:  1346.979 [ 512.586], Avg:   660.079 (0.200) <0-06:47:51> ({'r_t':  3355.7725, 'eps':     0.2001, 'len': 38335.2650, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  433000, Reward:  1367.351 [ 516.797], Avg:   661.709 (0.300) <0-06:48:55> ({'r_t':  3010.1068, 'eps':     0.3001, 'len': 38382.2840, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  434000, Reward:  1554.348 [ 398.157], Avg:   663.761 (0.400) <0-06:49:56> ({'r_t':  2802.6303, 'eps':     0.4001, 'len': 38428.0850, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  435000, Reward:  1573.053 [ 374.732], Avg:   665.846 (0.500) <0-06:50:53> ({'r_t':  1667.4062, 'eps':     0.5001, 'len': 38485.4230, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  436000, Reward:  1386.545 [ 516.507], Avg:   667.495 (0.600) <0-06:51:47> ({'r_t':   606.3407, 'eps':     0.6001, 'len': 38556.6750, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  437000, Reward:  1665.753 [ 340.460], Avg:   669.775 (0.700) <0-06:52:37> ({'r_t':  -379.0951, 'eps':     0.7001, 'len': 38658.0110, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  438000, Reward:  1548.051 [ 369.640], Avg:   671.775 (0.800) <0-06:53:24> ({'r_t':  -955.9074, 'eps':     0.8001, 'len': 38763.3350, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  439000, Reward:  1705.334 [ 313.062], Avg:   674.124 (0.900) <0-06:54:08> ({'r_t': -1184.4131, 'eps':     0.9001, 'len': 38867.4330, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  440000, Reward:  1672.471 [ 274.324], Avg:   676.388 (0.000) <0-06:57:22> ({'r_t': -1240.7552, 'eps':     0.0001, 'len': 38968.5140, 'dyn_loss':    21.8357, 'dot_loss':     3.3684, 'ddot_loss':     6.9184, 'rew_loss':    13.1553, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  441000, Reward:  1609.681 [ 394.218], Avg:   678.499 (0.100) <0-06:58:33> ({'r_t':  3674.6748, 'eps':     0.1001, 'len': 39035.9680, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  442000, Reward:  1470.804 [ 492.561], Avg:   680.288 (0.200) <0-06:59:41> ({'r_t':  3426.0567, 'eps':     0.2001, 'len': 39074.0310, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  443000, Reward:  1760.417 [  82.644], Avg:   682.721 (0.300) <0-07:00:45> ({'r_t':  3338.3564, 'eps':     0.3001, 'len': 39120.0620, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  444000, Reward:  1468.173 [ 512.805], Avg:   684.486 (0.400) <0-07:01:45> ({'r_t':  2785.4271, 'eps':     0.4001, 'len': 39163.0900, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  445000, Reward:  1672.574 [ 314.246], Avg:   686.701 (0.500) <0-07:02:42> ({'r_t':  1699.0744, 'eps':     0.5001, 'len': 39222.5860, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  446000, Reward:  1681.717 [ 282.407], Avg:   688.927 (0.600) <0-07:03:36> ({'r_t':   387.3782, 'eps':     0.6001, 'len': 39299.6920, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  447000, Reward:  1603.524 [ 414.160], Avg:   690.969 (0.700) <0-07:04:26> ({'r_t':  -368.0198, 'eps':     0.7001, 'len': 39390.0120, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  448000, Reward:  1755.985 [  68.013], Avg:   693.341 (0.800) <0-07:05:13> ({'r_t':  -887.8537, 'eps':     0.8001, 'len': 39484.5550, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  449000, Reward:  1625.835 [ 390.564], Avg:   695.413 (0.900) <0-07:05:57> ({'r_t': -1165.3969, 'eps':     0.9001, 'len': 39595.5690, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  450000, Reward:  1740.588 [ 491.856], Avg:   697.730 (0.000) <0-07:09:13> ({'r_t': -1246.8750, 'eps':     0.0001, 'len': 39700.8870, 'dyn_loss':    21.4970, 'dot_loss':     3.3380, 'ddot_loss':     6.8835, 'rew_loss':    13.0219, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  451000, Reward:  1956.632 [ 171.301], Avg:   700.516 (0.100) <0-07:10:24> ({'r_t':  4038.0083, 'eps':     0.1001, 'len': 39774.6910, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  452000, Reward:  1670.612 [ 594.984], Avg:   702.657 (0.200) <0-07:11:32> ({'r_t':  3887.8899, 'eps':     0.2001, 'len': 39809.8320, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  453000, Reward:  1598.456 [ 454.196], Avg:   704.630 (0.300) <0-07:12:36> ({'r_t':  3566.1890, 'eps':     0.3001, 'len': 39849.4750, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  454000, Reward:  1887.756 [ 358.991], Avg:   707.230 (0.400) <0-07:13:37> ({'r_t':  2777.5510, 'eps':     0.4001, 'len': 39894.7580, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  455000, Reward:  1906.259 [ 411.882], Avg:   709.860 (0.500) <0-07:14:34> ({'r_t':  1799.8135, 'eps':     0.5001, 'len': 39945.1690, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  456000, Reward:  1776.660 [ 457.212], Avg:   712.194 (0.600) <0-07:15:28> ({'r_t':   555.7015, 'eps':     0.6001, 'len': 40010.4540, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  457000, Reward:  1818.174 [ 412.480], Avg:   714.609 (0.700) <0-07:16:18> ({'r_t':  -478.3224, 'eps':     0.7001, 'len': 40102.2910, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  458000, Reward:  1710.616 [ 569.623], Avg:   716.779 (0.800) <0-07:17:05> ({'r_t':  -923.7149, 'eps':     0.8001, 'len': 40212.5110, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  459000, Reward:  1872.612 [ 266.976], Avg:   719.292 (0.900) <0-07:17:49> ({'r_t': -1118.1300, 'eps':     0.9001, 'len': 40321.5750, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  460000, Reward:  1558.944 [ 565.785], Avg:   721.113 (0.000) <0-07:21:05> ({'r_t': -1131.6657, 'eps':     0.0001, 'len': 40428.5510, 'dyn_loss':    21.5816, 'dot_loss':     3.3428, 'ddot_loss':     6.8788, 'rew_loss':    13.0748, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  461000, Reward:  1818.018 [ 500.964], Avg:   723.487 (0.100) <0-07:22:16> ({'r_t':  4092.0590, 'eps':     0.1001, 'len': 40499.5910, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  462000, Reward:  1847.736 [ 370.778], Avg:   725.915 (0.200) <0-07:23:24> ({'r_t':  4022.5124, 'eps':     0.2001, 'len': 40533.7900, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  463000, Reward:  1740.150 [ 474.151], Avg:   728.101 (0.300) <0-07:24:28> ({'r_t':  3623.0912, 'eps':     0.3001, 'len': 40571.8760, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  464000, Reward:  1853.669 [ 358.267], Avg:   730.522 (0.400) <0-07:25:29> ({'r_t':  2995.5412, 'eps':     0.4001, 'len': 40615.5650, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  465000, Reward:  1993.937 [ 182.594], Avg:   733.233 (0.500) <0-07:26:26> ({'r_t':  1730.0967, 'eps':     0.5001, 'len': 40670.6010, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  466000, Reward:  1913.937 [ 355.815], Avg:   735.761 (0.600) <0-07:27:19> ({'r_t':   571.5196, 'eps':     0.6001, 'len': 40744.0420, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  467000, Reward:  1905.385 [ 372.016], Avg:   738.261 (0.700) <0-07:28:10> ({'r_t':  -357.3185, 'eps':     0.7001, 'len': 40830.6590, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  468000, Reward:  1733.925 [ 554.330], Avg:   740.384 (0.800) <0-07:28:57> ({'r_t':  -926.6604, 'eps':     0.8001, 'len': 40937.4490, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  469000, Reward:  1645.259 [ 540.527], Avg:   742.309 (0.900) <0-07:29:40> ({'r_t': -1168.2152, 'eps':     0.9001, 'len': 41043.5050, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  470000, Reward:  1851.904 [ 402.367], Avg:   744.665 (0.000) <0-07:32:58> ({'r_t': -1140.4378, 'eps':     0.0001, 'len': 41148.5600, 'dyn_loss':    21.7627, 'dot_loss':     3.3960, 'ddot_loss':     7.0118, 'rew_loss':    13.0623, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  471000, Reward:  1973.642 [ 377.181], Avg:   747.268 (0.100) <0-07:34:09> ({'r_t':  4085.8094, 'eps':     0.1001, 'len': 41217.3020, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  472000, Reward:  2034.104 [ 166.515], Avg:   749.989 (0.200) <0-07:35:17> ({'r_t':  4095.4064, 'eps':     0.2001, 'len': 41251.0830, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  473000, Reward:  1974.155 [ 365.733], Avg:   752.572 (0.300) <0-07:36:21> ({'r_t':  3838.4585, 'eps':     0.3001, 'len': 41289.0140, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  474000, Reward:  1956.148 [ 369.887], Avg:   755.105 (0.400) <0-07:37:22> ({'r_t':  2845.4392, 'eps':     0.4001, 'len': 41328.0140, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  475000, Reward:  1914.800 [ 367.707], Avg:   757.542 (0.500) <0-07:38:19> ({'r_t':  1979.7431, 'eps':     0.5001, 'len': 41377.5010, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  476000, Reward:  1934.188 [ 218.732], Avg:   760.009 (0.600) <0-07:39:13> ({'r_t':   418.4305, 'eps':     0.6001, 'len': 41450.9910, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  477000, Reward:  1903.763 [ 378.389], Avg:   762.401 (0.700) <0-07:40:03> ({'r_t':  -411.6418, 'eps':     0.7001, 'len': 41546.1560, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  478000, Reward:  2023.691 [ 140.212], Avg:   765.034 (0.800) <0-07:40:50> ({'r_t':  -848.4050, 'eps':     0.8001, 'len': 41645.2740, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  479000, Reward:  1842.424 [ 479.869], Avg:   767.279 (0.900) <0-07:41:34> ({'r_t': -1101.8073, 'eps':     0.9001, 'len': 41766.0980, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  480000, Reward:  1785.664 [ 395.847], Avg:   769.396 (0.000) <0-07:44:53> ({'r_t': -1171.4115, 'eps':     0.0001, 'len': 41886.5160, 'dyn_loss':    21.7558, 'dot_loss':     3.3731, 'ddot_loss':     6.9665, 'rew_loss':    13.0350, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  481000, Reward:  2032.955 [ 180.924], Avg:   772.018 (0.100) <0-07:46:04> ({'r_t':  4025.9485, 'eps':     0.1001, 'len': 41959.4920, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  482000, Reward:  1873.877 [ 375.125], Avg:   774.299 (0.200) <0-07:47:12> ({'r_t':  4070.4706, 'eps':     0.2001, 'len': 41993.1530, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  483000, Reward:  2059.302 [ 143.050], Avg:   776.954 (0.300) <0-07:48:16> ({'r_t':  3473.4385, 'eps':     0.3001, 'len': 42030.2560, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  484000, Reward:  1953.061 [ 364.311], Avg:   779.379 (0.400) <0-07:49:17> ({'r_t':  2831.4513, 'eps':     0.4001, 'len': 42075.7520, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  485000, Reward:  2028.257 [ 151.897], Avg:   781.949 (0.500) <0-07:50:14> ({'r_t':  1616.0770, 'eps':     0.5001, 'len': 42133.5370, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  486000, Reward:  2027.109 [ 148.442], Avg:   784.505 (0.600) <0-07:51:07> ({'r_t':   575.9341, 'eps':     0.6001, 'len': 42202.3880, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  487000, Reward:  1757.531 [ 533.624], Avg:   786.499 (0.700) <0-07:51:58> ({'r_t':  -461.8480, 'eps':     0.7001, 'len': 42287.0080, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  488000, Reward:  2015.082 [ 179.190], Avg:   789.012 (0.800) <0-07:52:45> ({'r_t':  -975.3207, 'eps':     0.8001, 'len': 42393.0610, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  489000, Reward:  1875.882 [ 358.944], Avg:   791.230 (0.900) <0-07:53:28> ({'r_t': -1211.3160, 'eps':     0.9001, 'len': 42503.6390, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  490000, Reward:  1731.740 [ 609.804], Avg:   793.145 (0.000) <0-07:56:47> ({'r_t': -1220.5497, 'eps':     0.0001, 'len': 42601.4760, 'dyn_loss':    21.4631, 'dot_loss':     3.3357, 'ddot_loss':     6.8848, 'rew_loss':    12.9848, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  491000, Reward:  1553.068 [ 736.284], Avg:   794.690 (0.100) <0-07:57:58> ({'r_t':  4128.6943, 'eps':     0.1001, 'len': 42670.7150, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  492000, Reward:  1855.775 [ 544.256], Avg:   796.842 (0.200) <0-07:59:06> ({'r_t':  3884.6706, 'eps':     0.2001, 'len': 42709.0920, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  493000, Reward:  1879.013 [ 424.734], Avg:   799.033 (0.300) <0-08:00:10> ({'r_t':  3540.9584, 'eps':     0.3001, 'len': 42750.7160, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  494000, Reward:  1860.143 [ 572.344], Avg:   801.177 (0.400) <0-08:01:11> ({'r_t':  2771.5291, 'eps':     0.4001, 'len': 42798.7080, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  495000, Reward:  1669.959 [ 643.207], Avg:   802.928 (0.500) <0-08:02:08> ({'r_t':  1771.0179, 'eps':     0.5001, 'len': 42849.2270, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  496000, Reward:  1699.852 [ 684.738], Avg:   804.733 (0.600) <0-08:03:02> ({'r_t':   427.3814, 'eps':     0.6001, 'len': 42923.5270, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  497000, Reward:  1698.801 [ 632.245], Avg:   806.528 (0.700) <0-08:03:52> ({'r_t':  -608.4551, 'eps':     0.7001, 'len': 43010.9320, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  498000, Reward:  1445.724 [ 700.989], Avg:   807.809 (0.800) <0-08:04:40> ({'r_t': -1000.5863, 'eps':     0.8001, 'len': 43119.9100, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  499000, Reward:  1636.777 [ 687.396], Avg:   809.467 (0.900) <0-08:05:23> ({'r_t': -1098.2837, 'eps':     0.9001, 'len': 43229.1610, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  500000, Reward:  1722.001 [ 627.696], Avg:   811.288 (0.000) <0-08:08:43> ({'r_t': -1291.2846, 'eps':     0.0001, 'len': 43333.8850, 'dyn_loss':    21.6052, 'dot_loss':     3.3611, 'ddot_loss':     6.9512, 'rew_loss':    12.9540, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:  501000, Reward:  1609.188 [ 695.261], Avg:   812.878 (0.100) <0-08:09:55> ({'r_t':  4011.6572, 'eps':     0.1001, 'len': 43399.4220, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:  502000, Reward:  1636.061 [ 678.171], Avg:   814.514 (0.200) <0-08:11:03> ({'r_t':  3795.3253, 'eps':     0.2001, 'len': 43437.1950, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:  503000, Reward:  1958.644 [ 423.546], Avg:   816.785 (0.300) <0-08:12:07> ({'r_t':  3441.3948, 'eps':     0.3001, 'len': 43483.6960, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:  504000, Reward:  1711.348 [ 606.224], Avg:   818.556 (0.400) <0-08:13:08> ({'r_t':  2677.4958, 'eps':     0.4001, 'len': 43537.0960, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:  505000, Reward:  1854.042 [ 548.102], Avg:   820.602 (0.500) <0-08:14:05> ({'r_t':  1515.1382, 'eps':     0.5001, 'len': 43597.1970, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:  506000, Reward:  1920.802 [ 416.654], Avg:   822.772 (0.600) <0-08:14:59> ({'r_t':   477.9529, 'eps':     0.6001, 'len': 43671.6920, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:  507000, Reward:  1658.512 [ 649.258], Avg:   824.418 (0.700) <0-08:15:49> ({'r_t':  -405.3670, 'eps':     0.7001, 'len': 43766.0420, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:  508000, Reward:  1777.513 [ 507.292], Avg:   826.290 (0.800) <0-08:16:36> ({'r_t': -1027.7640, 'eps':     0.8001, 'len': 43874.5660, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:  509000, Reward:  1808.189 [ 543.375], Avg:   828.215 (0.900) <0-08:17:20> ({'r_t': -1146.9103, 'eps':     0.9001, 'len': 43983.3860, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:  510000, Reward:  1912.757 [ 174.827], Avg:   830.338 (0.000) <0-08:20:39> ({'r_t': -1248.2581, 'eps':     0.0001, 'len': 44085.8650, 'dyn_loss':    21.2803, 'dot_loss':     3.2812, 'ddot_loss':     6.7896, 'rew_loss':    12.9069, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  511000, Reward:  1996.550 [ 181.804], Avg:   832.615 (0.100) <0-08:21:50> ({'r_t':  4103.6096, 'eps':     0.1001, 'len': 44153.6540, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  512000, Reward:  1809.167 [ 482.196], Avg:   834.519 (0.200) <0-08:22:58> ({'r_t':  4013.8915, 'eps':     0.2001, 'len': 44189.1020, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  513000, Reward:  2003.126 [ 216.714], Avg:   836.793 (0.300) <0-08:24:02> ({'r_t':  3639.3838, 'eps':     0.3001, 'len': 44227.5130, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  514000, Reward:  1919.553 [ 391.127], Avg:   838.895 (0.400) <0-08:25:03> ({'r_t':  2829.5736, 'eps':     0.4001, 'len': 44266.6740, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  515000, Reward:  1894.863 [ 392.707], Avg:   840.942 (0.500) <0-08:26:00> ({'r_t':  1643.6094, 'eps':     0.5001, 'len': 44322.1230, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  516000, Reward:  1774.128 [ 540.901], Avg:   842.747 (0.600) <0-08:26:53> ({'r_t':   485.7652, 'eps':     0.6001, 'len': 44391.0260, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  517000, Reward:  1870.223 [ 404.318], Avg:   844.730 (0.700) <0-08:27:44> ({'r_t':  -313.2923, 'eps':     0.7001, 'len': 44468.8870, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  518000, Reward:  1845.530 [ 442.182], Avg:   846.658 (0.800) <0-08:28:31> ({'r_t':  -945.9697, 'eps':     0.8001, 'len': 44567.3270, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  519000, Reward:  1817.801 [ 484.014], Avg:   848.526 (0.900) <0-08:29:14> ({'r_t': -1161.8278, 'eps':     0.9001, 'len': 44672.0170, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  520000, Reward:  1813.187 [ 352.563], Avg:   850.378 (0.000) <0-08:32:34> ({'r_t': -1211.1670, 'eps':     0.0001, 'len': 44771.5700, 'dyn_loss':    20.9251, 'dot_loss':     3.2978, 'ddot_loss':     6.8377, 'rew_loss':    12.8989, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  521000, Reward:  1810.171 [ 348.893], Avg:   852.216 (0.100) <0-08:33:46> ({'r_t':  3762.8561, 'eps':     0.1001, 'len': 44838.0450, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  522000, Reward:  1835.783 [ 146.869], Avg:   854.097 (0.200) <0-08:34:53> ({'r_t':  3724.4728, 'eps':     0.2001, 'len': 44872.6790, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  523000, Reward:  1704.506 [ 431.441], Avg:   855.720 (0.300) <0-08:35:58> ({'r_t':  3293.6312, 'eps':     0.3001, 'len': 44913.8500, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  524000, Reward:  1522.215 [ 524.370], Avg:   856.989 (0.400) <0-08:36:59> ({'r_t':  2870.8612, 'eps':     0.4001, 'len': 44957.6310, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  525000, Reward:  1797.376 [ 339.965], Avg:   858.777 (0.500) <0-08:37:56> ({'r_t':  1680.8337, 'eps':     0.5001, 'len': 45012.4510, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  526000, Reward:  1897.537 [ 161.434], Avg:   860.748 (0.600) <0-08:38:49> ({'r_t':   521.7074, 'eps':     0.6001, 'len': 45080.2490, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  527000, Reward:  1871.267 [ 149.966], Avg:   862.662 (0.700) <0-08:39:39> ({'r_t':  -645.9429, 'eps':     0.7001, 'len': 45164.7050, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  528000, Reward:  1832.754 [ 115.875], Avg:   864.496 (0.800) <0-08:40:26> ({'r_t':  -903.2576, 'eps':     0.8001, 'len': 45264.7340, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  529000, Reward:  1781.882 [ 333.207], Avg:   866.227 (0.900) <0-08:41:10> ({'r_t': -1109.4532, 'eps':     0.9001, 'len': 45378.8720, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  530000, Reward:  1891.205 [ 373.284], Avg:   868.157 (0.000) <0-08:44:31> ({'r_t': -1175.1544, 'eps':     0.0001, 'len': 45481.2610, 'dyn_loss':    20.5873, 'dot_loss':     3.2572, 'ddot_loss':     6.7776, 'rew_loss':    12.6725, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  531000, Reward:  1942.538 [ 372.495], Avg:   870.177 (0.100) <0-08:45:42> ({'r_t':  4061.8342, 'eps':     0.1001, 'len': 45547.0560, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  532000, Reward:  1949.224 [ 259.310], Avg:   872.201 (0.200) <0-08:46:50> ({'r_t':  4069.1856, 'eps':     0.2001, 'len': 45581.5200, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  533000, Reward:  1817.271 [ 499.524], Avg:   873.971 (0.300) <0-08:47:54> ({'r_t':  3611.9026, 'eps':     0.3001, 'len': 45620.1390, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  534000, Reward:  2033.367 [ 165.602], Avg:   876.138 (0.400) <0-08:48:55> ({'r_t':  2931.6264, 'eps':     0.4001, 'len': 45664.1890, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  535000, Reward:  1916.145 [ 433.718], Avg:   878.078 (0.500) <0-08:49:52> ({'r_t':  1667.2969, 'eps':     0.5001, 'len': 45718.0670, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  536000, Reward:  2036.163 [ 134.360], Avg:   880.235 (0.600) <0-08:50:46> ({'r_t':   408.0078, 'eps':     0.6001, 'len': 45790.0340, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  537000, Reward:  1907.266 [ 438.137], Avg:   882.144 (0.700) <0-08:51:36> ({'r_t':  -419.4189, 'eps':     0.7001, 'len': 45879.6940, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  538000, Reward:  1909.880 [ 427.479], Avg:   884.051 (0.800) <0-08:52:24> ({'r_t':  -946.1475, 'eps':     0.8001, 'len': 45974.0660, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  539000, Reward:  1924.843 [ 380.209], Avg:   885.978 (0.900) <0-08:53:07> ({'r_t': -1160.2787, 'eps':     0.9001, 'len': 46083.2570, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  540000, Reward:  1936.887 [ 520.683], Avg:   887.920 (0.000) <0-08:56:28> ({'r_t': -1270.0391, 'eps':     0.0001, 'len': 46183.6080, 'dyn_loss':    21.4419, 'dot_loss':     3.3359, 'ddot_loss':     6.9170, 'rew_loss':    12.9307, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  541000, Reward:  2026.577 [ 212.381], Avg:   890.021 (0.100) <0-08:57:39> ({'r_t':  4107.5956, 'eps':     0.1001, 'len': 46252.4750, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  542000, Reward:  2004.543 [ 185.514], Avg:   892.074 (0.200) <0-08:58:47> ({'r_t':  3999.8539, 'eps':     0.2001, 'len': 46288.3550, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  543000, Reward:  2046.389 [ 170.159], Avg:   894.196 (0.300) <0-08:59:51> ({'r_t':  3655.9932, 'eps':     0.3001, 'len': 46329.3820, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  544000, Reward:  1922.738 [ 399.064], Avg:   896.083 (0.400) <0-09:00:51> ({'r_t':  2916.4140, 'eps':     0.4001, 'len': 46373.3540, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  545000, Reward:  1947.375 [ 389.824], Avg:   898.008 (0.500) <0-09:01:49> ({'r_t':  1701.1612, 'eps':     0.5001, 'len': 46429.8280, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  546000, Reward:  2041.240 [ 150.667], Avg:   900.098 (0.600) <0-09:02:42> ({'r_t':   537.3149, 'eps':     0.6001, 'len': 46505.0710, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  547000, Reward:  1929.533 [ 381.689], Avg:   901.977 (0.700) <0-09:03:32> ({'r_t':  -396.3339, 'eps':     0.7001, 'len': 46598.2500, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  548000, Reward:  1957.008 [ 376.544], Avg:   903.899 (0.800) <0-09:04:20> ({'r_t':  -946.0957, 'eps':     0.8001, 'len': 46696.2000, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  549000, Reward:  1958.091 [ 203.292], Avg:   905.815 (0.900) <0-09:05:03> ({'r_t': -1168.2646, 'eps':     0.9001, 'len': 46802.1450, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  550000, Reward:  2067.777 [ 133.850], Avg:   907.924 (0.000) <0-09:08:25> ({'r_t': -1195.5711, 'eps':     0.0001, 'len': 46898.8760, 'dyn_loss':    20.5740, 'dot_loss':     3.2449, 'ddot_loss':     6.7463, 'rew_loss':    12.6803, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  551000, Reward:  1995.778 [ 285.793], Avg:   909.895 (0.100) <0-09:09:36> ({'r_t':  4154.6825, 'eps':     0.1001, 'len': 46972.4740, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  552000, Reward:  2085.957 [ 132.607], Avg:   912.022 (0.200) <0-09:10:43> ({'r_t':  4066.9320, 'eps':     0.2001, 'len': 47006.7370, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  553000, Reward:  1917.944 [ 329.063], Avg:   913.837 (0.300) <0-09:11:48> ({'r_t':  3540.9815, 'eps':     0.3001, 'len': 47049.1550, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  554000, Reward:  2052.271 [ 158.161], Avg:   915.889 (0.400) <0-09:12:48> ({'r_t':  3021.3997, 'eps':     0.4001, 'len': 47095.0330, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  555000, Reward:  1999.100 [ 268.789], Avg:   917.837 (0.500) <0-09:13:45> ({'r_t':  1666.2022, 'eps':     0.5001, 'len': 47146.3640, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  556000, Reward:  2013.194 [ 293.100], Avg:   919.803 (0.600) <0-09:14:39> ({'r_t':   543.9012, 'eps':     0.6001, 'len': 47213.9380, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  557000, Reward:  1964.427 [ 439.634], Avg:   921.675 (0.700) <0-09:15:30> ({'r_t':  -424.0528, 'eps':     0.7001, 'len': 47303.5350, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  558000, Reward:  2008.287 [ 159.436], Avg:   923.619 (0.800) <0-09:16:16> ({'r_t':  -956.8725, 'eps':     0.8001, 'len': 47413.0530, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  559000, Reward:  2054.654 [ 136.595], Avg:   925.639 (0.900) <0-09:17:00> ({'r_t': -1113.1323, 'eps':     0.9001, 'len': 47524.9890, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  560000, Reward:  2012.401 [ 146.797], Avg:   927.576 (0.000) <0-09:20:23> ({'r_t': -1174.9989, 'eps':     0.0001, 'len': 47627.7990, 'dyn_loss':    21.6451, 'dot_loss':     3.3664, 'ddot_loss':     6.9771, 'rew_loss':    13.0102, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  561000, Reward:  1988.380 [ 160.037], Avg:   929.464 (0.100) <0-09:21:34> ({'r_t':  4026.2541, 'eps':     0.1001, 'len': 47693.3170, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  562000, Reward:  1949.548 [ 257.388], Avg:   931.276 (0.200) <0-09:22:42> ({'r_t':  4050.7890, 'eps':     0.2001, 'len': 47727.0530, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  563000, Reward:  1886.117 [ 279.534], Avg:   932.969 (0.300) <0-09:23:47> ({'r_t':  3697.4106, 'eps':     0.3001, 'len': 47764.8370, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  564000, Reward:  1914.930 [ 271.706], Avg:   934.707 (0.400) <0-09:24:47> ({'r_t':  2670.9858, 'eps':     0.4001, 'len': 47810.7630, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  565000, Reward:  1903.257 [ 177.192], Avg:   936.418 (0.500) <0-09:25:44> ({'r_t':  1497.0634, 'eps':     0.5001, 'len': 47871.5450, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  566000, Reward:  1859.671 [ 252.044], Avg:   938.046 (0.600) <0-09:26:38> ({'r_t':   502.9625, 'eps':     0.6001, 'len': 47942.1180, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  567000, Reward:  1961.549 [ 257.639], Avg:   939.848 (0.700) <0-09:27:28> ({'r_t':  -385.4508, 'eps':     0.7001, 'len': 48033.6020, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  568000, Reward:  1916.786 [ 368.455], Avg:   941.565 (0.800) <0-09:28:15> ({'r_t':  -894.9686, 'eps':     0.8001, 'len': 48135.9630, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  569000, Reward:  1925.275 [ 247.740], Avg:   943.291 (0.900) <0-09:28:58> ({'r_t': -1112.5388, 'eps':     0.9001, 'len': 48242.7320, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  570000, Reward:  1998.259 [ 265.064], Avg:   945.138 (0.000) <0-09:32:22> ({'r_t': -1182.1271, 'eps':     0.0001, 'len': 48347.3020, 'dyn_loss':    20.6832, 'dot_loss':     3.2625, 'ddot_loss':     6.7865, 'rew_loss':    12.6106, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  571000, Reward:  2099.413 [ 148.588], Avg:   947.156 (0.100) <0-09:33:33> ({'r_t':  4215.9808, 'eps':     0.1001, 'len': 48417.9320, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  572000, Reward:  2073.442 [ 161.800], Avg:   949.122 (0.200) <0-09:34:41> ({'r_t':  4163.8897, 'eps':     0.2001, 'len': 48451.1460, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  573000, Reward:  1947.415 [ 398.989], Avg:   950.861 (0.300) <0-09:35:46> ({'r_t':  3822.5908, 'eps':     0.3001, 'len': 48488.2780, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  574000, Reward:  1955.144 [ 372.548], Avg:   952.608 (0.400) <0-09:36:46> ({'r_t':  2827.3196, 'eps':     0.4001, 'len': 48530.5950, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  575000, Reward:  2091.652 [ 156.190], Avg:   954.585 (0.500) <0-09:37:43> ({'r_t':  1702.2058, 'eps':     0.5001, 'len': 48581.9390, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  576000, Reward:  2094.531 [ 149.861], Avg:   956.561 (0.600) <0-09:38:37> ({'r_t':   592.3627, 'eps':     0.6001, 'len': 48647.7740, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  577000, Reward:  2046.711 [ 181.429], Avg:   958.447 (0.700) <0-09:39:27> ({'r_t':  -367.6696, 'eps':     0.7001, 'len': 48734.3480, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  578000, Reward:  1966.889 [ 279.564], Avg:   960.189 (0.800) <0-09:40:14> ({'r_t':  -938.3451, 'eps':     0.8001, 'len': 48833.0270, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  579000, Reward:  2028.082 [ 174.559], Avg:   962.030 (0.900) <0-09:40:57> ({'r_t': -1143.8226, 'eps':     0.9001, 'len': 48929.2300, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  580000, Reward:  1913.112 [ 385.419], Avg:   963.667 (0.000) <0-09:44:20> ({'r_t': -1250.0294, 'eps':     0.0001, 'len': 49031.4030, 'dyn_loss':    21.0436, 'dot_loss':     3.3131, 'ddot_loss':     6.8802, 'rew_loss':    12.8416, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  581000, Reward:  2052.280 [ 143.574], Avg:   965.537 (0.100) <0-09:45:31> ({'r_t':  4166.4480, 'eps':     0.1001, 'len': 49092.2900, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  582000, Reward:  2047.803 [ 175.203], Avg:   967.394 (0.200) <0-09:46:39> ({'r_t':  4127.1741, 'eps':     0.2001, 'len': 49125.7780, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  583000, Reward:  2011.487 [ 202.123], Avg:   969.182 (0.300) <0-09:47:43> ({'r_t':  3763.5793, 'eps':     0.3001, 'len': 49162.7560, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  584000, Reward:  1984.902 [ 195.971], Avg:   970.918 (0.400) <0-09:48:44> ({'r_t':  2866.3430, 'eps':     0.4001, 'len': 49204.0310, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  585000, Reward:  2081.031 [ 136.302], Avg:   972.812 (0.500) <0-09:49:41> ({'r_t':  1722.7023, 'eps':     0.5001, 'len': 49256.7330, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  586000, Reward:  1985.376 [ 184.332], Avg:   974.537 (0.600) <0-09:50:35> ({'r_t':   529.2353, 'eps':     0.6001, 'len': 49325.8690, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  587000, Reward:  2024.317 [ 182.311], Avg:   976.322 (0.700) <0-09:51:25> ({'r_t':  -386.2117, 'eps':     0.7001, 'len': 49420.5270, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  588000, Reward:  1967.244 [ 204.025], Avg:   978.005 (0.800) <0-09:52:12> ({'r_t':  -925.3056, 'eps':     0.8001, 'len': 49515.6570, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  589000, Reward:  2035.299 [ 137.783], Avg:   979.797 (0.900) <0-09:52:55> ({'r_t': -1159.0410, 'eps':     0.9001, 'len': 49616.3800, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  590000, Reward:  1810.785 [ 540.450], Avg:   981.203 (0.000) <0-09:56:19> ({'r_t': -1212.8983, 'eps':     0.0001, 'len': 49723.5510, 'dyn_loss':    20.8716, 'dot_loss':     3.3186, 'ddot_loss':     6.9127, 'rew_loss':    12.7677, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  591000, Reward:  1813.626 [ 537.832], Avg:   982.609 (0.100) <0-09:57:30> ({'r_t':  4073.7009, 'eps':     0.1001, 'len': 49794.4730, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  592000, Reward:  1933.623 [ 405.568], Avg:   984.213 (0.200) <0-09:58:38> ({'r_t':  4022.0590, 'eps':     0.2001, 'len': 49828.6750, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  593000, Reward:  1724.487 [ 631.065], Avg:   985.459 (0.300) <0-09:59:43> ({'r_t':  3526.6330, 'eps':     0.3001, 'len': 49869.2890, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  594000, Reward:  1817.114 [ 562.660], Avg:   986.857 (0.400) <0-10:00:44> ({'r_t':  2760.6072, 'eps':     0.4001, 'len': 49914.9010, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  595000, Reward:  1506.933 [ 711.756], Avg:   987.729 (0.500) <0-10:01:41> ({'r_t':  1536.0419, 'eps':     0.5001, 'len': 49973.1110, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  596000, Reward:  1845.352 [ 405.217], Avg:   989.166 (0.600) <0-10:02:34> ({'r_t':   487.9629, 'eps':     0.6001, 'len': 50040.4480, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  597000, Reward:  1686.849 [ 624.272], Avg:   990.333 (0.700) <0-10:03:25> ({'r_t':  -508.7855, 'eps':     0.7001, 'len': 50125.8310, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  598000, Reward:  1645.868 [ 683.788], Avg:   991.427 (0.800) <0-10:04:12> ({'r_t':  -957.5410, 'eps':     0.8001, 'len': 50223.5650, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  599000, Reward:  2006.260 [ 167.834], Avg:   993.118 (0.900) <0-10:04:55> ({'r_t': -1136.6179, 'eps':     0.9001, 'len': 50336.2850, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  600000, Reward:  2068.736 [ 145.288], Avg:   994.908 (0.000) <0-10:08:22> ({'r_t': -1214.6969, 'eps':     0.0001, 'len': 50451.4300, 'dyn_loss':    20.9150, 'dot_loss':     3.2927, 'ddot_loss':     6.8489, 'rew_loss':    12.8587, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  601000, Reward:  2022.192 [ 178.441], Avg:   996.615 (0.100) <0-10:09:33> ({'r_t':  4079.2217, 'eps':     0.1001, 'len': 50522.3420, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  602000, Reward:  2023.042 [ 171.610], Avg:   998.317 (0.200) <0-10:10:41> ({'r_t':  4235.5626, 'eps':     0.2001, 'len': 50555.0470, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  603000, Reward:  1958.794 [ 366.132], Avg:   999.907 (0.300) <0-10:11:45> ({'r_t':  3542.0723, 'eps':     0.3001, 'len': 50592.7090, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  604000, Reward:  1946.573 [ 374.992], Avg:  1001.472 (0.400) <0-10:12:46> ({'r_t':  2686.3090, 'eps':     0.4001, 'len': 50640.2620, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  605000, Reward:  1611.233 [ 611.835], Avg:  1002.478 (0.500) <0-10:13:44> ({'r_t':  1595.0124, 'eps':     0.5001, 'len': 50704.0900, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  606000, Reward:  2069.579 [ 135.458], Avg:  1004.236 (0.600) <0-10:14:37> ({'r_t':   523.2384, 'eps':     0.6001, 'len': 50785.9520, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  607000, Reward:  1984.465 [ 379.565], Avg:  1005.848 (0.700) <0-10:15:28> ({'r_t':  -429.3984, 'eps':     0.7001, 'len': 50879.7160, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  608000, Reward:  2056.059 [ 144.445], Avg:  1007.573 (0.800) <0-10:16:15> ({'r_t':  -933.9926, 'eps':     0.8001, 'len': 50984.5600, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  609000, Reward:  1818.786 [ 486.742], Avg:  1008.902 (0.900) <0-10:16:58> ({'r_t': -1165.1772, 'eps':     0.9001, 'len': 51089.7890, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  610000, Reward:  1974.516 [ 142.395], Avg:  1010.483 (0.000) <0-10:20:24> ({'r_t': -1221.7904, 'eps':     0.0001, 'len': 51191.9630, 'dyn_loss':    20.9423, 'dot_loss':     3.2905, 'ddot_loss':     6.8629, 'rew_loss':    12.8640, 'lr':   9.13e-05, 'eps_e':     0.0001, 'lr_e':   9.13e-05})
Step:  611000, Reward:  2003.878 [ 175.528], Avg:  1012.106 (0.100) <0-10:21:35> ({'r_t':  4042.9677, 'eps':     0.1001, 'len': 51252.2360, 'lr':   9.13e-05, 'eps_e':     0.1001, 'lr_e':   9.13e-05})
Step:  612000, Reward:  1990.759 [ 147.700], Avg:  1013.703 (0.200) <0-10:22:43> ({'r_t':  4139.1215, 'eps':     0.2001, 'len': 51284.5990, 'lr':   9.13e-05, 'eps_e':     0.2001, 'lr_e':   9.13e-05})
Step:  613000, Reward:  2056.355 [ 147.469], Avg:  1015.401 (0.300) <0-10:23:47> ({'r_t':  3786.1365, 'eps':     0.3001, 'len': 51319.8930, 'lr':   9.13e-05, 'eps_e':     0.3001, 'lr_e':   9.13e-05})
Step:  614000, Reward:  1959.522 [ 173.402], Avg:  1016.936 (0.400) <0-10:24:48> ({'r_t':  2737.2915, 'eps':     0.4001, 'len': 51364.2800, 'lr':   9.13e-05, 'eps_e':     0.4001, 'lr_e':   9.13e-05})
Step:  615000, Reward:  1997.193 [ 160.681], Avg:  1018.527 (0.500) <0-10:25:45> ({'r_t':  1765.1412, 'eps':     0.5001, 'len': 51419.2260, 'lr':   9.13e-05, 'eps_e':     0.5001, 'lr_e':   9.13e-05})
Step:  616000, Reward:  1947.563 [ 194.728], Avg:  1020.033 (0.600) <0-10:26:39> ({'r_t':   514.9355, 'eps':     0.6001, 'len': 51490.5090, 'lr':   9.13e-05, 'eps_e':     0.6001, 'lr_e':   9.13e-05})
Step:  617000, Reward:  1966.424 [ 236.919], Avg:  1021.564 (0.700) <0-10:27:29> ({'r_t':  -392.0864, 'eps':     0.7001, 'len': 51578.2420, 'lr':   9.13e-05, 'eps_e':     0.7001, 'lr_e':   9.13e-05})
Step:  618000, Reward:  1928.859 [ 372.491], Avg:  1023.030 (0.800) <0-10:28:16> ({'r_t':  -932.7069, 'eps':     0.8001, 'len': 51669.2900, 'lr':   9.13e-05, 'eps_e':     0.8001, 'lr_e':   9.13e-05})
Step:  619000, Reward:  1963.324 [ 114.298], Avg:  1024.547 (0.900) <0-10:28:59> ({'r_t': -1182.9916, 'eps':     0.9001, 'len': 51770.4300, 'lr':   9.13e-05, 'eps_e':     0.9001, 'lr_e':   9.13e-05})
Step:  620000, Reward:  2047.000 [ 147.671], Avg:  1026.193 (0.000) <0-10:32:23> ({'r_t': -1214.8631, 'eps':     0.0001, 'len': 51879.9780, 'dyn_loss':    21.3473, 'dot_loss':     3.3262, 'ddot_loss':     6.9065, 'rew_loss':    12.8815, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  621000, Reward:  2012.662 [ 384.278], Avg:  1027.779 (0.100) <0-10:33:35> ({'r_t':  4152.5355, 'eps':     0.1001, 'len': 51942.2360, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  622000, Reward:  2003.416 [ 165.863], Avg:  1029.345 (0.200) <0-10:34:42> ({'r_t':  4249.4368, 'eps':     0.2001, 'len': 51975.0340, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  623000, Reward:  2067.114 [ 144.016], Avg:  1031.008 (0.300) <0-10:35:47> ({'r_t':  3856.1449, 'eps':     0.3001, 'len': 52010.9310, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  624000, Reward:  2052.392 [ 148.370], Avg:  1032.642 (0.400) <0-10:36:47> ({'r_t':  2901.0992, 'eps':     0.4001, 'len': 52052.6990, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  625000, Reward:  2049.251 [ 178.300], Avg:  1034.266 (0.500) <0-10:37:44> ({'r_t':  1663.1456, 'eps':     0.5001, 'len': 52106.5940, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  626000, Reward:  1968.649 [ 265.159], Avg:  1035.757 (0.600) <0-10:38:38> ({'r_t':   444.1867, 'eps':     0.6001, 'len': 52179.8380, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  627000, Reward:  1987.759 [ 194.440], Avg:  1037.273 (0.700) <0-10:39:28> ({'r_t':  -506.6331, 'eps':     0.7001, 'len': 52268.2110, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  628000, Reward:  2069.336 [ 145.248], Avg:  1038.913 (0.800) <0-10:40:15> ({'r_t': -1031.1558, 'eps':     0.8001, 'len': 52356.0330, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  629000, Reward:  2028.194 [ 191.733], Avg:  1040.484 (0.900) <0-10:40:58> ({'r_t': -1125.4607, 'eps':     0.9001, 'len': 52456.0850, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  630000, Reward:  1909.890 [ 277.170], Avg:  1041.861 (0.000) <0-10:44:23> ({'r_t': -1210.5303, 'eps':     0.0001, 'len': 52557.9360, 'dyn_loss':    20.5479, 'dot_loss':     3.2644, 'ddot_loss':     6.8102, 'rew_loss':    12.6673, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  631000, Reward:  1899.894 [ 410.465], Avg:  1043.219 (0.100) <0-10:45:34> ({'r_t':  4025.6533, 'eps':     0.1001, 'len': 52624.1640, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  632000, Reward:  1849.888 [ 462.756], Avg:  1044.493 (0.200) <0-10:46:42> ({'r_t':  4019.9828, 'eps':     0.2001, 'len': 52658.6170, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  633000, Reward:  1978.016 [ 243.022], Avg:  1045.966 (0.300) <0-10:47:47> ({'r_t':  3500.0805, 'eps':     0.3001, 'len': 52701.8360, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  634000, Reward:  1916.161 [ 396.321], Avg:  1047.336 (0.400) <0-10:48:48> ({'r_t':  2893.6708, 'eps':     0.4001, 'len': 52746.0330, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  635000, Reward:  1940.364 [ 261.024], Avg:  1048.740 (0.500) <0-10:49:44> ({'r_t':  1695.5102, 'eps':     0.5001, 'len': 52799.1000, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  636000, Reward:  1980.437 [ 299.702], Avg:  1050.203 (0.600) <0-10:50:38> ({'r_t':   360.4248, 'eps':     0.6001, 'len': 52865.1040, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  637000, Reward:  1959.807 [ 240.086], Avg:  1051.629 (0.700) <0-10:51:28> ({'r_t':  -418.9420, 'eps':     0.7001, 'len': 52952.8850, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  638000, Reward:  2052.379 [ 162.511], Avg:  1053.195 (0.800) <0-10:52:15> ({'r_t':  -986.4309, 'eps':     0.8001, 'len': 53057.4320, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  639000, Reward:  1948.909 [ 287.647], Avg:  1054.594 (0.900) <0-10:52:59> ({'r_t': -1076.4740, 'eps':     0.9001, 'len': 53170.7170, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  640000, Reward:  1948.463 [ 368.404], Avg:  1055.989 (0.000) <0-10:56:27> ({'r_t': -1195.8807, 'eps':     0.0001, 'len': 53279.2220, 'dyn_loss':    20.4861, 'dot_loss':     3.2811, 'ddot_loss':     6.8660, 'rew_loss':    12.6355, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  641000, Reward:  1979.499 [ 370.448], Avg:  1057.427 (0.100) <0-10:57:38> ({'r_t':  4196.1628, 'eps':     0.1001, 'len': 53354.4930, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  642000, Reward:  1788.643 [ 521.976], Avg:  1058.565 (0.200) <0-10:58:46> ({'r_t':  3953.2065, 'eps':     0.2001, 'len': 53390.0400, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  643000, Reward:  1603.150 [ 587.897], Avg:  1059.410 (0.300) <0-10:59:50> ({'r_t':  3251.4256, 'eps':     0.3001, 'len': 53434.6720, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  644000, Reward:  1854.236 [ 486.388], Avg:  1060.643 (0.400) <0-11:00:51> ({'r_t':  2776.7056, 'eps':     0.4001, 'len': 53483.1350, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  645000, Reward:  1916.839 [ 391.847], Avg:  1061.968 (0.500) <0-11:01:48> ({'r_t':  1549.9729, 'eps':     0.5001, 'len': 53541.6790, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  646000, Reward:  1667.050 [ 629.972], Avg:  1062.903 (0.600) <0-11:02:42> ({'r_t':   447.8967, 'eps':     0.6001, 'len': 53617.1110, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  647000, Reward:  1683.182 [ 615.972], Avg:  1063.860 (0.700) <0-11:03:33> ({'r_t':  -426.4293, 'eps':     0.7001, 'len': 53710.4590, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  648000, Reward:  1764.106 [ 558.689], Avg:  1064.939 (0.800) <0-11:04:20> ({'r_t':  -866.6939, 'eps':     0.8001, 'len': 53820.8870, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  649000, Reward:  1856.403 [ 486.757], Avg:  1066.157 (0.900) <0-11:05:04> ({'r_t': -1194.7293, 'eps':     0.9001, 'len': 53931.1770, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  650000, Reward:  2020.367 [ 185.930], Avg:  1067.623 (0.000) <0-11:08:31> ({'r_t': -1200.0289, 'eps':     0.0001, 'len': 54037.3550, 'dyn_loss':    20.3782, 'dot_loss':     3.2482, 'ddot_loss':     6.8100, 'rew_loss':    12.4433, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  651000, Reward:  2058.202 [ 138.137], Avg:  1069.142 (0.100) <0-11:09:42> ({'r_t':  4167.8075, 'eps':     0.1001, 'len': 54105.4440, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  652000, Reward:  1977.921 [ 371.398], Avg:  1070.534 (0.200) <0-11:10:50> ({'r_t':  4151.6163, 'eps':     0.2001, 'len': 54139.5610, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  653000, Reward:  2054.824 [ 134.062], Avg:  1072.039 (0.300) <0-11:11:54> ({'r_t':  3736.3580, 'eps':     0.3001, 'len': 54178.1160, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  654000, Reward:  1879.329 [ 492.097], Avg:  1073.271 (0.400) <0-11:12:55> ({'r_t':  2578.5092, 'eps':     0.4001, 'len': 54228.5240, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  655000, Reward:  1973.433 [ 373.975], Avg:  1074.643 (0.500) <0-11:13:52> ({'r_t':  1452.2364, 'eps':     0.5001, 'len': 54286.1920, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  656000, Reward:  2058.163 [ 157.617], Avg:  1076.140 (0.600) <0-11:14:45> ({'r_t':   432.9945, 'eps':     0.6001, 'len': 54361.6320, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  657000, Reward:  2025.496 [ 170.566], Avg:  1077.583 (0.700) <0-11:15:36> ({'r_t':  -549.7588, 'eps':     0.7001, 'len': 54444.9750, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  658000, Reward:  2028.817 [ 143.011], Avg:  1079.027 (0.800) <0-11:16:23> ({'r_t':  -900.4463, 'eps':     0.8001, 'len': 54551.7060, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  659000, Reward:  2079.980 [ 150.517], Avg:  1080.543 (0.900) <0-11:17:06> ({'r_t': -1153.3235, 'eps':     0.9001, 'len': 54657.4360, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  660000, Reward:  2038.914 [ 180.598], Avg:  1081.993 (0.000) <0-11:20:32> ({'r_t': -1164.7668, 'eps':     0.0001, 'len': 54762.6100, 'dyn_loss':    20.7269, 'dot_loss':     3.2870, 'ddot_loss':     6.8881, 'rew_loss':    12.7481, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  661000, Reward:  2058.937 [ 158.803], Avg:  1083.469 (0.100) <0-11:21:43> ({'r_t':  4200.8195, 'eps':     0.1001, 'len': 54829.0410, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  662000, Reward:  2026.053 [ 191.075], Avg:  1084.891 (0.200) <0-11:22:51> ({'r_t':  4144.7584, 'eps':     0.2001, 'len': 54861.5680, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  663000, Reward:  2049.123 [ 161.285], Avg:  1086.343 (0.300) <0-11:23:55> ({'r_t':  3783.4387, 'eps':     0.3001, 'len': 54897.7940, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  664000, Reward:  2012.255 [ 164.175], Avg:  1087.735 (0.400) <0-11:24:56> ({'r_t':  2980.3688, 'eps':     0.4001, 'len': 54937.4940, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  665000, Reward:  1981.703 [ 240.786], Avg:  1089.077 (0.500) <0-11:25:53> ({'r_t':  1736.9335, 'eps':     0.5001, 'len': 54986.3590, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  666000, Reward:  2053.837 [ 180.944], Avg:  1090.524 (0.600) <0-11:26:47> ({'r_t':   340.9163, 'eps':     0.6001, 'len': 55053.3350, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  667000, Reward:  2062.447 [ 140.878], Avg:  1091.979 (0.700) <0-11:27:37> ({'r_t':  -514.1610, 'eps':     0.7001, 'len': 55141.7950, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  668000, Reward:  2083.473 [ 137.358], Avg:  1093.461 (0.800) <0-11:28:24> ({'r_t':  -931.0066, 'eps':     0.8001, 'len': 55237.1600, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  669000, Reward:  1987.255 [ 211.387], Avg:  1094.795 (0.900) <0-11:29:07> ({'r_t': -1162.3606, 'eps':     0.9001, 'len': 55341.8850, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  670000, Reward:  2010.143 [ 163.852], Avg:  1096.159 (0.000) <0-11:32:37> ({'r_t': -1215.1800, 'eps':     0.0001, 'len': 55446.5490, 'dyn_loss':    20.9116, 'dot_loss':     3.3038, 'ddot_loss':     6.9151, 'rew_loss':    12.9085, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  671000, Reward:  2087.984 [ 150.232], Avg:  1097.635 (0.100) <0-11:33:48> ({'r_t':  4162.1366, 'eps':     0.1001, 'len': 55516.4180, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  672000, Reward:  1947.436 [ 381.280], Avg:  1098.898 (0.200) <0-11:34:56> ({'r_t':  4154.8926, 'eps':     0.2001, 'len': 55550.0430, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  673000, Reward:  1874.549 [ 494.889], Avg:  1100.048 (0.300) <0-11:36:01> ({'r_t':  3648.7257, 'eps':     0.3001, 'len': 55588.5830, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  674000, Reward:  2082.843 [ 149.361], Avg:  1101.504 (0.400) <0-11:37:01> ({'r_t':  2919.3085, 'eps':     0.4001, 'len': 55630.3920, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  675000, Reward:  1994.121 [ 161.596], Avg:  1102.825 (0.500) <0-11:37:58> ({'r_t':  1630.3298, 'eps':     0.5001, 'len': 55679.8190, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  676000, Reward:  2038.459 [ 178.319], Avg:  1104.207 (0.600) <0-11:38:52> ({'r_t':   430.2478, 'eps':     0.6001, 'len': 55749.6900, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  677000, Reward:  2060.673 [ 138.483], Avg:  1105.618 (0.700) <0-11:39:42> ({'r_t':  -420.8166, 'eps':     0.7001, 'len': 55839.1170, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  678000, Reward:  2072.352 [ 152.457], Avg:  1107.041 (0.800) <0-11:40:29> ({'r_t':  -937.9411, 'eps':     0.8001, 'len': 55932.1050, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  679000, Reward:  2026.884 [ 192.043], Avg:  1108.394 (0.900) <0-11:41:12> ({'r_t': -1177.2574, 'eps':     0.9001, 'len': 56029.7550, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  680000, Reward:  2075.763 [ 146.941], Avg:  1109.815 (0.000) <0-11:44:42> ({'r_t': -1266.0415, 'eps':     0.0001, 'len': 56130.2280, 'dyn_loss':    20.4887, 'dot_loss':     3.2552, 'ddot_loss':     6.8124, 'rew_loss':    12.5437, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  681000, Reward:  2046.229 [ 186.413], Avg:  1111.188 (0.100) <0-11:45:53> ({'r_t':  4170.1217, 'eps':     0.1001, 'len': 56193.8190, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  682000, Reward:  1939.618 [ 520.171], Avg:  1112.401 (0.200) <0-11:47:01> ({'r_t':  4135.1507, 'eps':     0.2001, 'len': 56228.1910, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  683000, Reward:  2071.688 [ 147.008], Avg:  1113.803 (0.300) <0-11:48:06> ({'r_t':  3809.4541, 'eps':     0.3001, 'len': 56266.6090, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  684000, Reward:  2025.637 [ 191.374], Avg:  1115.134 (0.400) <0-11:49:06> ({'r_t':  2742.5605, 'eps':     0.4001, 'len': 56305.5290, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  685000, Reward:  1815.995 [ 567.088], Avg:  1116.156 (0.500) <0-11:50:04> ({'r_t':  1589.9645, 'eps':     0.5001, 'len': 56361.0140, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  686000, Reward:  2088.868 [ 164.777], Avg:  1117.572 (0.600) <0-11:50:57> ({'r_t':   523.8439, 'eps':     0.6001, 'len': 56432.9740, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  687000, Reward:  1959.179 [ 331.834], Avg:  1118.795 (0.700) <0-11:51:48> ({'r_t':  -417.7895, 'eps':     0.7001, 'len': 56523.3860, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  688000, Reward:  2077.620 [ 138.848], Avg:  1120.187 (0.800) <0-11:52:34> ({'r_t':  -973.0163, 'eps':     0.8001, 'len': 56624.5470, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  689000, Reward:  1900.936 [ 431.368], Avg:  1121.318 (0.900) <0-11:53:18> ({'r_t': -1106.9461, 'eps':     0.9001, 'len': 56723.0200, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  690000, Reward:  2092.140 [ 153.011], Avg:  1122.723 (0.000) <0-11:56:45> ({'r_t': -1235.8139, 'eps':     0.0001, 'len': 56824.5530, 'dyn_loss':    20.5799, 'dot_loss':     3.2645, 'ddot_loss':     6.8255, 'rew_loss':    12.6086, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  691000, Reward:  2005.458 [ 166.228], Avg:  1123.999 (0.100) <0-11:57:56> ({'r_t':  4120.6537, 'eps':     0.1001, 'len': 56890.8780, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  692000, Reward:  2092.410 [ 130.778], Avg:  1125.396 (0.200) <0-11:59:04> ({'r_t':  4107.6498, 'eps':     0.2001, 'len': 56925.3200, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  693000, Reward:  1939.205 [ 393.900], Avg:  1126.569 (0.300) <0-12:00:09> ({'r_t':  3785.3497, 'eps':     0.3001, 'len': 56962.5910, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  694000, Reward:  1935.955 [ 367.493], Avg:  1127.733 (0.400) <0-12:01:10> ({'r_t':  2817.1319, 'eps':     0.4001, 'len': 57005.0360, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  695000, Reward:  2073.424 [ 165.640], Avg:  1129.092 (0.500) <0-12:02:07> ({'r_t':  1638.2508, 'eps':     0.5001, 'len': 57057.5660, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  696000, Reward:  1999.794 [ 378.491], Avg:  1130.341 (0.600) <0-12:03:00> ({'r_t':   531.1517, 'eps':     0.6001, 'len': 57123.5790, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  697000, Reward:  1987.356 [ 380.192], Avg:  1131.569 (0.700) <0-12:03:51> ({'r_t':  -418.0037, 'eps':     0.7001, 'len': 57216.8230, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  698000, Reward:  1776.774 [ 564.664], Avg:  1132.492 (0.800) <0-12:04:38> ({'r_t': -1040.1014, 'eps':     0.8001, 'len': 57316.8760, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  699000, Reward:  2038.113 [ 144.763], Avg:  1133.786 (0.900) <0-12:05:21> ({'r_t': -1095.9689, 'eps':     0.9001, 'len': 57426.8680, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  700000, Reward:  2027.861 [ 190.052], Avg:  1135.061 (0.000) <0-12:08:52> ({'r_t': -1192.6083, 'eps':     0.0001, 'len': 57539.9060, 'dyn_loss':    20.9940, 'dot_loss':     3.2994, 'ddot_loss':     6.8848, 'rew_loss':    12.7771, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  701000, Reward:  1947.073 [ 403.736], Avg:  1136.218 (0.100) <0-12:10:03> ({'r_t':  4136.8998, 'eps':     0.1001, 'len': 57606.6710, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  702000, Reward:  2053.544 [ 141.554], Avg:  1137.523 (0.200) <0-12:11:11> ({'r_t':  4217.7512, 'eps':     0.2001, 'len': 57640.7130, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  703000, Reward:  1978.651 [ 383.815], Avg:  1138.718 (0.300) <0-12:12:15> ({'r_t':  3778.1043, 'eps':     0.3001, 'len': 57675.5350, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  704000, Reward:  2066.254 [ 126.215], Avg:  1140.033 (0.400) <0-12:13:16> ({'r_t':  3032.4650, 'eps':     0.4001, 'len': 57716.9340, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  705000, Reward:  2069.858 [ 134.513], Avg:  1141.350 (0.500) <0-12:14:13> ({'r_t':  1509.5730, 'eps':     0.5001, 'len': 57773.3460, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  706000, Reward:  2059.389 [ 140.389], Avg:  1142.649 (0.600) <0-12:15:07> ({'r_t':   527.6662, 'eps':     0.6001, 'len': 57843.9840, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  707000, Reward:  2095.070 [ 148.761], Avg:  1143.994 (0.700) <0-12:15:57> ({'r_t':  -561.0868, 'eps':     0.7001, 'len': 57934.9700, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  708000, Reward:  1926.234 [ 389.350], Avg:  1145.097 (0.800) <0-12:16:44> ({'r_t': -1009.7997, 'eps':     0.8001, 'len': 58032.9950, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  709000, Reward:  1934.390 [ 368.532], Avg:  1146.209 (0.900) <0-12:17:27> ({'r_t': -1167.3629, 'eps':     0.9001, 'len': 58131.6420, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  710000, Reward:  1877.360 [ 413.720], Avg:  1147.237 (0.000) <0-12:20:54> ({'r_t': -1243.0990, 'eps':     0.0001, 'len': 58237.9360, 'dyn_loss':    20.6248, 'dot_loss':     3.2873, 'ddot_loss':     6.8875, 'rew_loss':    12.6758, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  711000, Reward:  2074.179 [ 174.832], Avg:  1148.539 (0.100) <0-12:22:06> ({'r_t':  4136.7858, 'eps':     0.1001, 'len': 58305.9360, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  712000, Reward:  1930.781 [ 406.957], Avg:  1149.636 (0.200) <0-12:23:14> ({'r_t':  4295.6560, 'eps':     0.2001, 'len': 58338.1640, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  713000, Reward:  2052.568 [ 166.024], Avg:  1150.901 (0.300) <0-12:24:18> ({'r_t':  3743.4910, 'eps':     0.3001, 'len': 58374.5340, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  714000, Reward:  2057.237 [ 133.055], Avg:  1152.169 (0.400) <0-12:25:19> ({'r_t':  2878.1725, 'eps':     0.4001, 'len': 58415.3110, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  715000, Reward:  1947.289 [ 173.362], Avg:  1153.279 (0.500) <0-12:26:16> ({'r_t':  1642.2785, 'eps':     0.5001, 'len': 58469.8790, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  716000, Reward:  2033.417 [ 187.309], Avg:  1154.507 (0.600) <0-12:27:09> ({'r_t':   427.6469, 'eps':     0.6001, 'len': 58543.4850, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  717000, Reward:  1917.671 [ 418.588], Avg:  1155.570 (0.700) <0-12:28:00> ({'r_t':  -397.8922, 'eps':     0.7001, 'len': 58635.0460, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  718000, Reward:  2014.201 [ 180.024], Avg:  1156.764 (0.800) <0-12:28:47> ({'r_t':  -913.6527, 'eps':     0.8001, 'len': 58736.8180, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  719000, Reward:  2026.070 [ 194.538], Avg:  1157.971 (0.900) <0-12:29:30> ({'r_t': -1196.6090, 'eps':     0.9001, 'len': 58844.1500, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  720000, Reward:  2068.849 [ 128.611], Avg:  1159.235 (0.000) <0-12:33:00> ({'r_t': -1229.0556, 'eps':     0.0001, 'len': 58942.6130, 'dyn_loss':    19.9989, 'dot_loss':     3.2430, 'ddot_loss':     6.8362, 'rew_loss':    12.4838, 'lr':   8.85e-05, 'eps_e':     0.0001, 'lr_e':   8.85e-05})
Step:  721000, Reward:  2076.067 [ 137.064], Avg:  1160.504 (0.100) <0-12:34:11> ({'r_t':  4146.9419, 'eps':     0.1001, 'len': 59011.1160, 'lr':   8.85e-05, 'eps_e':     0.1001, 'lr_e':   8.85e-05})
Step:  722000, Reward:  1972.606 [ 362.628], Avg:  1161.628 (0.200) <0-12:35:19> ({'r_t':  4181.0393, 'eps':     0.2001, 'len': 59044.5750, 'lr':   8.85e-05, 'eps_e':     0.2001, 'lr_e':   8.85e-05})
Step:  723000, Reward:  2069.920 [ 134.530], Avg:  1162.882 (0.300) <0-12:36:23> ({'r_t':  3828.4889, 'eps':     0.3001, 'len': 59080.1420, 'lr':   8.85e-05, 'eps_e':     0.3001, 'lr_e':   8.85e-05})
Step:  724000, Reward:  2065.233 [ 160.175], Avg:  1164.127 (0.400) <0-12:37:24> ({'r_t':  2840.7636, 'eps':     0.4001, 'len': 59119.9320, 'lr':   8.85e-05, 'eps_e':     0.4001, 'lr_e':   8.85e-05})
Step:  725000, Reward:  1975.013 [ 373.815], Avg:  1165.244 (0.500) <0-12:38:21> ({'r_t':  1696.0990, 'eps':     0.5001, 'len': 59172.5150, 'lr':   8.85e-05, 'eps_e':     0.5001, 'lr_e':   8.85e-05})
Step:  726000, Reward:  2068.290 [ 139.387], Avg:  1166.486 (0.600) <0-12:39:15> ({'r_t':   395.9156, 'eps':     0.6001, 'len': 59248.2870, 'lr':   8.85e-05, 'eps_e':     0.6001, 'lr_e':   8.85e-05})
Step:  727000, Reward:  2098.118 [ 117.466], Avg:  1167.766 (0.700) <0-12:40:05> ({'r_t':  -454.3965, 'eps':     0.7001, 'len': 59340.6080, 'lr':   8.85e-05, 'eps_e':     0.7001, 'lr_e':   8.85e-05})
Step:  728000, Reward:  2086.712 [ 155.115], Avg:  1169.026 (0.800) <0-12:40:52> ({'r_t':  -964.7091, 'eps':     0.8001, 'len': 59441.9630, 'lr':   8.85e-05, 'eps_e':     0.8001, 'lr_e':   8.85e-05})
Step:  729000, Reward:  1954.344 [ 379.727], Avg:  1170.102 (0.900) <0-12:41:35> ({'r_t': -1147.5743, 'eps':     0.9001, 'len': 59550.5870, 'lr':   8.85e-05, 'eps_e':     0.9001, 'lr_e':   8.85e-05})
Step:  730000, Reward:  1939.507 [ 504.634], Avg:  1171.154 (0.000) <0-12:45:06> ({'r_t': -1251.6570, 'eps':     0.0001, 'len': 59657.9240, 'dyn_loss':    20.4373, 'dot_loss':     3.2699, 'ddot_loss':     6.8685, 'rew_loss':    12.5403, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  731000, Reward:  2101.711 [ 130.895], Avg:  1172.426 (0.100) <0-12:46:17> ({'r_t':  4176.8200, 'eps':     0.1001, 'len': 59724.9150, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  732000, Reward:  2076.920 [ 162.120], Avg:  1173.660 (0.200) <0-12:47:25> ({'r_t':  4297.4705, 'eps':     0.2001, 'len': 59757.1900, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  733000, Reward:  2034.766 [ 173.661], Avg:  1174.833 (0.300) <0-12:48:30> ({'r_t':  3847.8773, 'eps':     0.3001, 'len': 59791.3090, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  734000, Reward:  2072.572 [ 161.357], Avg:  1176.054 (0.400) <0-12:49:30> ({'r_t':  2710.9779, 'eps':     0.4001, 'len': 59835.0540, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  735000, Reward:  2089.074 [ 147.793], Avg:  1177.295 (0.500) <0-12:50:27> ({'r_t':  1598.6694, 'eps':     0.5001, 'len': 59890.9190, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  736000, Reward:  2084.192 [ 147.769], Avg:  1178.525 (0.600) <0-12:51:21> ({'r_t':   329.7717, 'eps':     0.6001, 'len': 59966.1440, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  737000, Reward:  2074.861 [ 140.186], Avg:  1179.740 (0.700) <0-12:52:11> ({'r_t':  -307.3826, 'eps':     0.7001, 'len': 60049.0880, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  738000, Reward:  2042.174 [ 155.834], Avg:  1180.907 (0.800) <0-12:52:58> ({'r_t':  -984.9354, 'eps':     0.8001, 'len': 60141.1190, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  739000, Reward:  2049.230 [ 124.593], Avg:  1182.080 (0.900) <0-12:53:41> ({'r_t': -1141.0474, 'eps':     0.9001, 'len': 60249.1660, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  740000, Reward:  2060.365 [ 127.133], Avg:  1183.266 (0.000) <0-12:57:12> ({'r_t': -1228.6718, 'eps':     0.0001, 'len': 60348.6150, 'dyn_loss':    19.9254, 'dot_loss':     3.2134, 'ddot_loss':     6.7557, 'rew_loss':    12.4201, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  741000, Reward:  2069.932 [ 122.041], Avg:  1184.461 (0.100) <0-12:58:24> ({'r_t':  4084.5924, 'eps':     0.1001, 'len': 60410.6060, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  742000, Reward:  2012.689 [ 151.597], Avg:  1185.575 (0.200) <0-12:59:32> ({'r_t':  4029.5513, 'eps':     0.2001, 'len': 60444.1270, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  743000, Reward:  1919.897 [ 264.452], Avg:  1186.562 (0.300) <0-13:00:36> ({'r_t':  3761.6820, 'eps':     0.3001, 'len': 60483.6700, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  744000, Reward:  1924.936 [ 514.605], Avg:  1187.553 (0.400) <0-13:01:37> ({'r_t':  2665.8915, 'eps':     0.4001, 'len': 60526.9040, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  745000, Reward:  1974.020 [ 197.626], Avg:  1188.608 (0.500) <0-13:02:34> ({'r_t':  1588.4628, 'eps':     0.5001, 'len': 60583.7130, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  746000, Reward:  1938.526 [ 380.219], Avg:  1189.611 (0.600) <0-13:03:27> ({'r_t':   396.9585, 'eps':     0.6001, 'len': 60657.6910, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  747000, Reward:  1876.590 [ 267.372], Avg:  1190.530 (0.700) <0-13:04:18> ({'r_t':  -510.1427, 'eps':     0.7001, 'len': 60743.3260, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  748000, Reward:  1936.134 [ 198.943], Avg:  1191.525 (0.800) <0-13:05:05> ({'r_t':  -932.0995, 'eps':     0.8001, 'len': 60836.9700, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  749000, Reward:  2040.983 [ 177.276], Avg:  1192.658 (0.900) <0-13:05:48> ({'r_t': -1136.3348, 'eps':     0.9001, 'len': 60943.7000, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  750000, Reward:  1879.311 [ 460.905], Avg:  1193.572 (0.000) <0-13:09:20> ({'r_t': -1203.2992, 'eps':     0.0001, 'len': 61047.2170, 'dyn_loss':    20.2118, 'dot_loss':     3.2613, 'ddot_loss':     6.8691, 'rew_loss':    12.6041, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  751000, Reward:  1913.996 [ 539.817], Avg:  1194.530 (0.100) <0-13:10:32> ({'r_t':  4227.3600, 'eps':     0.1001, 'len': 61112.5760, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  752000, Reward:  2078.087 [ 157.410], Avg:  1195.704 (0.200) <0-13:11:40> ({'r_t':  4112.3872, 'eps':     0.2001, 'len': 61145.6690, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  753000, Reward:  1946.733 [ 519.640], Avg:  1196.700 (0.300) <0-13:12:44> ({'r_t':  3746.0628, 'eps':     0.3001, 'len': 61181.8490, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  754000, Reward:  2075.838 [ 170.689], Avg:  1197.864 (0.400) <0-13:13:46> ({'r_t':  2692.0400, 'eps':     0.4001, 'len': 61223.8070, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  755000, Reward:  1862.158 [ 622.197], Avg:  1198.743 (0.500) <0-13:14:43> ({'r_t':  1658.0685, 'eps':     0.5001, 'len': 61280.3590, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  756000, Reward:  2048.003 [ 188.325], Avg:  1199.865 (0.600) <0-13:15:37> ({'r_t':   448.8362, 'eps':     0.6001, 'len': 61350.2150, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  757000, Reward:  1911.544 [ 519.309], Avg:  1200.804 (0.700) <0-13:16:28> ({'r_t':  -404.1234, 'eps':     0.7001, 'len': 61441.9100, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  758000, Reward:  1895.449 [ 387.815], Avg:  1201.719 (0.800) <0-13:17:15> ({'r_t':  -967.8562, 'eps':     0.8001, 'len': 61541.5270, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  759000, Reward:  1970.501 [ 376.003], Avg:  1202.730 (0.900) <0-13:17:58> ({'r_t': -1140.7225, 'eps':     0.9001, 'len': 61646.6800, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  760000, Reward:  2039.162 [ 142.653], Avg:  1203.829 (0.000) <0-13:21:31> ({'r_t': -1240.4459, 'eps':     0.0001, 'len': 61753.8190, 'dyn_loss':    19.7654, 'dot_loss':     3.1880, 'ddot_loss':     6.7312, 'rew_loss':    12.4152, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  761000, Reward:  1876.057 [ 506.867], Avg:  1204.712 (0.100) <0-13:22:43> ({'r_t':  4085.9849, 'eps':     0.1001, 'len': 61821.3480, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  762000, Reward:  2041.893 [ 177.619], Avg:  1205.809 (0.200) <0-13:23:51> ({'r_t':  4124.9247, 'eps':     0.2001, 'len': 61854.7040, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  763000, Reward:  1990.060 [ 388.722], Avg:  1206.835 (0.300) <0-13:24:56> ({'r_t':  3699.3164, 'eps':     0.3001, 'len': 61892.8270, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  764000, Reward:  1925.154 [ 382.779], Avg:  1207.774 (0.400) <0-13:25:57> ({'r_t':  2993.8542, 'eps':     0.4001, 'len': 61933.0300, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  765000, Reward:  2028.678 [ 168.514], Avg:  1208.846 (0.500) <0-13:26:54> ({'r_t':  1699.7557, 'eps':     0.5001, 'len': 61987.6690, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  766000, Reward:  2027.244 [ 167.699], Avg:  1209.913 (0.600) <0-13:27:48> ({'r_t':   321.1306, 'eps':     0.6001, 'len': 62059.9610, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  767000, Reward:  1963.758 [ 386.425], Avg:  1210.895 (0.700) <0-13:28:38> ({'r_t':  -349.3361, 'eps':     0.7001, 'len': 62160.1390, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  768000, Reward:  1955.730 [ 377.161], Avg:  1211.863 (0.800) <0-13:29:25> ({'r_t':  -970.9804, 'eps':     0.8001, 'len': 62261.3890, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  769000, Reward:  1913.362 [ 376.638], Avg:  1212.774 (0.900) <0-13:30:08> ({'r_t': -1159.9110, 'eps':     0.9001, 'len': 62369.6370, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  770000, Reward:  1855.966 [ 478.085], Avg:  1213.608 (0.000) <0-13:33:41> ({'r_t': -1272.3172, 'eps':     0.0001, 'len': 62474.8900, 'dyn_loss':    20.1714, 'dot_loss':     3.2290, 'ddot_loss':     6.8017, 'rew_loss':    12.5573, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  771000, Reward:  1924.650 [ 366.327], Avg:  1214.530 (0.100) <0-13:34:53> ({'r_t':  4157.1021, 'eps':     0.1001, 'len': 62539.9650, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  772000, Reward:  2033.396 [ 163.915], Avg:  1215.589 (0.200) <0-13:36:01> ({'r_t':  4135.6920, 'eps':     0.2001, 'len': 62573.2060, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  773000, Reward:  1852.201 [ 472.963], Avg:  1216.411 (0.300) <0-13:37:06> ({'r_t':  3765.2240, 'eps':     0.3001, 'len': 62612.7050, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  774000, Reward:  1739.425 [ 558.130], Avg:  1217.086 (0.400) <0-13:38:07> ({'r_t':  2793.8515, 'eps':     0.4001, 'len': 62656.6630, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  775000, Reward:  1739.134 [ 578.166], Avg:  1217.759 (0.500) <0-13:39:04> ({'r_t':  1705.2514, 'eps':     0.5001, 'len': 62711.3980, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  776000, Reward:  1833.232 [ 448.738], Avg:  1218.551 (0.600) <0-13:39:58> ({'r_t':   328.1231, 'eps':     0.6001, 'len': 62786.7550, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  777000, Reward:  1825.121 [ 482.680], Avg:  1219.331 (0.700) <0-13:40:49> ({'r_t':  -351.4960, 'eps':     0.7001, 'len': 62879.8110, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  778000, Reward:  1917.925 [ 405.649], Avg:  1220.228 (0.800) <0-13:41:36> ({'r_t':  -967.6006, 'eps':     0.8001, 'len': 62978.4220, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  779000, Reward:  1828.279 [ 472.337], Avg:  1221.007 (0.900) <0-13:42:19> ({'r_t': -1141.2012, 'eps':     0.9001, 'len': 63085.9560, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  780000, Reward:  2027.021 [ 187.944], Avg:  1222.039 (0.000) <0-13:45:51> ({'r_t': -1256.3670, 'eps':     0.0001, 'len': 63188.6560, 'dyn_loss':    20.0449, 'dot_loss':     3.2228, 'ddot_loss':     6.7946, 'rew_loss':    12.3848, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  781000, Reward:  2073.765 [ 143.580], Avg:  1223.128 (0.100) <0-13:47:03> ({'r_t':  4215.1459, 'eps':     0.1001, 'len': 63254.6250, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  782000, Reward:  2039.721 [ 160.775], Avg:  1224.171 (0.200) <0-13:48:11> ({'r_t':  4101.8139, 'eps':     0.2001, 'len': 63288.1150, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  783000, Reward:  2026.976 [ 174.728], Avg:  1225.195 (0.300) <0-13:49:16> ({'r_t':  3543.3089, 'eps':     0.3001, 'len': 63327.9590, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  784000, Reward:  2062.484 [ 130.995], Avg:  1226.262 (0.400) <0-13:50:17> ({'r_t':  2619.2974, 'eps':     0.4001, 'len': 63371.1120, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  785000, Reward:  1993.262 [ 276.566], Avg:  1227.238 (0.500) <0-13:51:14> ({'r_t':  1534.9656, 'eps':     0.5001, 'len': 63433.6480, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  786000, Reward:  1960.311 [ 376.400], Avg:  1228.169 (0.600) <0-13:52:08> ({'r_t':   352.5062, 'eps':     0.6001, 'len': 63505.1020, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  787000, Reward:  1930.264 [ 334.593], Avg:  1229.060 (0.700) <0-13:52:59> ({'r_t':  -429.0183, 'eps':     0.7001, 'len': 63596.0210, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  788000, Reward:  1951.631 [ 266.316], Avg:  1229.976 (0.800) <0-13:53:46> ({'r_t':  -934.7449, 'eps':     0.8001, 'len': 63694.5380, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  789000, Reward:  1941.253 [ 340.380], Avg:  1230.876 (0.900) <0-13:54:29> ({'r_t': -1158.4675, 'eps':     0.9001, 'len': 63791.9380, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  790000, Reward:  2012.333 [ 186.083], Avg:  1231.864 (0.000) <0-13:58:01> ({'r_t': -1231.4225, 'eps':     0.0001, 'len': 63897.0210, 'dyn_loss':    20.3208, 'dot_loss':     3.2552, 'ddot_loss':     6.8571, 'rew_loss':    12.7245, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  791000, Reward:  1911.481 [ 363.629], Avg:  1232.722 (0.100) <0-13:59:13> ({'r_t':  4160.3780, 'eps':     0.1001, 'len': 63964.7490, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  792000, Reward:  1855.846 [ 348.031], Avg:  1233.508 (0.200) <0-14:00:21> ({'r_t':  3885.1898, 'eps':     0.2001, 'len': 64000.6490, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  793000, Reward:  1825.008 [ 479.357], Avg:  1234.253 (0.300) <0-14:01:25> ({'r_t':  3663.8232, 'eps':     0.3001, 'len': 64040.1960, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  794000, Reward:  1860.699 [ 503.296], Avg:  1235.041 (0.400) <0-14:02:26> ({'r_t':  2687.0552, 'eps':     0.4001, 'len': 64083.8760, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  795000, Reward:  1750.291 [ 611.036], Avg:  1235.688 (0.500) <0-14:03:24> ({'r_t':  1464.1450, 'eps':     0.5001, 'len': 64143.3560, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  796000, Reward:  1902.773 [ 411.214], Avg:  1236.525 (0.600) <0-14:04:17> ({'r_t':   382.6114, 'eps':     0.6001, 'len': 64213.0840, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  797000, Reward:  1977.707 [ 382.113], Avg:  1237.454 (0.700) <0-14:05:07> ({'r_t':  -425.7720, 'eps':     0.7001, 'len': 64302.8080, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  798000, Reward:  1782.715 [ 416.490], Avg:  1238.136 (0.800) <0-14:05:54> ({'r_t':  -983.4568, 'eps':     0.8001, 'len': 64398.6260, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  799000, Reward:  1885.811 [ 386.875], Avg:  1238.946 (0.900) <0-14:06:38> ({'r_t': -1145.2828, 'eps':     0.9001, 'len': 64498.0300, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  800000, Reward:  1952.688 [ 388.402], Avg:  1239.837 (0.000) <0-14:10:11> ({'r_t': -1253.9334, 'eps':     0.0001, 'len': 64595.6370, 'dyn_loss':    19.6537, 'dot_loss':     3.2024, 'ddot_loss':     6.7701, 'rew_loss':    12.3337, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  801000, Reward:  1873.053 [ 500.949], Avg:  1240.627 (0.100) <0-14:11:23> ({'r_t':  4204.3833, 'eps':     0.1001, 'len': 64662.4820, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  802000, Reward:  1928.017 [ 394.019], Avg:  1241.483 (0.200) <0-14:12:31> ({'r_t':  4190.8990, 'eps':     0.2001, 'len': 64695.4320, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  803000, Reward:  2088.267 [ 152.346], Avg:  1242.536 (0.300) <0-14:13:35> ({'r_t':  3688.2312, 'eps':     0.3001, 'len': 64731.4670, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  804000, Reward:  2067.040 [ 153.570], Avg:  1243.560 (0.400) <0-14:14:36> ({'r_t':  2792.0363, 'eps':     0.4001, 'len': 64775.1200, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  805000, Reward:  2078.744 [ 141.455], Avg:  1244.596 (0.500) <0-14:15:34> ({'r_t':  1536.4455, 'eps':     0.5001, 'len': 64832.6280, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  806000, Reward:  2063.634 [ 134.909], Avg:  1245.611 (0.600) <0-14:16:27> ({'r_t':   450.4962, 'eps':     0.6001, 'len': 64899.4500, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  807000, Reward:  2059.803 [ 134.770], Avg:  1246.619 (0.700) <0-14:17:18> ({'r_t':  -382.8131, 'eps':     0.7001, 'len': 64980.9420, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  808000, Reward:  2065.617 [ 166.636], Avg:  1247.631 (0.800) <0-14:18:05> ({'r_t':  -933.1864, 'eps':     0.8001, 'len': 65069.5360, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  809000, Reward:  2050.166 [ 145.518], Avg:  1248.622 (0.900) <0-14:18:48> ({'r_t': -1120.9713, 'eps':     0.9001, 'len': 65171.5750, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  810000, Reward:  1908.653 [ 360.495], Avg:  1249.436 (0.000) <0-14:22:22> ({'r_t': -1190.4729, 'eps':     0.0001, 'len': 65280.2470, 'dyn_loss':    20.1682, 'dot_loss':     3.2315, 'ddot_loss':     6.8335, 'rew_loss':    12.4323, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  811000, Reward:  1961.055 [ 380.414], Avg:  1250.312 (0.100) <0-14:23:34> ({'r_t':  4275.8682, 'eps':     0.1001, 'len': 65346.3380, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  812000, Reward:  2051.998 [ 151.945], Avg:  1251.298 (0.200) <0-14:24:42> ({'r_t':  4163.3303, 'eps':     0.2001, 'len': 65379.6450, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  813000, Reward:  2086.020 [ 148.212], Avg:  1252.324 (0.300) <0-14:25:46> ({'r_t':  3769.8303, 'eps':     0.3001, 'len': 65415.2510, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  814000, Reward:  2075.546 [ 152.544], Avg:  1253.334 (0.400) <0-14:26:47> ({'r_t':  2905.4967, 'eps':     0.4001, 'len': 65456.4210, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  815000, Reward:  1954.041 [ 389.583], Avg:  1254.193 (0.500) <0-14:27:44> ({'r_t':  1533.4772, 'eps':     0.5001, 'len': 65510.5160, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  816000, Reward:  1952.253 [ 370.611], Avg:  1255.047 (0.600) <0-14:28:38> ({'r_t':   279.4151, 'eps':     0.6001, 'len': 65579.8630, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  817000, Reward:  2067.280 [ 150.322], Avg:  1256.040 (0.700) <0-14:29:28> ({'r_t':  -365.3017, 'eps':     0.7001, 'len': 65662.1200, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  818000, Reward:  1969.773 [ 387.550], Avg:  1256.911 (0.800) <0-14:30:15> ({'r_t':  -940.0736, 'eps':     0.8001, 'len': 65752.6700, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  819000, Reward:  2076.706 [ 158.182], Avg:  1257.911 (0.900) <0-14:30:59> ({'r_t': -1106.5380, 'eps':     0.9001, 'len': 65858.8340, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  820000, Reward:  2069.524 [ 133.600], Avg:  1258.900 (0.000) <0-14:34:32> ({'r_t': -1186.1441, 'eps':     0.0001, 'len': 65962.2850, 'dyn_loss':    19.5546, 'dot_loss':     3.1676, 'ddot_loss':     6.7112, 'rew_loss':    12.2009, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  821000, Reward:  2060.855 [ 171.482], Avg:  1259.875 (0.100) <0-14:35:44> ({'r_t':  4193.3856, 'eps':     0.1001, 'len': 66032.2920, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  822000, Reward:  2033.987 [ 157.316], Avg:  1260.816 (0.200) <0-14:36:52> ({'r_t':  4159.4330, 'eps':     0.2001, 'len': 66065.4260, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  823000, Reward:  1979.650 [ 371.903], Avg:  1261.688 (0.300) <0-14:37:57> ({'r_t':  3567.0771, 'eps':     0.3001, 'len': 66104.1670, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  824000, Reward:  2042.571 [ 180.203], Avg:  1262.635 (0.400) <0-14:38:57> ({'r_t':  2562.9147, 'eps':     0.4001, 'len': 66151.3240, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  825000, Reward:  1951.232 [ 387.211], Avg:  1263.469 (0.500) <0-14:39:55> ({'r_t':  1559.6828, 'eps':     0.5001, 'len': 66207.4280, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  826000, Reward:  1988.711 [ 176.343], Avg:  1264.346 (0.600) <0-14:40:49> ({'r_t':   233.1273, 'eps':     0.6001, 'len': 66283.1490, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  827000, Reward:  1993.318 [ 178.666], Avg:  1265.226 (0.700) <0-14:41:39> ({'r_t':  -452.3895, 'eps':     0.7001, 'len': 66376.7820, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  828000, Reward:  2035.383 [ 154.111], Avg:  1266.155 (0.800) <0-14:42:26> ({'r_t':  -891.4869, 'eps':     0.8001, 'len': 66482.9280, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  829000, Reward:  2028.821 [ 170.057], Avg:  1267.074 (0.900) <0-14:43:09> ({'r_t': -1169.2775, 'eps':     0.9001, 'len': 66589.2630, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  830000, Reward:  2061.875 [ 146.871], Avg:  1268.030 (0.000) <0-14:46:45> ({'r_t': -1255.8929, 'eps':     0.0001, 'len': 66685.3440, 'dyn_loss':    20.4548, 'dot_loss':     3.2551, 'ddot_loss':     6.8534, 'rew_loss':    12.4769, 'lr':   8.59e-05, 'eps_e':     0.0001, 'lr_e':   8.59e-05})
Step:  831000, Reward:  1876.133 [ 499.373], Avg:  1268.761 (0.100) <0-14:47:56> ({'r_t':  4170.9620, 'eps':     0.1001, 'len': 66751.2660, 'lr':   8.59e-05, 'eps_e':     0.1001, 'lr_e':   8.59e-05})
Step:  832000, Reward:  2084.557 [ 137.342], Avg:  1269.740 (0.200) <0-14:49:05> ({'r_t':  4204.8362, 'eps':     0.2001, 'len': 66785.0590, 'lr':   8.59e-05, 'eps_e':     0.2001, 'lr_e':   8.59e-05})
Step:  833000, Reward:  1889.230 [ 414.597], Avg:  1270.483 (0.300) <0-14:50:09> ({'r_t':  3543.8047, 'eps':     0.3001, 'len': 66824.4820, 'lr':   8.59e-05, 'eps_e':     0.3001, 'lr_e':   8.59e-05})
Step:  834000, Reward:  2065.063 [ 161.338], Avg:  1271.435 (0.400) <0-14:51:10> ({'r_t':  2755.5201, 'eps':     0.4001, 'len': 66869.4630, 'lr':   8.59e-05, 'eps_e':     0.4001, 'lr_e':   8.59e-05})
Step:  835000, Reward:  1807.587 [ 517.402], Avg:  1272.076 (0.500) <0-14:52:07> ({'r_t':  1492.6490, 'eps':     0.5001, 'len': 66925.5690, 'lr':   8.59e-05, 'eps_e':     0.5001, 'lr_e':   8.59e-05})
Step:  836000, Reward:  1944.034 [ 527.905], Avg:  1272.879 (0.600) <0-14:53:01> ({'r_t':   415.8815, 'eps':     0.6001, 'len': 66998.9950, 'lr':   8.59e-05, 'eps_e':     0.6001, 'lr_e':   8.59e-05})
Step:  837000, Reward:  1869.055 [ 497.229], Avg:  1273.590 (0.700) <0-14:53:51> ({'r_t':  -463.8467, 'eps':     0.7001, 'len': 67088.5990, 'lr':   8.59e-05, 'eps_e':     0.7001, 'lr_e':   8.59e-05})
Step:  838000, Reward:  1791.449 [ 582.790], Avg:  1274.208 (0.800) <0-14:54:38> ({'r_t':  -944.5832, 'eps':     0.8001, 'len': 67186.9860, 'lr':   8.59e-05, 'eps_e':     0.8001, 'lr_e':   8.59e-05})
Step:  839000, Reward:  1980.416 [ 378.671], Avg:  1275.048 (0.900) <0-14:55:22> ({'r_t': -1172.3193, 'eps':     0.9001, 'len': 67294.5100, 'lr':   8.59e-05, 'eps_e':     0.9001, 'lr_e':   8.59e-05})
Step:  840000, Reward:  2029.364 [ 145.899], Avg:  1275.945 (0.000) <0-14:58:54> ({'r_t': -1184.7617, 'eps':     0.0001, 'len': 67398.8470, 'dyn_loss':    19.9787, 'dot_loss':     3.2107, 'ddot_loss':     6.7824, 'rew_loss':    12.4071, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  841000, Reward:  2053.101 [ 172.776], Avg:  1276.868 (0.100) <0-15:00:06> ({'r_t':  4089.1958, 'eps':     0.1001, 'len': 67465.9700, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  842000, Reward:  1950.612 [ 368.358], Avg:  1277.668 (0.200) <0-15:01:14> ({'r_t':  4141.4614, 'eps':     0.2001, 'len': 67499.3100, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  843000, Reward:  1938.207 [ 386.824], Avg:  1278.450 (0.300) <0-15:02:18> ({'r_t':  3657.2711, 'eps':     0.3001, 'len': 67536.7130, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  844000, Reward:  2017.470 [ 219.858], Avg:  1279.325 (0.400) <0-15:03:20> ({'r_t':  2760.4103, 'eps':     0.4001, 'len': 67583.5820, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  845000, Reward:  2059.822 [ 148.598], Avg:  1280.247 (0.500) <0-15:04:17> ({'r_t':  1562.5789, 'eps':     0.5001, 'len': 67639.4100, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  846000, Reward:  2052.642 [ 135.734], Avg:  1281.159 (0.600) <0-15:05:11> ({'r_t':   401.7803, 'eps':     0.6001, 'len': 67718.6990, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  847000, Reward:  2024.250 [ 163.965], Avg:  1282.036 (0.700) <0-15:06:01> ({'r_t':  -490.3242, 'eps':     0.7001, 'len': 67817.7490, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  848000, Reward:  1985.806 [ 214.739], Avg:  1282.864 (0.800) <0-15:06:48> ({'r_t':  -888.1845, 'eps':     0.8001, 'len': 67924.0820, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  849000, Reward:  1998.862 [ 190.895], Avg:  1283.707 (0.900) <0-15:07:31> ({'r_t': -1123.7431, 'eps':     0.9001, 'len': 68026.9500, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  850000, Reward:  1766.349 [ 471.230], Avg:  1284.274 (0.000) <0-15:11:05> ({'r_t': -1219.9773, 'eps':     0.0001, 'len': 68126.4050, 'dyn_loss':    19.6522, 'dot_loss':     3.1694, 'ddot_loss':     6.7126, 'rew_loss':    12.2654, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  851000, Reward:  1997.436 [ 271.579], Avg:  1285.111 (0.100) <0-15:12:17> ({'r_t':  4200.4336, 'eps':     0.1001, 'len': 68191.2110, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  852000, Reward:  1973.444 [ 401.131], Avg:  1285.918 (0.200) <0-15:13:25> ({'r_t':  4206.1439, 'eps':     0.2001, 'len': 68223.6340, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  853000, Reward:  1910.010 [ 362.788], Avg:  1286.649 (0.300) <0-15:14:30> ({'r_t':  3683.5470, 'eps':     0.3001, 'len': 68262.2180, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  854000, Reward:  2080.824 [ 152.099], Avg:  1287.578 (0.400) <0-15:15:30> ({'r_t':  2693.7034, 'eps':     0.4001, 'len': 68308.1470, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  855000, Reward:  2060.429 [ 172.778], Avg:  1288.480 (0.500) <0-15:16:28> ({'r_t':  1467.8828, 'eps':     0.5001, 'len': 68362.9140, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  856000, Reward:  2068.580 [ 133.940], Avg:  1289.391 (0.600) <0-15:17:21> ({'r_t':   520.7596, 'eps':     0.6001, 'len': 68439.2580, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  857000, Reward:  2005.745 [ 244.793], Avg:  1290.226 (0.700) <0-15:18:12> ({'r_t':  -414.8854, 'eps':     0.7001, 'len': 68524.8490, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  858000, Reward:  1997.718 [ 201.005], Avg:  1291.049 (0.800) <0-15:18:59> ({'r_t':  -922.7007, 'eps':     0.8001, 'len': 68615.8390, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  859000, Reward:  2005.281 [ 277.335], Avg:  1291.880 (0.900) <0-15:19:42> ({'r_t': -1127.2325, 'eps':     0.9001, 'len': 68719.4440, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  860000, Reward:  2028.712 [ 154.261], Avg:  1292.736 (0.000) <0-15:23:16> ({'r_t': -1195.3991, 'eps':     0.0001, 'len': 68834.3660, 'dyn_loss':    19.6092, 'dot_loss':     3.1834, 'ddot_loss':     6.7479, 'rew_loss':    12.2223, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  861000, Reward:  2083.074 [ 151.525], Avg:  1293.652 (0.100) <0-15:24:28> ({'r_t':  4154.1125, 'eps':     0.1001, 'len': 68902.6320, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  862000, Reward:  2079.313 [ 125.899], Avg:  1294.563 (0.200) <0-15:25:36> ({'r_t':  4081.7028, 'eps':     0.2001, 'len': 68936.9300, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  863000, Reward:  2068.042 [ 159.047], Avg:  1295.458 (0.300) <0-15:26:41> ({'r_t':  3591.0214, 'eps':     0.3001, 'len': 68978.9960, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  864000, Reward:  2071.804 [ 146.876], Avg:  1296.356 (0.400) <0-15:27:42> ({'r_t':  2623.4624, 'eps':     0.4001, 'len': 69024.1850, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  865000, Reward:  2047.963 [ 155.002], Avg:  1297.223 (0.500) <0-15:28:39> ({'r_t':  1575.9361, 'eps':     0.5001, 'len': 69080.8380, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  866000, Reward:  1961.445 [ 370.919], Avg:  1297.990 (0.600) <0-15:29:33> ({'r_t':   377.7086, 'eps':     0.6001, 'len': 69150.7000, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  867000, Reward:  2038.200 [ 156.760], Avg:  1298.842 (0.700) <0-15:30:23> ({'r_t':  -445.9916, 'eps':     0.7001, 'len': 69231.8300, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  868000, Reward:  2074.371 [ 151.647], Avg:  1299.735 (0.800) <0-15:31:10> ({'r_t':  -927.4846, 'eps':     0.8001, 'len': 69332.0570, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  869000, Reward:  2078.857 [ 144.832], Avg:  1300.630 (0.900) <0-15:31:53> ({'r_t': -1164.3845, 'eps':     0.9001, 'len': 69436.0570, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  870000, Reward:  1953.479 [ 382.575], Avg:  1301.380 (0.000) <0-15:35:28> ({'r_t': -1227.4903, 'eps':     0.0001, 'len': 69543.5880, 'dyn_loss':    19.7656, 'dot_loss':     3.2151, 'ddot_loss':     6.8215, 'rew_loss':    12.3914, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  871000, Reward:  1835.287 [ 487.265], Avg:  1301.992 (0.100) <0-15:36:40> ({'r_t':  4137.8073, 'eps':     0.1001, 'len': 69611.3520, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  872000, Reward:  1812.324 [ 605.052], Avg:  1302.577 (0.200) <0-15:37:48> ({'r_t':  4180.6583, 'eps':     0.2001, 'len': 69644.8620, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  873000, Reward:  1968.639 [ 380.011], Avg:  1303.339 (0.300) <0-15:38:52> ({'r_t':  3602.0452, 'eps':     0.3001, 'len': 69682.3010, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  874000, Reward:  1939.511 [ 516.132], Avg:  1304.066 (0.400) <0-15:39:54> ({'r_t':  2801.6899, 'eps':     0.4001, 'len': 69727.2200, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  875000, Reward:  1921.270 [ 371.492], Avg:  1304.770 (0.500) <0-15:40:51> ({'r_t':  1616.7695, 'eps':     0.5001, 'len': 69780.8630, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  876000, Reward:  1871.334 [ 500.199], Avg:  1305.416 (0.600) <0-15:41:45> ({'r_t':   447.3220, 'eps':     0.6001, 'len': 69851.0070, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  877000, Reward:  2051.256 [ 162.957], Avg:  1306.266 (0.700) <0-15:42:35> ({'r_t':  -396.1307, 'eps':     0.7001, 'len': 69929.3450, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  878000, Reward:  1939.434 [ 366.713], Avg:  1306.986 (0.800) <0-15:43:22> ({'r_t':  -936.4619, 'eps':     0.8001, 'len': 70025.6490, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  879000, Reward:  1957.272 [ 378.507], Avg:  1307.725 (0.900) <0-15:44:05> ({'r_t': -1204.3629, 'eps':     0.9001, 'len': 70124.7000, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  880000, Reward:  2047.107 [ 139.068], Avg:  1308.564 (0.000) <0-15:47:40> ({'r_t': -1217.9893, 'eps':     0.0001, 'len': 70216.6310, 'dyn_loss':    19.8634, 'dot_loss':     3.1900, 'ddot_loss':     6.7610, 'rew_loss':    12.3487, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  881000, Reward:  2086.507 [ 141.547], Avg:  1309.447 (0.100) <0-15:48:52> ({'r_t':  4150.9012, 'eps':     0.1001, 'len': 70278.2180, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  882000, Reward:  2086.128 [ 154.336], Avg:  1310.326 (0.200) <0-15:50:00> ({'r_t':  4247.6655, 'eps':     0.2001, 'len': 70310.6730, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  883000, Reward:  2027.493 [ 221.942], Avg:  1311.137 (0.300) <0-15:51:05> ({'r_t':  3780.9264, 'eps':     0.3001, 'len': 70345.8510, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  884000, Reward:  2010.254 [ 276.677], Avg:  1311.927 (0.400) <0-15:52:06> ({'r_t':  2899.7156, 'eps':     0.4001, 'len': 70388.1280, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  885000, Reward:  2020.171 [ 261.492], Avg:  1312.727 (0.500) <0-15:53:04> ({'r_t':  1622.9654, 'eps':     0.5001, 'len': 70435.5850, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  886000, Reward:  1921.326 [ 491.974], Avg:  1313.413 (0.600) <0-15:53:57> ({'r_t':   527.6024, 'eps':     0.6001, 'len': 70506.2360, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  887000, Reward:  2003.637 [ 390.949], Avg:  1314.190 (0.700) <0-15:54:47> ({'r_t':  -414.1993, 'eps':     0.7001, 'len': 70590.0930, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  888000, Reward:  1984.217 [ 297.203], Avg:  1314.944 (0.800) <0-15:55:35> ({'r_t':  -968.9910, 'eps':     0.8001, 'len': 70676.0420, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  889000, Reward:  2063.255 [ 123.438], Avg:  1315.785 (0.900) <0-15:56:18> ({'r_t': -1114.9745, 'eps':     0.9001, 'len': 70777.8370, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  890000, Reward:  1914.351 [ 377.347], Avg:  1316.456 (0.000) <0-15:59:54> ({'r_t': -1211.6191, 'eps':     0.0001, 'len': 70884.0200, 'dyn_loss':    19.1902, 'dot_loss':     3.1232, 'ddot_loss':     6.6518, 'rew_loss':    11.9843, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  891000, Reward:  2027.681 [ 159.935], Avg:  1317.254 (0.100) <0-16:01:06> ({'r_t':  4184.0661, 'eps':     0.1001, 'len': 70952.9930, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  892000, Reward:  2052.525 [ 170.896], Avg:  1318.077 (0.200) <0-16:02:15> ({'r_t':  4106.8744, 'eps':     0.2001, 'len': 70986.9760, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  893000, Reward:  1766.366 [ 500.934], Avg:  1318.579 (0.300) <0-16:03:19> ({'r_t':  3785.3991, 'eps':     0.3001, 'len': 71021.5020, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  894000, Reward:  2019.282 [ 157.930], Avg:  1319.361 (0.400) <0-16:04:20> ({'r_t':  2921.0802, 'eps':     0.4001, 'len': 71060.6120, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  895000, Reward:  1953.746 [ 379.227], Avg:  1320.069 (0.500) <0-16:05:17> ({'r_t':  1741.4424, 'eps':     0.5001, 'len': 71109.1350, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  896000, Reward:  2016.353 [ 171.599], Avg:  1320.846 (0.600) <0-16:06:11> ({'r_t':   404.2902, 'eps':     0.6001, 'len': 71180.7700, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  897000, Reward:  1918.397 [ 362.485], Avg:  1321.511 (0.700) <0-16:07:02> ({'r_t':  -511.8763, 'eps':     0.7001, 'len': 71274.1540, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  898000, Reward:  1969.916 [ 393.706], Avg:  1322.232 (0.800) <0-16:07:49> ({'r_t':  -948.6995, 'eps':     0.8001, 'len': 71372.7050, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  899000, Reward:  2035.496 [ 114.347], Avg:  1323.025 (0.900) <0-16:08:32> ({'r_t': -1164.1963, 'eps':     0.9001, 'len': 71484.9880, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  900000, Reward:  2078.412 [ 147.651], Avg:  1323.863 (0.000) <0-16:12:10> ({'r_t': -1249.6705, 'eps':     0.0001, 'len': 71591.2480, 'dyn_loss':    19.2519, 'dot_loss':     3.1382, 'ddot_loss':     6.6637, 'rew_loss':    12.2124, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  901000, Reward:  2090.386 [ 170.850], Avg:  1324.713 (0.100) <0-16:13:22> ({'r_t':  4170.3810, 'eps':     0.1001, 'len': 71654.3380, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  902000, Reward:  2081.093 [ 150.054], Avg:  1325.551 (0.200) <0-16:14:30> ({'r_t':  4250.6564, 'eps':     0.2001, 'len': 71686.9910, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  903000, Reward:  1983.108 [ 432.179], Avg:  1326.278 (0.300) <0-16:15:35> ({'r_t':  3689.1651, 'eps':     0.3001, 'len': 71724.6590, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  904000, Reward:  2086.618 [ 136.832], Avg:  1327.118 (0.400) <0-16:16:36> ({'r_t':  2940.3175, 'eps':     0.4001, 'len': 71766.2140, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  905000, Reward:  2092.569 [ 167.411], Avg:  1327.963 (0.500) <0-16:17:33> ({'r_t':  1500.1099, 'eps':     0.5001, 'len': 71817.4820, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  906000, Reward:  2095.168 [ 144.224], Avg:  1328.809 (0.600) <0-16:18:27> ({'r_t':   426.3339, 'eps':     0.6001, 'len': 71892.7000, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  907000, Reward:  2092.098 [ 145.395], Avg:  1329.650 (0.700) <0-16:19:18> ({'r_t':  -470.2251, 'eps':     0.7001, 'len': 71985.0360, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  908000, Reward:  1975.147 [ 373.389], Avg:  1330.360 (0.800) <0-16:20:05> ({'r_t': -1011.2164, 'eps':     0.8001, 'len': 72082.9520, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  909000, Reward:  2057.718 [ 136.720], Avg:  1331.159 (0.900) <0-16:20:48> ({'r_t': -1095.4885, 'eps':     0.9001, 'len': 72186.3220, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  910000, Reward:  2039.666 [ 174.721], Avg:  1331.937 (0.000) <0-16:24:22> ({'r_t': -1238.4054, 'eps':     0.0001, 'len': 72291.3320, 'dyn_loss':    19.2502, 'dot_loss':     3.1692, 'ddot_loss':     6.7299, 'rew_loss':    12.1596, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  911000, Reward:  2069.479 [ 129.795], Avg:  1332.745 (0.100) <0-16:25:34> ({'r_t':  4227.6492, 'eps':     0.1001, 'len': 72360.6980, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  912000, Reward:  1882.322 [ 540.058], Avg:  1333.347 (0.200) <0-16:26:42> ({'r_t':  4148.6667, 'eps':     0.2001, 'len': 72394.6060, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  913000, Reward:  1961.100 [ 425.315], Avg:  1334.034 (0.300) <0-16:27:47> ({'r_t':  3671.8836, 'eps':     0.3001, 'len': 72432.4560, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  914000, Reward:  2082.392 [ 126.008], Avg:  1334.852 (0.400) <0-16:28:48> ({'r_t':  2815.2143, 'eps':     0.4001, 'len': 72479.4840, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  915000, Reward:  2040.472 [ 198.435], Avg:  1335.622 (0.500) <0-16:29:46> ({'r_t':  1508.8590, 'eps':     0.5001, 'len': 72533.1560, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  916000, Reward:  1999.955 [ 218.080], Avg:  1336.347 (0.600) <0-16:30:39> ({'r_t':   448.0261, 'eps':     0.6001, 'len': 72601.7220, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  917000, Reward:  1983.807 [ 380.422], Avg:  1337.052 (0.700) <0-16:31:30> ({'r_t':  -527.9439, 'eps':     0.7001, 'len': 72689.6730, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  918000, Reward:  2022.600 [ 195.416], Avg:  1337.798 (0.800) <0-16:32:17> ({'r_t':  -906.7870, 'eps':     0.8001, 'len': 72788.0110, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  919000, Reward:  1955.888 [ 415.087], Avg:  1338.470 (0.900) <0-16:33:00> ({'r_t': -1191.2009, 'eps':     0.9001, 'len': 72884.8910, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  920000, Reward:  2010.200 [ 186.668], Avg:  1339.199 (0.000) <0-16:36:38> ({'r_t': -1225.5461, 'eps':     0.0001, 'len': 72986.6180, 'dyn_loss':    19.2649, 'dot_loss':     3.1548, 'ddot_loss':     6.7084, 'rew_loss':    12.1353, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  921000, Reward:  2090.188 [ 144.349], Avg:  1340.014 (0.100) <0-16:37:49> ({'r_t':  4147.8194, 'eps':     0.1001, 'len': 73054.7050, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  922000, Reward:  2073.285 [ 163.590], Avg:  1340.808 (0.200) <0-16:38:58> ({'r_t':  4135.9444, 'eps':     0.2001, 'len': 73087.9360, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  923000, Reward:  2050.648 [ 138.896], Avg:  1341.577 (0.300) <0-16:40:02> ({'r_t':  3578.1474, 'eps':     0.3001, 'len': 73126.9930, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  924000, Reward:  2071.729 [ 136.076], Avg:  1342.366 (0.400) <0-16:41:03> ({'r_t':  2694.0145, 'eps':     0.4001, 'len': 73173.1150, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  925000, Reward:  1969.161 [ 382.102], Avg:  1343.043 (0.500) <0-16:42:01> ({'r_t':  1708.7255, 'eps':     0.5001, 'len': 73228.4450, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  926000, Reward:  2083.896 [ 132.012], Avg:  1343.842 (0.600) <0-16:42:55> ({'r_t':   389.1575, 'eps':     0.6001, 'len': 73295.2930, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  927000, Reward:  1984.145 [ 371.265], Avg:  1344.532 (0.700) <0-16:43:45> ({'r_t':  -363.8962, 'eps':     0.7001, 'len': 73381.3490, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  928000, Reward:  1858.555 [ 490.783], Avg:  1345.085 (0.800) <0-16:44:32> ({'r_t':  -993.3278, 'eps':     0.8001, 'len': 73476.5000, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  929000, Reward:  1950.041 [ 371.017], Avg:  1345.736 (0.900) <0-16:45:15> ({'r_t': -1142.8916, 'eps':     0.9001, 'len': 73579.3860, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  930000, Reward:  1974.003 [ 176.603], Avg:  1346.411 (0.000) <0-16:48:50> ({'r_t': -1232.8220, 'eps':     0.0001, 'len': 73675.6950, 'dyn_loss':    19.0866, 'dot_loss':     3.1256, 'ddot_loss':     6.6490, 'rew_loss':    12.1635, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  931000, Reward:  2092.965 [ 133.968], Avg:  1347.212 (0.100) <0-16:50:02> ({'r_t':  4196.5860, 'eps':     0.1001, 'len': 73738.5760, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  932000, Reward:  2077.389 [ 123.409], Avg:  1347.994 (0.200) <0-16:51:10> ({'r_t':  4263.8494, 'eps':     0.2001, 'len': 73770.9400, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  933000, Reward:  2073.892 [ 151.432], Avg:  1348.771 (0.300) <0-16:52:15> ({'r_t':  3590.9450, 'eps':     0.3001, 'len': 73807.3660, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  934000, Reward:  1903.596 [ 425.809], Avg:  1349.365 (0.400) <0-16:53:16> ({'r_t':  2885.3580, 'eps':     0.4001, 'len': 73848.7230, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  935000, Reward:  2050.819 [ 201.744], Avg:  1350.114 (0.500) <0-16:54:14> ({'r_t':  1778.6420, 'eps':     0.5001, 'len': 73901.0330, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  936000, Reward:  2086.786 [ 145.868], Avg:  1350.900 (0.600) <0-16:55:08> ({'r_t':   426.9650, 'eps':     0.6001, 'len': 73976.5050, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  937000, Reward:  2010.537 [ 266.561], Avg:  1351.604 (0.700) <0-16:55:58> ({'r_t':  -411.3832, 'eps':     0.7001, 'len': 74058.3670, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  938000, Reward:  1995.491 [ 264.999], Avg:  1352.289 (0.800) <0-16:56:45> ({'r_t':  -975.9512, 'eps':     0.8001, 'len': 74155.2500, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  939000, Reward:  1924.126 [ 510.315], Avg:  1352.898 (0.900) <0-16:57:28> ({'r_t': -1159.6003, 'eps':     0.9001, 'len': 74252.9410, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  940000, Reward:  2022.239 [ 177.562], Avg:  1353.609 (0.000) <0-17:01:05> ({'r_t': -1223.5595, 'eps':     0.0001, 'len': 74350.0450, 'dyn_loss':    18.8385, 'dot_loss':     3.1056, 'ddot_loss':     6.6248, 'rew_loss':    12.0042, 'lr':   8.33e-05, 'eps_e':     0.0001, 'lr_e':   8.33e-05})
Step:  941000, Reward:  1953.362 [ 372.955], Avg:  1354.246 (0.100) <0-17:02:17> ({'r_t':  4189.3854, 'eps':     0.1001, 'len': 74414.5610, 'lr':   8.33e-05, 'eps_e':     0.1001, 'lr_e':   8.33e-05})
Step:  942000, Reward:  2055.159 [ 145.760], Avg:  1354.989 (0.200) <0-17:03:25> ({'r_t':  4117.9162, 'eps':     0.2001, 'len': 74448.3550, 'lr':   8.33e-05, 'eps_e':     0.2001, 'lr_e':   8.33e-05})
Step:  943000, Reward:  1962.704 [ 422.406], Avg:  1355.633 (0.300) <0-17:04:30> ({'r_t':  3698.6090, 'eps':     0.3001, 'len': 74485.9690, 'lr':   8.33e-05, 'eps_e':     0.3001, 'lr_e':   8.33e-05})
Step:  944000, Reward:  1964.270 [ 375.644], Avg:  1356.277 (0.400) <0-17:05:31> ({'r_t':  2732.9986, 'eps':     0.4001, 'len': 74527.7440, 'lr':   8.33e-05, 'eps_e':     0.4001, 'lr_e':   8.33e-05})
Step:  945000, Reward:  2074.890 [ 154.489], Avg:  1357.036 (0.500) <0-17:06:28> ({'r_t':  1655.7529, 'eps':     0.5001, 'len': 74578.6810, 'lr':   8.33e-05, 'eps_e':     0.5001, 'lr_e':   8.33e-05})
Step:  946000, Reward:  1993.588 [ 245.256], Avg:  1357.709 (0.600) <0-17:07:22> ({'r_t':   283.3583, 'eps':     0.6001, 'len': 74647.6290, 'lr':   8.33e-05, 'eps_e':     0.6001, 'lr_e':   8.33e-05})
Step:  947000, Reward:  1997.927 [ 250.122], Avg:  1358.384 (0.700) <0-17:08:13> ({'r_t':  -445.4099, 'eps':     0.7001, 'len': 74735.2060, 'lr':   8.33e-05, 'eps_e':     0.7001, 'lr_e':   8.33e-05})
Step:  948000, Reward:  1968.188 [ 385.650], Avg:  1359.027 (0.800) <0-17:09:00> ({'r_t':  -873.4628, 'eps':     0.8001, 'len': 74833.6700, 'lr':   8.33e-05, 'eps_e':     0.8001, 'lr_e':   8.33e-05})
Step:  949000, Reward:  1922.699 [ 359.258], Avg:  1359.620 (0.900) <0-17:09:43> ({'r_t': -1107.7912, 'eps':     0.9001, 'len': 74935.7460, 'lr':   8.33e-05, 'eps_e':     0.9001, 'lr_e':   8.33e-05})
Step:  950000, Reward:  2087.196 [ 163.030], Avg:  1360.385 (0.000) <0-17:13:21> ({'r_t': -1201.5135, 'eps':     0.0001, 'len': 75040.8750, 'dyn_loss':    19.7540, 'dot_loss':     3.1997, 'ddot_loss':     6.7858, 'rew_loss':    12.2758, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
Step:  951000, Reward:  2113.895 [ 166.524], Avg:  1361.176 (0.100) <0-17:14:33> ({'r_t':  4239.3797, 'eps':     0.1001, 'len': 75107.0800, 'lr':   8.08e-05, 'eps_e':     0.1001, 'lr_e':   8.08e-05})
Step:  952000, Reward:  2112.754 [ 145.917], Avg:  1361.965 (0.200) <0-17:15:41> ({'r_t':  4199.0275, 'eps':     0.2001, 'len': 75139.6800, 'lr':   8.08e-05, 'eps_e':     0.2001, 'lr_e':   8.08e-05})
Step:  953000, Reward:  2080.834 [ 135.431], Avg:  1362.719 (0.300) <0-17:16:46> ({'r_t':  3768.5988, 'eps':     0.3001, 'len': 75175.7300, 'lr':   8.08e-05, 'eps_e':     0.3001, 'lr_e':   8.08e-05})
Step:  954000, Reward:  2054.372 [ 165.929], Avg:  1363.443 (0.400) <0-17:17:47> ({'r_t':  2838.8584, 'eps':     0.4001, 'len': 75214.8610, 'lr':   8.08e-05, 'eps_e':     0.4001, 'lr_e':   8.08e-05})
Step:  955000, Reward:  2079.315 [ 149.349], Avg:  1364.192 (0.500) <0-17:18:45> ({'r_t':  1728.2541, 'eps':     0.5001, 'len': 75267.4340, 'lr':   8.08e-05, 'eps_e':     0.5001, 'lr_e':   8.08e-05})
Step:  956000, Reward:  2080.747 [ 154.342], Avg:  1364.940 (0.600) <0-17:19:38> ({'r_t':   478.0363, 'eps':     0.6001, 'len': 75334.0990, 'lr':   8.08e-05, 'eps_e':     0.6001, 'lr_e':   8.08e-05})
Step:  957000, Reward:  1865.252 [ 505.820], Avg:  1365.463 (0.700) <0-17:20:28> ({'r_t':  -389.8436, 'eps':     0.7001, 'len': 75422.3520, 'lr':   8.08e-05, 'eps_e':     0.7001, 'lr_e':   8.08e-05})
Step:  958000, Reward:  2075.229 [ 138.494], Avg:  1366.203 (0.800) <0-17:21:16> ({'r_t':  -856.1624, 'eps':     0.8001, 'len': 75524.4940, 'lr':   8.08e-05, 'eps_e':     0.8001, 'lr_e':   8.08e-05})
Step:  959000, Reward:  2084.348 [ 125.885], Avg:  1366.951 (0.900) <0-17:21:59> ({'r_t': -1138.8573, 'eps':     0.9001, 'len': 75626.6130, 'lr':   8.08e-05, 'eps_e':     0.9001, 'lr_e':   8.08e-05})
Step:  960000, Reward:  1997.172 [ 262.235], Avg:  1367.607 (0.000) <0-17:25:37> ({'r_t': -1145.4165, 'eps':     0.0001, 'len': 75732.4440, 'dyn_loss':    18.9963, 'dot_loss':     3.1096, 'ddot_loss':     6.6349, 'rew_loss':    12.0835, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
Step:  961000, Reward:  1978.522 [ 386.204], Avg:  1368.242 (0.100) <0-17:26:49> ({'r_t':  4112.0423, 'eps':     0.1001, 'len': 75799.6840, 'lr':   8.08e-05, 'eps_e':     0.1001, 'lr_e':   8.08e-05})
Step:  962000, Reward:  2077.340 [ 165.148], Avg:  1368.978 (0.200) <0-17:27:58> ({'r_t':  3974.5603, 'eps':     0.2001, 'len': 75833.2040, 'lr':   8.08e-05, 'eps_e':     0.2001, 'lr_e':   8.08e-05})
Step:  963000, Reward:  2017.205 [ 168.861], Avg:  1369.650 (0.300) <0-17:29:02> ({'r_t':  3709.4490, 'eps':     0.3001, 'len': 75870.6200, 'lr':   8.08e-05, 'eps_e':     0.3001, 'lr_e':   8.08e-05})
Step:  964000, Reward:  1950.023 [ 374.657], Avg:  1370.252 (0.400) <0-17:30:03> ({'r_t':  2790.9672, 'eps':     0.4001, 'len': 75912.8460, 'lr':   8.08e-05, 'eps_e':     0.4001, 'lr_e':   8.08e-05})
Step:  965000, Reward:  2038.768 [ 212.752], Avg:  1370.944 (0.500) <0-17:31:01> ({'r_t':  1538.7970, 'eps':     0.5001, 'len': 75967.3420, 'lr':   8.08e-05, 'eps_e':     0.5001, 'lr_e':   8.08e-05})
Step:  966000, Reward:  2029.639 [ 187.134], Avg:  1371.625 (0.600) <0-17:31:54> ({'r_t':   457.6312, 'eps':     0.6001, 'len': 76044.4950, 'lr':   8.08e-05, 'eps_e':     0.6001, 'lr_e':   8.08e-05})
Step:  967000, Reward:  2031.282 [ 176.417], Avg:  1372.307 (0.700) <0-17:32:45> ({'r_t':  -383.6227, 'eps':     0.7001, 'len': 76133.1020, 'lr':   8.08e-05, 'eps_e':     0.7001, 'lr_e':   8.08e-05})
Step:  968000, Reward:  1953.983 [ 378.591], Avg:  1372.907 (0.800) <0-17:33:32> ({'r_t':  -878.9770, 'eps':     0.8001, 'len': 76228.1360, 'lr':   8.08e-05, 'eps_e':     0.8001, 'lr_e':   8.08e-05})
Step:  969000, Reward:  1957.502 [ 381.383], Avg:  1373.510 (0.900) <0-17:34:15> ({'r_t': -1182.7067, 'eps':     0.9001, 'len': 76336.5910, 'lr':   8.08e-05, 'eps_e':     0.9001, 'lr_e':   8.08e-05})
Step:  970000, Reward:  1991.426 [ 150.230], Avg:  1374.146 (0.000) <0-17:37:52> ({'r_t': -1236.0650, 'eps':     0.0001, 'len': 76444.2760, 'dyn_loss':    19.1106, 'dot_loss':     3.1509, 'ddot_loss':     6.7367, 'rew_loss':    12.1542, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
Step:  971000, Reward:  2031.621 [ 205.389], Avg:  1374.822 (0.100) <0-17:39:04> ({'r_t':  4145.0730, 'eps':     0.1001, 'len': 76507.6380, 'lr':   8.08e-05, 'eps_e':     0.1001, 'lr_e':   8.08e-05})
Step:  972000, Reward:  1990.832 [ 387.066], Avg:  1375.455 (0.200) <0-17:40:12> ({'r_t':  4096.9895, 'eps':     0.2001, 'len': 76541.5000, 'lr':   8.08e-05, 'eps_e':     0.2001, 'lr_e':   8.08e-05})
Step:  973000, Reward:  2044.544 [ 159.994], Avg:  1376.142 (0.300) <0-17:41:17> ({'r_t':  3714.0101, 'eps':     0.3001, 'len': 76577.2840, 'lr':   8.08e-05, 'eps_e':     0.3001, 'lr_e':   8.08e-05})
Step:  974000, Reward:  2049.636 [ 144.603], Avg:  1376.833 (0.400) <0-17:42:18> ({'r_t':  2929.0896, 'eps':     0.4001, 'len': 76620.0640, 'lr':   8.08e-05, 'eps_e':     0.4001, 'lr_e':   8.08e-05})
Step:  975000, Reward:  2026.978 [ 152.304], Avg:  1377.499 (0.500) <0-17:43:15> ({'r_t':  1600.5604, 'eps':     0.5001, 'len': 76673.1740, 'lr':   8.08e-05, 'eps_e':     0.5001, 'lr_e':   8.08e-05})
Step:  976000, Reward:  1861.662 [ 351.818], Avg:  1377.995 (0.600) <0-17:44:09> ({'r_t':   567.2804, 'eps':     0.6001, 'len': 76740.9510, 'lr':   8.08e-05, 'eps_e':     0.6001, 'lr_e':   8.08e-05})
Step:  977000, Reward:  1912.796 [ 378.920], Avg:  1378.542 (0.700) <0-17:44:59> ({'r_t':  -360.0801, 'eps':     0.7001, 'len': 76822.8530, 'lr':   8.08e-05, 'eps_e':     0.7001, 'lr_e':   8.08e-05})
Step:  978000, Reward:  2015.825 [ 160.562], Avg:  1379.193 (0.800) <0-17:45:46> ({'r_t':  -942.9705, 'eps':     0.8001, 'len': 76920.5190, 'lr':   8.08e-05, 'eps_e':     0.8001, 'lr_e':   8.08e-05})
Step:  979000, Reward:  1874.208 [ 413.277], Avg:  1379.698 (0.900) <0-17:46:30> ({'r_t': -1139.0701, 'eps':     0.9001, 'len': 77026.6590, 'lr':   8.08e-05, 'eps_e':     0.9001, 'lr_e':   8.08e-05})
Step:  980000, Reward:  2077.183 [ 132.471], Avg:  1380.409 (0.000) <0-17:50:10> ({'r_t': -1205.2288, 'eps':     0.0001, 'len': 77132.0440, 'dyn_loss':    19.3337, 'dot_loss':     3.1335, 'ddot_loss':     6.6844, 'rew_loss':    12.1698, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
Step:  981000, Reward:  2033.756 [ 146.415], Avg:  1381.074 (0.100) <0-17:51:21> ({'r_t':  4257.7383, 'eps':     0.1001, 'len': 77200.8790, 'lr':   8.08e-05, 'eps_e':     0.1001, 'lr_e':   8.08e-05})
Step:  982000, Reward:  2069.528 [ 151.788], Avg:  1381.774 (0.200) <0-17:52:30> ({'r_t':  4191.0869, 'eps':     0.2001, 'len': 77233.9970, 'lr':   8.08e-05, 'eps_e':     0.2001, 'lr_e':   8.08e-05})
Step:  983000, Reward:  2005.479 [ 186.392], Avg:  1382.408 (0.300) <0-17:53:34> ({'r_t':  3744.1744, 'eps':     0.3001, 'len': 77271.8500, 'lr':   8.08e-05, 'eps_e':     0.3001, 'lr_e':   8.08e-05})
Step:  984000, Reward:  2051.993 [ 158.811], Avg:  1383.088 (0.400) <0-17:54:35> ({'r_t':  2870.8240, 'eps':     0.4001, 'len': 77314.0050, 'lr':   8.08e-05, 'eps_e':     0.4001, 'lr_e':   8.08e-05})
Step:  985000, Reward:  2069.873 [ 139.277], Avg:  1383.785 (0.500) <0-17:55:33> ({'r_t':  1458.1883, 'eps':     0.5001, 'len': 77369.7510, 'lr':   8.08e-05, 'eps_e':     0.5001, 'lr_e':   8.08e-05})
Step:  986000, Reward:  1934.134 [ 408.798], Avg:  1384.342 (0.600) <0-17:56:27> ({'r_t':   477.2102, 'eps':     0.6001, 'len': 77440.5260, 'lr':   8.08e-05, 'eps_e':     0.6001, 'lr_e':   8.08e-05})
Step:  987000, Reward:  2066.965 [ 135.685], Avg:  1385.033 (0.700) <0-17:57:17> ({'r_t':  -509.3583, 'eps':     0.7001, 'len': 77527.4710, 'lr':   8.08e-05, 'eps_e':     0.7001, 'lr_e':   8.08e-05})
Step:  988000, Reward:  2036.567 [ 121.010], Avg:  1385.692 (0.800) <0-17:58:04> ({'r_t':  -947.1945, 'eps':     0.8001, 'len': 77626.3530, 'lr':   8.08e-05, 'eps_e':     0.8001, 'lr_e':   8.08e-05})
Step:  989000, Reward:  2008.753 [ 193.326], Avg:  1386.321 (0.900) <0-17:58:47> ({'r_t': -1164.1799, 'eps':     0.9001, 'len': 77729.5230, 'lr':   8.08e-05, 'eps_e':     0.9001, 'lr_e':   8.08e-05})
Step:  990000, Reward:  2053.488 [ 135.632], Avg:  1386.994 (0.000) <0-18:02:24> ({'r_t': -1245.7015, 'eps':     0.0001, 'len': 77829.6270, 'dyn_loss':    19.0544, 'dot_loss':     3.1328, 'ddot_loss':     6.6812, 'rew_loss':    12.0997, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
Step:  991000, Reward:  2074.797 [ 123.485], Avg:  1387.688 (0.100) <0-18:03:36> ({'r_t':  4203.1528, 'eps':     0.1001, 'len': 77894.1340, 'lr':   8.08e-05, 'eps_e':     0.1001, 'lr_e':   8.08e-05})
Step:  992000, Reward:  1969.639 [ 365.882], Avg:  1388.274 (0.200) <0-18:04:44> ({'r_t':  4254.7964, 'eps':     0.2001, 'len': 77927.9290, 'lr':   8.08e-05, 'eps_e':     0.2001, 'lr_e':   8.08e-05})
Step:  993000, Reward:  2076.796 [ 145.739], Avg:  1388.967 (0.300) <0-18:05:49> ({'r_t':  3905.2285, 'eps':     0.3001, 'len': 77963.5260, 'lr':   8.08e-05, 'eps_e':     0.3001, 'lr_e':   8.08e-05})
Step:  994000, Reward:  2073.052 [ 149.533], Avg:  1389.654 (0.400) <0-18:06:50> ({'r_t':  2828.5891, 'eps':     0.4001, 'len': 78002.9880, 'lr':   8.08e-05, 'eps_e':     0.4001, 'lr_e':   8.08e-05})
Step:  995000, Reward:  2069.031 [ 130.263], Avg:  1390.336 (0.500) <0-18:07:48> ({'r_t':  1544.6603, 'eps':     0.5001, 'len': 78058.2030, 'lr':   8.08e-05, 'eps_e':     0.5001, 'lr_e':   8.08e-05})
Step:  996000, Reward:  2074.176 [ 144.210], Avg:  1391.022 (0.600) <0-18:08:41> ({'r_t':   376.5499, 'eps':     0.6001, 'len': 78127.4340, 'lr':   8.08e-05, 'eps_e':     0.6001, 'lr_e':   8.08e-05})
Step:  997000, Reward:  1903.618 [ 505.403], Avg:  1391.536 (0.700) <0-18:09:32> ({'r_t':  -413.9826, 'eps':     0.7001, 'len': 78218.2910, 'lr':   8.08e-05, 'eps_e':     0.7001, 'lr_e':   8.08e-05})
Step:  998000, Reward:  2028.783 [ 142.054], Avg:  1392.174 (0.800) <0-18:10:19> ({'r_t':  -911.8469, 'eps':     0.8001, 'len': 78315.7850, 'lr':   8.08e-05, 'eps_e':     0.8001, 'lr_e':   8.08e-05})
Step:  999000, Reward:  2036.467 [ 179.270], Avg:  1392.818 (0.900) <0-18:11:02> ({'r_t': -1159.6773, 'eps':     0.9001, 'len': 78420.0630, 'lr':   8.08e-05, 'eps_e':     0.9001, 'lr_e':   8.08e-05})
Step: 1000000, Reward:  1976.529 [ 368.646], Avg:  1393.401 (0.000) <0-18:14:41> ({'r_t': -1261.9852, 'eps':     0.0001, 'len': 78525.3850, 'dyn_loss':    19.2576, 'dot_loss':     3.1615, 'ddot_loss':     6.7442, 'rew_loss':    12.1743, 'lr':   8.08e-05, 'eps_e':     0.0001, 'lr_e':   8.08e-05})
