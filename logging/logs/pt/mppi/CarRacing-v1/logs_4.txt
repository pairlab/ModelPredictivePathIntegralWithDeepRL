Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CarRacing-v1, Date: 03/06/2020 22:41:05
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 6b45e60fd9407cf6551acce4378c896d71efc5c8
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.99
   NUM_STEPS = 40
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 5000
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 250
   DYN_EPOCHS = 10
   TRAIN_EVERY = 1000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 40
      LAMBDA = 0.1
      COV = 0.5
   REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
   DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
   dynamics_size = 13
   state_size = (80,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 1000000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.5
      PATIENCE = 5
      LEARN_RATE = 0.001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 0.1
      BETA_DOT = 1
      BETA_DDOT = 1,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f2d96419e90> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f2d9f9f2c10>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f2d9637f320>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f2d9c08dc10> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f2d96375bd0> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost
							# reward = progress + np.tanh(vy/self.vtarget) - cost
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_size = 13
			obs = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  2.000e-02  3.657e-01  4.017e-01  4.572e-01  5.260e-01  6.036e-01  2.700e-01  3.171e-01  3.850e-01  4.646e-01  5.509e-01  1.792e-01  2.444e-01  3.277e-01  4.184e-01  5.125e-01  1.063e-01  1.973e-01  2.942e-01  3.927e-01  4.918e-01  1.024e-01  1.953e-01  2.929e-01  3.917e-01  4.910e-01]
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 		return state
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.spec = next_spec
			
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f2e14e077a0>
					step = <function CarRacing.step at 0x7f2e14e07170>
					render = <function CarRacing.render at 0x7f2e3bfbd290>
					dynamics_spec = <staticmethod object at 0x7f2e14e0ce50>
					track_spec = <function CarRacing.track_spec at 0x7f2e3bfbd3b0>
					observation = <function CarRacing.observation at 0x7f2e3bfbd440>
					dynamics_keys = <staticmethod object at 0x7f2e14e0cd50>
					observation_spec = <staticmethod object at 0x7f2e14e0cd90>
					close = <function CarRacing.close at 0x7f2e3bfbd5f0>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(80,) 
			dtype = float32
			shape = (80,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f2d96375510> 
			observation_space = Box(80,) 
				dtype = float32
				shape = (80,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (80,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f2d96375b90> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=202, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 32872), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=203, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48434), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=204, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33634), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=205, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50606), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=206, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 32950), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=207, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 37564), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=208, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 37766), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=209, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56318), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=210, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49032), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=211, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56200), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=212, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 60614), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=213, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 35338), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=214, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58836), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=215, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45076), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=216, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 43288), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=217, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58158), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f2d96375910> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f2d963699d0> 
		state_size = (80,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7f2d96369a50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f2d963241d0> 
			size = (3,)
			dt = 0.2
			action = [ 1.000 -0.240  1.000]
			daction_dt = [-0.078 -0.745 -0.112]
		discrete = False
		action_size = (3,)
		state_size = (80,)
		config = <src.utils.config.Config object at 0x7f2d9c1b6a50> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.99
			NUM_STEPS = 40
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 5000
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 250
			DYN_EPOCHS = 10
			TRAIN_EVERY = 1000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7f2e3bf57d90> 
				NSAMPLES = 100
				HORIZON = 40
				LAMBDA = 0.1
				COV = 0.5
			REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
			DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
			dynamics_size = 13
			state_size = (80,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 1000000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7f2d9c1a3250> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.5
				PATIENCE = 5
				LEARN_RATE = 0.001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 0.1
				BETA_DOT = 1
				BETA_DDOT = 1
		stats = <src.utils.logger.Stats object at 0x7f2d96324150> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7f2d96324250> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f2d9c1b6a50> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.99
				NUM_STEPS = 40
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 5000
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 250
				DYN_EPOCHS = 10
				TRAIN_EVERY = 1000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7f2e3bf57d90> 
					NSAMPLES = 100
					HORIZON = 40
					LAMBDA = 0.1
					COV = 0.5
				REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
				DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
				dynamics_size = 13
				state_size = (80,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 1000000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7f2d9c1a3250> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.5
					PATIENCE = 5
					LEARN_RATE = 0.001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 0.1
					BETA_DOT = 1
					BETA_DDOT = 1
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7f2d96324310> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=29, out_features=256, bias=True)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (linear3): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(29, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (state_ddot): Linear(in_features=512, out_features=13, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7f2d9c027bd0> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7f2d9c1b6a50> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.99
						NUM_STEPS = 40
						MAX_BUFFER_SIZE = 1000000
						REPLAY_BATCH_SIZE = 5000
						TARGET_UPDATE_RATE = 0.0004
						BATCH_SIZE = 250
						DYN_EPOCHS = 10
						TRAIN_EVERY = 1000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7f2e3bf57d90> 
							NSAMPLES = 100
							HORIZON = 40
							LAMBDA = 0.1
							COV = 0.5
						REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
						DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
						dynamics_size = 13
						state_size = (80,)
						action_size = (3,)
						env_name = CarRacing-v1
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 1000000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7f2d9c1a3250> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.5
							PATIENCE = 5
							LEARN_RATE = 0.001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 0.1
							BETA_DOT = 1
							BETA_DDOT = 1
					device = cuda
					state_size = (80,)
					action_size = (3,)
					discrete = False
					dyn_index = 13
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f2d963245d0>
				state_size = (80,)
				action_size = (3,)
			mu = [ 0.000  0.000  0.000]
			cov = [[ 0.500  0.000  0.000]
			 [ 0.000  0.500  0.000]
			 [ 0.000  0.000  0.500]]
			icov = [[ 2.000  0.000  0.000]
			 [ 0.000  2.000  0.000]
			 [ 0.000  0.000  2.000]]
			lamda = 0.1
			horizon = 40
			nsamples = 100
			action_size = (3,)
			control = [[[-0.547 -0.716  0.319]
			  [-0.469 -0.640  0.953]
			  [ 0.152 -0.901  0.525]
			  [-0.592 -0.597  0.190]
			  [-0.589  0.581  0.571]
			  [-0.924 -0.757  0.673]
			  [ 0.879  0.540  0.372]
			  [ 0.002 -0.919  0.130]
			  [-0.327 -0.851  0.044]
			  [ 0.011 -0.988  0.432]
			  [-0.546  0.789 -0.292]
			  [-0.124 -0.400  0.156]
			  [ 0.983  0.278  0.581]
			  [ 0.862  0.682  0.410]
			  [ 0.832 -0.349  0.226]
			  [-0.204 -0.865  0.315]
			  [-0.688  0.935 -0.727]
			  [-0.955 -0.079 -0.985]
			  [ 0.356 -0.813  0.998]
			  [-0.639  0.388 -0.117]
			  [-0.159  0.947  0.592]
			  [ 0.983 -0.068 -0.983]
			  [-0.463 -0.753 -0.078]
			  [-0.755 -0.365  0.036]
			  [ 0.229  0.153 -0.558]
			  [ 0.102 -0.960 -0.320]
			  [ 0.603  0.536  0.482]
			  [ 0.678  0.313  0.596]
			  [ 0.513 -0.168  0.812]
			  [-0.816 -0.985 -0.827]
			  [ 0.489  0.090 -0.065]
			  [-0.594 -0.506 -0.258]
			  [ 0.122 -0.633  0.364]
			  [-0.566 -0.794 -0.617]
			  [-0.389  0.098  0.403]
			  [ 0.321  0.413  0.215]
			  [-0.409 -0.848  0.620]
			  [-0.558 -0.349 -0.036]
			  [ 0.798 -0.377  0.945]
			  [ 0.775 -0.976 -0.957]]]
			noise = [[[[-0.583  0.434 -0.750]
			   [ 0.858  0.853  0.096]
			   [-0.093 -0.899  0.054]
			   ...
			   [-0.118  0.209 -0.144]
			   [ 1.697  0.585 -1.308]
			   [ 0.468  0.085 -0.715]]
			
			  [[ 0.818 -0.029 -0.389]
			   [-0.191 -0.405  0.227]
			   [ 0.602  1.597  0.615]
			   ...
			   [ 0.062 -0.298  0.375]
			   [-0.495 -0.588 -0.055]
			   [-0.455  0.152 -0.341]]
			
			  [[ 0.621  2.229  0.835]
			   [ 0.757  0.099  0.611]
			   [ 0.828  0.125 -1.352]
			   ...
			   [ 0.049  0.737  0.998]
			   [-0.840  0.847  0.461]
			   [-0.094  0.464 -0.230]]
			
			  ...
			
			  [[ 0.624 -0.830 -0.055]
			   [-1.449 -0.232  1.855]
			   [-0.766  1.588 -0.772]
			   ...
			   [ 0.641 -0.339 -0.087]
			   [-0.360  0.306  0.160]
			   [ 0.491  0.502  0.021]]
			
			  [[ 0.937  0.829  0.006]
			   [-0.453  0.520 -1.553]
			   [ 0.147  0.324  1.134]
			   ...
			   [ 0.644  0.365  0.608]
			   [-0.663  0.843 -1.441]
			   [ 0.335  0.138 -0.961]]
			
			  [[-0.220  0.087 -0.575]
			   [-0.343  1.296 -1.029]
			   [-1.116 -0.577 -0.004]
			   ...
			   [ 1.680 -0.310  0.199]
			   [-0.583  0.351  0.003]
			   [ 0.418  0.288 -0.059]]]]
			init_cost = [[  4.158  -8.044  -0.889   2.048   6.178  -1.300  -9.546 -15.951   9.492  12.557 -23.947  -6.939  -7.730  10.316   1.237  -3.498   8.382   7.511  -6.469  -9.380  -3.572   8.663  -1.381   8.902  -1.831  -9.935   5.985 -15.327   8.096  -6.080 -21.372  -2.450  -6.582 -14.790  16.931  -9.232  -8.818 -17.484   5.319   5.393  -1.141   3.698  -6.508   4.795   0.885  -2.605  14.688  -6.289   5.130  -0.549  -3.489  -1.413  -1.361 -12.277  -6.284  18.140   2.758   7.838 -16.428   3.767  10.515 -10.444   5.641   3.992   0.036 -10.618  -5.237 -10.875  16.009   7.838  -4.023   2.874  -2.670  -8.760   3.943   4.195 -10.394   3.134  -4.843   1.424  -2.366   5.244   4.777   3.150   4.237 -19.303  12.723  -3.538  -5.261   3.373  -1.430   9.598   7.004  14.115  -0.374   2.621 -10.740  10.858 -16.088 -18.551]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f2d9fa7ded0> 
			buffer = deque([], maxlen=1000000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f2d96324cd0> 
		size = (3,)
		dt = 0.2
		action = [-1.000 -1.000 -0.541]
		daction_dt = [ 1.550  0.893  0.114]
	discrete = False
	action_size = (3,)
	state_size = (80,)
	config = <src.utils.config.Config object at 0x7f2d9c1b6a50> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.99
		NUM_STEPS = 40
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 5000
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 250
		DYN_EPOCHS = 10
		TRAIN_EVERY = 1000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7f2e3bf57d90> 
			NSAMPLES = 100
			HORIZON = 40
			LAMBDA = 0.1
			COV = 0.5
		REWARD_MODEL = src.envs.CarRacing.objective.cost:CostModel
		DYNAMICS_SPEC = src.envs.CarRacing.car_racing:CarRacing
		dynamics_size = 13
		state_size = (80,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 1000000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7f2d9c1a3250> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.5
			PATIENCE = 5
			LEARN_RATE = 0.001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 0.1
			BETA_DOT = 1
			BETA_DDOT = 1
	stats = <src.utils.logger.Stats object at 0x7f2d96324dd0> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.config = config
		self.action_size = action_size
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		controls = np.clip(self.control[:,None,:,:] + self.noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1) #+ self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm)
		self.control += np.sum(weights[:,:,None,None]*self.noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		action_greedy = self.network.get_action(np.array(state))
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def partition(self, x):
		num_splits = x.shape[0]//self.config.NUM_STEPS
		if num_splits == 0:
			arr = np.zeros([self.config.NUM_STEPS, *x.shape[1:]])
			arr[-x.shape[0]:] = x
			num_splits = 1
			x = arr
		arr = x[:num_splits*self.config.NUM_STEPS].reshape(num_splits, self.config.NUM_STEPS, *x.shape[1:])
		return arr

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(np.array, zip(*buffer))
			states, actions, next_states, rewards, dones = [self.partition(x) for x in (states, actions, next_states, rewards, dones)]
			buffer.clear()
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			pbar = tqdm.trange(self.config.DYN_EPOCHS*self.config.REPLAY_BATCH_SIZE//self.config.BATCH_SIZE)
			for _ in pbar:
				states, actions, next_states, rewards, dones = self.replay_buffer.sample(self.config.BATCH_SIZE, dtype=self.to_tensor)[0]
				loss = self.network.optimize(states, actions, next_states, rewards, dones)
				pbar.set_postfix_str(f"Loss: {loss:.4f}")
			self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward:  -571.153 [ 953.990], Avg:  -571.153 (1.000) <0-00:00:00> ({'r_t':    -1.1339, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    1000, Reward:  -223.538 [ 181.496], Avg:  -397.345 (1.000) <0-00:01:54> ({'r_t': -2003.0909, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    2000, Reward:  -218.169 [ 200.093], Avg:  -337.620 (1.000) <0-00:03:53> ({'r_t': -1886.1445, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    3000, Reward:  -187.532 [ 132.982], Avg:  -300.098 (1.000) <0-00:05:49> ({'r_t': -2640.7745, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    4000, Reward:  -486.686 [ 869.199], Avg:  -337.416 (1.000) <0-00:07:43> ({'r_t': -1976.7989, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    5000, Reward:  -363.186 [ 639.098], Avg:  -341.711 (1.000) <0-00:09:43> ({'r_t': -1667.9992, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    6000, Reward:  -397.686 [ 598.749], Avg:  -349.707 (1.000) <0-00:11:44> ({'r_t': -2037.8021, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    7000, Reward:  -324.323 [ 569.835], Avg:  -346.534 (1.000) <0-00:13:39> ({'r_t': -2215.6333, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    8000, Reward:  -865.622 [2828.391], Avg:  -404.211 (1.000) <0-00:15:42> ({'r_t': -1703.5285, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:    9000, Reward:  -341.259 [ 291.419], Avg:  -397.916 (1.000) <0-00:17:52> ({'r_t': -1998.5480, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   10000, Reward:  -237.807 [ 194.857], Avg:  -383.360 (1.000) <0-00:19:55> ({'r_t': -1976.5343, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   11000, Reward:  -317.053 [ 263.346], Avg:  -377.835 (1.000) <0-00:21:45> ({'r_t': -2145.0919, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   12000, Reward:  -235.949 [ 123.679], Avg:  -366.920 (1.000) <0-00:23:38> ({'r_t': -2287.4163, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   13000, Reward:  -676.957 [1328.873], Avg:  -389.066 (1.000) <0-00:25:41> ({'r_t': -2343.0577, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   14000, Reward:  -431.116 [ 653.966], Avg:  -391.869 (1.000) <0-00:27:37> ({'r_t': -1714.4298, 'eps':     1.0000, 'lr':     0.0010, 'eps_e':     1.0000, 'lr_e':     0.0010})
Step:   15000, Reward:  -212.989 [ 169.143], Avg:  -380.689 (0.990) <0-00:29:43> ({'r_t': -2126.4611, 'eps':     0.9900, 'dyn_loss': 46879.3711, 'dot_loss':   367.8899, 'ddot_loss':    34.7877, 'rew_loss':   546.5007, 'lr':     0.0010, 'eps_e':     0.9900, 'lr_e':     0.0010})
Step:   16000, Reward:  -217.190 [ 152.130], Avg:  -371.072 (0.980) <0-00:31:47> ({'r_t': -2434.1908, 'eps':     0.9801, 'dyn_loss':  1007.7136, 'dot_loss':    29.0056, 'ddot_loss':    15.8651, 'rew_loss':   565.8826, 'lr':     0.0010, 'eps_e':     0.9801, 'lr_e':     0.0010})
Step:   17000, Reward:  -320.614 [ 226.390], Avg:  -368.268 (0.970) <0-00:33:59> ({'r_t': -2744.7457, 'eps':     0.9703, 'dyn_loss':   714.2037, 'dot_loss':    19.2788, 'ddot_loss':    12.0688, 'rew_loss':   595.0992, 'lr':     0.0010, 'eps_e':     0.9703, 'lr_e':     0.0010})
Step:   18000, Reward:  -440.258 [ 594.369], Avg:  -372.057 (0.961) <0-00:36:13> ({'r_t': -1645.9487, 'eps':     0.9606, 'dyn_loss':   476.3643, 'dot_loss':    13.8410, 'ddot_loss':     9.6644, 'rew_loss':   588.1622, 'lr':     0.0010, 'eps_e':     0.9606, 'lr_e':     0.0010})
Step:   19000, Reward:  -350.433 [ 487.737], Avg:  -370.976 (0.951) <0-00:38:18> ({'r_t': -2008.4456, 'eps':     0.9510, 'dyn_loss':   344.9637, 'dot_loss':    11.0082, 'ddot_loss':     8.1738, 'rew_loss':   581.5895, 'lr':     0.0010, 'eps_e':     0.9510, 'lr_e':     0.0010})
Step:   20000, Reward:  -403.927 [ 538.808], Avg:  -372.545 (0.941) <0-00:40:38> ({'r_t': -1809.5362, 'eps':     0.9415, 'dyn_loss':   247.1904, 'dot_loss':     9.0015, 'ddot_loss':     7.1766, 'rew_loss':   595.6969, 'lr':     0.0010, 'eps_e':     0.9415, 'lr_e':     0.0010})
Step:   21000, Reward:  -207.545 [ 109.215], Avg:  -365.045 (0.932) <0-00:42:39> ({'r_t': -1896.4591, 'eps':     0.9321, 'dyn_loss':   185.7457, 'dot_loss':     7.4509, 'ddot_loss':     6.3377, 'rew_loss':   580.6124, 'lr':     0.0010, 'eps_e':     0.9321, 'lr_e':     0.0010})
Step:   22000, Reward:  -213.823 [ 161.542], Avg:  -358.470 (0.923) <0-00:44:35> ({'r_t': -1699.8396, 'eps':     0.9227, 'dyn_loss':   146.3410, 'dot_loss':     6.3805, 'ddot_loss':     5.7566, 'rew_loss':   528.3622, 'lr':     0.0010, 'eps_e':     0.9227, 'lr_e':     0.0010})
Step:   23000, Reward:  -193.065 [ 178.557], Avg:  -351.578 (0.914) <0-00:46:55> ({'r_t': -1565.8472, 'eps':     0.9135, 'dyn_loss':   132.4819, 'dot_loss':     5.6998, 'ddot_loss':     5.3235, 'rew_loss':   499.0137, 'lr':     0.0010, 'eps_e':     0.9135, 'lr_e':     0.0010})
Step:   24000, Reward:  -549.137 [1151.022], Avg:  -359.481 (0.904) <0-00:49:03> ({'r_t': -1435.9109, 'eps':     0.9044, 'dyn_loss':   113.2840, 'dot_loss':     5.0147, 'ddot_loss':     4.8949, 'rew_loss':   562.1287, 'lr':     0.0010, 'eps_e':     0.9044, 'lr_e':     0.0010})
Step:   25000, Reward:  -164.058 [ 103.492], Avg:  -351.964 (0.895) <0-00:51:03> ({'r_t': -1535.1638, 'eps':     0.8953, 'dyn_loss':   104.1315, 'dot_loss':     4.5300, 'ddot_loss':     4.5391, 'rew_loss':   551.5998, 'lr':     0.0010, 'eps_e':     0.8953, 'lr_e':     0.0010})
Step:   26000, Reward:  -235.838 [ 201.245], Avg:  -347.663 (0.886) <0-00:53:22> ({'r_t': -1360.0856, 'eps':     0.8864, 'dyn_loss':    95.1655, 'dot_loss':     4.1193, 'ddot_loss':     4.2623, 'rew_loss':   483.8242, 'lr':     0.0010, 'eps_e':     0.8864, 'lr_e':     0.0010})
Step:   27000, Reward:  -179.981 [ 126.077], Avg:  -341.675 (0.878) <0-00:55:24> ({'r_t': -1463.2373, 'eps':     0.8775, 'dyn_loss':    84.1295, 'dot_loss':     3.7235, 'ddot_loss':     4.0246, 'rew_loss':   468.4273, 'lr':     0.0010, 'eps_e':     0.8775, 'lr_e':     0.0010})
Step:   28000, Reward:  -152.475 [  83.558], Avg:  -335.151 (0.869) <0-00:57:20> ({'r_t': -1567.1855, 'eps':     0.8687, 'dyn_loss':    80.7912, 'dot_loss':     3.4584, 'ddot_loss':     3.8022, 'rew_loss':   439.1279, 'lr':     0.0010, 'eps_e':     0.8687, 'lr_e':     0.0010})
Step:   29000, Reward:  -257.630 [ 208.972], Avg:  -332.567 (0.860) <0-00:59:40> ({'r_t': -1453.2392, 'eps':     0.8601, 'dyn_loss':    76.2924, 'dot_loss':     3.1837, 'ddot_loss':     3.5511, 'rew_loss':   480.8614, 'lr':     0.0010, 'eps_e':     0.8601, 'lr_e':     0.0010})
Step:   30000, Reward:  -179.915 [ 116.465], Avg:  -327.642 (0.851) <0-01:01:47> ({'r_t': -1260.4265, 'eps':     0.8515, 'dyn_loss':    71.4058, 'dot_loss':     2.9552, 'ddot_loss':     3.3917, 'rew_loss':   440.9369, 'lr':     0.0010, 'eps_e':     0.8515, 'lr_e':     0.0010})
Step:   31000, Reward:  -177.119 [ 100.444], Avg:  -322.939 (0.843) <0-01:03:51> ({'r_t': -1356.2568, 'eps':     0.8429, 'dyn_loss':    68.5223, 'dot_loss':     2.7685, 'ddot_loss':     3.2396, 'rew_loss':   424.0109, 'lr':     0.0010, 'eps_e':     0.8429, 'lr_e':     0.0010})
Step:   32000, Reward:  -226.255 [ 155.832], Avg:  -320.009 (0.835) <0-01:06:02> ({'r_t': -1267.4747, 'eps':     0.8345, 'dyn_loss':    63.9179, 'dot_loss':     2.6021, 'ddot_loss':     3.1187, 'rew_loss':   415.8120, 'lr':     0.0010, 'eps_e':     0.8345, 'lr_e':     0.0010})
Step:   33000, Reward:  -182.541 [ 126.426], Avg:  -315.966 (0.826) <0-01:08:04> ({'r_t': -1439.3808, 'eps':     0.8262, 'dyn_loss':    60.0752, 'dot_loss':     2.4735, 'ddot_loss':     3.0436, 'rew_loss':   402.9610, 'lr':     0.0010, 'eps_e':     0.8262, 'lr_e':     0.0010})
Step:   34000, Reward:  -177.148 [  99.762], Avg:  -311.999 (0.818) <0-01:10:04> ({'r_t': -1522.9421, 'eps':     0.8179, 'dyn_loss':    61.2195, 'dot_loss':     2.3751, 'ddot_loss':     2.9529, 'rew_loss':   402.1443, 'lr':     0.0010, 'eps_e':     0.8179, 'lr_e':     0.0010})
Step:   35000, Reward:  -238.933 [ 183.887], Avg:  -309.970 (0.810) <0-01:12:18> ({'r_t': -1358.3415, 'eps':     0.8097, 'dyn_loss':    56.3811, 'dot_loss':     2.2523, 'ddot_loss':     2.8511, 'rew_loss':   372.0079, 'lr':     0.0010, 'eps_e':     0.8097, 'lr_e':     0.0010})
Step:   36000, Reward:  -467.112 [1208.054], Avg:  -314.217 (0.802) <0-01:14:28> ({'r_t': -1343.8788, 'eps':     0.8016, 'dyn_loss':    56.2745, 'dot_loss':     2.1972, 'ddot_loss':     2.8151, 'rew_loss':   379.9890, 'lr':     0.0010, 'eps_e':     0.8016, 'lr_e':     0.0010})
Step:   37000, Reward:  -277.894 [ 202.162], Avg:  -313.261 (0.794) <0-01:16:33> ({'r_t': -1273.1144, 'eps':     0.7936, 'dyn_loss':    51.3850, 'dot_loss':     2.1358, 'ddot_loss':     2.7998, 'rew_loss':   356.0659, 'lr':     0.0010, 'eps_e':     0.7936, 'lr_e':     0.0010})
Step:   38000, Reward:  -197.230 [ 184.472], Avg:  -310.286 (0.786) <0-01:18:50> ({'r_t': -1306.9361, 'eps':     0.7857, 'dyn_loss':    51.5405, 'dot_loss':     2.0612, 'ddot_loss':     2.7262, 'rew_loss':   362.2662, 'lr':     0.0010, 'eps_e':     0.7857, 'lr_e':     0.0010})
Step:   39000, Reward:  -240.206 [ 217.109], Avg:  -308.534 (0.778) <0-01:21:09> ({'r_t': -1294.9946, 'eps':     0.7778, 'dyn_loss':    49.2216, 'dot_loss':     2.0217, 'ddot_loss':     2.7040, 'rew_loss':   357.3840, 'lr':     0.0010, 'eps_e':     0.7778, 'lr_e':     0.0010})
Step:   40000, Reward:  -288.818 [ 448.465], Avg:  -308.053 (0.770) <0-01:23:11> ({'r_t': -1260.5786, 'eps':     0.7700, 'dyn_loss':    48.5335, 'dot_loss':     1.9810, 'ddot_loss':     2.6853, 'rew_loss':   350.7596, 'lr':     0.0010, 'eps_e':     0.7700, 'lr_e':     0.0010})
Step:   41000, Reward:  -180.643 [ 117.105], Avg:  -305.019 (0.762) <0-01:25:15> ({'r_t': -1424.2320, 'eps':     0.7623, 'dyn_loss':    47.0847, 'dot_loss':     1.9619, 'ddot_loss':     2.6789, 'rew_loss':   334.0821, 'lr':     0.0010, 'eps_e':     0.7623, 'lr_e':     0.0010})
Step:   42000, Reward:  -148.944 [  62.430], Avg:  -301.390 (0.755) <0-01:27:08> ({'r_t': -1250.1936, 'eps':     0.7547, 'dyn_loss':    47.7366, 'dot_loss':     1.9197, 'ddot_loss':     2.6473, 'rew_loss':   330.7394, 'lr':     0.0010, 'eps_e':     0.7547, 'lr_e':     0.0010})
Step:   43000, Reward:  -201.282 [ 157.794], Avg:  -299.115 (0.747) <0-01:29:23> ({'r_t': -1523.9333, 'eps':     0.7472, 'dyn_loss':    51.5514, 'dot_loss':     1.9838, 'ddot_loss':     2.6758, 'rew_loss':   312.3640, 'lr':     0.0010, 'eps_e':     0.7472, 'lr_e':     0.0010})
Step:   44000, Reward:  -192.782 [ 153.225], Avg:  -296.752 (0.740) <0-01:31:43> ({'r_t': -1385.2789, 'eps':     0.7397, 'dyn_loss':    46.4792, 'dot_loss':     1.9200, 'ddot_loss':     2.6596, 'rew_loss':   301.6786, 'lr':     0.0010, 'eps_e':     0.7397, 'lr_e':     0.0010})
Step:   45000, Reward:  -258.300 [ 244.674], Avg:  -295.916 (0.732) <0-01:33:51> ({'r_t': -1282.8590, 'eps':     0.7323, 'dyn_loss':    45.9048, 'dot_loss':     1.8749, 'ddot_loss':     2.6392, 'rew_loss':   318.6173, 'lr':     0.0010, 'eps_e':     0.7323, 'lr_e':     0.0010})
Step:   46000, Reward:  -249.266 [ 193.609], Avg:  -294.923 (0.725) <0-01:36:11> ({'r_t': -1276.1441, 'eps':     0.7250, 'dyn_loss':    43.7364, 'dot_loss':     1.8411, 'ddot_loss':     2.6281, 'rew_loss':   302.1426, 'lr':     0.0010, 'eps_e':     0.7250, 'lr_e':     0.0010})
Step:   47000, Reward:  -175.485 [ 105.728], Avg:  -292.435 (0.718) <0-01:38:21> ({'r_t': -1288.4417, 'eps':     0.7177, 'dyn_loss':    43.2502, 'dot_loss':     1.8029, 'ddot_loss':     2.6121, 'rew_loss':   299.8865, 'lr':     0.0010, 'eps_e':     0.7177, 'lr_e':     0.0010})
Step:   48000, Reward:  -260.036 [ 130.148], Avg:  -291.774 (0.711) <0-01:40:30> ({'r_t': -1228.2769, 'eps':     0.7106, 'dyn_loss':    41.7315, 'dot_loss':     1.7722, 'ddot_loss':     2.5997, 'rew_loss':   285.8869, 'lr':     0.0010, 'eps_e':     0.7106, 'lr_e':     0.0010})
Step:   49000, Reward:  -196.949 [ 111.034], Avg:  -289.877 (0.703) <0-01:42:28> ({'r_t': -1268.1771, 'eps':     0.7034, 'dyn_loss':    41.3163, 'dot_loss':     1.7694, 'ddot_loss':     2.6220, 'rew_loss':   311.9849, 'lr':     0.0010, 'eps_e':     0.7034, 'lr_e':     0.0010})
Step:   50000, Reward:  -157.640 [  92.288], Avg:  -287.284 (0.696) <0-01:44:29> ({'r_t': -1248.9216, 'eps':     0.6964, 'dyn_loss':    40.7624, 'dot_loss':     1.7259, 'ddot_loss':     2.5893, 'rew_loss':   277.5494, 'lr':     0.0010, 'eps_e':     0.6964, 'lr_e':     0.0010})
Step:   51000, Reward:  -165.069 [  89.497], Avg:  -284.934 (0.689) <0-01:46:29> ({'r_t': -1244.5550, 'eps':     0.6894, 'dyn_loss':    39.7301, 'dot_loss':     1.7074, 'ddot_loss':     2.5767, 'rew_loss':   293.0526, 'lr':     0.0010, 'eps_e':     0.6894, 'lr_e':     0.0010})
Step:   52000, Reward:  -209.154 [ 144.435], Avg:  -283.504 (0.683) <0-01:48:39> ({'r_t': -1187.3820, 'eps':     0.6826, 'dyn_loss':    39.9150, 'dot_loss':     1.6973, 'ddot_loss':     2.5825, 'rew_loss':   257.4484, 'lr':     0.0010, 'eps_e':     0.6826, 'lr_e':     0.0010})
Step:   53000, Reward:  -230.437 [ 160.651], Avg:  -282.521 (0.676) <0-01:50:52> ({'r_t': -1224.9000, 'eps':     0.6757, 'dyn_loss':    39.7905, 'dot_loss':     1.6827, 'ddot_loss':     2.5860, 'rew_loss':   264.5144, 'lr':     0.0010, 'eps_e':     0.6757, 'lr_e':     0.0010})
Step:   54000, Reward:  -208.657 [ 111.528], Avg:  -281.178 (0.669) <0-01:52:56> ({'r_t': -1234.2829, 'eps':     0.6690, 'dyn_loss':    40.8015, 'dot_loss':     1.6661, 'ddot_loss':     2.5634, 'rew_loss':   268.4824, 'lr':     0.0010, 'eps_e':     0.6690, 'lr_e':     0.0010})
Step:   55000, Reward:  -209.544 [ 103.184], Avg:  -279.899 (0.662) <0-01:54:55> ({'r_t': -1258.2331, 'eps':     0.6623, 'dyn_loss':    39.2161, 'dot_loss':     1.6437, 'ddot_loss':     2.5615, 'rew_loss':   262.5246, 'lr':     0.0010, 'eps_e':     0.6623, 'lr_e':     0.0010})
Step:   56000, Reward:  -157.997 [  88.479], Avg:  -277.761 (0.656) <0-01:56:54> ({'r_t': -1222.5719, 'eps':     0.6557, 'dyn_loss':    37.5349, 'dot_loss':     1.6213, 'ddot_loss':     2.5541, 'rew_loss':   252.2307, 'lr':     0.0010, 'eps_e':     0.6557, 'lr_e':     0.0010})
Step:   57000, Reward:  -136.703 [  70.797], Avg:  -275.329 (0.649) <0-01:58:47> ({'r_t': -1227.4428, 'eps':     0.6491, 'dyn_loss':    38.2477, 'dot_loss':     1.6288, 'ddot_loss':     2.5887, 'rew_loss':   235.4812, 'lr':     0.0010, 'eps_e':     0.6491, 'lr_e':     0.0010})
Step:   58000, Reward:  -231.924 [ 175.116], Avg:  -274.593 (0.643) <0-02:01:06> ({'r_t': -1218.8091, 'eps':     0.6426, 'dyn_loss':    35.8307, 'dot_loss':     1.5864, 'ddot_loss':     2.5542, 'rew_loss':   239.4227, 'lr':     0.0010, 'eps_e':     0.6426, 'lr_e':     0.0010})
Step:   59000, Reward:  -195.844 [  87.554], Avg:  -273.280 (0.636) <0-02:03:05> ({'r_t': -1193.0352, 'eps':     0.6362, 'dyn_loss':    34.8510, 'dot_loss':     1.5653, 'ddot_loss':     2.5422, 'rew_loss':   232.8106, 'lr':     0.0010, 'eps_e':     0.6362, 'lr_e':     0.0010})
Step:   60000, Reward:  -211.205 [ 129.195], Avg:  -272.263 (0.630) <0-02:05:06> ({'r_t': -1258.5226, 'eps':     0.6298, 'dyn_loss':    35.3279, 'dot_loss':     1.5484, 'ddot_loss':     2.5215, 'rew_loss':   253.4611, 'lr':     0.0010, 'eps_e':     0.6298, 'lr_e':     0.0010})
Step:   61000, Reward:  -186.304 [ 126.493], Avg:  -270.876 (0.624) <0-02:07:26> ({'r_t': -1206.6834, 'eps':     0.6235, 'dyn_loss':    32.0399, 'dot_loss':     1.5053, 'ddot_loss':     2.4784, 'rew_loss':   228.3667, 'lr':     0.0010, 'eps_e':     0.6235, 'lr_e':     0.0010})
Step:   62000, Reward:  -159.424 [  70.005], Avg:  -269.107 (0.617) <0-02:09:23> ({'r_t': -1269.1827, 'eps':     0.6173, 'dyn_loss':    34.3966, 'dot_loss':     1.5174, 'ddot_loss':     2.5007, 'rew_loss':   240.9594, 'lr':     0.0010, 'eps_e':     0.6173, 'lr_e':     0.0010})
Step:   63000, Reward:  -183.218 [ 124.739], Avg:  -267.765 (0.611) <0-02:11:33> ({'r_t': -1207.1810, 'eps':     0.6111, 'dyn_loss':    35.3786, 'dot_loss':     1.5091, 'ddot_loss':     2.4802, 'rew_loss':   227.8107, 'lr':     0.0010, 'eps_e':     0.6111, 'lr_e':     0.0010})
Step:   64000, Reward:  -166.947 [  94.430], Avg:  -266.214 (0.605) <0-02:13:35> ({'r_t': -1203.5936, 'eps':     0.6050, 'dyn_loss':    30.4585, 'dot_loss':     1.4613, 'ddot_loss':     2.4445, 'rew_loss':   228.8670, 'lr':     0.0010, 'eps_e':     0.6050, 'lr_e':     0.0010})
Step:   65000, Reward:  -252.399 [ 156.533], Avg:  -266.005 (0.599) <0-02:15:55> ({'r_t': -1185.5927, 'eps':     0.5990, 'dyn_loss':    31.9509, 'dot_loss':     1.4771, 'ddot_loss':     2.4802, 'rew_loss':   217.0657, 'lr':     0.0010, 'eps_e':     0.5990, 'lr_e':     0.0010})
Step:   66000, Reward:  -160.318 [  81.868], Avg:  -264.428 (0.593) <0-02:18:04> ({'r_t': -1194.8347, 'eps':     0.5930, 'dyn_loss':    28.1622, 'dot_loss':     1.4489, 'ddot_loss':     2.4598, 'rew_loss':   219.0678, 'lr':     0.0010, 'eps_e':     0.5930, 'lr_e':     0.0010})
Step:   67000, Reward:  -148.624 [  53.827], Avg:  -262.725 (0.587) <0-02:20:00> ({'r_t': -1229.2378, 'eps':     0.5870, 'dyn_loss':    27.2843, 'dot_loss':     1.4114, 'ddot_loss':     2.4165, 'rew_loss':   215.6510, 'lr':     0.0010, 'eps_e':     0.5870, 'lr_e':     0.0010})
Step:   68000, Reward:  -204.774 [  96.005], Avg:  -261.885 (0.581) <0-02:22:04> ({'r_t': -1182.2044, 'eps':     0.5812, 'dyn_loss':    27.6094, 'dot_loss':     1.3934, 'ddot_loss':     2.3996, 'rew_loss':   184.5153, 'lr':     0.0010, 'eps_e':     0.5812, 'lr_e':     0.0010})
Step:   69000, Reward:  -133.615 [  89.282], Avg:  -260.052 (0.575) <0-02:24:02> ({'r_t': -1196.5267, 'eps':     0.5754, 'dyn_loss':    24.0644, 'dot_loss':     1.3650, 'ddot_loss':     2.3910, 'rew_loss':   196.6068, 'lr':     0.0010, 'eps_e':     0.5754, 'lr_e':     0.0010})
Step:   70000, Reward:  -279.812 [ 206.674], Avg:  -260.331 (0.570) <0-02:26:22> ({'r_t': -1139.5528, 'eps':     0.5696, 'dyn_loss':    26.2162, 'dot_loss':     1.3788, 'ddot_loss':     2.4226, 'rew_loss':   209.1825, 'lr':     0.0010, 'eps_e':     0.5696, 'lr_e':     0.0010})
Step:   71000, Reward:  -190.102 [ 151.291], Avg:  -259.355 (0.564) <0-02:28:35> ({'r_t': -1174.3442, 'eps':     0.5639, 'dyn_loss':    23.4333, 'dot_loss':     1.3400, 'ddot_loss':     2.3803, 'rew_loss':   202.9013, 'lr':     0.0010, 'eps_e':     0.5639, 'lr_e':     0.0010})
Step:   72000, Reward:  -226.103 [ 158.879], Avg:  -258.900 (0.558) <0-02:30:40> ({'r_t': -1144.7851, 'eps':     0.5583, 'dyn_loss':    22.9307, 'dot_loss':     1.3224, 'ddot_loss':     2.3676, 'rew_loss':   191.0880, 'lr':     0.0010, 'eps_e':     0.5583, 'lr_e':     0.0010})
Step:   73000, Reward:  -197.765 [ 134.418], Avg:  -258.073 (0.553) <0-02:32:48> ({'r_t': -1124.4695, 'eps':     0.5527, 'dyn_loss':    21.7497, 'dot_loss':     1.2922, 'ddot_loss':     2.3282, 'rew_loss':   190.3098, 'lr':     0.0010, 'eps_e':     0.5527, 'lr_e':     0.0010})
Step:   74000, Reward:  -150.203 [ 125.671], Avg:  -256.635 (0.547) <0-02:34:59> ({'r_t': -1131.9077, 'eps':     0.5472, 'dyn_loss':    23.1384, 'dot_loss':     1.2794, 'ddot_loss':     2.2991, 'rew_loss':   193.4767, 'lr':     0.0010, 'eps_e':     0.5472, 'lr_e':     0.0010})
Step:   75000, Reward:  -214.321 [ 175.098], Avg:  -256.078 (0.542) <0-02:37:11> ({'r_t': -1208.1298, 'eps':     0.5417, 'dyn_loss':    23.1496, 'dot_loss':     1.2655, 'ddot_loss':     2.2906, 'rew_loss':   187.9772, 'lr':     0.0010, 'eps_e':     0.5417, 'lr_e':     0.0010})
Step:   76000, Reward:  -193.395 [ 189.670], Avg:  -255.264 (0.536) <0-02:39:28> ({'r_t': -1148.0192, 'eps':     0.5363, 'dyn_loss':    20.3673, 'dot_loss':     1.2284, 'ddot_loss':     2.2559, 'rew_loss':   194.6918, 'lr':     0.0010, 'eps_e':     0.5363, 'lr_e':     0.0010})
Step:   77000, Reward:  -196.386 [ 178.580], Avg:  -254.510 (0.531) <0-02:41:48> ({'r_t': -1171.8178, 'eps':     0.5309, 'dyn_loss':    20.0047, 'dot_loss':     1.2073, 'ddot_loss':     2.2232, 'rew_loss':   163.3065, 'lr':     0.0010, 'eps_e':     0.5309, 'lr_e':     0.0010})
Step:   78000, Reward:  -218.665 [ 163.121], Avg:  -254.056 (0.526) <0-02:44:06> ({'r_t': -1139.8627, 'eps':     0.5256, 'dyn_loss':    20.9289, 'dot_loss':     1.2058, 'ddot_loss':     2.2141, 'rew_loss':   178.7234, 'lr':     0.0010, 'eps_e':     0.5256, 'lr_e':     0.0010})
Step:   79000, Reward:  -146.017 [  74.714], Avg:  -252.705 (0.520) <0-02:46:18> ({'r_t': -1155.0397, 'eps':     0.5203, 'dyn_loss':    20.2839, 'dot_loss':     1.1871, 'ddot_loss':     2.1922, 'rew_loss':   185.5527, 'lr':     0.0010, 'eps_e':     0.5203, 'lr_e':     0.0010})
Step:   80000, Reward:  -174.239 [ 112.515], Avg:  -251.737 (0.515) <0-02:48:28> ({'r_t': -1134.2004, 'eps':     0.5151, 'dyn_loss':    18.8072, 'dot_loss':     1.1563, 'ddot_loss':     2.1556, 'rew_loss':   182.1310, 'lr':     0.0010, 'eps_e':     0.5151, 'lr_e':     0.0010})
Step:   81000, Reward:  -193.061 [ 171.756], Avg:  -251.021 (0.510) <0-02:50:48> ({'r_t': -1101.5986, 'eps':     0.5100, 'dyn_loss':    18.4917, 'dot_loss':     1.1327, 'ddot_loss':     2.1285, 'rew_loss':   171.5056, 'lr':     0.0010, 'eps_e':     0.5100, 'lr_e':     0.0010})
Step:   82000, Reward:  -132.296 [  75.091], Avg:  -249.591 (0.505) <0-02:52:51> ({'r_t': -1083.1876, 'eps':     0.5049, 'dyn_loss':    19.7402, 'dot_loss':     1.1598, 'ddot_loss':     2.1702, 'rew_loss':   184.8414, 'lr':     0.0010, 'eps_e':     0.5049, 'lr_e':     0.0010})
Step:   83000, Reward:  -165.999 [ 120.695], Avg:  -248.595 (0.500) <0-02:55:09> ({'r_t': -1098.9722, 'eps':     0.4998, 'dyn_loss':    18.1335, 'dot_loss':     1.1205, 'ddot_loss':     2.1212, 'rew_loss':   179.6043, 'lr':     0.0010, 'eps_e':     0.4998, 'lr_e':     0.0010})
Step:   84000, Reward:  -221.795 [ 137.715], Avg:  -248.280 (0.495) <0-02:57:23> ({'r_t': -1210.5709, 'eps':     0.4948, 'dyn_loss':    17.9968, 'dot_loss':     1.1052, 'ddot_loss':     2.1030, 'rew_loss':   163.2064, 'lr':     0.0010, 'eps_e':     0.4948, 'lr_e':     0.0010})
Step:   85000, Reward:  -214.959 [  71.923], Avg:  -247.893 (0.490) <0-02:59:26> ({'r_t': -1116.3146, 'eps':     0.4899, 'dyn_loss':    18.4493, 'dot_loss':     1.0914, 'ddot_loss':     2.0687, 'rew_loss':   163.5244, 'lr':     0.0010, 'eps_e':     0.4899, 'lr_e':     0.0010})
Step:   86000, Reward:  -202.957 [ 171.505], Avg:  -247.376 (0.485) <0-03:01:46> ({'r_t': -1084.8988, 'eps':     0.4850, 'dyn_loss':    19.0891, 'dot_loss':     1.0922, 'ddot_loss':     2.0674, 'rew_loss':   171.7376, 'lr':     0.0010, 'eps_e':     0.4850, 'lr_e':     0.0010})
Step:   87000, Reward:  -179.278 [  96.695], Avg:  -246.602 (0.480) <0-03:03:49> ({'r_t': -1109.5830, 'eps':     0.4801, 'dyn_loss':    17.8015, 'dot_loss':     1.0684, 'ddot_loss':     2.0309, 'rew_loss':   156.1465, 'lr':     0.0010, 'eps_e':     0.4801, 'lr_e':     0.0010})
Step:   88000, Reward:  -215.643 [ 179.621], Avg:  -246.254 (0.475) <0-03:06:09> ({'r_t': -1084.9017, 'eps':     0.4753, 'dyn_loss':    16.0589, 'dot_loss':     1.0379, 'ddot_loss':     1.9987, 'rew_loss':   152.7850, 'lr':     0.0010, 'eps_e':     0.4753, 'lr_e':     0.0010})
Step:   89000, Reward:  -198.074 [ 135.637], Avg:  -245.719 (0.471) <0-03:08:15> ({'r_t': -1150.2370, 'eps':     0.4706, 'dyn_loss':    16.2746, 'dot_loss':     1.0355, 'ddot_loss':     1.9908, 'rew_loss':   163.4154, 'lr':     0.0010, 'eps_e':     0.4706, 'lr_e':     0.0010})
Step:   90000, Reward:  -213.944 [ 167.804], Avg:  -245.370 (0.466) <0-03:10:32> ({'r_t': -1072.6594, 'eps':     0.4659, 'dyn_loss':    17.7705, 'dot_loss':     1.0542, 'ddot_loss':     2.0191, 'rew_loss':   169.1401, 'lr':     0.0010, 'eps_e':     0.4659, 'lr_e':     0.0010})
Step:   91000, Reward:  -232.584 [ 180.178], Avg:  -245.231 (0.461) <0-03:12:51> ({'r_t': -1136.0952, 'eps':     0.4612, 'dyn_loss':    16.6197, 'dot_loss':     1.0341, 'ddot_loss':     1.9933, 'rew_loss':   169.3511, 'lr':     0.0010, 'eps_e':     0.4612, 'lr_e':     0.0010})
Step:   92000, Reward:  -166.421 [  90.404], Avg:  -244.384 (0.457) <0-03:14:51> ({'r_t': -1134.8982, 'eps':     0.4566, 'dyn_loss':    16.0949, 'dot_loss':     1.0085, 'ddot_loss':     1.9465, 'rew_loss':   154.1415, 'lr':     0.0010, 'eps_e':     0.4566, 'lr_e':     0.0010})
Step:   93000, Reward:  -176.168 [ 118.721], Avg:  -243.658 (0.452) <0-03:17:11> ({'r_t': -1084.4928, 'eps':     0.4520, 'dyn_loss':    16.9120, 'dot_loss':     1.0255, 'ddot_loss':     1.9803, 'rew_loss':   164.4159, 'lr':     0.0010, 'eps_e':     0.4520, 'lr_e':     0.0010})
Step:   94000, Reward:  -197.391 [ 151.664], Avg:  -243.171 (0.448) <0-03:19:19> ({'r_t': -1078.4826, 'eps':     0.4475, 'dyn_loss':    14.6942, 'dot_loss':     0.9873, 'ddot_loss':     1.9319, 'rew_loss':   161.6707, 'lr':     0.0010, 'eps_e':     0.4475, 'lr_e':     0.0010})
Step:   95000, Reward:  -189.749 [ 162.365], Avg:  -242.614 (0.443) <0-03:21:35> ({'r_t': -1092.0941, 'eps':     0.4430, 'dyn_loss':    16.0225, 'dot_loss':     1.0122, 'ddot_loss':     1.9722, 'rew_loss':   158.6111, 'lr':     0.0010, 'eps_e':     0.4430, 'lr_e':     0.0010})
Step:   96000, Reward:  -120.984 [  86.120], Avg:  -241.360 (0.439) <0-03:23:32> ({'r_t': -1148.0775, 'eps':     0.4386, 'dyn_loss':    15.7954, 'dot_loss':     0.9985, 'ddot_loss':     1.9468, 'rew_loss':   142.1173, 'lr':     0.0010, 'eps_e':     0.4386, 'lr_e':     0.0010})
Step:   97000, Reward:  -141.812 [  73.577], Avg:  -240.345 (0.434) <0-03:25:30> ({'r_t': -1031.3076, 'eps':     0.4342, 'dyn_loss':    14.2588, 'dot_loss':     0.9612, 'ddot_loss':     1.8898, 'rew_loss':   144.9264, 'lr':     0.0010, 'eps_e':     0.4342, 'lr_e':     0.0010})
Step:   98000, Reward:  -286.009 [ 221.188], Avg:  -240.806 (0.430) <0-03:27:50> ({'r_t': -1157.5716, 'eps':     0.4299, 'dyn_loss':    15.7414, 'dot_loss':     0.9730, 'ddot_loss':     1.8995, 'rew_loss':   158.8299, 'lr':     0.0010, 'eps_e':     0.4299, 'lr_e':     0.0010})
Step:   99000, Reward:  -193.552 [ 132.924], Avg:  -240.333 (0.426) <0-03:30:02> ({'r_t': -1053.3822, 'eps':     0.4256, 'dyn_loss':    14.5567, 'dot_loss':     0.9600, 'ddot_loss':     1.8918, 'rew_loss':   148.4187, 'lr':     0.0010, 'eps_e':     0.4256, 'lr_e':     0.0010})
Step:  100000, Reward:  -177.365 [ 144.571], Avg:  -239.710 (0.421) <0-03:32:17> ({'r_t': -1039.0710, 'eps':     0.4213, 'dyn_loss':    14.5721, 'dot_loss':     0.9688, 'ddot_loss':     1.9042, 'rew_loss':   147.2255, 'lr':     0.0010, 'eps_e':     0.4213, 'lr_e':     0.0010})
Step:  101000, Reward:  -183.972 [  98.179], Avg:  -239.163 (0.417) <0-03:34:21> ({'r_t': -1098.6988, 'eps':     0.4171, 'dyn_loss':    15.0978, 'dot_loss':     0.9630, 'ddot_loss':     1.8845, 'rew_loss':   148.5821, 'lr':     0.0010, 'eps_e':     0.4171, 'lr_e':     0.0010})
Step:  102000, Reward:  -238.631 [ 170.254], Avg:  -239.158 (0.413) <0-03:36:39> ({'r_t': -1109.1863, 'eps':     0.4129, 'dyn_loss':    12.9151, 'dot_loss':     0.9416, 'ddot_loss':     1.8724, 'rew_loss':   136.3902, 'lr':     0.0010, 'eps_e':     0.4129, 'lr_e':     0.0010})
Step:  103000, Reward:  -185.635 [ 141.888], Avg:  -238.644 (0.409) <0-03:38:54> ({'r_t': -1112.9988, 'eps':     0.4088, 'dyn_loss':    14.5982, 'dot_loss':     0.9728, 'ddot_loss':     1.9221, 'rew_loss':   130.5031, 'lr':     0.0010, 'eps_e':     0.4088, 'lr_e':     0.0010})
Step:  104000, Reward:  -140.432 [  79.399], Avg:  -237.708 (0.405) <0-03:40:51> ({'r_t': -1296.6187, 'eps':     0.4047, 'dyn_loss':    14.6669, 'dot_loss':     0.9501, 'ddot_loss':     1.8664, 'rew_loss':   141.1943, 'lr':     0.0010, 'eps_e':     0.4047, 'lr_e':     0.0010})
Step:  105000, Reward:  -150.239 [  62.788], Avg:  -236.883 (0.401) <0-03:42:57> ({'r_t':  -999.1712, 'eps':     0.4007, 'dyn_loss':    13.2357, 'dot_loss':     0.9386, 'ddot_loss':     1.8589, 'rew_loss':   138.4597, 'lr':     0.0010, 'eps_e':     0.4007, 'lr_e':     0.0010})
Step:  106000, Reward:  -178.464 [ 144.434], Avg:  -236.337 (0.397) <0-03:45:03> ({'r_t':  -964.4369, 'eps':     0.3967, 'dyn_loss':    13.4690, 'dot_loss':     0.9164, 'ddot_loss':     1.8225, 'rew_loss':   143.0531, 'lr':     0.0010, 'eps_e':     0.3967, 'lr_e':     0.0010})
Step:  107000, Reward:  -162.415 [ 160.129], Avg:  -235.653 (0.393) <0-03:47:20> ({'r_t': -1070.4200, 'eps':     0.3927, 'dyn_loss':    13.3755, 'dot_loss':     0.9220, 'ddot_loss':     1.8314, 'rew_loss':   130.1687, 'lr':     0.0010, 'eps_e':     0.3927, 'lr_e':     0.0010})
Step:  108000, Reward:  -236.142 [ 177.973], Avg:  -235.657 (0.389) <0-03:49:35> ({'r_t': -1078.1318, 'eps':     0.3888, 'dyn_loss':    13.2968, 'dot_loss':     0.9270, 'ddot_loss':     1.8375, 'rew_loss':   120.8540, 'lr':     0.0010, 'eps_e':     0.3888, 'lr_e':     0.0010})
Step:  109000, Reward:  -175.741 [ 133.515], Avg:  -235.112 (0.385) <0-03:51:43> ({'r_t': -1068.8383, 'eps':     0.3849, 'dyn_loss':    12.6316, 'dot_loss':     0.9142, 'ddot_loss':     1.8304, 'rew_loss':   137.8748, 'lr':     0.0010, 'eps_e':     0.3849, 'lr_e':     0.0010})
Step:  110000, Reward:  -135.633 [  73.167], Avg:  -234.216 (0.381) <0-03:53:43> ({'r_t': -1107.7000, 'eps':     0.3810, 'dyn_loss':    13.8135, 'dot_loss':     0.9367, 'ddot_loss':     1.8533, 'rew_loss':   133.2675, 'lr':     0.0010, 'eps_e':     0.3810, 'lr_e':     0.0010})
Step:  111000, Reward:  -138.166 [  68.774], Avg:  -233.359 (0.377) <0-03:55:41> ({'r_t': -1040.6119, 'eps':     0.3772, 'dyn_loss':    12.2788, 'dot_loss':     0.9079, 'ddot_loss':     1.8239, 'rew_loss':   128.0321, 'lr':     0.0010, 'eps_e':     0.3772, 'lr_e':     0.0010})
Step:  112000, Reward:  -207.296 [ 196.412], Avg:  -233.128 (0.373) <0-03:57:57> ({'r_t':  -997.9781, 'eps':     0.3735, 'dyn_loss':    12.3467, 'dot_loss':     0.9040, 'ddot_loss':     1.8146, 'rew_loss':   115.4335, 'lr':     0.0010, 'eps_e':     0.3735, 'lr_e':     0.0010})
Step:  113000, Reward:  -250.306 [ 141.289], Avg:  -233.279 (0.370) <0-04:00:10> ({'r_t': -1018.2858, 'eps':     0.3697, 'dyn_loss':    12.0508, 'dot_loss':     0.8899, 'ddot_loss':     1.7760, 'rew_loss':   132.4361, 'lr':     0.0010, 'eps_e':     0.3697, 'lr_e':     0.0010})
Step:  114000, Reward:  -288.819 [ 151.832], Avg:  -233.762 (0.366) <0-04:02:23> ({'r_t': -1164.5630, 'eps':     0.3660, 'dyn_loss':    12.3565, 'dot_loss':     0.9025, 'ddot_loss':     1.8044, 'rew_loss':   139.2084, 'lr':     0.0010, 'eps_e':     0.3660, 'lr_e':     0.0010})
Step:  115000, Reward:  -155.232 [ 144.639], Avg:  -233.085 (0.362) <0-04:04:39> ({'r_t': -1060.8411, 'eps':     0.3624, 'dyn_loss':    14.9643, 'dot_loss':     0.9189, 'ddot_loss':     1.8122, 'rew_loss':   127.7029, 'lr':     0.0010, 'eps_e':     0.3624, 'lr_e':     0.0010})
Step:  116000, Reward:  -211.950 [ 182.788], Avg:  -232.904 (0.359) <0-04:06:58> ({'r_t':  -941.3053, 'eps':     0.3587, 'dyn_loss':    13.6105, 'dot_loss':     0.8971, 'ddot_loss':     1.7917, 'rew_loss':   135.9650, 'lr':     0.0010, 'eps_e':     0.3587, 'lr_e':     0.0010})
Step:  117000, Reward:  -246.680 [ 157.179], Avg:  -233.021 (0.355) <0-04:09:10> ({'r_t': -1006.2225, 'eps':     0.3552, 'dyn_loss':    12.6009, 'dot_loss':     0.8964, 'ddot_loss':     1.7860, 'rew_loss':   106.5162, 'lr':     0.0010, 'eps_e':     0.3552, 'lr_e':     0.0010})
Step:  118000, Reward:  -184.956 [ 200.806], Avg:  -232.617 (0.352) <0-04:11:30> ({'r_t': -1087.7524, 'eps':     0.3516, 'dyn_loss':    11.7696, 'dot_loss':     0.8648, 'ddot_loss':     1.7366, 'rew_loss':   125.2484, 'lr':     0.0010, 'eps_e':     0.3516, 'lr_e':     0.0010})
Step:  119000, Reward:  -173.450 [ 127.308], Avg:  -232.124 (0.348) <0-04:13:42> ({'r_t': -1044.6315, 'eps':     0.3481, 'dyn_loss':    12.6119, 'dot_loss':     0.8715, 'ddot_loss':     1.7399, 'rew_loss':   126.5489, 'lr':     0.0010, 'eps_e':     0.3481, 'lr_e':     0.0010})
Step:  120000, Reward:  -214.781 [ 199.068], Avg:  -231.981 (0.345) <0-04:16:02> ({'r_t': -1044.4633, 'eps':     0.3446, 'dyn_loss':    11.5271, 'dot_loss':     0.8587, 'ddot_loss':     1.7226, 'rew_loss':   131.6078, 'lr':     0.0010, 'eps_e':     0.3446, 'lr_e':     0.0010})
Step:  121000, Reward:  -167.471 [  67.704], Avg:  -231.452 (0.341) <0-04:18:01> ({'r_t': -1141.6058, 'eps':     0.3412, 'dyn_loss':    12.1168, 'dot_loss':     0.8652, 'ddot_loss':     1.7248, 'rew_loss':   128.9030, 'lr':     0.0010, 'eps_e':     0.3412, 'lr_e':     0.0010})
Step:  122000, Reward:  -186.245 [ 158.780], Avg:  -231.084 (0.338) <0-04:20:21> ({'r_t':  -969.2011, 'eps':     0.3378, 'dyn_loss':    12.5512, 'dot_loss':     0.8609, 'ddot_loss':     1.7148, 'rew_loss':   118.8042, 'lr':     0.0010, 'eps_e':     0.3378, 'lr_e':     0.0010})
Step:  123000, Reward:  -164.033 [  93.302], Avg:  -230.543 (0.334) <0-04:22:33> ({'r_t':  -984.3064, 'eps':     0.3344, 'dyn_loss':    12.7347, 'dot_loss':     0.8509, 'ddot_loss':     1.6995, 'rew_loss':   127.2736, 'lr':     0.0010, 'eps_e':     0.3344, 'lr_e':     0.0010})
Step:  124000, Reward:  -209.001 [ 135.205], Avg:  -230.371 (0.331) <0-04:24:50> ({'r_t':  -989.6395, 'eps':     0.3310, 'dyn_loss':    11.2563, 'dot_loss':     0.8325, 'ddot_loss':     1.6634, 'rew_loss':   113.0566, 'lr':     0.0010, 'eps_e':     0.3310, 'lr_e':     0.0010})
Step:  125000, Reward:  -233.412 [ 134.899], Avg:  -230.395 (0.328) <0-04:27:03> ({'r_t': -1044.3352, 'eps':     0.3277, 'dyn_loss':    10.9996, 'dot_loss':     0.8446, 'ddot_loss':     1.6963, 'rew_loss':   124.8412, 'lr':     0.0010, 'eps_e':     0.3277, 'lr_e':     0.0010})
Step:  126000, Reward:  -142.962 [  92.435], Avg:  -229.707 (0.324) <0-04:29:03> ({'r_t':  -988.2139, 'eps':     0.3244, 'dyn_loss':    11.2367, 'dot_loss':     0.8247, 'ddot_loss':     1.6515, 'rew_loss':   114.6674, 'lr':     0.0010, 'eps_e':     0.3244, 'lr_e':     0.0010})
Step:  127000, Reward:  -211.351 [ 152.079], Avg:  -229.563 (0.321) <0-04:31:12> ({'r_t':  -936.5729, 'eps':     0.3212, 'dyn_loss':    11.6298, 'dot_loss':     0.8302, 'ddot_loss':     1.6621, 'rew_loss':   116.1777, 'lr':     0.0010, 'eps_e':     0.3212, 'lr_e':     0.0010})
Step:  128000, Reward:  -241.258 [ 212.527], Avg:  -229.654 (0.318) <0-04:33:32> ({'r_t': -1032.9171, 'eps':     0.3180, 'dyn_loss':    11.1835, 'dot_loss':     0.8359, 'ddot_loss':     1.6711, 'rew_loss':   104.5384, 'lr':     0.0010, 'eps_e':     0.3180, 'lr_e':     0.0010})
Step:  129000, Reward:  -184.942 [ 113.111], Avg:  -229.310 (0.315) <0-04:35:44> ({'r_t': -1005.3504, 'eps':     0.3148, 'dyn_loss':    11.9103, 'dot_loss':     0.8231, 'ddot_loss':     1.6369, 'rew_loss':   120.7724, 'lr':     0.0010, 'eps_e':     0.3148, 'lr_e':     0.0010})
Step:  130000, Reward:  -237.139 [ 201.509], Avg:  -229.370 (0.312) <0-04:38:04> ({'r_t':  -953.5963, 'eps':     0.3117, 'dyn_loss':    11.1090, 'dot_loss':     0.8058, 'ddot_loss':     1.6025, 'rew_loss':   109.2363, 'lr':     0.0010, 'eps_e':     0.3117, 'lr_e':     0.0010})
Step:  131000, Reward:  -205.737 [ 203.334], Avg:  -229.191 (0.309) <0-04:40:23> ({'r_t':  -918.9114, 'eps':     0.3085, 'dyn_loss':    10.8723, 'dot_loss':     0.8134, 'ddot_loss':     1.6198, 'rew_loss':   112.0939, 'lr':     0.0010, 'eps_e':     0.3085, 'lr_e':     0.0010})
Step:  132000, Reward:  -217.404 [ 176.320], Avg:  -229.102 (0.305) <0-04:42:43> ({'r_t':  -966.8246, 'eps':     0.3055, 'dyn_loss':    11.3806, 'dot_loss':     0.8153, 'ddot_loss':     1.6195, 'rew_loss':   106.2730, 'lr':     0.0010, 'eps_e':     0.3055, 'lr_e':     0.0010})
Step:  133000, Reward:  -188.922 [ 154.221], Avg:  -228.802 (0.302) <0-04:45:00> ({'r_t': -1089.3249, 'eps':     0.3024, 'dyn_loss':    11.2839, 'dot_loss':     0.8009, 'ddot_loss':     1.5910, 'rew_loss':   117.0235, 'lr':     0.0010, 'eps_e':     0.3024, 'lr_e':     0.0010})
Step:  134000, Reward:  -288.082 [ 232.894], Avg:  -229.242 (0.299) <0-04:47:20> ({'r_t':  -919.7011, 'eps':     0.2994, 'dyn_loss':    10.5029, 'dot_loss':     0.7811, 'ddot_loss':     1.5533, 'rew_loss':   113.4937, 'lr':     0.0010, 'eps_e':     0.2994, 'lr_e':     0.0010})
Step:  135000, Reward:  -181.421 [ 117.121], Avg:  -228.890 (0.296) <0-04:49:24> ({'r_t': -1140.0403, 'eps':     0.2964, 'dyn_loss':    10.4230, 'dot_loss':     0.7842, 'ddot_loss':     1.5624, 'rew_loss':   107.3982, 'lr':     0.0010, 'eps_e':     0.2964, 'lr_e':     0.0010})
Step:  136000, Reward:  -254.846 [ 346.300], Avg:  -229.079 (0.293) <0-04:51:44> ({'r_t':  -951.4837, 'eps':     0.2934, 'dyn_loss':    10.4650, 'dot_loss':     0.7729, 'ddot_loss':     1.5339, 'rew_loss':   118.7846, 'lr':     0.0010, 'eps_e':     0.2934, 'lr_e':     0.0010})
Step:  137000, Reward:  -211.076 [ 153.922], Avg:  -228.949 (0.290) <0-04:54:00> ({'r_t': -1038.3166, 'eps':     0.2905, 'dyn_loss':    10.3540, 'dot_loss':     0.7580, 'ddot_loss':     1.5056, 'rew_loss':   106.9743, 'lr':     0.0010, 'eps_e':     0.2905, 'lr_e':     0.0010})
Step:  138000, Reward:  -196.881 [ 164.371], Avg:  -228.718 (0.288) <0-04:56:20> ({'r_t':  -935.3312, 'eps':     0.2876, 'dyn_loss':    11.3349, 'dot_loss':     0.7777, 'ddot_loss':     1.5385, 'rew_loss':   116.5964, 'lr':     0.0010, 'eps_e':     0.2876, 'lr_e':     0.0010})
Step:  139000, Reward:  -206.415 [ 202.347], Avg:  -228.559 (0.285) <0-04:58:39> ({'r_t': -1075.8923, 'eps':     0.2847, 'dyn_loss':    11.0383, 'dot_loss':     0.7772, 'ddot_loss':     1.5299, 'rew_loss':   105.9917, 'lr':     0.0010, 'eps_e':     0.2847, 'lr_e':     0.0010})
Step:  140000, Reward:  -238.477 [ 139.748], Avg:  -228.629 (0.282) <0-05:00:50> ({'r_t':  -871.5074, 'eps':     0.2819, 'dyn_loss':    10.2848, 'dot_loss':     0.7566, 'ddot_loss':     1.4976, 'rew_loss':   118.4561, 'lr':     0.0010, 'eps_e':     0.2819, 'lr_e':     0.0010})
Step:  141000, Reward:  -151.532 [ 115.654], Avg:  -228.086 (0.279) <0-05:03:04> ({'r_t':  -938.8096, 'eps':     0.2790, 'dyn_loss':     9.7667, 'dot_loss':     0.7519, 'ddot_loss':     1.4929, 'rew_loss':   122.4664, 'lr':     0.0010, 'eps_e':     0.2790, 'lr_e':     0.0010})
Step:  142000, Reward:  -138.866 [ 121.583], Avg:  -227.462 (0.276) <0-05:05:12> ({'r_t':  -929.3143, 'eps':     0.2763, 'dyn_loss':    11.2806, 'dot_loss':     0.7623, 'ddot_loss':     1.5018, 'rew_loss':   119.1561, 'lr':     0.0010, 'eps_e':     0.2763, 'lr_e':     0.0010})
Step:  143000, Reward:  -173.974 [ 145.232], Avg:  -227.091 (0.273) <0-05:07:25> ({'r_t':  -911.8542, 'eps':     0.2735, 'dyn_loss':    10.7384, 'dot_loss':     0.7513, 'ddot_loss':     1.4759, 'rew_loss':   113.7091, 'lr':     0.0010, 'eps_e':     0.2735, 'lr_e':     0.0010})
Step:  144000, Reward:  -184.745 [ 136.203], Avg:  -226.799 (0.271) <0-05:09:35> ({'r_t':  -857.4725, 'eps':     0.2708, 'dyn_loss':    10.9793, 'dot_loss':     0.7678, 'ddot_loss':     1.5069, 'rew_loss':   116.8226, 'lr':     0.0010, 'eps_e':     0.2708, 'lr_e':     0.0010})
Step:  145000, Reward:  -256.903 [ 172.937], Avg:  -227.005 (0.268) <0-05:11:54> ({'r_t':  -865.7060, 'eps':     0.2680, 'dyn_loss':    10.4970, 'dot_loss':     0.7296, 'ddot_loss':     1.4368, 'rew_loss':   122.2292, 'lr':     0.0010, 'eps_e':     0.2680, 'lr_e':     0.0010})
Step:  146000, Reward:  -145.045 [  94.220], Avg:  -226.448 (0.265) <0-05:14:12> ({'r_t':  -946.6241, 'eps':     0.2654, 'dyn_loss':     9.8316, 'dot_loss':     0.7321, 'ddot_loss':     1.4475, 'rew_loss':   110.7421, 'lr':     0.0010, 'eps_e':     0.2654, 'lr_e':     0.0010})
Step:  147000, Reward:  -197.973 [ 136.340], Avg:  -226.255 (0.263) <0-05:16:31> ({'r_t':  -756.5248, 'eps':     0.2627, 'dyn_loss':    10.7472, 'dot_loss':     0.7338, 'ddot_loss':     1.4343, 'rew_loss':   108.5716, 'lr':     0.0010, 'eps_e':     0.2627, 'lr_e':     0.0010})
Step:  148000, Reward:  -311.800 [ 360.423], Avg:  -226.829 (0.260) <0-05:18:51> ({'r_t':  -915.5949, 'eps':     0.2601, 'dyn_loss':    11.2014, 'dot_loss':     0.7354, 'ddot_loss':     1.4308, 'rew_loss':   119.4377, 'lr':     0.0010, 'eps_e':     0.2601, 'lr_e':     0.0010})
Step:  149000, Reward:  -192.354 [ 144.907], Avg:  -226.599 (0.257) <0-05:21:11> ({'r_t':  -783.2620, 'eps':     0.2575, 'dyn_loss':    11.6332, 'dot_loss':     0.7357, 'ddot_loss':     1.4277, 'rew_loss':   104.6549, 'lr':     0.0010, 'eps_e':     0.2575, 'lr_e':     0.0010})
Step:  150000, Reward:  -144.401 [  86.304], Avg:  -226.055 (0.255) <0-05:23:14> ({'r_t':  -907.8758, 'eps':     0.2549, 'dyn_loss':    10.4650, 'dot_loss':     0.7202, 'ddot_loss':     1.3994, 'rew_loss':   109.5083, 'lr':     0.0010, 'eps_e':     0.2549, 'lr_e':     0.0010})
Step:  151000, Reward:  -184.635 [ 130.817], Avg:  -225.783 (0.252) <0-05:25:22> ({'r_t':  -962.4195, 'eps':     0.2524, 'dyn_loss':    12.2030, 'dot_loss':     0.7564, 'ddot_loss':     1.4624, 'rew_loss':   109.9815, 'lr':     0.0010, 'eps_e':     0.2524, 'lr_e':     0.0010})
Step:  152000, Reward:  -310.863 [ 447.011], Avg:  -226.339 (0.250) <0-05:27:42> ({'r_t':  -949.6233, 'eps':     0.2498, 'dyn_loss':    10.8676, 'dot_loss':     0.7178, 'ddot_loss':     1.3901, 'rew_loss':   116.5032, 'lr':     0.0010, 'eps_e':     0.2498, 'lr_e':     0.0010})
Step:  153000, Reward:  -230.247 [ 185.361], Avg:  -226.364 (0.247) <0-05:30:01> ({'r_t':  -734.8084, 'eps':     0.2473, 'dyn_loss':    14.4532, 'dot_loss':     0.7695, 'ddot_loss':     1.4700, 'rew_loss':    96.6820, 'lr':     0.0010, 'eps_e':     0.2473, 'lr_e':     0.0010})
Step:  154000, Reward:  -210.026 [ 140.121], Avg:  -226.259 (0.245) <0-05:32:10> ({'r_t':  -814.9843, 'eps':     0.2449, 'dyn_loss':  7138.8740, 'dot_loss':    91.4536, 'ddot_loss':    18.9575, 'rew_loss':   113.2778, 'lr':     0.0010, 'eps_e':     0.2449, 'lr_e':     0.0010})
Step:  155000, Reward:  -116.950 [  64.913], Avg:  -225.558 (0.242) <0-05:34:11> ({'r_t': -1170.2563, 'eps':     0.2424, 'dyn_loss': 946122.1250, 'dot_loss':  8673.5977, 'ddot_loss':   880.3267, 'rew_loss':    98.0006, 'lr':     0.0010, 'eps_e':     0.2424, 'lr_e':     0.0010})
Step:  156000, Reward:  -167.805 [ 129.158], Avg:  -225.190 (0.240) <0-05:36:29> ({'r_t': -1073.6236, 'eps':     0.2400, 'dyn_loss': 636651.8750, 'dot_loss': 10093.0742, 'ddot_loss':  1038.2831, 'rew_loss':   109.1070, 'lr':     0.0010, 'eps_e':     0.2400, 'lr_e':     0.0010})
Step:  157000, Reward:  -157.935 [ 124.554], Avg:  -224.764 (0.238) <0-05:38:43> ({'r_t': -1055.7939, 'eps':     0.2376, 'dyn_loss': 806113.8750, 'dot_loss': 11830.0723, 'ddot_loss':  1229.3524, 'rew_loss':    92.3618, 'lr':     0.0010, 'eps_e':     0.2376, 'lr_e':     0.0010})
Step:  158000, Reward:  -146.129 [ 127.416], Avg:  -224.270 (0.235) <0-05:40:53> ({'r_t': -1096.1535, 'eps':     0.2352, 'dyn_loss': 1548404.5000, 'dot_loss': 15804.9277, 'ddot_loss':  1524.9213, 'rew_loss':   115.5221, 'lr':     0.0010, 'eps_e':     0.2352, 'lr_e':     0.0010})
Step:  159000, Reward:  -152.734 [  97.933], Avg:  -223.823 (0.233) <0-05:42:59> ({'r_t': -1120.2873, 'eps':     0.2329, 'dyn_loss': 451817.0938, 'dot_loss': 10046.6416, 'ddot_loss':  1462.3276, 'rew_loss':   100.5066, 'lr':     0.0010, 'eps_e':     0.2329, 'lr_e':     0.0010})
Step:  160000, Reward:  -135.750 [ 110.627], Avg:  -223.276 (0.231) <0-05:45:05> ({'r_t': -1121.2093, 'eps':     0.2305, 'dyn_loss': 396247.3125, 'dot_loss': 10185.6113, 'ddot_loss':  1507.1040, 'rew_loss':   106.2427, 'lr':     0.0010, 'eps_e':     0.2305, 'lr_e':     0.0010})
Step:  161000, Reward:  -156.008 [ 106.101], Avg:  -222.860 (0.228) <0-05:47:13> ({'r_t': -1094.7591, 'eps':     0.2282, 'dyn_loss': 793059.0625, 'dot_loss': 12561.5107, 'ddot_loss':  1609.3188, 'rew_loss':   100.4639, 'lr':     0.0010, 'eps_e':     0.2282, 'lr_e':     0.0010})
Step:  162000, Reward:  -120.257 [  65.231], Avg:  -222.231 (0.226) <0-05:49:17> ({'r_t': -1067.0573, 'eps':     0.2259, 'dyn_loss': 769218.1250, 'dot_loss': 16261.4004, 'ddot_loss':  2055.3389, 'rew_loss':   105.1244, 'lr':     0.0010, 'eps_e':     0.2259, 'lr_e':     0.0010})
Step:  163000, Reward:  -168.229 [ 139.248], Avg:  -221.902 (0.224) <0-05:51:28> ({'r_t': -1073.6296, 'eps':     0.2237, 'dyn_loss': 1256717.0000, 'dot_loss': 19541.9805, 'ddot_loss':  2087.2234, 'rew_loss':    96.7886, 'lr':     0.0010, 'eps_e':     0.2237, 'lr_e':     0.0010})
Step:  164000, Reward:  -148.626 [ 176.475], Avg:  -221.458 (0.221) <0-05:53:48> ({'r_t': -1103.1871, 'eps':     0.2215, 'dyn_loss': 3625756.2500, 'dot_loss': 38322.2461, 'ddot_loss':  3505.0413, 'rew_loss':   106.0478, 'lr':     0.0010, 'eps_e':     0.2215, 'lr_e':     0.0010})
Step:  165000, Reward:  -162.634 [ 126.076], Avg:  -221.103 (0.219) <0-05:56:03> ({'r_t': -1089.6799, 'eps':     0.2192, 'dyn_loss': 6635664.0000, 'dot_loss': 54706.1406, 'ddot_loss':  4145.3584, 'rew_loss':    97.3030, 'lr':     0.0010, 'eps_e':     0.2192, 'lr_e':     0.0010})
Step:  166000, Reward:  -144.833 [ 116.325], Avg:  -220.647 (0.217) <0-05:58:21> ({'r_t': -1084.3240, 'eps':     0.2170, 'dyn_loss': 3864488.7500, 'dot_loss': 56683.0703, 'ddot_loss':  4898.6064, 'rew_loss':    91.1536, 'lr':     0.0010, 'eps_e':     0.2170, 'lr_e':     0.0010})
Step:  167000, Reward:  -110.308 [  54.149], Avg:  -219.990 (0.215) <0-06:00:22> ({'r_t': -1050.0470, 'eps':     0.2149, 'dyn_loss': 3501268.2500, 'dot_loss': 59392.6055, 'ddot_loss':  4816.8457, 'rew_loss':    92.4705, 'lr':     0.0010, 'eps_e':     0.2149, 'lr_e':     0.0010})
Step:  168000, Reward:  -175.386 [  88.475], Avg:  -219.726 (0.213) <0-06:02:24> ({'r_t': -1078.6225, 'eps':     0.2127, 'dyn_loss': 11319539.0000, 'dot_loss': 96507.8359, 'ddot_loss':  6153.3394, 'rew_loss':   100.0234, 'lr':     0.0010, 'eps_e':     0.2127, 'lr_e':     0.0010})
Step:  169000, Reward:  -144.213 [  87.273], Avg:  -219.282 (0.211) <0-06:04:30> ({'r_t': -1121.6210, 'eps':     0.2106, 'dyn_loss': 14315524.0000, 'dot_loss': 118297.7266, 'ddot_loss': 10351.1914, 'rew_loss':    98.2268, 'lr':     0.0010, 'eps_e':     0.2106, 'lr_e':     0.0010})
Step:  170000, Reward:  -132.768 [  64.395], Avg:  -218.776 (0.208) <0-06:06:27> ({'r_t': -1093.9731, 'eps':     0.2085, 'dyn_loss': 29159734.0000, 'dot_loss': 205875.3594, 'ddot_loss': 13035.4570, 'rew_loss':   105.8000, 'lr':     0.0010, 'eps_e':     0.2085, 'lr_e':     0.0010})
Step:  171000, Reward:  -132.800 [  86.013], Avg:  -218.276 (0.206) <0-06:08:39> ({'r_t': -1080.7487, 'eps':     0.2064, 'dyn_loss': 34106332.0000, 'dot_loss': 207065.2656, 'ddot_loss': 10669.4434, 'rew_loss':    96.7482, 'lr':     0.0010, 'eps_e':     0.2064, 'lr_e':     0.0010})
Step:  172000, Reward:  -147.780 [  94.480], Avg:  -217.868 (0.204) <0-06:10:47> ({'r_t': -1023.9015, 'eps':     0.2043, 'dyn_loss': 22364782.0000, 'dot_loss': 136935.7656, 'ddot_loss':  8828.8770, 'rew_loss':   100.7383, 'lr':     0.0010, 'eps_e':     0.2043, 'lr_e':     0.0010})
Step:  173000, Reward:  -145.800 [ 130.616], Avg:  -217.454 (0.202) <0-06:12:51> ({'r_t': -1057.2270, 'eps':     0.2023, 'dyn_loss': 12554856.0000, 'dot_loss': 127099.5469, 'ddot_loss':  7960.3262, 'rew_loss':   104.8743, 'lr':     0.0010, 'eps_e':     0.2023, 'lr_e':     0.0010})
Step:  174000, Reward:  -144.432 [  96.322], Avg:  -217.037 (0.200) <0-06:14:50> ({'r_t': -1033.8361, 'eps':     0.2003, 'dyn_loss': 15529667.0000, 'dot_loss': 89063.9766, 'ddot_loss':  4990.7012, 'rew_loss':    89.8578, 'lr':     0.0010, 'eps_e':     0.2003, 'lr_e':     0.0010})
Step:  175000, Reward:  -140.944 [ 114.849], Avg:  -216.605 (0.198) <0-06:16:56> ({'r_t': -1144.4179, 'eps':     0.1983, 'dyn_loss': 8250745.0000, 'dot_loss': 69502.8438, 'ddot_loss':  5122.7441, 'rew_loss':    95.1527, 'lr':     0.0010, 'eps_e':     0.1983, 'lr_e':     0.0010})
Step:  176000, Reward:  -115.898 [  98.310], Avg:  -216.036 (0.196) <0-06:19:02> ({'r_t': -1095.3912, 'eps':     0.1963, 'dyn_loss': 17354384.0000, 'dot_loss': 146100.9375, 'ddot_loss':  9379.4180, 'rew_loss':    93.2524, 'lr':     0.0010, 'eps_e':     0.1963, 'lr_e':     0.0010})
Step:  177000, Reward:  -151.472 [  96.674], Avg:  -215.673 (0.194) <0-06:21:04> ({'r_t': -1090.9628, 'eps':     0.1943, 'dyn_loss': 17476140.0000, 'dot_loss': 122998.1562, 'ddot_loss':  7700.0781, 'rew_loss':   100.0845, 'lr':     0.0010, 'eps_e':     0.1943, 'lr_e':     0.0010})
Step:  178000, Reward:  -111.757 [  76.251], Avg:  -215.092 (0.192) <0-06:23:02> ({'r_t': -1094.6807, 'eps':     0.1924, 'dyn_loss': 45188932.0000, 'dot_loss': 387597.6250, 'ddot_loss': 14799.0947, 'rew_loss':    98.1815, 'lr':     0.0010, 'eps_e':     0.1924, 'lr_e':     0.0010})
Step:  179000, Reward:  -121.902 [  73.226], Avg:  -214.575 (0.190) <0-06:25:04> ({'r_t': -1147.1116, 'eps':     0.1905, 'dyn_loss': 29204888.0000, 'dot_loss': 303920.1250, 'ddot_loss': 13062.7324, 'rew_loss':    97.8145, 'lr':     0.0010, 'eps_e':     0.1905, 'lr_e':     0.0010})
Step:  180000, Reward:  -105.371 [  53.123], Avg:  -213.971 (0.189) <0-06:27:00> ({'r_t': -1081.6706, 'eps':     0.1886, 'dyn_loss': 247858416.0000, 'dot_loss': 880275.5625, 'ddot_loss': 10040.7764, 'rew_loss':    90.8191, 'lr':     0.0010, 'eps_e':     0.1886, 'lr_e':     0.0010})
Step:  181000, Reward:   -82.187 [  39.237], Avg:  -213.247 (0.187) <0-06:28:51> ({'r_t': -1097.8838, 'eps':     0.1867, 'dyn_loss': 482726304.0000, 'dot_loss': 1496833.1250, 'ddot_loss':  9992.8418, 'rew_loss':    99.1954, 'lr':     0.0010, 'eps_e':     0.1867, 'lr_e':     0.0010})
Step:  182000, Reward:  -146.144 [ 123.091], Avg:  -212.881 (0.185) <0-06:30:55> ({'r_t': -1044.0847, 'eps':     0.1848, 'dyn_loss': 69515528.0000, 'dot_loss': 337789.7188, 'ddot_loss':  9158.0059, 'rew_loss':    99.4733, 'lr':     0.0010, 'eps_e':     0.1848, 'lr_e':     0.0010})
Step:  183000, Reward:  -226.748 [ 204.210], Avg:  -212.956 (0.183) <0-06:33:11> ({'r_t': -1091.3770, 'eps':     0.1830, 'dyn_loss': 236835248.0000, 'dot_loss': 755410.9375, 'ddot_loss':  9361.4902, 'rew_loss':    90.3478, 'lr':     0.0010, 'eps_e':     0.1830, 'lr_e':     0.0010})
Step:  184000, Reward:  -161.230 [ 121.178], Avg:  -212.676 (0.181) <0-06:35:28> ({'r_t': -1109.2957, 'eps':     0.1811, 'dyn_loss': 83182920.0000, 'dot_loss': 334481.5938, 'ddot_loss': 10319.0508, 'rew_loss':    81.7749, 'lr':     0.0010, 'eps_e':     0.1811, 'lr_e':     0.0010})
Step:  185000, Reward:  -127.368 [ 108.590], Avg:  -212.218 (0.179) <0-06:37:39> ({'r_t': -1052.4431, 'eps':     0.1793, 'dyn_loss': 71424616.0000, 'dot_loss': 230886.3594, 'ddot_loss':  9852.7891, 'rew_loss':    80.3189, 'lr':     0.0010, 'eps_e':     0.1793, 'lr_e':     0.0010})
Step:  186000, Reward:  -104.777 [  61.737], Avg:  -211.643 (0.178) <0-06:39:38> ({'r_t': -1084.8907, 'eps':     0.1775, 'dyn_loss': 137656736.0000, 'dot_loss': 408536.8750, 'ddot_loss': 11615.8223, 'rew_loss':    92.5324, 'lr':     0.0010, 'eps_e':     0.1775, 'lr_e':     0.0010})
Step:  187000, Reward:  -121.142 [  92.866], Avg:  -211.162 (0.176) <0-06:41:39> ({'r_t': -1114.5837, 'eps':     0.1757, 'dyn_loss': 86395328.0000, 'dot_loss': 406704.8125, 'ddot_loss': 16192.0342, 'rew_loss':    75.3819, 'lr':     0.0010, 'eps_e':     0.1757, 'lr_e':     0.0010})
Step:  188000, Reward:  -110.290 [ 100.400], Avg:  -210.628 (0.174) <0-06:43:39> ({'r_t': -1128.3871, 'eps':     0.1740, 'dyn_loss': 62092048.0000, 'dot_loss': 302097.3125, 'ddot_loss': 15501.9307, 'rew_loss':    84.6911, 'lr':     0.0010, 'eps_e':     0.1740, 'lr_e':     0.0010})
Step:  189000, Reward:  -117.566 [  84.010], Avg:  -210.138 (0.172) <0-06:45:47> ({'r_t': -1108.1885, 'eps':     0.1722, 'dyn_loss': 145706992.0000, 'dot_loss': 690110.8750, 'ddot_loss': 23326.0254, 'rew_loss':    89.0572, 'lr':     0.0010, 'eps_e':     0.1722, 'lr_e':     0.0010})
Step:  190000, Reward:  -133.901 [ 130.539], Avg:  -209.739 (0.171) <0-06:48:02> ({'r_t': -1117.5847, 'eps':     0.1705, 'dyn_loss': 285700000.0000, 'dot_loss': 1184613.2500, 'ddot_loss': 31295.1367, 'rew_loss':    92.1820, 'lr':     0.0010, 'eps_e':     0.1705, 'lr_e':     0.0010})
Step:  191000, Reward:  -126.838 [ 103.953], Avg:  -209.307 (0.169) <0-06:50:05> ({'r_t': -1095.5015, 'eps':     0.1688, 'dyn_loss': 131233952.0000, 'dot_loss': 942425.1250, 'ddot_loss': 40811.9727, 'rew_loss':    83.6901, 'lr':     0.0010, 'eps_e':     0.1688, 'lr_e':     0.0010})
Step:  192000, Reward:   -96.770 [  54.607], Avg:  -208.724 (0.167) <0-06:51:55> ({'r_t': -1078.2136, 'eps':     0.1671, 'dyn_loss': 66941936.0000, 'dot_loss': 514572.0938, 'ddot_loss': 33785.0039, 'rew_loss':    77.6709, 'lr':     0.0010, 'eps_e':     0.1671, 'lr_e':     0.0010})
Step:  193000, Reward:  -134.252 [  73.202], Avg:  -208.340 (0.165) <0-06:53:57> ({'r_t': -1114.4593, 'eps':     0.1655, 'dyn_loss': 92595048.0000, 'dot_loss': 631006.3750, 'ddot_loss': 33111.2227, 'rew_loss':    73.2575, 'lr':     0.0010, 'eps_e':     0.1655, 'lr_e':     0.0010})
Step:  194000, Reward:  -167.022 [ 155.468], Avg:  -208.128 (0.164) <0-06:56:10> ({'r_t': -1091.4609, 'eps':     0.1638, 'dyn_loss': 133947632.0000, 'dot_loss': 915013.1250, 'ddot_loss': 34158.4766, 'rew_loss':    79.0875, 'lr':     0.0010, 'eps_e':     0.1638, 'lr_e':     0.0010})
Step:  195000, Reward:  -113.335 [  77.312], Avg:  -207.645 (0.162) <0-06:58:19> ({'r_t': -1110.9866, 'eps':     0.1622, 'dyn_loss': 156605680.0000, 'dot_loss': 863979.0000, 'ddot_loss': 32270.3184, 'rew_loss':    78.1714, 'lr':     0.0010, 'eps_e':     0.1622, 'lr_e':     0.0010})
Step:  196000, Reward:  -138.923 [ 136.868], Avg:  -207.296 (0.161) <0-07:00:29> ({'r_t': -1075.5045, 'eps':     0.1605, 'dyn_loss': 137430720.0000, 'dot_loss': 781286.3750, 'ddot_loss': 34390.8711, 'rew_loss':   101.0683, 'lr':     0.0010, 'eps_e':     0.1605, 'lr_e':     0.0010})
Step:  197000, Reward:  -129.581 [  74.773], Avg:  -206.903 (0.159) <0-07:02:27> ({'r_t': -1071.7379, 'eps':     0.1589, 'dyn_loss': 60425840.0000, 'dot_loss': 649501.6250, 'ddot_loss': 36413.9648, 'rew_loss':    78.2874, 'lr':     0.0010, 'eps_e':     0.1589, 'lr_e':     0.0010})
Step:  198000, Reward:  -135.194 [ 114.663], Avg:  -206.543 (0.157) <0-07:04:36> ({'r_t': -1077.9070, 'eps':     0.1574, 'dyn_loss': 51558252.0000, 'dot_loss': 530960.2500, 'ddot_loss': 32018.7051, 'rew_loss':    77.8110, 'lr':     0.0010, 'eps_e':     0.1574, 'lr_e':     0.0010})
Step:  199000, Reward:  -116.428 [  81.474], Avg:  -206.092 (0.156) <0-07:06:36> ({'r_t': -1079.6019, 'eps':     0.1558, 'dyn_loss': 59020876.0000, 'dot_loss': 757180.9375, 'ddot_loss': 43970.3711, 'rew_loss':    77.6484, 'lr':     0.0010, 'eps_e':     0.1558, 'lr_e':     0.0010})
Step:  200000, Reward:  -164.751 [ 149.867], Avg:  -205.887 (0.154) <0-07:08:48> ({'r_t': -1069.0535, 'eps':     0.1542, 'dyn_loss': 182505008.0000, 'dot_loss': 1008990.5625, 'ddot_loss': 41332.9766, 'rew_loss':    83.4793, 'lr':     0.0010, 'eps_e':     0.1542, 'lr_e':     0.0010})
Step:  201000, Reward:  -142.984 [ 139.212], Avg:  -205.575 (0.153) <0-07:10:56> ({'r_t': -1089.9071, 'eps':     0.1527, 'dyn_loss': 146534528.0000, 'dot_loss': 508045.2188, 'ddot_loss': 17692.7148, 'rew_loss':    82.6959, 'lr':     0.0010, 'eps_e':     0.1527, 'lr_e':     0.0010})
Step:  202000, Reward:  -124.577 [  69.918], Avg:  -205.176 (0.151) <0-07:12:53> ({'r_t': -1116.9725, 'eps':     0.1512, 'dyn_loss': 164486368.0000, 'dot_loss': 1439858.8750, 'ddot_loss': 38120.9258, 'rew_loss':    74.7449, 'lr':     0.0010, 'eps_e':     0.1512, 'lr_e':     0.0010})
Step:  203000, Reward:  -130.801 [ 104.351], Avg:  -204.812 (0.150) <0-07:14:55> ({'r_t': -1067.2372, 'eps':     0.1496, 'dyn_loss': 105768752.0000, 'dot_loss': 1009281.7500, 'ddot_loss': 32458.0410, 'rew_loss':    95.4286, 'lr':     0.0010, 'eps_e':     0.1496, 'lr_e':     0.0010})
Step:  204000, Reward:  -188.294 [ 169.367], Avg:  -204.731 (0.148) <0-07:17:11> ({'r_t': -1038.1633, 'eps':     0.1481, 'dyn_loss': 65258024.0000, 'dot_loss': 584743.7500, 'ddot_loss': 24696.0879, 'rew_loss':    73.7451, 'lr':     0.0010, 'eps_e':     0.1481, 'lr_e':     0.0010})
Step:  205000, Reward:   -88.604 [  43.297], Avg:  -204.168 (0.147) <0-07:19:05> ({'r_t': -1103.7819, 'eps':     0.1467, 'dyn_loss': 132727160.0000, 'dot_loss': 631589.9375, 'ddot_loss': 20403.9824, 'rew_loss':    83.5113, 'lr':     0.0010, 'eps_e':     0.1467, 'lr_e':     0.0010})
Step:  206000, Reward:  -135.179 [ 104.632], Avg:  -203.834 (0.145) <0-07:21:06> ({'r_t': -1126.6048, 'eps':     0.1452, 'dyn_loss': 63945296.0000, 'dot_loss': 727686.8125, 'ddot_loss': 29364.9941, 'rew_loss':    81.4240, 'lr':     0.0010, 'eps_e':     0.1452, 'lr_e':     0.0010})
Step:  207000, Reward:  -159.431 [ 125.667], Avg:  -203.621 (0.144) <0-07:23:17> ({'r_t': -1091.7103, 'eps':     0.1437, 'dyn_loss': 94647864.0000, 'dot_loss': 647717.6250, 'ddot_loss': 25665.4746, 'rew_loss':    78.7491, 'lr':     0.0010, 'eps_e':     0.1437, 'lr_e':     0.0010})
Step:  208000, Reward:  -136.521 [ 130.823], Avg:  -203.300 (0.142) <0-07:25:35> ({'r_t': -1088.7760, 'eps':     0.1423, 'dyn_loss': 58204476.0000, 'dot_loss': 598041.8125, 'ddot_loss': 27076.7949, 'rew_loss':    89.6076, 'lr':     0.0010, 'eps_e':     0.1423, 'lr_e':     0.0010})
Step:  209000, Reward:   -96.253 [  62.057], Avg:  -202.790 (0.141) <0-07:27:35> ({'r_t': -1095.9043, 'eps':     0.1409, 'dyn_loss': 489268512.0000, 'dot_loss': 1715572.1250, 'ddot_loss': 29120.8750, 'rew_loss':    82.5215, 'lr':     0.0010, 'eps_e':     0.1409, 'lr_e':     0.0010})
Step:  210000, Reward:  -117.243 [  64.753], Avg:  -202.385 (0.139) <0-07:29:32> ({'r_t': -1092.4248, 'eps':     0.1395, 'dyn_loss': 367767744.0000, 'dot_loss': 1220242.2500, 'ddot_loss': 26991.1543, 'rew_loss':    65.6392, 'lr':     0.0010, 'eps_e':     0.1395, 'lr_e':     0.0010})
Step:  211000, Reward:  -131.097 [ 122.076], Avg:  -202.048 (0.138) <0-07:31:34> ({'r_t': -1027.4092, 'eps':     0.1381, 'dyn_loss': 210320336.0000, 'dot_loss': 730901.3750, 'ddot_loss': 24363.4707, 'rew_loss':    81.4217, 'lr':     0.0010, 'eps_e':     0.1381, 'lr_e':     0.0010})
Step:  212000, Reward:  -111.445 [  94.115], Avg:  -201.623 (0.137) <0-07:33:41> ({'r_t': -1072.4861, 'eps':     0.1367, 'dyn_loss': 142919776.0000, 'dot_loss': 817043.9375, 'ddot_loss': 31714.9668, 'rew_loss':    78.8076, 'lr':     0.0010, 'eps_e':     0.1367, 'lr_e':     0.0010})
Step:  213000, Reward:   -98.511 [  62.519], Avg:  -201.141 (0.135) <0-07:35:42> ({'r_t': -1087.2440, 'eps':     0.1353, 'dyn_loss': 175865408.0000, 'dot_loss': 1025252.5625, 'ddot_loss': 34853.9922, 'rew_loss':    75.5187, 'lr':     0.0010, 'eps_e':     0.1353, 'lr_e':     0.0010})
Step:  214000, Reward:  -108.670 [  63.560], Avg:  -200.711 (0.134) <0-07:37:41> ({'r_t': -1100.7877, 'eps':     0.1340, 'dyn_loss': 283235776.0000, 'dot_loss': 912508.2500, 'ddot_loss': 26031.6621, 'rew_loss':    74.5236, 'lr':     0.0010, 'eps_e':     0.1340, 'lr_e':     0.0010})
Step:  215000, Reward:   -93.865 [  42.926], Avg:  -200.216 (0.133) <0-07:39:33> ({'r_t': -1017.3773, 'eps':     0.1326, 'dyn_loss': 170447136.0000, 'dot_loss': 614307.7500, 'ddot_loss': 24204.3965, 'rew_loss':    89.3733, 'lr':     0.0010, 'eps_e':     0.1326, 'lr_e':     0.0010})
Step:  216000, Reward:  -150.275 [ 102.143], Avg:  -199.986 (0.131) <0-07:41:39> ({'r_t': -1027.1096, 'eps':     0.1313, 'dyn_loss': 182870432.0000, 'dot_loss': 809202.3750, 'ddot_loss': 29842.3672, 'rew_loss':    65.7830, 'lr':     0.0010, 'eps_e':     0.1313, 'lr_e':     0.0010})
Step:  217000, Reward:   -96.311 [  54.561], Avg:  -199.511 (0.130) <0-07:43:35> ({'r_t': -1068.1065, 'eps':     0.1300, 'dyn_loss': 206028432.0000, 'dot_loss': 1051196.7500, 'ddot_loss': 34951.6172, 'rew_loss':    65.1068, 'lr':     0.0010, 'eps_e':     0.1300, 'lr_e':     0.0010})
Step:  218000, Reward:  -163.541 [ 100.840], Avg:  -199.346 (0.129) <0-07:45:38> ({'r_t': -1046.7403, 'eps':     0.1287, 'dyn_loss': 254698080.0000, 'dot_loss': 1692811.8750, 'ddot_loss': 56364.9805, 'rew_loss':    76.7467, 'lr':     0.0010, 'eps_e':     0.1287, 'lr_e':     0.0010})
Step:  219000, Reward:  -103.281 [  52.866], Avg:  -198.910 (0.127) <0-07:47:33> ({'r_t': -1082.9091, 'eps':     0.1274, 'dyn_loss': 803482368.0000, 'dot_loss': 3020289.2500, 'ddot_loss': 38125.5586, 'rew_loss':    75.1566, 'lr':     0.0010, 'eps_e':     0.1274, 'lr_e':     0.0010})
Step:  220000, Reward:  -127.085 [  83.884], Avg:  -198.585 (0.126) <0-07:49:39> ({'r_t': -1072.9297, 'eps':     0.1261, 'dyn_loss': 280028512.0000, 'dot_loss': 1100433.1250, 'ddot_loss': 23472.1621, 'rew_loss':    64.3280, 'lr':     0.0010, 'eps_e':     0.1261, 'lr_e':     0.0010})
Step:  221000, Reward:  -106.538 [  79.887], Avg:  -198.170 (0.125) <0-07:51:38> ({'r_t': -1060.3834, 'eps':     0.1249, 'dyn_loss': 502215232.0000, 'dot_loss': 1712540.7500, 'ddot_loss': 31681.4844, 'rew_loss':    76.0745, 'lr':     0.0010, 'eps_e':     0.1249, 'lr_e':     0.0010})
Step:  222000, Reward:   -98.469 [  44.235], Avg:  -197.723 (0.124) <0-07:53:30> ({'r_t': -1054.4948, 'eps':     0.1236, 'dyn_loss': 157667744.0000, 'dot_loss': 994916.2500, 'ddot_loss': 37863.6016, 'rew_loss':    77.9270, 'lr':     0.0010, 'eps_e':     0.1236, 'lr_e':     0.0010})
Step:  223000, Reward:  -112.997 [  84.171], Avg:  -197.345 (0.122) <0-07:55:33> ({'r_t': -1066.4902, 'eps':     0.1224, 'dyn_loss': 148714560.0000, 'dot_loss': 1079379.2500, 'ddot_loss': 44032.2109, 'rew_loss':    76.6502, 'lr':     0.0010, 'eps_e':     0.1224, 'lr_e':     0.0010})
Step:  224000, Reward:  -138.178 [ 159.515], Avg:  -197.082 (0.121) <0-07:57:52> ({'r_t': -1036.8501, 'eps':     0.1212, 'dyn_loss': 153753072.0000, 'dot_loss': 1359002.7500, 'ddot_loss': 45062.0430, 'rew_loss':    80.2080, 'lr':     0.0010, 'eps_e':     0.1212, 'lr_e':     0.0010})
Step:  225000, Reward:   -92.186 [  53.985], Avg:  -196.618 (0.120) <0-07:59:47> ({'r_t': -1050.2029, 'eps':     0.1200, 'dyn_loss': 116659488.0000, 'dot_loss': 1118361.5000, 'ddot_loss': 36572.6250, 'rew_loss':    71.0572, 'lr':     0.0010, 'eps_e':     0.1200, 'lr_e':     0.0010})
Step:  226000, Reward:   -95.669 [  68.120], Avg:  -196.173 (0.119) <0-08:01:41> ({'r_t': -1110.6815, 'eps':     0.1188, 'dyn_loss': 316152832.0000, 'dot_loss': 949099.3750, 'ddot_loss': 25089.8457, 'rew_loss':    78.2930, 'lr':     0.0010, 'eps_e':     0.1188, 'lr_e':     0.0010})
Step:  227000, Reward:   -87.493 [  48.398], Avg:  -195.696 (0.118) <0-08:03:34> ({'r_t': -1075.4034, 'eps':     0.1176, 'dyn_loss': 382088896.0000, 'dot_loss': 1029233.1875, 'ddot_loss': 20169.3320, 'rew_loss':    70.2545, 'lr':     0.0010, 'eps_e':     0.1176, 'lr_e':     0.0010})
Step:  228000, Reward:   -95.283 [  48.238], Avg:  -195.258 (0.116) <0-08:05:28> ({'r_t': -1120.8795, 'eps':     0.1164, 'dyn_loss': 898667904.0000, 'dot_loss': 2655679.7500, 'ddot_loss': 23870.8047, 'rew_loss':    78.3231, 'lr':     0.0010, 'eps_e':     0.1164, 'lr_e':     0.0010})
Step:  229000, Reward:  -197.931 [ 167.299], Avg:  -195.269 (0.115) <0-08:07:47> ({'r_t': -1034.7577, 'eps':     0.1152, 'dyn_loss': 482870560.0000, 'dot_loss': 1645111.0000, 'ddot_loss': 28358.4570, 'rew_loss':    71.3964, 'lr':     0.0010, 'eps_e':     0.1152, 'lr_e':     0.0010})
Step:  230000, Reward:   -89.086 [  34.047], Avg:  -194.810 (0.114) <0-08:09:38> ({'r_t': -1065.3779, 'eps':     0.1141, 'dyn_loss': 210637408.0000, 'dot_loss': 943916.7500, 'ddot_loss': 31778.5605, 'rew_loss':    78.0423, 'lr':     0.0010, 'eps_e':     0.1141, 'lr_e':     0.0010})
Step:  231000, Reward:  -151.608 [  96.284], Avg:  -194.623 (0.113) <0-08:11:42> ({'r_t': -1077.8856, 'eps':     0.1129, 'dyn_loss': 348327232.0000, 'dot_loss': 2345918.5000, 'ddot_loss': 58178.0156, 'rew_loss':    76.2708, 'lr':     0.0010, 'eps_e':     0.1129, 'lr_e':     0.0010})
Step:  232000, Reward:   -94.195 [  51.199], Avg:  -194.192 (0.112) <0-08:13:37> ({'r_t': -1089.3401, 'eps':     0.1118, 'dyn_loss': 525175168.0000, 'dot_loss': 3335695.2500, 'ddot_loss': 81121.7578, 'rew_loss':    63.1398, 'lr':     0.0010, 'eps_e':     0.1118, 'lr_e':     0.0010})
Step:  233000, Reward:  -123.627 [  87.697], Avg:  -193.891 (0.111) <0-08:15:38> ({'r_t': -1040.0741, 'eps':     0.1107, 'dyn_loss': 406619264.0000, 'dot_loss': 2076472.5000, 'ddot_loss': 63590.5703, 'rew_loss':    70.8814, 'lr':     0.0010, 'eps_e':     0.1107, 'lr_e':     0.0010})
Step:  234000, Reward:  -121.821 [  83.124], Avg:  -193.584 (0.110) <0-08:17:40> ({'r_t': -1044.8354, 'eps':     0.1096, 'dyn_loss': 1823876096.0000, 'dot_loss': 5582727.0000, 'ddot_loss': 68228.7812, 'rew_loss':    73.8484, 'lr':     0.0010, 'eps_e':     0.1096, 'lr_e':     0.0010})
Step:  235000, Reward:  -103.666 [  61.065], Avg:  -193.203 (0.108) <0-08:19:33> ({'r_t': -1046.6187, 'eps':     0.1085, 'dyn_loss': 1469825408.0000, 'dot_loss': 4449470.5000, 'ddot_loss': 66984.1797, 'rew_loss':    70.9587, 'lr':     0.0010, 'eps_e':     0.1085, 'lr_e':     0.0010})
Step:  236000, Reward:  -129.245 [  71.654], Avg:  -192.933 (0.107) <0-08:21:27> ({'r_t': -1051.3969, 'eps':     0.1074, 'dyn_loss': 781106816.0000, 'dot_loss': 2682486.5000, 'ddot_loss': 68510.5391, 'rew_loss':    65.4791, 'lr':     0.0010, 'eps_e':     0.1074, 'lr_e':     0.0010})
Step:  237000, Reward:  -101.077 [  51.595], Avg:  -192.547 (0.106) <0-08:23:22> ({'r_t': -1077.4916, 'eps':     0.1063, 'dyn_loss': 418856800.0000, 'dot_loss': 2100424.7500, 'ddot_loss': 72473.2266, 'rew_loss':    57.6967, 'lr':     0.0010, 'eps_e':     0.1063, 'lr_e':     0.0010})
Step:  238000, Reward:  -119.383 [  87.157], Avg:  -192.241 (0.105) <0-08:25:30> ({'r_t': -1021.7269, 'eps':     0.1053, 'dyn_loss': 877606016.0000, 'dot_loss': 3134719.2500, 'ddot_loss': 66456.0391, 'rew_loss':    72.8857, 'lr':     0.0010, 'eps_e':     0.1053, 'lr_e':     0.0010})
Step:  239000, Reward:  -122.313 [  88.035], Avg:  -191.950 (0.104) <0-08:27:42> ({'r_t': -1100.1349, 'eps':     0.1042, 'dyn_loss': 680292864.0000, 'dot_loss': 2740952.2500, 'ddot_loss': 73380.2266, 'rew_loss':    71.2783, 'lr':     0.0010, 'eps_e':     0.1042, 'lr_e':     0.0010})
Step:  240000, Reward:  -102.879 [  87.968], Avg:  -191.580 (0.103) <0-08:29:40> ({'r_t': -1088.6586, 'eps':     0.1032, 'dyn_loss': 474875648.0000, 'dot_loss': 2627284.2500, 'ddot_loss': 74785.9766, 'rew_loss':    71.8576, 'lr':     0.0010, 'eps_e':     0.1032, 'lr_e':     0.0010})
Step:  241000, Reward:  -128.544 [ 125.676], Avg:  -191.320 (0.102) <0-08:31:51> ({'r_t': -1133.4745, 'eps':     0.1021, 'dyn_loss': 246733328.0000, 'dot_loss': 1762261.6250, 'ddot_loss': 70253.1172, 'rew_loss':    72.0561, 'lr':     0.0010, 'eps_e':     0.1021, 'lr_e':     0.0010})
Step:  242000, Reward:  -179.985 [ 132.925], Avg:  -191.273 (0.101) <0-08:33:57> ({'r_t': -1057.6623, 'eps':     0.1011, 'dyn_loss': 450218592.0000, 'dot_loss': 2828705.2500, 'ddot_loss': 74265.6172, 'rew_loss':    85.5893, 'lr':     0.0010, 'eps_e':     0.1011, 'lr_e':     0.0010})
Step:  243000, Reward:   -74.107 [  33.498], Avg:  -190.793 (0.100) <0-08:35:47> ({'r_t': -1044.4767, 'eps':     0.1001, 'dyn_loss': 253111216.0000, 'dot_loss': 2439291.0000, 'ddot_loss': 72781.1406, 'rew_loss':    63.7082, 'lr':     0.0010, 'eps_e':     0.1001, 'lr_e':     0.0010})
Step:  244000, Reward:  -108.264 [  63.992], Avg:  -190.456 (0.100) <0-08:37:51> ({'r_t': -1097.0278, 'eps':     0.1000, 'dyn_loss': 289375104.0000, 'dot_loss': 1279216.3750, 'ddot_loss': 56743.3281, 'rew_loss':    66.9190, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  245000, Reward:   -80.100 [  22.092], Avg:  -190.008 (0.100) <0-08:39:38> ({'r_t': -1054.1131, 'eps':     0.1000, 'dyn_loss': 205768000.0000, 'dot_loss': 972489.2500, 'ddot_loss': 54665.2617, 'rew_loss':    65.7885, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  246000, Reward:   -81.745 [  49.494], Avg:  -189.569 (0.100) <0-08:41:31> ({'r_t': -1063.8944, 'eps':     0.1000, 'dyn_loss': 314306848.0000, 'dot_loss': 1037475.5000, 'ddot_loss': 40196.2617, 'rew_loss':    60.9572, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  247000, Reward:   -86.274 [  56.134], Avg:  -189.153 (0.100) <0-08:43:33> ({'r_t': -1075.2173, 'eps':     0.1000, 'dyn_loss': 1621529216.0000, 'dot_loss': 4879654.5000, 'ddot_loss': 30427.0469, 'rew_loss':    64.0598, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  248000, Reward:  -113.088 [  59.241], Avg:  -188.847 (0.100) <0-08:45:28> ({'r_t': -1032.7040, 'eps':     0.1000, 'dyn_loss': 1053038656.0000, 'dot_loss': 3141640.2500, 'ddot_loss': 32220.2129, 'rew_loss':    71.1039, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  249000, Reward:   -99.380 [  50.000], Avg:  -188.489 (0.100) <0-08:47:25> ({'r_t': -1052.5811, 'eps':     0.1000, 'dyn_loss': 1318389376.0000, 'dot_loss': 3653593.0000, 'ddot_loss': 42718.5586, 'rew_loss':    72.0332, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  250000, Reward:  -116.939 [  72.858], Avg:  -188.204 (0.100) <0-08:49:23> ({'r_t': -1066.3057, 'eps':     0.1000, 'dyn_loss': 702466624.0000, 'dot_loss': 1869250.1250, 'ddot_loss': 35747.9531, 'rew_loss':    61.6388, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  251000, Reward:  -149.838 [ 163.595], Avg:  -188.052 (0.100) <0-08:51:42> ({'r_t': -1112.2394, 'eps':     0.1000, 'dyn_loss': 622728448.0000, 'dot_loss': 2396129.5000, 'ddot_loss': 53415.8086, 'rew_loss':    66.7231, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  252000, Reward:  -166.285 [ 179.022], Avg:  -187.966 (0.100) <0-08:53:58> ({'r_t': -1099.6083, 'eps':     0.1000, 'dyn_loss': 596242688.0000, 'dot_loss': 1735776.8750, 'ddot_loss': 43328.7109, 'rew_loss':    72.3948, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  253000, Reward:   -83.835 [  48.540], Avg:  -187.556 (0.100) <0-08:55:53> ({'r_t': -1038.1216, 'eps':     0.1000, 'dyn_loss': 328467904.0000, 'dot_loss': 1402022.7500, 'ddot_loss': 47920.0312, 'rew_loss':    73.3469, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  254000, Reward:  -116.904 [  73.455], Avg:  -187.279 (0.100) <0-08:57:55> ({'r_t': -1112.5574, 'eps':     0.1000, 'dyn_loss': 1125869184.0000, 'dot_loss': 3415421.5000, 'ddot_loss': 39079.8789, 'rew_loss':    77.6081, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  255000, Reward:   -90.328 [  51.817], Avg:  -186.900 (0.100) <0-08:59:48> ({'r_t': -1052.5415, 'eps':     0.1000, 'dyn_loss': 463125664.0000, 'dot_loss': 1768099.5000, 'ddot_loss': 43328.0312, 'rew_loss':    66.7395, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  256000, Reward:  -124.971 [ 101.146], Avg:  -186.659 (0.100) <0-09:01:56> ({'r_t': -1039.7060, 'eps':     0.1000, 'dyn_loss': 534445376.0000, 'dot_loss': 2655658.0000, 'ddot_loss': 68185.5938, 'rew_loss':    58.0869, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  257000, Reward:   -87.962 [  37.761], Avg:  -186.277 (0.100) <0-09:03:48> ({'r_t': -1046.6875, 'eps':     0.1000, 'dyn_loss': 387777696.0000, 'dot_loss': 2292656.7500, 'ddot_loss': 65740.1797, 'rew_loss':    67.2495, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  258000, Reward:  -112.343 [  86.313], Avg:  -185.991 (0.100) <0-09:05:53> ({'r_t': -1078.0162, 'eps':     0.1000, 'dyn_loss': 775759616.0000, 'dot_loss': 2738092.2500, 'ddot_loss': 52577.3633, 'rew_loss':    62.8865, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  259000, Reward:  -133.493 [ 135.968], Avg:  -185.789 (0.100) <0-09:08:12> ({'r_t': -1025.2788, 'eps':     0.1000, 'dyn_loss': 956562176.0000, 'dot_loss': 3395817.0000, 'ddot_loss': 60787.4961, 'rew_loss':    66.8824, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  260000, Reward:  -124.825 [  96.471], Avg:  -185.556 (0.100) <0-09:10:18> ({'r_t': -1088.2878, 'eps':     0.1000, 'dyn_loss': 1674388480.0000, 'dot_loss': 6128667.0000, 'ddot_loss': 67700.7969, 'rew_loss':    58.3303, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  261000, Reward:   -75.580 [  25.885], Avg:  -185.136 (0.100) <0-09:12:06> ({'r_t': -1054.7131, 'eps':     0.1000, 'dyn_loss': 1407918080.0000, 'dot_loss': 5131466.0000, 'ddot_loss': 72955.2422, 'rew_loss':    69.4418, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  262000, Reward:  -127.469 [ 160.734], Avg:  -184.917 (0.100) <0-09:14:15> ({'r_t': -1081.2098, 'eps':     0.1000, 'dyn_loss': 1168433664.0000, 'dot_loss': 4082222.7500, 'ddot_loss': 57820.9727, 'rew_loss':    62.0843, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  263000, Reward:  -123.232 [ 162.752], Avg:  -184.683 (0.100) <0-09:16:31> ({'r_t': -1096.9596, 'eps':     0.1000, 'dyn_loss': 654102976.0000, 'dot_loss': 2133747.2500, 'ddot_loss': 50792.9648, 'rew_loss':    64.5820, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  264000, Reward:   -82.722 [  35.043], Avg:  -184.298 (0.100) <0-09:18:23> ({'r_t': -1125.9497, 'eps':     0.1000, 'dyn_loss': 521705792.0000, 'dot_loss': 1548051.3750, 'ddot_loss': 46457.6602, 'rew_loss':    55.3502, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  265000, Reward:  -106.979 [ 108.502], Avg:  -184.008 (0.100) <0-09:20:27> ({'r_t': -1141.5170, 'eps':     0.1000, 'dyn_loss': 364529760.0000, 'dot_loss': 1375189.6250, 'ddot_loss': 49424.7695, 'rew_loss':    68.3466, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  266000, Reward:   -86.869 [  65.869], Avg:  -183.644 (0.100) <0-09:22:29> ({'r_t': -1123.9478, 'eps':     0.1000, 'dyn_loss': 460298368.0000, 'dot_loss': 1645629.5000, 'ddot_loss': 48039.0391, 'rew_loss':    65.8305, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  267000, Reward:   -68.997 [  20.002], Avg:  -183.216 (0.100) <0-09:24:16> ({'r_t': -1117.2818, 'eps':     0.1000, 'dyn_loss': 516186112.0000, 'dot_loss': 1760083.5000, 'ddot_loss': 48062.9609, 'rew_loss':    57.7425, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  268000, Reward:   -81.777 [  35.778], Avg:  -182.839 (0.100) <0-09:26:09> ({'r_t': -1135.4218, 'eps':     0.1000, 'dyn_loss': 1040397120.0000, 'dot_loss': 3770819.7500, 'ddot_loss': 68451.8125, 'rew_loss':    65.6164, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  269000, Reward:  -187.025 [ 168.011], Avg:  -182.855 (0.100) <0-09:28:26> ({'r_t': -1075.2190, 'eps':     0.1000, 'dyn_loss': 2463443968.0000, 'dot_loss': 7696875.0000, 'ddot_loss': 73553.0703, 'rew_loss':    68.4707, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  270000, Reward:  -106.210 [  64.775], Avg:  -182.572 (0.100) <0-09:30:26> ({'r_t': -1082.1876, 'eps':     0.1000, 'dyn_loss': 5893605376.0000, 'dot_loss': 19098964.0000, 'ddot_loss': 89594.7812, 'rew_loss':    63.4434, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  271000, Reward:  -115.615 [  77.276], Avg:  -182.326 (0.100) <0-09:32:35> ({'r_t': -1108.0695, 'eps':     0.1000, 'dyn_loss': 7114663424.0000, 'dot_loss': 23412872.0000, 'ddot_loss': 89915.0781, 'rew_loss':    64.7821, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  272000, Reward:  -158.341 [ 158.078], Avg:  -182.238 (0.100) <0-09:34:49> ({'r_t': -1119.3621, 'eps':     0.1000, 'dyn_loss': 4727986688.0000, 'dot_loss': 14699495.0000, 'ddot_loss': 76068.3438, 'rew_loss':    60.4046, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  273000, Reward:  -111.075 [  68.473], Avg:  -181.978 (0.100) <0-09:36:44> ({'r_t': -1106.1415, 'eps':     0.1000, 'dyn_loss': 7326601728.0000, 'dot_loss': 22925046.0000, 'ddot_loss': 82749.9844, 'rew_loss':    55.6687, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  274000, Reward:  -167.769 [ 168.464], Avg:  -181.926 (0.100) <0-09:39:02> ({'r_t': -1102.7295, 'eps':     0.1000, 'dyn_loss': 4334616064.0000, 'dot_loss': 12770400.0000, 'ddot_loss': 78012.8047, 'rew_loss':    76.3464, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  275000, Reward:   -92.964 [  38.922], Avg:  -181.604 (0.100) <0-09:40:55> ({'r_t': -1083.7499, 'eps':     0.1000, 'dyn_loss': 3951882752.0000, 'dot_loss': 11559006.0000, 'ddot_loss': 76054.5312, 'rew_loss':    64.0707, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  276000, Reward:  -104.126 [  95.896], Avg:  -181.324 (0.100) <0-09:43:00> ({'r_t': -1103.5253, 'eps':     0.1000, 'dyn_loss': 2803988992.0000, 'dot_loss': 7603000.5000, 'ddot_loss': 73325.5078, 'rew_loss':    56.9700, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  277000, Reward:   -90.832 [  55.821], Avg:  -180.999 (0.100) <0-09:45:01> ({'r_t': -1083.4675, 'eps':     0.1000, 'dyn_loss': 2933075456.0000, 'dot_loss': 7982061.5000, 'ddot_loss': 74462.9219, 'rew_loss':    58.4315, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  278000, Reward:  -144.103 [ 119.694], Avg:  -180.866 (0.100) <0-09:47:09> ({'r_t': -1079.2713, 'eps':     0.1000, 'dyn_loss': 3028172032.0000, 'dot_loss': 8507816.0000, 'ddot_loss': 73765.7734, 'rew_loss':    60.8681, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  279000, Reward:  -101.573 [  85.124], Avg:  -180.583 (0.100) <0-09:49:13> ({'r_t': -1108.6893, 'eps':     0.1000, 'dyn_loss': 3297411072.0000, 'dot_loss': 9679158.0000, 'ddot_loss': 75935.3203, 'rew_loss':    50.7250, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  280000, Reward:  -107.046 [  83.037], Avg:  -180.322 (0.100) <0-09:51:16> ({'r_t': -1110.8090, 'eps':     0.1000, 'dyn_loss': 3006277120.0000, 'dot_loss': 8996775.0000, 'ddot_loss': 74128.3438, 'rew_loss':    60.2810, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  281000, Reward:  -116.682 [  94.665], Avg:  -180.096 (0.100) <0-09:53:21> ({'r_t': -1081.4314, 'eps':     0.1000, 'dyn_loss': 1811825280.0000, 'dot_loss': 5610590.0000, 'ddot_loss': 68411.9062, 'rew_loss':    48.8935, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  282000, Reward:  -120.802 [ 101.748], Avg:  -179.886 (0.100) <0-09:55:20> ({'r_t': -1099.4313, 'eps':     0.1000, 'dyn_loss': 1151399936.0000, 'dot_loss': 3762778.2500, 'ddot_loss': 68775.5312, 'rew_loss':    68.6044, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  283000, Reward:  -118.342 [  96.612], Avg:  -179.670 (0.100) <0-09:57:23> ({'r_t': -1084.1485, 'eps':     0.1000, 'dyn_loss': 1963414784.0000, 'dot_loss': 5763042.5000, 'ddot_loss': 62031.3398, 'rew_loss':    59.9883, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  284000, Reward:  -115.081 [ 117.257], Avg:  -179.443 (0.100) <0-09:59:30> ({'r_t': -1107.2893, 'eps':     0.1000, 'dyn_loss': 2459259136.0000, 'dot_loss': 6801159.0000, 'ddot_loss': 65236.3008, 'rew_loss':    66.3446, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  285000, Reward:  -110.293 [  74.652], Avg:  -179.201 (0.100) <0-10:01:30> ({'r_t': -1097.5877, 'eps':     0.1000, 'dyn_loss': 3666351104.0000, 'dot_loss': 11356100.0000, 'ddot_loss': 85630.1797, 'rew_loss':    55.9136, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  286000, Reward:  -112.578 [  86.138], Avg:  -178.969 (0.100) <0-10:03:43> ({'r_t': -1058.8828, 'eps':     0.1000, 'dyn_loss': 2377311744.0000, 'dot_loss': 7452891.0000, 'ddot_loss': 84168.2969, 'rew_loss':    56.3411, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  287000, Reward:  -112.576 [  75.242], Avg:  -178.739 (0.100) <0-10:05:41> ({'r_t': -1061.2180, 'eps':     0.1000, 'dyn_loss': 2076685824.0000, 'dot_loss': 5700387.0000, 'ddot_loss': 76835.6328, 'rew_loss':    68.2610, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  288000, Reward:  -108.495 [  67.022], Avg:  -178.496 (0.100) <0-10:07:41> ({'r_t': -1056.4014, 'eps':     0.1000, 'dyn_loss': 2296811776.0000, 'dot_loss': 6315564.5000, 'ddot_loss': 75423.0234, 'rew_loss':    54.2646, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  289000, Reward:  -109.211 [  84.887], Avg:  -178.257 (0.100) <0-10:09:41> ({'r_t': -1028.9659, 'eps':     0.1000, 'dyn_loss': 2776910848.0000, 'dot_loss': 8333016.5000, 'ddot_loss': 83215.8516, 'rew_loss':    61.4434, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  290000, Reward:  -127.515 [  82.499], Avg:  -178.082 (0.100) <0-10:11:40> ({'r_t': -1087.4001, 'eps':     0.1000, 'dyn_loss': 4031142912.0000, 'dot_loss': 13158651.0000, 'ddot_loss': 93421.0938, 'rew_loss':    53.6854, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  291000, Reward:  -198.095 [ 159.780], Avg:  -178.151 (0.100) <0-10:13:55> ({'r_t': -1105.8411, 'eps':     0.1000, 'dyn_loss': 2949719040.0000, 'dot_loss': 10205978.0000, 'ddot_loss': 96895.0781, 'rew_loss':    51.4899, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  292000, Reward:  -106.013 [  56.369], Avg:  -177.905 (0.100) <0-10:15:49> ({'r_t': -1102.3022, 'eps':     0.1000, 'dyn_loss': 2268908800.0000, 'dot_loss': 7729299.0000, 'ddot_loss': 97095.8438, 'rew_loss':    56.3840, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  293000, Reward:  -156.502 [ 145.340], Avg:  -177.832 (0.100) <0-10:18:06> ({'r_t': -1065.2335, 'eps':     0.1000, 'dyn_loss': 1821724928.0000, 'dot_loss': 6995696.5000, 'ddot_loss': 101173.5234, 'rew_loss':    57.2304, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  294000, Reward:  -102.761 [  78.245], Avg:  -177.577 (0.100) <0-10:20:13> ({'r_t': -1072.0883, 'eps':     0.1000, 'dyn_loss': 1557151360.0000, 'dot_loss': 5869438.0000, 'ddot_loss': 97254.5000, 'rew_loss':    61.2983, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  295000, Reward:   -72.587 [  22.715], Avg:  -177.223 (0.100) <0-10:22:02> ({'r_t': -1053.0631, 'eps':     0.1000, 'dyn_loss': 1940435712.0000, 'dot_loss': 6948310.0000, 'ddot_loss': 101081.7266, 'rew_loss':    62.4236, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  296000, Reward:  -137.352 [ 104.396], Avg:  -177.088 (0.100) <0-10:24:12> ({'r_t': -1097.5410, 'eps':     0.1000, 'dyn_loss': 4551455232.0000, 'dot_loss': 12094519.0000, 'ddot_loss': 86439.3906, 'rew_loss':    68.5195, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  297000, Reward:  -104.980 [  53.775], Avg:  -176.846 (0.100) <0-10:26:06> ({'r_t': -1033.3374, 'eps':     0.1000, 'dyn_loss': 2374509824.0000, 'dot_loss': 5770658.5000, 'ddot_loss': 77456.1953, 'rew_loss':    53.9830, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  298000, Reward:   -89.624 [  44.685], Avg:  -176.555 (0.100) <0-10:28:04> ({'r_t': -1057.0856, 'eps':     0.1000, 'dyn_loss': 2485275904.0000, 'dot_loss': 6509742.0000, 'ddot_loss': 89800.9297, 'rew_loss':    56.3565, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  299000, Reward:  -144.136 [ 166.430], Avg:  -176.447 (0.100) <0-10:30:18> ({'r_t': -1130.9692, 'eps':     0.1000, 'dyn_loss': 2478392320.0000, 'dot_loss': 7064722.0000, 'ddot_loss': 84681.6797, 'rew_loss':    66.5310, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  300000, Reward:  -151.747 [ 104.463], Avg:  -176.365 (0.100) <0-10:32:27> ({'r_t': -1090.6253, 'eps':     0.1000, 'dyn_loss': 3837309696.0000, 'dot_loss': 13323212.0000, 'ddot_loss': 122664.6562, 'rew_loss':    65.7577, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  301000, Reward:   -88.693 [  21.726], Avg:  -176.074 (0.100) <0-10:34:16> ({'r_t': -1057.8462, 'eps':     0.1000, 'dyn_loss': 23425284096.0000, 'dot_loss': 78160536.0000, 'ddot_loss': 256060.1250, 'rew_loss':    55.5898, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  302000, Reward:   -86.140 [  36.847], Avg:  -175.777 (0.100) <0-10:36:08> ({'r_t': -1052.1950, 'eps':     0.1000, 'dyn_loss': 23587432448.0000, 'dot_loss': 81088776.0000, 'ddot_loss': 263321.1250, 'rew_loss':    49.0974, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  303000, Reward:   -79.669 [  24.965], Avg:  -175.461 (0.100) <0-10:37:57> ({'r_t': -1047.7075, 'eps':     0.1000, 'dyn_loss': 19419713536.0000, 'dot_loss': 62055904.0000, 'ddot_loss': 228278.1562, 'rew_loss':    58.1171, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  304000, Reward:  -103.790 [  28.920], Avg:  -175.226 (0.100) <0-10:39:46> ({'r_t': -1051.4196, 'eps':     0.1000, 'dyn_loss': 13099612160.0000, 'dot_loss': 38248260.0000, 'ddot_loss': 205152.0156, 'rew_loss':    54.1635, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  305000, Reward:  -113.464 [  59.153], Avg:  -175.024 (0.100) <0-10:41:44> ({'r_t': -1030.0872, 'eps':     0.1000, 'dyn_loss': 18070548480.0000, 'dot_loss': 57216188.0000, 'ddot_loss': 224922.8438, 'rew_loss':    66.7126, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  306000, Reward:  -125.248 [ 108.266], Avg:  -174.862 (0.100) <0-10:43:53> ({'r_t': -1056.5124, 'eps':     0.1000, 'dyn_loss': 11077050368.0000, 'dot_loss': 34785832.0000, 'ddot_loss': 204500.9531, 'rew_loss':    53.3103, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  307000, Reward:  -118.556 [  52.668], Avg:  -174.680 (0.100) <0-10:45:48> ({'r_t': -1043.6098, 'eps':     0.1000, 'dyn_loss': 11834705920.0000, 'dot_loss': 33847068.0000, 'ddot_loss': 202180.8594, 'rew_loss':    51.3750, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  308000, Reward:   -89.716 [  33.929], Avg:  -174.405 (0.100) <0-10:47:38> ({'r_t': -1065.2249, 'eps':     0.1000, 'dyn_loss': 14128122880.0000, 'dot_loss': 48761960.0000, 'ddot_loss': 271775.1562, 'rew_loss':    54.7789, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  309000, Reward:  -104.660 [ 133.526], Avg:  -174.180 (0.100) <0-10:49:58> ({'r_t': -1025.5656, 'eps':     0.1000, 'dyn_loss': 11729562624.0000, 'dot_loss': 43806136.0000, 'ddot_loss': 289836.9062, 'rew_loss':    55.7641, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  310000, Reward:  -141.476 [ 115.896], Avg:  -174.074 (0.100) <0-10:52:07> ({'r_t': -1053.1149, 'eps':     0.1000, 'dyn_loss': 17589598208.0000, 'dot_loss': 59810312.0000, 'ddot_loss': 334104.7188, 'rew_loss':    58.1342, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  311000, Reward:   -90.541 [  41.591], Avg:  -173.807 (0.100) <0-10:53:57> ({'r_t': -1081.1498, 'eps':     0.1000, 'dyn_loss': 13443566592.0000, 'dot_loss': 52216168.0000, 'ddot_loss': 406187.2500, 'rew_loss':    45.6430, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  312000, Reward:   -90.536 [  33.715], Avg:  -173.541 (0.100) <0-10:55:46> ({'r_t': -1071.8725, 'eps':     0.1000, 'dyn_loss': 45924646912.0000, 'dot_loss': 153047008.0000, 'ddot_loss': 423979.5938, 'rew_loss':    63.1607, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  313000, Reward:  -149.884 [ 107.656], Avg:  -173.465 (0.100) <0-10:57:49> ({'r_t': -1051.1471, 'eps':     0.1000, 'dyn_loss': 37764390912.0000, 'dot_loss': 118980464.0000, 'ddot_loss': 324096.0938, 'rew_loss':    53.7783, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  314000, Reward:   -94.202 [  42.780], Avg:  -173.214 (0.100) <0-10:59:42> ({'r_t': -1081.7968, 'eps':     0.1000, 'dyn_loss': 28250236928.0000, 'dot_loss': 85649432.0000, 'ddot_loss': 267760.9688, 'rew_loss':    48.3149, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  315000, Reward:  -132.303 [ 110.843], Avg:  -173.084 (0.100) <0-11:01:44> ({'r_t': -1059.5331, 'eps':     0.1000, 'dyn_loss': 24599089152.0000, 'dot_loss': 74667272.0000, 'ddot_loss': 247450.5156, 'rew_loss':    45.8948, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  316000, Reward:   -95.157 [  48.122], Avg:  -172.838 (0.100) <0-11:03:39> ({'r_t': -1033.3093, 'eps':     0.1000, 'dyn_loss': 22669662208.0000, 'dot_loss': 69161800.0000, 'ddot_loss': 233858.3125, 'rew_loss':    48.8512, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  317000, Reward:  -123.440 [  84.864], Avg:  -172.683 (0.100) <0-11:05:47> ({'r_t': -1035.3474, 'eps':     0.1000, 'dyn_loss': 23055376384.0000, 'dot_loss': 70690544.0000, 'ddot_loss': 231534.0781, 'rew_loss':    56.6177, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  318000, Reward:  -116.698 [  61.920], Avg:  -172.508 (0.100) <0-11:07:53> ({'r_t': -1054.2665, 'eps':     0.1000, 'dyn_loss': 20216723456.0000, 'dot_loss': 60270220.0000, 'ddot_loss': 212940.1719, 'rew_loss':    56.2597, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  319000, Reward:  -100.494 [  49.269], Avg:  -172.283 (0.100) <0-11:09:47> ({'r_t': -1045.5628, 'eps':     0.1000, 'dyn_loss': 51197440000.0000, 'dot_loss': 162301504.0000, 'ddot_loss': 397487.5000, 'rew_loss':    54.3341, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  320000, Reward:  -135.179 [  78.849], Avg:  -172.167 (0.100) <0-11:11:43> ({'r_t': -1040.5668, 'eps':     0.1000, 'dyn_loss': 37341724672.0000, 'dot_loss': 109201560.0000, 'ddot_loss': 334201.7188, 'rew_loss':    49.9421, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  321000, Reward:  -142.670 [  87.282], Avg:  -172.075 (0.100) <0-11:13:55> ({'r_t': -1044.9358, 'eps':     0.1000, 'dyn_loss': 24526723072.0000, 'dot_loss': 70478264.0000, 'ddot_loss': 273834.6875, 'rew_loss':    50.4333, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  322000, Reward:   -78.679 [  24.881], Avg:  -171.786 (0.100) <0-11:15:41> ({'r_t': -1085.7693, 'eps':     0.1000, 'dyn_loss': 20184571904.0000, 'dot_loss': 57595980.0000, 'ddot_loss': 249688.5000, 'rew_loss':    42.9048, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  323000, Reward:  -102.645 [  68.740], Avg:  -171.573 (0.100) <0-11:17:46> ({'r_t': -1057.9139, 'eps':     0.1000, 'dyn_loss': 16775604224.0000, 'dot_loss': 47385672.0000, 'ddot_loss': 231764.2344, 'rew_loss':    52.1336, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  324000, Reward:  -158.350 [ 112.708], Avg:  -171.532 (0.100) <0-11:19:57> ({'r_t': -1050.4969, 'eps':     0.1000, 'dyn_loss': 14483801088.0000, 'dot_loss': 40627060.0000, 'ddot_loss': 219096.8594, 'rew_loss':    54.7065, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  325000, Reward:  -128.586 [ 108.277], Avg:  -171.400 (0.100) <0-11:21:59> ({'r_t': -1055.3681, 'eps':     0.1000, 'dyn_loss': 13009479680.0000, 'dot_loss': 35761656.0000, 'ddot_loss': 205471.2344, 'rew_loss':    55.9697, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  326000, Reward:  -116.288 [  99.850], Avg:  -171.232 (0.100) <0-11:24:01> ({'r_t': -1048.0504, 'eps':     0.1000, 'dyn_loss': 11700859904.0000, 'dot_loss': 32310258.0000, 'ddot_loss': 199161.2969, 'rew_loss':    55.6801, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  327000, Reward:  -183.130 [ 133.358], Avg:  -171.268 (0.100) <0-11:26:09> ({'r_t': -1075.3571, 'eps':     0.1000, 'dyn_loss': 10629814272.0000, 'dot_loss': 29926896.0000, 'ddot_loss': 198936.2969, 'rew_loss':    57.4319, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  328000, Reward:  -119.015 [  71.409], Avg:  -171.109 (0.100) <0-11:28:03> ({'r_t': -1039.8087, 'eps':     0.1000, 'dyn_loss': 9424007168.0000, 'dot_loss': 26333782.0000, 'ddot_loss': 189801.1719, 'rew_loss':    56.5972, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  329000, Reward:  -101.614 [  60.387], Avg:  -170.899 (0.100) <0-11:30:03> ({'r_t': -1079.2789, 'eps':     0.1000, 'dyn_loss': 8381151744.0000, 'dot_loss': 23119812.0000, 'ddot_loss': 181299.0625, 'rew_loss':    53.9094, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  330000, Reward:  -124.319 [  92.848], Avg:  -170.758 (0.100) <0-11:32:06> ({'r_t': -1089.1678, 'eps':     0.1000, 'dyn_loss': 7447128576.0000, 'dot_loss': 20334570.0000, 'ddot_loss': 171326.6406, 'rew_loss':    49.7669, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  331000, Reward:  -107.251 [  55.157], Avg:  -170.567 (0.100) <0-11:34:05> ({'r_t': -1060.0095, 'eps':     0.1000, 'dyn_loss': 6634801664.0000, 'dot_loss': 17476892.0000, 'ddot_loss': 160658.4219, 'rew_loss':    56.8683, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  332000, Reward:  -135.773 [ 106.977], Avg:  -170.462 (0.100) <0-11:36:12> ({'r_t': -1078.0993, 'eps':     0.1000, 'dyn_loss': 5856004608.0000, 'dot_loss': 15255199.0000, 'ddot_loss': 156102.8906, 'rew_loss':    43.7669, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  333000, Reward:  -109.709 [  75.920], Avg:  -170.280 (0.100) <0-11:38:15> ({'r_t': -1039.6155, 'eps':     0.1000, 'dyn_loss': 5086775296.0000, 'dot_loss': 13682942.0000, 'ddot_loss': 155228.2656, 'rew_loss':    48.5668, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  334000, Reward:  -124.480 [  88.414], Avg:  -170.144 (0.100) <0-11:40:12> ({'r_t': -1079.1478, 'eps':     0.1000, 'dyn_loss': 4327176704.0000, 'dot_loss': 11560957.0000, 'ddot_loss': 147867.2500, 'rew_loss':    51.0462, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  335000, Reward:  -102.866 [  83.618], Avg:  -169.943 (0.100) <0-11:42:15> ({'r_t': -1044.7915, 'eps':     0.1000, 'dyn_loss': 3747162624.0000, 'dot_loss': 10042833.0000, 'ddot_loss': 144936.4219, 'rew_loss':    47.8714, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  336000, Reward:  -176.873 [ 159.401], Avg:  -169.964 (0.100) <0-11:44:24> ({'r_t': -1045.8972, 'eps':     0.1000, 'dyn_loss': 3295362304.0000, 'dot_loss': 9186081.0000, 'ddot_loss': 147027.1406, 'rew_loss':    52.5831, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  337000, Reward:  -123.959 [  96.704], Avg:  -169.828 (0.100) <0-11:46:34> ({'r_t': -1032.2951, 'eps':     0.1000, 'dyn_loss': 2899997184.0000, 'dot_loss': 8533499.0000, 'ddot_loss': 153349.2969, 'rew_loss':    54.5431, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  338000, Reward:  -138.245 [ 159.094], Avg:  -169.735 (0.100) <0-11:48:52> ({'r_t': -1061.7336, 'eps':     0.1000, 'dyn_loss': 2573934080.0000, 'dot_loss': 7378758.5000, 'ddot_loss': 146732.8125, 'rew_loss':    46.6114, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  339000, Reward:  -102.225 [  48.846], Avg:  -169.536 (0.100) <0-11:50:45> ({'r_t': -1033.4122, 'eps':     0.1000, 'dyn_loss': 2113287040.0000, 'dot_loss': 6469393.0000, 'ddot_loss': 149439.8281, 'rew_loss':    53.2327, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  340000, Reward:  -154.452 [ 135.474], Avg:  -169.492 (0.100) <0-11:53:04> ({'r_t': -1118.2641, 'eps':     0.1000, 'dyn_loss': 1897669248.0000, 'dot_loss': 5544658.0000, 'ddot_loss': 141658.4062, 'rew_loss':    57.8526, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  341000, Reward:  -133.193 [ 108.344], Avg:  -169.386 (0.100) <0-11:55:04> ({'r_t': -1074.3056, 'eps':     0.1000, 'dyn_loss': 1537977856.0000, 'dot_loss': 4746253.0000, 'ddot_loss': 141986.0625, 'rew_loss':    52.3557, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  342000, Reward:  -114.844 [  64.448], Avg:  -169.227 (0.100) <0-11:57:02> ({'r_t': -1064.0049, 'eps':     0.1000, 'dyn_loss': 1247195904.0000, 'dot_loss': 4142259.5000, 'ddot_loss': 143641.5469, 'rew_loss':    56.4321, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  343000, Reward:  -104.199 [  79.559], Avg:  -169.038 (0.100) <0-11:59:07> ({'r_t': -1069.2082, 'eps':     0.1000, 'dyn_loss': 1110312320.0000, 'dot_loss': 3876856.2500, 'ddot_loss': 145238.8438, 'rew_loss':    50.1561, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  344000, Reward:  -135.971 [ 107.547], Avg:  -168.942 (0.100) <0-12:01:12> ({'r_t': -1081.0331, 'eps':     0.1000, 'dyn_loss': 2083259008.0000, 'dot_loss': 6506539.5000, 'ddot_loss': 132287.9375, 'rew_loss':    52.4259, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  345000, Reward:  -125.950 [  83.870], Avg:  -168.818 (0.100) <0-12:03:08> ({'r_t': -1045.3856, 'eps':     0.1000, 'dyn_loss': 3067290368.0000, 'dot_loss': 11112882.0000, 'ddot_loss': 170357.6406, 'rew_loss':    55.7768, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  346000, Reward:  -138.260 [  94.084], Avg:  -168.729 (0.100) <0-12:05:10> ({'r_t': -1045.6030, 'eps':     0.1000, 'dyn_loss': 2376141312.0000, 'dot_loss': 8528159.0000, 'ddot_loss': 160915.0312, 'rew_loss':    46.1362, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  347000, Reward:  -106.672 [  46.255], Avg:  -168.551 (0.100) <0-12:07:03> ({'r_t': -1056.5908, 'eps':     0.1000, 'dyn_loss': 3190453248.0000, 'dot_loss': 9111103.0000, 'ddot_loss': 151934.2969, 'rew_loss':    54.1228, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  348000, Reward:  -113.319 [  61.053], Avg:  -168.393 (0.100) <0-12:08:58> ({'r_t': -1030.0737, 'eps':     0.1000, 'dyn_loss': 2702804736.0000, 'dot_loss': 7202005.5000, 'ddot_loss': 150998.0625, 'rew_loss':    59.2919, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  349000, Reward:   -96.843 [  60.409], Avg:  -168.188 (0.100) <0-12:10:52> ({'r_t': -1013.9740, 'eps':     0.1000, 'dyn_loss': 2188355328.0000, 'dot_loss': 6287572.5000, 'ddot_loss': 162729.4375, 'rew_loss':    42.6017, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  350000, Reward:  -130.334 [  97.975], Avg:  -168.081 (0.100) <0-12:12:57> ({'r_t': -1011.0257, 'eps':     0.1000, 'dyn_loss': 1509768704.0000, 'dot_loss': 5208371.0000, 'ddot_loss': 174489.3594, 'rew_loss':    52.1473, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  351000, Reward:   -99.585 [  63.125], Avg:  -167.886 (0.100) <0-12:14:53> ({'r_t': -1069.4124, 'eps':     0.1000, 'dyn_loss': 1558162944.0000, 'dot_loss': 4676717.5000, 'ddot_loss': 153725.8438, 'rew_loss':    59.4599, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  352000, Reward:   -99.281 [  62.196], Avg:  -167.692 (0.100) <0-12:16:55> ({'r_t': -1047.8609, 'eps':     0.1000, 'dyn_loss': 1629531008.0000, 'dot_loss': 4796882.5000, 'ddot_loss': 145887.1250, 'rew_loss':    42.8921, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  353000, Reward:  -117.332 [  80.579], Avg:  -167.549 (0.100) <0-12:18:56> ({'r_t': -1049.1554, 'eps':     0.1000, 'dyn_loss': 1689073408.0000, 'dot_loss': 4841165.0000, 'ddot_loss': 141452.3594, 'rew_loss':    51.9793, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  354000, Reward:  -106.567 [  70.671], Avg:  -167.378 (0.100) <0-12:20:57> ({'r_t': -1061.6190, 'eps':     0.1000, 'dyn_loss': 1568697728.0000, 'dot_loss': 4542881.5000, 'ddot_loss': 137060.2656, 'rew_loss':    56.8852, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  355000, Reward:  -104.466 [  53.888], Avg:  -167.201 (0.100) <0-12:22:54> ({'r_t': -1076.0588, 'eps':     0.1000, 'dyn_loss': 5370171904.0000, 'dot_loss': 14755210.0000, 'ddot_loss': 134392.0781, 'rew_loss':    47.4492, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  356000, Reward:  -147.237 [ 124.441], Avg:  -167.145 (0.100) <0-12:25:04> ({'r_t': -1039.8870, 'eps':     0.1000, 'dyn_loss': 5784717824.0000, 'dot_loss': 15004662.0000, 'ddot_loss': 120323.7578, 'rew_loss':    46.7989, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  357000, Reward:  -123.945 [ 117.827], Avg:  -167.024 (0.100) <0-12:27:15> ({'r_t': -1084.7735, 'eps':     0.1000, 'dyn_loss': 8157014016.0000, 'dot_loss': 26083750.0000, 'ddot_loss': 161200.6562, 'rew_loss':    56.6317, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  358000, Reward:  -130.849 [ 103.552], Avg:  -166.924 (0.100) <0-12:29:22> ({'r_t': -1103.7003, 'eps':     0.1000, 'dyn_loss': 17093404672.0000, 'dot_loss': 62325156.0000, 'ddot_loss': 360743.2812, 'rew_loss':    41.6100, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  359000, Reward:  -157.143 [ 135.248], Avg:  -166.896 (0.100) <0-12:31:26> ({'r_t': -1112.3668, 'eps':     0.1000, 'dyn_loss': 57560272896.0000, 'dot_loss': 163335040.0000, 'ddot_loss': 695457.9375, 'rew_loss':    47.8983, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  360000, Reward:   -86.288 [  53.839], Avg:  -166.673 (0.100) <0-12:33:23> ({'r_t': -1156.4695, 'eps':     0.1000, 'dyn_loss': 27915038720.0000, 'dot_loss': 86381680.0000, 'ddot_loss': 646802.5000, 'rew_loss':    47.4400, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  361000, Reward:  -132.487 [  92.402], Avg:  -166.579 (0.100) <0-12:35:31> ({'r_t': -1145.2381, 'eps':     0.1000, 'dyn_loss': 74942545920.0000, 'dot_loss': 242429696.0000, 'ddot_loss': 1806229.8750, 'rew_loss':    44.1895, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
Step:  362000, Reward:  -156.172 [ 108.698], Avg:  -166.550 (0.100) <0-12:37:48> ({'r_t': -1130.6325, 'eps':     0.1000, 'dyn_loss': 64788942848.0000, 'dot_loss': 203755280.0000, 'ddot_loss': 1693115.8750, 'rew_loss':    61.8910, 'lr':     0.0010, 'eps_e':     0.1000, 'lr_e':     0.0010})
