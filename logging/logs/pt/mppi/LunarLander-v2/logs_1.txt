Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: LunarLander-v2, Date: 07/06/2020 12:54:25
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 78eaab65753a45444c8c1759c8997485b5d39aaa
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 2000
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 250
   DYN_EPOCHS = 1
   TRAIN_EVERY = 2000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 40
      LAMBDA = 0.1
      COV = 0.5
   dynamics_size = 8
   state_size = (8,)
   action_size = [4]
   env_name = LunarLander-v2
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.98
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fa2e8219650> 
	env = <GymEnv<TimeLimit<LunarLander<LunarLander-v2>>>> 
		env = <TimeLimit<LunarLander<LunarLander-v2>>> 
			env = <LunarLander<LunarLander-v2>> 
				np_random = RandomState(MT19937)
				viewer = None
				world = b2World(autoClearForces=True,
				        bodies=[b2Body(active=True,
				                      angle=0.0,
				                      angularDamping=0.0,
				                      angularVelocity=0.0,
				                      awake=True,
				                      bullet=False,
				                      contacts=[],
				                      fixedRotation=False,...  )],
				        bodyCount=4,
				        contactCount=0,
				        contactFilter=None,
				        contactListener=ContactDetector(),
				        contactManager=b2ContactManager(allocator=<Swig Object of type 'b2BlockAllocator *' at 0x7fa2e8263e40>,
				                                        broadPhase=proxyCount=14,),
				                                        contactCount=0,
				                                        contactFilter=b2ContactFilter(),
				                                        contactList=None,
				                                        contactListener=b2ContactListener(),
				                                        ),
				        contacts=[],
				        continuousPhysics=True,
				        destructionListener=None,
				        gravity=b2Vec2(0,-10),
				        jointCount=2,
				        joints=[b2RevoluteJoint(active=True,
				                               anchorA=b2Vec2(10.0718,13.3081),
				                               anchorB=b2Vec2(10.0718,13.3081),
				                               angle=0.5393946170806885,
				                               bodyA=b2Body(active=True,...  )],
				        locked=False,
				        proxyCount=14,
				        renderer=None,
				        subStepping=False,
				        warmStarting=True,
				        )
				moon = b2Body(active=True,
				       angle=0.0,
				       angularDamping=0.0,
				       angularVelocity=0.0,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.0,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.0,
				                                      awake=True,...  )],
				       inertia=0.0,
				       joints=[],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(0,0),
				       localCenter=b2Vec2(0,0),
				       mass=0.0,
				       massData=I=0.0,center=b2Vec2(0,0),mass=0.0,),
				       position=b2Vec2(0,0),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e82062d0> >,angle=0.0,position=b2Vec2(0,0),),
				       type=0,
				       userData=None,
				       worldCenter=b2Vec2(0,0),
				       )
				lander = b2Body(active=True,
				       angle=-0.008309007622301579,
				       angularDamping=0.0,
				       angularVelocity=-0.4116286039352417,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.008309007622301579,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.4116286039352417,...  )],
				       inertia=0.8333148956298828,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.63445,-1.56826),
				       localCenter=b2Vec2(0,0.101307),
				       mass=4.816666603088379,
				       massData=I=0.8333148956298828,center=b2Vec2(0,0.101307),mass=4.816666603088379,),
				       position=b2Vec2(10.0718,13.3081),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e8206420> >,angle=-0.008309007622301579,position=b2Vec2(10.0718,13.3081),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.0726,13.4094),
				       )
				particles = []
				prev_reward = None
				observation_space = Box(8,) 
					dtype = float32
					shape = (8,)
					low = [-inf -inf -inf -inf -inf -inf -inf -inf]
					high = [ inf  inf  inf  inf  inf  inf  inf  inf]
					bounded_below = [False False False False False False False False]
					bounded_above = [False False False False False False False False]
					np_random = RandomState(MT19937)
				action_space = Discrete(4) 
					n = 4
					shape = ()
					dtype = int64
					np_random = RandomState(MT19937)
				game_over = False
				prev_shaping = -217.09111634476272
				helipad_x1 = 8.0
				helipad_x2 = 12.0
				helipad_y = 3.3333333333333335
				sky_polys = [[(0.0, 4.585919835063695), (2.0, 2.8712079810212856), (2.0, 13.333333333333334), (0.0, 13.333333333333334)], [(2.0, 2.8712079810212856), (4.0, 1.8073948552868195), (4.0, 13.333333333333334), (2.0, 13.333333333333334)], [(4.0, 1.8073948552868195), (6.0, 2.201480573058143), (6.0, 13.333333333333334), (4.0, 13.333333333333334)], [(6.0, 2.201480573058143), (8.0, 3.3000000000000003), (8.0, 13.333333333333334), (6.0, 13.333333333333334)], [(8.0, 3.3000000000000003), (10.0, 3.3000000000000003), (10.0, 13.333333333333334), (8.0, 13.333333333333334)], [(10.0, 3.3000000000000003), (12.0, 3.3000000000000003), (12.0, 13.333333333333334), (10.0, 13.333333333333334)], [(12.0, 3.3000000000000003), (14.0, 2.45891468372139), (14.0, 13.333333333333334), (12.0, 13.333333333333334)], [(14.0, 2.45891468372139), (16.0, 2.0236391586370512), (16.0, 13.333333333333334), (14.0, 13.333333333333334)], [(16.0, 2.0236391586370512), (18.0, 2.2417375513629314), (18.0, 13.333333333333334), (16.0, 13.333333333333334)], [(18.0, 2.2417375513629314), (20.0, 3.6990152947420945), (20.0, 13.333333333333334), (18.0, 13.333333333333334)]]
				legs = [b2Body(active=True,
				       angle=0.4810855984687805,
				       angularDamping=0.0,
				       angularVelocity=-0.4116266369819641,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.4810855984687805,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.4116266369819641,
				                                      awake=True,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.33237,-1.83),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(10.9404,13.0847),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e82061e0> >,angle=0.48108556866645813,position=b2Vec2(10.9404,13.0847),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.9404,13.0847),
				       ), b2Body(active=True,
				       angle=-0.5029194355010986,
				       angularDamping=0.0,
				       angularVelocity=-0.411620557308197,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.5029194355010986,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.411620557308197,
				                                      awake=True,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.33237,-1.30653),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(9.19845,13.1037),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e82062d0> >,angle=-0.5029194355010986,position=b2Vec2(9.19845,13.1037),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.19845,13.1037),
				       )]
				drawlist = [b2Body(active=True,
				       angle=-0.008309007622301579,
				       angularDamping=0.0,
				       angularVelocity=-0.4116286039352417,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.008309007622301579,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.4116286039352417,...  )],
				       inertia=0.8333148956298828,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.63445,-1.56826),
				       localCenter=b2Vec2(0,0.101307),
				       mass=4.816666603088379,
				       massData=I=0.8333148956298828,center=b2Vec2(0,0.101307),mass=4.816666603088379,),
				       position=b2Vec2(10.0718,13.3081),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e8206a80> >,angle=-0.008309007622301579,position=b2Vec2(10.0718,13.3081),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.0726,13.4094),
				       ), b2Body(active=True,
				       angle=0.4810855984687805,
				       angularDamping=0.0,
				       angularVelocity=-0.4116266369819641,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.4810855984687805,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.4116266369819641,
				                                      awake=True,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.33237,-1.83),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(10.9404,13.0847),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e823bba0> >,angle=0.48108556866645813,position=b2Vec2(10.9404,13.0847),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.9404,13.0847),
				       ), b2Body(active=True,
				       angle=-0.5029194355010986,
				       angularDamping=0.0,
				       angularVelocity=-0.411620557308197,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.5029194355010986,
				                                      angularDamping=0.0,
				                                      angularVelocity=-0.411620557308197,
				                                      awake=True,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(10.0718,13.3081),
				                                                anchorB=b2Vec2(10.0718,13.3081),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(3.33237,-1.30653),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(9.19845,13.1037),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa2e823bba0> >,angle=-0.5029194355010986,position=b2Vec2(9.19845,13.1037),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.19845,13.1037),
				       )]
				spec = EnvSpec(LunarLander-v2) 
					id = LunarLander-v2
					entry_point = gym.envs.box2d:LunarLander
					reward_threshold = 200
					nondeterministic = False
					max_episode_steps = 1000
				verbose = 0
			action_space = Discrete(4) 
				n = 4
				shape = ()
				dtype = int64
				np_random = RandomState(MT19937)
			observation_space = Box(8,) 
				dtype = float32
				shape = (8,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False]
				bounded_above = [False False False False False False False False]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		action_space = Discrete(4) 
			n = 4
			shape = ()
			dtype = int64
			np_random = RandomState(MT19937)
		observation_space = Box(8,) 
			dtype = float32
			shape = (8,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False]
			bounded_above = [False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fa2e8220c50> 
			observation_space = Box(8,) 
				dtype = float32
				shape = (8,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False]
				bounded_above = [False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (8,)
	action_size = [4]
	action_space = Discrete(4) 
		n = 4
		shape = ()
		dtype = int64
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fa2e8044c50> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45492), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=35, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55072), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=46, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40760), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=83, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45264), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=85, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38318), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=86, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55074), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=87, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34924), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=88, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59728), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=110, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55700), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=112, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47628), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=113, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49814), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=114, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49938), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=115, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53118), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=116, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 39602), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=117, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 52540), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=118, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47352), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fa2e81b5cd0> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fa2e8048f10> 
		state_size = (8,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fa2e8632d50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fa2e804e090> 
			size = [4]
			dt = 0.2
			action = [-1.000  0.469 -0.454 -0.157]
			daction_dt = [-1.048  0.285 -0.553 -0.113]
		discrete = True
		action_size = [4]
		state_size = (8,)
		config = <src.utils.config.Config object at 0x7fa2f0017d10> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 2000
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 250
			DYN_EPOCHS = 1
			TRAIN_EVERY = 2000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fa392516790> 
				NSAMPLES = 100
				HORIZON = 40
				LAMBDA = 0.1
				COV = 0.5
			dynamics_size = 8
			state_size = (8,)
			action_size = [4]
			env_name = LunarLander-v2
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fa2f0008890> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.98
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fa2e804e050> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fa2e804e110> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fa2f0017d10> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 2000
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 250
				DYN_EPOCHS = 1
				TRAIN_EVERY = 2000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fa392516790> 
					NSAMPLES = 100
					HORIZON = 40
					LAMBDA = 0.1
					COV = 0.5
				dynamics_size = 8
				state_size = (8,)
				action_size = [4]
				env_name = LunarLander-v2
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fa2f0008890> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.98
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fa2e804e150> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=20, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(20, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=8, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fa2e804e1d0> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fa2f0017d10> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = 500
						MAX_BUFFER_SIZE = 1000000
						REPLAY_BATCH_SIZE = 2000
						TARGET_UPDATE_RATE = 0.0004
						BATCH_SIZE = 250
						DYN_EPOCHS = 1
						TRAIN_EVERY = 2000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fa392516790> 
							NSAMPLES = 100
							HORIZON = 40
							LAMBDA = 0.1
							COV = 0.5
						dynamics_size = 8
						state_size = (8,)
						action_size = [4]
						env_name = LunarLander-v2
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = <list len=17>
						tcp_rank = 0
						num_envs = 1
						nsteps = 500000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fa2f0008890> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.98
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (8,)
					action_size = [4]
					discrete = True
					dyn_index = 8
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa2e804e850>
				state_size = (8,)
				action_size = [4]
			mu = [ 0.000  0.000  0.000  0.000]
			cov = [[ 0.500  0.000  0.000  0.000]
			 [ 0.000  0.500  0.000  0.000]
			 [ 0.000  0.000  0.500  0.000]
			 [ 0.000  0.000  0.000  0.500]]
			icov = [[ 2.000  0.000  0.000  0.000]
			 [ 0.000  2.000  0.000  0.000]
			 [ 0.000  0.000  2.000  0.000]
			 [ 0.000  0.000  0.000  2.000]]
			lamda = 0.1
			horizon = 40
			nsamples = 100
			action_size = [4]
			control = [[[ 5.802e-01  9.048e-01  5.867e-01  9.372e-01]
			  [-3.713e-01 -8.989e-01  7.250e-01  8.185e-01]
			  [-9.670e-01 -7.024e-01  5.572e-01 -5.786e-01]
			  [-3.318e-01 -8.918e-01 -2.661e-01 -1.910e-03]
			  [ 2.983e-01 -9.142e-01  4.240e-01 -3.240e-01]
			  [ 2.316e-01  3.472e-01  7.375e-01  8.610e-02]
			  [ 7.367e-01 -2.072e-01 -4.829e-01  2.020e-01]
			  [-7.103e-01  3.407e-01  9.964e-02  5.919e-01]
			  [-3.402e-01  5.903e-01 -2.863e-01 -2.399e-01]
			  [ 1.083e-01  6.489e-01 -4.464e-01 -5.124e-01]
			  [-8.013e-01 -8.656e-01 -1.373e-02  8.550e-01]
			  [ 2.559e-02  8.553e-01  2.871e-01 -9.567e-01]
			  [-1.555e-01  4.460e-01 -8.592e-01  5.258e-01]
			  [ 6.065e-02  6.444e-01 -7.458e-01  3.823e-01]
			  [-3.231e-01  5.193e-01 -2.117e-01 -2.064e-01]
			  [-2.793e-01 -7.483e-01  8.162e-01 -3.789e-01]
			  [-8.106e-01 -7.071e-01 -3.077e-01  3.868e-01]
			  [-4.414e-01 -7.223e-03  2.883e-01  1.163e-01]
			  [-2.029e-01 -2.978e-01 -5.812e-01 -7.927e-01]
			  [ 9.256e-01 -2.391e-01  6.379e-01  2.030e-01]
			  [ 4.735e-01  5.872e-01  8.959e-01 -2.818e-01]
			  [-3.933e-03  3.096e-01  1.800e-01 -6.021e-01]
			  [ 4.395e-01 -1.662e-01  9.534e-02 -5.389e-01]
			  [-3.827e-01 -5.549e-01  1.813e-01 -1.812e-01]
			  [ 3.608e-01  8.456e-01  6.675e-01 -1.889e-01]
			  [-6.154e-01 -1.586e-01  6.705e-01  9.176e-01]
			  [ 2.806e-01  9.565e-01  8.907e-01  3.367e-01]
			  [ 1.092e-01 -5.618e-01 -4.542e-01 -7.303e-01]
			  [ 5.029e-01  8.253e-01 -1.658e-01 -3.456e-01]
			  [-9.530e-01  1.379e-01 -8.209e-01  4.967e-01]
			  [-7.903e-01 -3.772e-01  2.894e-01  2.207e-01]
			  [-3.736e-01  4.728e-01  3.423e-01 -1.260e-01]
			  [-3.574e-01  8.520e-01 -6.519e-01  7.233e-02]
			  [ 9.421e-01 -5.748e-01  9.237e-01 -3.484e-01]
			  [ 5.562e-02 -7.542e-01  7.676e-01  2.175e-01]
			  [ 6.300e-01  4.938e-01 -9.204e-02 -8.541e-01]
			  [-3.891e-01 -6.464e-01  9.533e-01 -3.684e-01]
			  [-9.567e-05 -4.549e-01  1.415e-01 -7.907e-01]
			  [-6.634e-01 -7.545e-01 -9.230e-02  5.796e-01]
			  [ 2.432e-01  7.234e-01 -8.017e-01  9.935e-01]]]
			noise = [[[[ 5.390e-02  5.232e-01  8.293e-01  6.396e-01]
			   [-9.599e-01  2.931e-01 -8.049e-01  2.017e-01]
			   [ 9.577e-02  4.220e-01 -8.527e-01 -2.263e-01]
			   ...
			   [-9.563e-01  1.905e-01  4.924e-01  5.898e-01]
			   [-8.738e-01 -2.037e-02  7.614e-01  4.540e-01]
			   [-1.106e-01  3.096e-01 -4.837e-01  5.937e-01]]
			
			  [[-2.827e-01  1.030e+00 -1.120e+00 -7.104e-01]
			   [ 2.815e-01  3.899e-01  2.036e-01  5.678e-01]
			   [-1.014e+00  5.143e-01 -2.762e-01 -4.034e-01]
			   ...
			   [ 5.411e-01  8.021e-01  1.081e+00 -6.367e-02]
			   [ 5.176e-01 -1.570e-01 -3.720e-01  1.320e+00]
			   [-5.116e-01 -1.165e+00  1.300e-01 -7.553e-01]]
			
			  [[-6.215e-01 -5.873e-01  8.361e-02 -8.285e-01]
			   [-5.519e-01 -2.468e-01  4.632e-01  8.355e-01]
			   [ 4.988e-01 -1.335e-01  1.548e-01  7.533e-01]
			   ...
			   [-2.023e-01 -9.484e-01 -1.171e-03  1.116e-02]
			   [-9.959e-01  1.650e-01 -5.875e-02 -3.242e-01]
			   [-4.571e-01  8.538e-01  5.081e-01  1.030e+00]]
			
			  ...
			
			  [[-8.338e-02  1.831e+00 -1.056e+00  1.815e-01]
			   [-9.574e-01  1.075e+00 -9.724e-02 -3.131e-02]
			   [ 5.251e-01 -2.826e-01 -8.736e-01  4.343e-02]
			   ...
			   [ 1.318e-01  1.290e+00  4.180e-02 -9.770e-01]
			   [ 7.336e-02  1.146e+00  8.046e-01 -2.674e-01]
			   [ 1.222e+00 -3.967e-01 -8.763e-01 -1.127e-01]]
			
			  [[-4.632e-01  2.314e-02  9.543e-01  1.615e+00]
			   [ 7.990e-01  5.209e-01 -3.199e-02  7.345e-01]
			   [-4.571e-01 -3.338e-01  1.513e-01  2.892e-02]
			   ...
			   [-4.666e-01  4.630e-01 -3.678e-01  6.890e-01]
			   [-1.707e-01  5.559e-01  1.432e-01 -9.749e-01]
			   [-2.624e-01 -3.328e-01 -4.428e-01  7.275e-01]]
			
			  [[-1.047e+00 -1.523e+00  6.064e-01  3.820e-01]
			   [-5.993e-01  1.247e-01  4.706e-01  8.908e-01]
			   [-2.446e-01 -3.251e-01  1.057e+00  2.995e-01]
			   ...
			   [ 4.873e-01  2.316e-01 -2.756e-01 -4.163e-01]
			   [-6.535e-01  6.832e-01 -5.781e-01  1.011e+00]
			   [-1.157e+00  1.474e-01 -7.119e-01  3.605e-01]]]]
			init_cost = [[ -1.386  10.250   4.303  -5.622  -9.067   7.203  -8.443   4.495   1.508  -0.660  -6.103  -5.674  10.184  -8.699  -6.883  12.446 -12.976  -5.555 -25.535   4.615   1.198  17.199  -5.455  -5.066   4.357  17.056  19.283   9.558  11.564   9.659  -5.197   2.218 -11.533  -9.162   9.250 -25.779  -6.468  14.138  -6.275  -3.191  -6.805   8.444  -4.306  -4.769  -7.769 -17.721  -5.630  -8.569   1.327   3.305  -1.200 -10.344 -22.474  10.878  -1.149   2.046  -8.995  -5.458   9.242 -12.436  -1.666  14.568  -4.338  -2.375   3.635  31.431   8.446  -5.223  24.164  -4.519  -0.754  -5.394   0.679   6.338 -10.845  -0.064  -2.931 -23.844 -11.377 -11.169  -5.434   4.160  18.416   5.710 -10.676  -6.762   4.338 -18.121 -11.236   2.914 -12.837  -0.218   5.709  -2.029   9.607  -3.814  -5.744   6.314  -6.318  10.167]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fa2e804e790> 
			buffer = deque([], maxlen=1000000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fa2e80670d0> 
		size = [4]
		dt = 0.2
		action = [ 1.000 -1.000  0.632  0.662]
		daction_dt = [ 1.141  0.293 -0.410  1.975]
	discrete = True
	action_size = [4]
	state_size = (8,)
	config = <src.utils.config.Config object at 0x7fa2f0017d10> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 2000
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 250
		DYN_EPOCHS = 1
		TRAIN_EVERY = 2000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fa392516790> 
			NSAMPLES = 100
			HORIZON = 40
			LAMBDA = 0.1
			COV = 0.5
		dynamics_size = 8
		state_size = (8,)
		action_size = [4]
		env_name = LunarLander-v2
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fa2f0008890> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.98
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fa2e3048350> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		controls = np.clip(self.control[:,None,:,:] + self.noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls[...,:horizon,:], x, numpy=True)
		costs = -np.sum(rewards, -1) #+ self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control += np.sum(weights[:,:,None,None]*self.noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[1, self.horizon, *self.action_size]).repeat(batch_size, 0)
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[1, self.nsamples, self.horizon]).repeat(batch_size, 0)
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def partition(self, x):
		if self.config.NUM_STEPS is None:
			return x[None,...]
		num_splits = x.shape[0]//self.config.NUM_STEPS
		if num_splits == 0:
			arr = np.zeros([self.config.NUM_STEPS, *x.shape[1:]])
			arr[-x.shape[0]:] = x
			num_splits = 1
			x = arr
		arr = x[:num_splits*self.config.NUM_STEPS].reshape(num_splits, self.config.NUM_STEPS, *x.shape[1:])
		return arr

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: np.stack(x)[None], zip(*buffer))
			buffer.clear()
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.TRAIN_EVERY)/self.config.TRAIN_EVERY if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:  -192.592 [  62.604], Avg:  -192.592 (1.000) <0-00:00:00> ({'r_t':    -0.5506, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:  -281.979 [  99.678], Avg:  -237.286 (1.000) <0-00:00:06> ({'r_t': -2949.8789, 'eps':     1.0000, 'len':    83.4920, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward:  -236.933 [ 122.643], Avg:  -237.168 (1.000) <0-00:00:12> ({'r_t': -3082.7972, 'eps':     1.0000, 'len':   263.9240, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward:  -214.328 [  74.767], Avg:  -231.458 (1.000) <0-00:00:18> ({'r_t': -3102.9618, 'eps':     1.0000, 'len':   444.4910, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward:  -195.144 [ 114.132], Avg:  -224.195 (1.000) <0-00:00:24> ({'r_t': -3323.3097, 'eps':     1.0000, 'len':   623.8220, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward:  -164.150 [ 104.248], Avg:  -214.188 (1.000) <0-00:00:30> ({'r_t': -3198.4582, 'eps':     1.0000, 'len':   809.5440, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward:  -259.719 [ 112.832], Avg:  -220.692 (1.000) <0-00:00:37> ({'r_t': -3051.9967, 'eps':     1.0000, 'len':   990.8750, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward:  -277.641 [ 123.523], Avg:  -227.811 (1.000) <0-00:00:43> ({'r_t': -3073.2211, 'eps':     1.0000, 'len':  1170.2990, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward:  -238.553 [ 136.426], Avg:  -229.004 (1.000) <0-00:00:49> ({'r_t': -3131.7877, 'eps':     1.0000, 'len':  1352.1080, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward:  -254.613 [ 120.217], Avg:  -231.565 (1.000) <0-00:00:55> ({'r_t': -3168.7428, 'eps':     1.0000, 'len':  1538.8140, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward:  -182.596 [  87.854], Avg:  -227.113 (1.000) <0-00:01:02> ({'r_t': -3282.9324, 'eps':     1.0000, 'len':  1719.1230, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward:  -196.325 [ 106.719], Avg:  -224.548 (1.000) <0-00:01:08> ({'r_t': -3147.6202, 'eps':     1.0000, 'len':  1899.8600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward:  -240.004 [ 113.248], Avg:  -225.737 (0.001) <0-00:01:38> ({'r_t': -3127.8322, 'eps':     0.0005, 'len':  2079.8800, 'dyn_loss': 18311.6191, 'dot_loss':   232.9126, 'ddot_loss':    25.1652, 'rew_loss':    16.8688, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   13000, Reward:  -210.199 [  91.085], Avg:  -224.627 (0.500) <0-00:02:31> ({'r_t': -2581.4808, 'eps':     0.5005, 'len':  2266.5550, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   14000, Reward:  -217.974 [  98.777], Avg:  -224.183 (0.001) <0-00:03:19> ({'r_t': -2279.6079, 'eps':     0.0005, 'len':  2437.3150, 'dyn_loss':   269.4031, 'dot_loss':    29.1783, 'ddot_loss':     9.7236, 'rew_loss':    12.3945, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   15000, Reward:  -229.603 [ 132.694], Avg:  -224.522 (0.500) <0-00:04:13> ({'r_t': -2768.6283, 'eps':     0.5005, 'len':  2618.1790, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   16000, Reward:  -195.202 [ 109.274], Avg:  -222.797 (0.001) <0-00:05:03> ({'r_t': -2712.1549, 'eps':     0.0005, 'len':  2794.0140, 'dyn_loss':   104.8823, 'dot_loss':    14.0840, 'ddot_loss':     5.5556, 'rew_loss':    14.0550, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   17000, Reward:  -230.239 [ 108.168], Avg:  -223.211 (0.500) <0-00:05:58> ({'r_t': -2754.3122, 'eps':     0.5005, 'len':  2968.4690, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   18000, Reward:  -183.591 [  99.685], Avg:  -221.125 (0.001) <0-00:06:48> ({'r_t': -2376.5381, 'eps':     0.0005, 'len':  3137.3770, 'dyn_loss':    59.4097, 'dot_loss':     8.7363, 'ddot_loss':     3.7655, 'rew_loss':    13.0463, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   19000, Reward:  -301.909 [  82.743], Avg:  -225.165 (0.500) <0-00:07:43> ({'r_t': -2970.8840, 'eps':     0.5005, 'len':  3316.3310, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   20000, Reward:  -209.895 [  85.766], Avg:  -224.437 (0.001) <0-00:08:33> ({'r_t': -2908.3884, 'eps':     0.0005, 'len':  3505.7450, 'dyn_loss':    39.4455, 'dot_loss':     6.0654, 'ddot_loss':     2.7636, 'rew_loss':    12.7549, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   21000, Reward:  -227.824 [ 114.812], Avg:  -224.591 (0.500) <0-00:09:28> ({'r_t': -2565.0537, 'eps':     0.5005, 'len':  3688.9510, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   22000, Reward:  -203.814 [ 116.740], Avg:  -223.688 (0.001) <0-00:10:16> ({'r_t': -2736.3529, 'eps':     0.0005, 'len':  3871.2860, 'dyn_loss':    28.8824, 'dot_loss':     4.5555, 'ddot_loss':     2.1666, 'rew_loss':    13.4306, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   23000, Reward:  -243.871 [ 134.162], Avg:  -224.529 (0.500) <0-00:11:12> ({'r_t': -2305.9623, 'eps':     0.5005, 'len':  4050.4900, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   24000, Reward:  -166.424 [  98.236], Avg:  -222.205 (0.001) <0-00:12:02> ({'r_t': -2606.8510, 'eps':     0.0005, 'len':  4218.7840, 'dyn_loss':    22.8432, 'dot_loss':     3.6551, 'ddot_loss':     1.7962, 'rew_loss':    12.1533, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   25000, Reward:  -124.925 [ 126.711], Avg:  -218.463 (0.500) <0-00:13:50> ({'r_t': -2290.5749, 'eps':     0.5005, 'len':  4390.4970, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   26000, Reward:  -178.437 [ 106.606], Avg:  -216.981 (0.001) <0-00:14:42> ({'r_t': -2427.7630, 'eps':     0.0005, 'len':  4559.3490, 'dyn_loss':    18.4184, 'dot_loss':     2.9806, 'ddot_loss':     1.5148, 'rew_loss':    12.1278, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   27000, Reward:  -206.517 [  87.578], Avg:  -216.607 (0.500) <0-00:15:40> ({'r_t': -1837.0364, 'eps':     0.5005, 'len':  4730.9690, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   28000, Reward:  -246.948 [ 125.131], Avg:  -217.653 (0.001) <0-00:16:31> ({'r_t': -2521.7207, 'eps':     0.0005, 'len':  4896.9570, 'dyn_loss':    15.3652, 'dot_loss':     2.4912, 'ddot_loss':     1.2932, 'rew_loss':    11.8562, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   29000, Reward:  -229.393 [ 110.469], Avg:  -218.045 (0.500) <0-00:17:29> ({'r_t': -1379.7308, 'eps':     0.5005, 'len':  5053.5530, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   30000, Reward:  -176.227 [  97.305], Avg:  -216.696 (0.001) <0-00:18:26> ({'r_t': -2046.8509, 'eps':     0.0005, 'len':  5191.6950, 'dyn_loss':    13.0245, 'dot_loss':     2.1149, 'ddot_loss':     1.1241, 'rew_loss':    10.1812, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   31000, Reward:  -180.115 [ 129.641], Avg:  -215.553 (0.500) <0-00:19:30> ({'r_t': -1380.5447, 'eps':     0.5005, 'len':  5339.7820, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   32000, Reward:  -210.547 [  95.669], Avg:  -215.401 (0.001) <0-00:20:24> ({'r_t': -2174.9265, 'eps':     0.0005, 'len':  5480.9470, 'dyn_loss':    11.1194, 'dot_loss':     1.8125, 'ddot_loss':     0.9881, 'rew_loss':    10.6664, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   33000, Reward:  -156.965 [ 105.103], Avg:  -213.682 (0.500) <0-00:21:25> ({'r_t': -1388.6952, 'eps':     0.5005, 'len':  5628.8590, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   34000, Reward:  -118.427 [ 109.198], Avg:  -210.961 (0.001) <0-00:22:25> ({'r_t': -1709.3401, 'eps':     0.0005, 'len':  5761.7120, 'dyn_loss':     9.5446, 'dot_loss':     1.5631, 'ddot_loss':     0.8714, 'rew_loss':     9.6502, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   35000, Reward:  -121.475 [ 146.018], Avg:  -208.475 (0.500) <0-00:23:27> ({'r_t': -1385.8759, 'eps':     0.5005, 'len':  5895.3770, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   36000, Reward:  -160.027 [ 117.207], Avg:  -207.165 (0.001) <0-00:24:54> ({'r_t': -2111.7594, 'eps':     0.0005, 'len':  6018.1610, 'dyn_loss':     8.3587, 'dot_loss':     1.3666, 'ddot_loss':     0.7792, 'rew_loss':     9.2956, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   37000, Reward:  -178.952 [ 109.213], Avg:  -206.423 (0.500) <0-00:25:53> ({'r_t': -1132.4817, 'eps':     0.5005, 'len':  6161.4560, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   38000, Reward:  -117.862 [  65.828], Avg:  -204.152 (0.001) <0-00:26:52> ({'r_t': -2186.3526, 'eps':     0.0005, 'len':  6291.0350, 'dyn_loss':     7.3973, 'dot_loss':     1.2063, 'ddot_loss':     0.7054, 'rew_loss':     9.0186, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   39000, Reward:   -98.032 [  74.213], Avg:  -201.499 (0.500) <0-00:27:51> ({'r_t': -1134.5687, 'eps':     0.5005, 'len':  6430.9860, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   40000, Reward:  -120.523 [  83.092], Avg:  -199.524 (0.001) <0-00:28:50> ({'r_t': -1990.1567, 'eps':     0.0005, 'len':  6558.0470, 'dyn_loss':     6.5640, 'dot_loss':     1.0655, 'ddot_loss':     0.6346, 'rew_loss':     8.9476, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   41000, Reward:  -171.868 [ 156.650], Avg:  -198.866 (0.500) <0-00:29:51> ({'r_t': -1087.7097, 'eps':     0.5005, 'len':  6697.5330, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   42000, Reward:  -241.211 [ 115.593], Avg:  -199.850 (0.001) <0-00:30:51> ({'r_t': -2102.8601, 'eps':     0.0005, 'len':  6824.3490, 'dyn_loss':     5.8273, 'dot_loss':     0.9504, 'ddot_loss':     0.5893, 'rew_loss':     9.5774, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   43000, Reward:  -156.069 [  76.595], Avg:  -198.855 (0.500) <0-00:32:40> ({'r_t': -1188.2818, 'eps':     0.5005, 'len':  6962.3300, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   44000, Reward:  -207.096 [ 109.919], Avg:  -199.039 (0.001) <0-00:34:28> ({'r_t': -1895.7011, 'eps':     0.0005, 'len':  7090.9620, 'dyn_loss':     5.1620, 'dot_loss':     0.8414, 'ddot_loss':     0.5358, 'rew_loss':     9.1459, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   45000, Reward:  -236.291 [ 143.928], Avg:  -199.848 (0.500) <0-00:35:29> ({'r_t': -1169.4826, 'eps':     0.5005, 'len':  7221.8450, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   46000, Reward:  -271.328 [ 125.188], Avg:  -201.369 (0.001) <0-00:36:33> ({'r_t': -1958.4048, 'eps':     0.0005, 'len':  7342.4490, 'dyn_loss':     4.7006, 'dot_loss':     0.7540, 'ddot_loss':     0.4893, 'rew_loss':     8.7412, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   47000, Reward:  -236.500 [ 121.944], Avg:  -202.101 (0.500) <0-00:37:36> ({'r_t': -1247.0631, 'eps':     0.5005, 'len':  7475.7760, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   48000, Reward:  -323.099 [ 127.030], Avg:  -204.570 (0.001) <0-00:38:37> ({'r_t': -2148.5367, 'eps':     0.0005, 'len':  7588.7080, 'dyn_loss':     4.1449, 'dot_loss':     0.6682, 'ddot_loss':     0.4414, 'rew_loss':     8.4014, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   49000, Reward:  -338.263 [ 137.819], Avg:  -207.244 (0.500) <0-00:39:35> ({'r_t': -1876.4997, 'eps':     0.5005, 'len':  7723.3560, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   50000, Reward:  -311.506 [ 108.481], Avg:  -209.289 (0.001) <0-00:40:37> ({'r_t': -1936.9062, 'eps':     0.0005, 'len':  7840.6970, 'dyn_loss':     3.8293, 'dot_loss':     0.6051, 'ddot_loss':     0.4122, 'rew_loss':     8.3886, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   51000, Reward:  -273.292 [ 148.579], Avg:  -210.520 (0.500) <0-00:41:38> ({'r_t': -1716.2234, 'eps':     0.5005, 'len':  7971.5430, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   52000, Reward:  -372.204 [ 113.841], Avg:  -213.570 (0.001) <0-00:43:05> ({'r_t': -1934.6457, 'eps':     0.0005, 'len':  8082.5450, 'dyn_loss':     3.4413, 'dot_loss':     0.5439, 'ddot_loss':     0.3886, 'rew_loss':     9.0918, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   53000, Reward:  -319.874 [ 123.067], Avg:  -215.539 (0.500) <0-00:44:02> ({'r_t': -1610.7210, 'eps':     0.5005, 'len':  8208.4230, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   54000, Reward:  -330.592 [ 193.069], Avg:  -217.631 (0.001) <0-00:45:04> ({'r_t': -2014.6661, 'eps':     0.0005, 'len':  8320.4650, 'dyn_loss':     3.0654, 'dot_loss':     0.4841, 'ddot_loss':     0.3470, 'rew_loss':     7.9379, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   55000, Reward:  -253.539 [ 141.010], Avg:  -218.272 (0.500) <0-00:46:09> ({'r_t': -1733.7751, 'eps':     0.5005, 'len':  8454.5350, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   56000, Reward:  -306.306 [ 103.865], Avg:  -219.816 (0.001) <0-00:47:09> ({'r_t': -2136.5453, 'eps':     0.0005, 'len':  8567.2370, 'dyn_loss':     2.8324, 'dot_loss':     0.4353, 'ddot_loss':     0.3274, 'rew_loss':     8.5359, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   57000, Reward:  -258.930 [ 112.536], Avg:  -220.491 (0.500) <0-00:48:08> ({'r_t': -1561.4454, 'eps':     0.5005, 'len':  8697.7570, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   58000, Reward:  -294.105 [ 100.506], Avg:  -221.738 (0.001) <0-00:49:12> ({'r_t': -1947.5441, 'eps':     0.0005, 'len':  8807.9720, 'dyn_loss':     2.5542, 'dot_loss':     0.3874, 'ddot_loss':     0.2977, 'rew_loss':     7.8423, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   59000, Reward:  -290.805 [ 140.921], Avg:  -222.890 (0.500) <0-00:50:09> ({'r_t': -1764.6294, 'eps':     0.5005, 'len':  8936.9100, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   60000, Reward:  -286.845 [ 111.109], Avg:  -223.938 (0.001) <0-00:51:14> ({'r_t': -1859.7338, 'eps':     0.0005, 'len':  9043.4540, 'dyn_loss':     2.3496, 'dot_loss':     0.3446, 'ddot_loss':     0.2746, 'rew_loss':     7.6450, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   61000, Reward:  -308.594 [ 161.154], Avg:  -225.303 (0.500) <0-00:52:10> ({'r_t': -1695.8445, 'eps':     0.5005, 'len':  9164.9720, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   62000, Reward:  -323.180 [ 151.823], Avg:  -226.857 (0.001) <0-00:53:12> ({'r_t': -1837.8715, 'eps':     0.0005, 'len':  9271.7190, 'dyn_loss':     2.1683, 'dot_loss':     0.3077, 'ddot_loss':     0.2535, 'rew_loss':     7.7841, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   63000, Reward:  -275.891 [ 159.670], Avg:  -227.623 (0.500) <0-00:54:11> ({'r_t': -1503.5775, 'eps':     0.5005, 'len':  9393.6360, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   64000, Reward:  -210.711 [  74.732], Avg:  -227.363 (0.001) <0-00:55:16> ({'r_t': -1780.9009, 'eps':     0.0005, 'len':  9492.5070, 'dyn_loss':     1.9054, 'dot_loss':     0.2757, 'ddot_loss':     0.2379, 'rew_loss':     7.7636, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   65000, Reward:  -232.708 [ 105.881], Avg:  -227.444 (0.500) <0-00:56:13> ({'r_t': -1178.5336, 'eps':     0.5005, 'len':  9608.5100, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   66000, Reward:  -189.341 [ 105.369], Avg:  -226.875 (0.001) <0-00:57:59> ({'r_t': -1876.3368, 'eps':     0.0005, 'len':  9711.2500, 'dyn_loss':     1.7115, 'dot_loss':     0.2506, 'ddot_loss':     0.2219, 'rew_loss':     7.6538, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   67000, Reward:  -181.454 [ 101.401], Avg:  -226.207 (0.500) <0-00:59:01> ({'r_t': -1012.5355, 'eps':     0.5005, 'len':  9839.2760, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   68000, Reward:  -125.146 [  90.307], Avg:  -224.743 (0.001) <0-01:00:11> ({'r_t': -1658.9300, 'eps':     0.0005, 'len':  9950.5920, 'dyn_loss':     1.5418, 'dot_loss':     0.2298, 'ddot_loss':     0.2194, 'rew_loss':     7.8004, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   69000, Reward:  -110.320 [  98.328], Avg:  -223.108 (0.500) <0-01:01:10> ({'r_t':  -753.8581, 'eps':     0.5005, 'len': 10076.6620, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   70000, Reward:  -106.558 [  84.094], Avg:  -221.466 (0.001) <0-01:02:29> ({'r_t': -1498.9558, 'eps':     0.0005, 'len': 10179.8500, 'dyn_loss':     1.2786, 'dot_loss':     0.1984, 'ddot_loss':     0.1885, 'rew_loss':     6.9894, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   71000, Reward:  -119.297 [ 109.571], Avg:  -220.047 (0.500) <0-01:04:11> ({'r_t':  -574.9146, 'eps':     0.5005, 'len': 10297.1580, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   72000, Reward:   -89.534 [  76.264], Avg:  -218.260 (0.001) <0-01:05:22> ({'r_t': -1595.6426, 'eps':     0.0005, 'len': 10387.8190, 'dyn_loss':     1.1741, 'dot_loss':     0.1889, 'ddot_loss':     0.2022, 'rew_loss':     8.6273, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   73000, Reward:  -116.162 [  68.199], Avg:  -216.880 (0.500) <0-01:07:01> ({'r_t':  -581.1914, 'eps':     0.5005, 'len': 10505.1170, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   74000, Reward:   -44.176 [  50.136], Avg:  -214.577 (0.001) <0-01:08:50> ({'r_t': -1475.7591, 'eps':     0.0005, 'len': 10597.3880, 'dyn_loss':     0.9291, 'dot_loss':     0.1644, 'ddot_loss':     0.1747, 'rew_loss':     7.3626, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   75000, Reward:   -73.694 [  53.685], Avg:  -212.723 (0.500) <0-01:09:54> ({'r_t':  -402.1562, 'eps':     0.5005, 'len': 10720.3600, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   76000, Reward:   -57.922 [  84.689], Avg:  -210.713 (0.001) <0-01:11:29> ({'r_t': -1689.6158, 'eps':     0.0005, 'len': 10820.1590, 'dyn_loss':     0.7703, 'dot_loss':     0.1483, 'ddot_loss':     0.1700, 'rew_loss':     7.4104, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   77000, Reward:   -45.398 [  59.706], Avg:  -208.594 (0.500) <0-01:13:12> ({'r_t':  -305.0387, 'eps':     0.5005, 'len': 10939.7300, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   78000, Reward:   -31.057 [  66.352], Avg:  -206.346 (0.001) <0-01:15:02> ({'r_t': -1609.5894, 'eps':     0.0005, 'len': 11031.8250, 'dyn_loss':     0.6444, 'dot_loss':     0.1340, 'ddot_loss':     0.1597, 'rew_loss':     7.8339, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   79000, Reward:   -29.102 [  49.708], Avg:  -204.131 (0.500) <0-01:16:46> ({'r_t':  -346.9860, 'eps':     0.5005, 'len': 11151.1600, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   80000, Reward:     6.535 [  87.177], Avg:  -201.530 (0.001) <0-01:18:42> ({'r_t': -1449.4626, 'eps':     0.0005, 'len': 11250.4790, 'dyn_loss':     0.5192, 'dot_loss':     0.1195, 'ddot_loss':     0.1502, 'rew_loss':     8.4045, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   81000, Reward:   -67.310 [  83.098], Avg:  -199.893 (0.500) <0-01:20:33> ({'r_t':  -253.9619, 'eps':     0.5005, 'len': 11353.1380, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   82000, Reward:     9.689 [  72.496], Avg:  -197.368 (0.001) <0-01:22:30> ({'r_t': -1374.1203, 'eps':     0.0005, 'len': 11430.2970, 'dyn_loss':     0.4304, 'dot_loss':     0.1056, 'ddot_loss':     0.1385, 'rew_loss':     7.5546, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   83000, Reward:    -6.657 [ 100.381], Avg:  -195.098 (0.500) <0-01:24:21> ({'r_t':  -134.1796, 'eps':     0.5005, 'len': 11534.1300, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   84000, Reward:    -9.043 [  82.470], Avg:  -192.909 (0.001) <0-01:26:21> ({'r_t': -1372.9720, 'eps':     0.0005, 'len': 11618.1510, 'dyn_loss':     0.3872, 'dot_loss':     0.1013, 'ddot_loss':     0.1431, 'rew_loss':     8.1769, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   85000, Reward:    22.215 [  93.291], Avg:  -190.407 (0.500) <0-01:28:12> ({'r_t':  -130.2581, 'eps':     0.5005, 'len': 11726.8060, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   86000, Reward:    -4.029 [  65.060], Avg:  -188.265 (0.001) <0-01:30:11> ({'r_t': -1288.0132, 'eps':     0.0005, 'len': 11800.6930, 'dyn_loss':     0.3061, 'dot_loss':     0.0854, 'ddot_loss':     0.1249, 'rew_loss':     7.9050, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   87000, Reward:   -34.019 [  80.010], Avg:  -186.512 (0.500) <0-01:32:02> ({'r_t':   -68.1006, 'eps':     0.5005, 'len': 11894.5640, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   88000, Reward:    19.033 [  59.765], Avg:  -184.203 (0.001) <0-01:34:03> ({'r_t': -1406.0503, 'eps':     0.0005, 'len': 11963.6420, 'dyn_loss':     0.2654, 'dot_loss':     0.0767, 'ddot_loss':     0.1159, 'rew_loss':     7.2846, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   89000, Reward:    -2.019 [  92.188], Avg:  -182.179 (0.500) <0-01:35:54> ({'r_t':   -81.0110, 'eps':     0.5005, 'len': 12060.0870, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   90000, Reward:     6.940 [  74.596], Avg:  -180.100 (0.001) <0-01:37:55> ({'r_t': -1451.4753, 'eps':     0.0005, 'len': 12133.7750, 'dyn_loss':     0.2070, 'dot_loss':     0.0653, 'ddot_loss':     0.1036, 'rew_loss':     6.8900, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   91000, Reward:   -19.623 [  86.416], Avg:  -178.356 (0.500) <0-01:39:46> ({'r_t':   -83.0822, 'eps':     0.5005, 'len': 12234.7660, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   92000, Reward:   -36.742 [  55.812], Avg:  -176.833 (0.001) <0-01:41:47> ({'r_t': -1246.6034, 'eps':     0.0005, 'len': 12296.5940, 'dyn_loss':     0.2032, 'dot_loss':     0.0664, 'ddot_loss':     0.1120, 'rew_loss':     7.9839, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   93000, Reward:    -8.855 [  73.037], Avg:  -175.046 (0.500) <0-01:43:38> ({'r_t':   -86.9434, 'eps':     0.5005, 'len': 12402.9600, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   94000, Reward:     0.210 [  37.006], Avg:  -173.201 (0.001) <0-01:45:38> ({'r_t': -1204.2169, 'eps':     0.0005, 'len': 12472.7920, 'dyn_loss':     0.1637, 'dot_loss':     0.0562, 'ddot_loss':     0.0978, 'rew_loss':     7.9724, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   95000, Reward:   -17.392 [  56.938], Avg:  -171.578 (0.500) <0-01:47:29> ({'r_t':  -112.7151, 'eps':     0.5005, 'len': 12572.3530, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   96000, Reward:    12.416 [  51.079], Avg:  -169.682 (0.001) <0-01:49:32> ({'r_t': -1449.9890, 'eps':     0.0005, 'len': 12641.9220, 'dyn_loss':     0.1660, 'dot_loss':     0.0592, 'ddot_loss':     0.1077, 'rew_loss':     8.3400, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   97000, Reward:   -30.415 [  41.333], Avg:  -168.260 (0.500) <0-01:50:43> ({'r_t':   -81.4106, 'eps':     0.5005, 'len': 12743.8500, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   98000, Reward:   -14.990 [  67.131], Avg:  -166.712 (0.001) <0-01:52:44> ({'r_t': -1222.1739, 'eps':     0.0005, 'len': 12813.5280, 'dyn_loss':     0.1333, 'dot_loss':     0.0498, 'ddot_loss':     0.0928, 'rew_loss':     8.1079, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   99000, Reward:    12.285 [  55.297], Avg:  -164.922 (0.500) <0-01:54:36> ({'r_t':   -81.2438, 'eps':     0.5005, 'len': 12910.4160, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  100000, Reward:     2.263 [  69.099], Avg:  -163.267 (0.001) <0-01:56:39> ({'r_t': -1358.0911, 'eps':     0.0005, 'len': 12978.2530, 'dyn_loss':     0.1276, 'dot_loss':     0.0463, 'ddot_loss':     0.0878, 'rew_loss':     7.8615, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  101000, Reward:   -85.306 [ 180.905], Avg:  -162.503 (0.500) <0-01:58:30> ({'r_t':   -64.9969, 'eps':     0.5005, 'len': 13076.6840, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  102000, Reward:    -2.453 [  78.381], Avg:  -160.949 (0.001) <0-02:00:33> ({'r_t': -1194.6888, 'eps':     0.0005, 'len': 13149.2420, 'dyn_loss':     0.1210, 'dot_loss':     0.0433, 'ddot_loss':     0.0835, 'rew_loss':     7.9224, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  103000, Reward:     0.170 [  59.555], Avg:  -159.400 (0.500) <0-02:02:24> ({'r_t':   -64.7345, 'eps':     0.5005, 'len': 13245.2170, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  104000, Reward:    -6.967 [  42.531], Avg:  -157.948 (0.001) <0-02:04:27> ({'r_t': -1419.0849, 'eps':     0.0005, 'len': 13317.4220, 'dyn_loss':     0.1172, 'dot_loss':     0.0426, 'ddot_loss':     0.0843, 'rew_loss':     8.4554, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  105000, Reward:    -6.613 [  52.652], Avg:  -156.520 (0.500) <0-02:06:18> ({'r_t':  -116.1948, 'eps':     0.5005, 'len': 13426.2650, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  106000, Reward:     3.798 [  49.139], Avg:  -155.022 (0.001) <0-02:08:22> ({'r_t': -1518.5515, 'eps':     0.0005, 'len': 13505.2100, 'dyn_loss':     0.1036, 'dot_loss':     0.0373, 'ddot_loss':     0.0742, 'rew_loss':     7.6359, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  107000, Reward:    -5.996 [  55.260], Avg:  -153.642 (0.500) <0-02:10:13> ({'r_t':  -143.7324, 'eps':     0.5005, 'len': 13618.4030, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  108000, Reward:    -5.314 [  26.975], Avg:  -152.281 (0.001) <0-02:12:19> ({'r_t': -1249.5481, 'eps':     0.0005, 'len': 13674.9990, 'dyn_loss':     0.1096, 'dot_loss':     0.0424, 'ddot_loss':     0.0859, 'rew_loss':     8.6580, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  109000, Reward:   -25.145 [  34.272], Avg:  -151.125 (0.500) <0-02:14:11> ({'r_t':  -108.1504, 'eps':     0.5005, 'len': 13777.7230, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  110000, Reward:   -33.332 [  73.051], Avg:  -150.064 (0.001) <0-02:16:04> ({'r_t': -1244.8247, 'eps':     0.0005, 'len': 13851.7570, 'dyn_loss':     0.0930, 'dot_loss':     0.0348, 'ddot_loss':     0.0707, 'rew_loss':     7.7715, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  111000, Reward:   -27.697 [  77.736], Avg:  -148.972 (0.500) <0-02:17:41> ({'r_t':  -141.0447, 'eps':     0.5005, 'len': 13954.0670, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  112000, Reward:   -31.580 [  46.427], Avg:  -147.933 (0.001) <0-02:19:35> ({'r_t': -1362.4654, 'eps':     0.0005, 'len': 14021.6580, 'dyn_loss':     0.1121, 'dot_loss':     0.0460, 'ddot_loss':     0.0960, 'rew_loss':     9.2626, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  113000, Reward:   -24.628 [  57.436], Avg:  -146.851 (0.500) <0-02:21:12> ({'r_t':  -118.7677, 'eps':     0.5005, 'len': 14125.9570, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  114000, Reward:     5.155 [  29.630], Avg:  -145.529 (0.001) <0-02:23:22> ({'r_t': -1502.5271, 'eps':     0.0005, 'len': 14202.5410, 'dyn_loss':     0.0958, 'dot_loss':     0.0377, 'ddot_loss':     0.0785, 'rew_loss':     8.5269, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  115000, Reward:     2.468 [  50.452], Avg:  -144.254 (0.500) <0-02:25:14> ({'r_t':  -135.0012, 'eps':     0.5005, 'len': 14307.4920, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  116000, Reward:   -19.913 [  79.239], Avg:  -143.191 (0.001) <0-02:27:14> ({'r_t': -1235.2668, 'eps':     0.0005, 'len': 14371.5130, 'dyn_loss':     0.1191, 'dot_loss':     0.0505, 'ddot_loss':     0.1068, 'rew_loss':     9.8126, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  117000, Reward:    -8.236 [  64.572], Avg:  -142.047 (0.500) <0-02:29:46> ({'r_t':   -94.6260, 'eps':     0.5005, 'len': 14465.7970, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  118000, Reward:   -59.687 [ 101.917], Avg:  -141.355 (0.001) <0-02:32:29> ({'r_t': -1584.2141, 'eps':     0.0005, 'len': 14540.4090, 'dyn_loss':     0.0952, 'dot_loss':     0.0369, 'ddot_loss':     0.0772, 'rew_loss':     8.4015, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  119000, Reward:   -61.086 [  66.516], Avg:  -140.686 (0.500) <0-02:34:22> ({'r_t':   -92.7358, 'eps':     0.5005, 'len': 14648.5540, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  120000, Reward:   -49.579 [ 115.061], Avg:  -139.933 (0.001) <0-02:36:17> ({'r_t': -1318.9128, 'eps':     0.0005, 'len': 14719.6630, 'dyn_loss':     0.1088, 'dot_loss':     0.0476, 'ddot_loss':     0.1016, 'rew_loss':     9.4133, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  121000, Reward:     0.109 [  49.446], Avg:  -138.785 (0.500) <0-02:37:55> ({'r_t':  -116.6224, 'eps':     0.5005, 'len': 14824.6870, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  122000, Reward:   -28.767 [  55.750], Avg:  -137.891 (0.001) <0-02:39:52> ({'r_t': -1264.5656, 'eps':     0.0005, 'len': 14901.2050, 'dyn_loss':     0.1057, 'dot_loss':     0.0449, 'ddot_loss':     0.0953, 'rew_loss':     9.2794, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  123000, Reward:   -51.449 [  90.418], Avg:  -137.194 (0.500) <0-02:41:29> ({'r_t':  -100.9442, 'eps':     0.5005, 'len': 14995.6980, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  124000, Reward:    21.124 [  94.612], Avg:  -135.927 (0.001) <0-02:43:23> ({'r_t': -1411.7121, 'eps':     0.0005, 'len': 15075.0770, 'dyn_loss':     0.0907, 'dot_loss':     0.0377, 'ddot_loss':     0.0796, 'rew_loss':     8.4628, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  125000, Reward:   -42.815 [  83.215], Avg:  -135.188 (0.500) <0-02:45:00> ({'r_t':   -11.3374, 'eps':     0.5005, 'len': 15176.9610, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  126000, Reward:   -18.492 [  65.791], Avg:  -134.269 (0.001) <0-02:46:53> ({'r_t': -1500.9182, 'eps':     0.0005, 'len': 15252.2260, 'dyn_loss':     0.0840, 'dot_loss':     0.0369, 'ddot_loss':     0.0785, 'rew_loss':     8.6191, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  127000, Reward:   -22.946 [  74.921], Avg:  -133.400 (0.500) <0-02:48:30> ({'r_t':  -165.6529, 'eps':     0.5005, 'len': 15356.5780, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  128000, Reward:   -16.099 [  47.944], Avg:  -132.490 (0.001) <0-02:50:24> ({'r_t': -1540.8732, 'eps':     0.0005, 'len': 15431.1580, 'dyn_loss':     0.0913, 'dot_loss':     0.0414, 'ddot_loss':     0.0886, 'rew_loss':     8.9771, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  129000, Reward:   -31.704 [  75.687], Avg:  -131.715 (0.500) <0-02:52:01> ({'r_t':  -128.7176, 'eps':     0.5005, 'len': 15541.2830, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  130000, Reward:   -38.522 [ 114.311], Avg:  -131.004 (0.001) <0-02:53:58> ({'r_t': -1240.7907, 'eps':     0.0005, 'len': 15609.1680, 'dyn_loss':     0.1047, 'dot_loss':     0.0506, 'ddot_loss':     0.1091, 'rew_loss':     9.4437, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  131000, Reward:     0.271 [  54.828], Avg:  -130.009 (0.500) <0-02:55:35> ({'r_t':   -55.9555, 'eps':     0.5005, 'len': 15707.1440, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  132000, Reward:    18.453 [  67.746], Avg:  -128.893 (0.001) <0-02:57:29> ({'r_t': -1412.9459, 'eps':     0.0005, 'len': 15780.0340, 'dyn_loss':     0.0994, 'dot_loss':     0.0472, 'ddot_loss':     0.1015, 'rew_loss':     9.3742, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  133000, Reward:    11.659 [  66.219], Avg:  -127.844 (0.500) <0-02:59:06> ({'r_t':   -90.8146, 'eps':     0.5005, 'len': 15889.8050, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  134000, Reward:    24.422 [  92.836], Avg:  -126.716 (0.001) <0-03:01:06> ({'r_t': -1210.3245, 'eps':     0.0005, 'len': 15954.4510, 'dyn_loss':     0.1043, 'dot_loss':     0.0477, 'ddot_loss':     0.1020, 'rew_loss':     9.4094, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  135000, Reward:    -2.600 [ 108.288], Avg:  -125.803 (0.500) <0-03:02:48> ({'r_t':  -104.2236, 'eps':     0.5005, 'len': 16058.7090, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  136000, Reward:     2.388 [  33.634], Avg:  -124.868 (0.001) <0-03:04:47> ({'r_t': -1255.8340, 'eps':     0.0005, 'len': 16133.4940, 'dyn_loss':     0.0945, 'dot_loss':     0.0442, 'ddot_loss':     0.0955, 'rew_loss':     8.8829, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  137000, Reward:   -67.551 [  78.364], Avg:  -124.452 (0.500) <0-03:06:31> ({'r_t':   -96.3920, 'eps':     0.5005, 'len': 16231.3630, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  138000, Reward:   -54.242 [ 100.987], Avg:  -123.947 (0.001) <0-03:08:34> ({'r_t': -1242.1000, 'eps':     0.0005, 'len': 16294.3120, 'dyn_loss':     0.1048, 'dot_loss':     0.0536, 'ddot_loss':     0.1167, 'rew_loss':     9.7164, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  139000, Reward:   -38.500 [  86.632], Avg:  -123.337 (0.500) <0-03:10:13> ({'r_t':  -151.8528, 'eps':     0.5005, 'len': 16392.7340, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  140000, Reward:   -35.723 [  42.299], Avg:  -122.716 (0.001) <0-03:12:16> ({'r_t': -1392.9146, 'eps':     0.0005, 'len': 16461.9790, 'dyn_loss':     0.1014, 'dot_loss':     0.0498, 'ddot_loss':     0.1078, 'rew_loss':     9.8923, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  141000, Reward:   -61.117 [  62.320], Avg:  -122.282 (0.500) <0-03:13:59> ({'r_t':  -203.7550, 'eps':     0.5005, 'len': 16571.4200, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  142000, Reward:   -32.033 [  81.502], Avg:  -121.651 (0.001) <0-03:16:07> ({'r_t': -1425.6757, 'eps':     0.0005, 'len': 16651.1430, 'dyn_loss':     0.1064, 'dot_loss':     0.0529, 'ddot_loss':     0.1146, 'rew_loss':    10.2082, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  143000, Reward:   -87.818 [  84.856], Avg:  -121.416 (0.500) <0-03:17:57> ({'r_t':   -96.3844, 'eps':     0.5005, 'len': 16760.0480, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  144000, Reward:    27.391 [  60.358], Avg:  -120.389 (0.001) <0-03:20:27> ({'r_t': -1158.1461, 'eps':     0.0005, 'len': 16822.4480, 'dyn_loss':     0.1062, 'dot_loss':     0.0548, 'ddot_loss':     0.1198, 'rew_loss':    10.1003, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  145000, Reward:   -20.509 [  76.881], Avg:  -119.705 (0.500) <0-03:22:44> ({'r_t':  -112.7655, 'eps':     0.5005, 'len': 16913.3540, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  146000, Reward:    -7.541 [  62.504], Avg:  -118.942 (0.001) <0-03:25:21> ({'r_t': -1523.0722, 'eps':     0.0005, 'len': 16985.6760, 'dyn_loss':     0.0933, 'dot_loss':     0.0473, 'ddot_loss':     0.1037, 'rew_loss':     9.0927, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  147000, Reward:    -9.933 [  74.796], Avg:  -118.206 (0.500) <0-03:27:44> ({'r_t':  -140.4723, 'eps':     0.5005, 'len': 17086.4680, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  148000, Reward:    43.005 [  45.084], Avg:  -117.124 (0.001) <0-03:30:26> ({'r_t': -1439.4129, 'eps':     0.0005, 'len': 17156.7390, 'dyn_loss':     0.1040, 'dot_loss':     0.0518, 'ddot_loss':     0.1125, 'rew_loss':     9.5902, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  149000, Reward:     4.605 [  72.938], Avg:  -116.312 (0.500) <0-03:32:48> ({'r_t':   -64.8807, 'eps':     0.5005, 'len': 17259.3510, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  150000, Reward:     4.849 [  70.538], Avg:  -115.510 (0.001) <0-03:35:27> ({'r_t': -1407.4807, 'eps':     0.0005, 'len': 17332.4550, 'dyn_loss':     0.1022, 'dot_loss':     0.0536, 'ddot_loss':     0.1177, 'rew_loss':     9.6613, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  151000, Reward:    36.727 [  35.495], Avg:  -114.508 (0.500) <0-03:37:51> ({'r_t':   -41.7101, 'eps':     0.5005, 'len': 17433.5340, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  152000, Reward:   -15.486 [  68.836], Avg:  -113.861 (0.001) <0-03:40:32> ({'r_t': -1483.7443, 'eps':     0.0005, 'len': 17504.5710, 'dyn_loss':     0.1059, 'dot_loss':     0.0534, 'ddot_loss':     0.1165, 'rew_loss':     9.6186, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  153000, Reward:   -38.156 [  64.176], Avg:  -113.370 (0.500) <0-03:42:53> ({'r_t':  -249.2546, 'eps':     0.5005, 'len': 17615.2080, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  154000, Reward:   -11.232 [  51.983], Avg:  -112.711 (0.001) <0-03:45:39> ({'r_t': -1355.0223, 'eps':     0.0005, 'len': 17699.3000, 'dyn_loss':     0.1225, 'dot_loss':     0.0661, 'ddot_loss':     0.1459, 'rew_loss':    10.6094, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  155000, Reward:    -4.208 [  74.417], Avg:  -112.015 (0.500) <0-03:48:03> ({'r_t':   -58.5778, 'eps':     0.5005, 'len': 17802.7050, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  156000, Reward:    -0.088 [  62.674], Avg:  -111.302 (0.001) <0-03:50:42> ({'r_t': -1342.1835, 'eps':     0.0005, 'len': 17866.5920, 'dyn_loss':     0.0974, 'dot_loss':     0.0507, 'ddot_loss':     0.1117, 'rew_loss':     9.2562, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  157000, Reward:   -36.756 [  73.860], Avg:  -110.830 (0.500) <0-03:53:04> ({'r_t':  -150.8598, 'eps':     0.5005, 'len': 17968.8760, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  158000, Reward:    -3.480 [  68.237], Avg:  -110.155 (0.001) <0-03:55:44> ({'r_t': -1339.9732, 'eps':     0.0005, 'len': 18043.4070, 'dyn_loss':     0.0936, 'dot_loss':     0.0469, 'ddot_loss':     0.1028, 'rew_loss':     9.0912, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  159000, Reward:    11.228 [  47.191], Avg:  -109.397 (0.500) <0-03:58:06> ({'r_t':  -107.1529, 'eps':     0.5005, 'len': 18143.8430, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  160000, Reward:   -31.118 [  70.247], Avg:  -108.910 (0.001) <0-04:00:49> ({'r_t': -1368.4130, 'eps':     0.0005, 'len': 18221.8120, 'dyn_loss':     0.1061, 'dot_loss':     0.0536, 'ddot_loss':     0.1176, 'rew_loss':     9.6755, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  161000, Reward:    13.591 [  84.382], Avg:  -108.154 (0.500) <0-04:03:15> ({'r_t':  -110.3459, 'eps':     0.5005, 'len': 18329.8340, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  162000, Reward:    15.746 [  72.074], Avg:  -107.394 (0.001) <0-04:06:00> ({'r_t': -1362.4699, 'eps':     0.0005, 'len': 18402.8990, 'dyn_loss':     0.1152, 'dot_loss':     0.0597, 'ddot_loss':     0.1311, 'rew_loss':    10.3272, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  163000, Reward:    -1.216 [  53.456], Avg:  -106.747 (0.500) <0-04:08:26> ({'r_t':  -179.4651, 'eps':     0.5005, 'len': 18514.4380, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  164000, Reward:   -37.541 [  69.371], Avg:  -106.327 (0.001) <0-04:11:11> ({'r_t': -1272.6774, 'eps':     0.0005, 'len': 18585.8120, 'dyn_loss':     0.1015, 'dot_loss':     0.0527, 'ddot_loss':     0.1163, 'rew_loss':     9.6500, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  165000, Reward:   -38.667 [  87.109], Avg:  -105.920 (0.500) <0-04:13:35> ({'r_t':  -130.0000, 'eps':     0.5005, 'len': 18686.1420, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  166000, Reward:    -5.993 [  96.367], Avg:  -105.321 (0.001) <0-04:16:31> ({'r_t': -1227.2030, 'eps':     0.0005, 'len': 18759.4500, 'dyn_loss':     0.1148, 'dot_loss':     0.0668, 'ddot_loss':     0.1496, 'rew_loss':    10.3904, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  167000, Reward:     3.342 [  87.858], Avg:  -104.674 (0.500) <0-04:18:56> ({'r_t':   -82.7364, 'eps':     0.5005, 'len': 18863.8670, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  168000, Reward:   -48.457 [  91.973], Avg:  -104.342 (0.001) <0-04:21:36> ({'r_t': -1415.0914, 'eps':     0.0005, 'len': 18939.0610, 'dyn_loss':     0.0994, 'dot_loss':     0.0547, 'ddot_loss':     0.1210, 'rew_loss':     9.5945, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  169000, Reward:     1.193 [  44.133], Avg:  -103.721 (0.500) <0-04:23:19> ({'r_t':   -39.4853, 'eps':     0.5005, 'len': 19034.4060, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  170000, Reward:     4.966 [ 103.584], Avg:  -103.085 (0.001) <0-04:25:23> ({'r_t': -1443.8583, 'eps':     0.0005, 'len': 19103.5080, 'dyn_loss':     0.1099, 'dot_loss':     0.0613, 'ddot_loss':     0.1361, 'rew_loss':    10.0264, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  171000, Reward:     1.780 [  86.181], Avg:  -102.476 (0.500) <0-04:27:06> ({'r_t':  -135.0852, 'eps':     0.5005, 'len': 19206.5780, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  172000, Reward:    56.395 [  77.694], Avg:  -101.557 (0.001) <0-04:29:18> ({'r_t': -1356.3303, 'eps':     0.0005, 'len': 19269.5770, 'dyn_loss':     0.1098, 'dot_loss':     0.0602, 'ddot_loss':     0.1332, 'rew_loss':     9.9533, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  173000, Reward:    12.674 [  96.204], Avg:  -100.901 (0.500) <0-04:31:08> ({'r_t':   -76.3987, 'eps':     0.5005, 'len': 19369.9290, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  174000, Reward:    23.246 [  96.753], Avg:  -100.191 (0.001) <0-04:33:16> ({'r_t': -1284.0108, 'eps':     0.0005, 'len': 19443.6200, 'dyn_loss':     0.1067, 'dot_loss':     0.0589, 'ddot_loss':     0.1308, 'rew_loss':     9.9303, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  175000, Reward:     6.231 [  67.978], Avg:   -99.587 (0.500) <0-04:34:59> ({'r_t':  -158.4059, 'eps':     0.5005, 'len': 19549.3680, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  176000, Reward:    -6.669 [  72.424], Avg:   -99.062 (0.001) <0-04:37:04> ({'r_t': -1449.2929, 'eps':     0.0005, 'len': 19624.6020, 'dyn_loss':     0.0939, 'dot_loss':     0.0527, 'ddot_loss':     0.1176, 'rew_loss':     8.9775, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  177000, Reward:    -8.547 [  53.067], Avg:   -98.553 (0.500) <0-04:38:47> ({'r_t':   -79.3454, 'eps':     0.5005, 'len': 19730.8860, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  178000, Reward:    24.376 [  95.459], Avg:   -97.867 (0.001) <0-04:40:55> ({'r_t': -1332.9356, 'eps':     0.0005, 'len': 19798.0800, 'dyn_loss':     0.1127, 'dot_loss':     0.0622, 'ddot_loss':     0.1381, 'rew_loss':    10.3603, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  179000, Reward:   -10.551 [ 102.476], Avg:   -97.381 (0.500) <0-04:42:39> ({'r_t':   -62.1689, 'eps':     0.5005, 'len': 19893.5740, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  180000, Reward:   -22.786 [  68.030], Avg:   -96.969 (0.001) <0-04:44:46> ({'r_t': -1419.3363, 'eps':     0.0005, 'len': 19964.9210, 'dyn_loss':     0.1025, 'dot_loss':     0.0563, 'ddot_loss':     0.1250, 'rew_loss':     9.5068, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  181000, Reward:   -24.264 [  70.564], Avg:   -96.570 (0.500) <0-04:46:29> ({'r_t':   -91.7804, 'eps':     0.5005, 'len': 20064.9990, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  182000, Reward:   -19.763 [  53.295], Avg:   -96.150 (0.001) <0-04:48:38> ({'r_t': -1408.9886, 'eps':     0.0005, 'len': 20134.5550, 'dyn_loss':     0.1101, 'dot_loss':     0.0617, 'ddot_loss':     0.1373, 'rew_loss':     9.8584, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  183000, Reward:   -13.210 [  49.238], Avg:   -95.699 (0.500) <0-04:50:22> ({'r_t':  -115.4155, 'eps':     0.5005, 'len': 20239.8700, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  184000, Reward:    37.156 [  72.741], Avg:   -94.981 (0.001) <0-04:52:31> ({'r_t': -1324.4506, 'eps':     0.0005, 'len': 20304.0850, 'dyn_loss':     0.1123, 'dot_loss':     0.0624, 'ddot_loss':     0.1386, 'rew_loss':    10.1264, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  185000, Reward:   -15.752 [  42.427], Avg:   -94.555 (0.500) <0-04:54:15> ({'r_t':   -75.4996, 'eps':     0.5005, 'len': 20412.9580, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  186000, Reward:     4.524 [  42.679], Avg:   -94.025 (0.001) <0-04:56:20> ({'r_t': -1371.6426, 'eps':     0.0005, 'len': 20489.9170, 'dyn_loss':     0.0986, 'dot_loss':     0.0538, 'ddot_loss':     0.1192, 'rew_loss':     9.2315, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  187000, Reward:     4.022 [  56.723], Avg:   -93.504 (0.500) <0-04:58:03> ({'r_t':   -72.0246, 'eps':     0.5005, 'len': 20596.4630, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  188000, Reward:   -13.676 [  58.285], Avg:   -93.082 (0.001) <0-05:00:13> ({'r_t': -1401.2115, 'eps':     0.0005, 'len': 20678.7720, 'dyn_loss':     0.1084, 'dot_loss':     0.0630, 'ddot_loss':     0.1400, 'rew_loss':    10.0687, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  189000, Reward:    -2.561 [  64.577], Avg:   -92.605 (0.500) <0-05:01:57> ({'r_t':   -65.2068, 'eps':     0.5005, 'len': 20784.4070, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  190000, Reward:    10.265 [  54.143], Avg:   -92.067 (0.001) <0-05:04:02> ({'r_t': -1510.7716, 'eps':     0.0005, 'len': 20860.4040, 'dyn_loss':     0.1048, 'dot_loss':     0.0552, 'ddot_loss':     0.1220, 'rew_loss':     9.6415, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  191000, Reward:   -10.868 [  55.256], Avg:   -91.644 (0.500) <0-05:05:46> ({'r_t':   -98.2638, 'eps':     0.5005, 'len': 20970.1610, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  192000, Reward:    16.635 [  67.009], Avg:   -91.083 (0.001) <0-05:07:51> ({'r_t': -1322.9950, 'eps':     0.0005, 'len': 21035.7130, 'dyn_loss':     0.1027, 'dot_loss':     0.0562, 'ddot_loss':     0.1243, 'rew_loss':     9.7178, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  193000, Reward:   -10.277 [  87.130], Avg:   -90.666 (0.500) <0-05:09:34> ({'r_t':   -53.4600, 'eps':     0.5005, 'len': 21134.8170, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  194000, Reward:    15.957 [  65.847], Avg:   -90.119 (0.001) <0-05:11:44> ({'r_t': -1408.7412, 'eps':     0.0005, 'len': 21199.3970, 'dyn_loss':     0.1139, 'dot_loss':     0.0628, 'ddot_loss':     0.1387, 'rew_loss':    10.1132, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  195000, Reward:     3.189 [  52.289], Avg:   -89.643 (0.500) <0-05:13:27> ({'r_t':    -6.0599, 'eps':     0.5005, 'len': 21302.3270, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  196000, Reward:   -25.067 [  50.563], Avg:   -89.315 (0.001) <0-05:15:37> ({'r_t': -1477.3182, 'eps':     0.0005, 'len': 21367.9700, 'dyn_loss':     0.1105, 'dot_loss':     0.0634, 'ddot_loss':     0.1410, 'rew_loss':    10.1308, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  197000, Reward:   -22.313 [  59.747], Avg:   -88.977 (0.500) <0-05:17:20> ({'r_t':  -115.1503, 'eps':     0.5005, 'len': 21480.5260, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  198000, Reward:   -44.212 [  80.574], Avg:   -88.752 (0.001) <0-05:19:27> ({'r_t': -1330.0546, 'eps':     0.0005, 'len': 21544.2890, 'dyn_loss':     0.0988, 'dot_loss':     0.0529, 'ddot_loss':     0.1167, 'rew_loss':     8.9901, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  199000, Reward:   -13.735 [  39.035], Avg:   -88.377 (0.500) <0-05:21:11> ({'r_t':  -119.4710, 'eps':     0.5005, 'len': 21654.0830, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  200000, Reward:    -9.793 [  38.566], Avg:   -87.986 (0.001) <0-05:23:19> ({'r_t': -1436.2412, 'eps':     0.0005, 'len': 21726.9230, 'dyn_loss':     0.1121, 'dot_loss':     0.0613, 'ddot_loss':     0.1356, 'rew_loss':    10.2657, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  201000, Reward:   -43.404 [  91.853], Avg:   -87.765 (0.500) <0-05:25:02> ({'r_t':  -188.2629, 'eps':     0.5005, 'len': 21839.3960, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  202000, Reward:    10.529 [  76.877], Avg:   -87.281 (0.001) <0-05:27:11> ({'r_t': -1384.2469, 'eps':     0.0005, 'len': 21927.2710, 'dyn_loss':     0.1109, 'dot_loss':     0.0620, 'ddot_loss':     0.1374, 'rew_loss':    10.1268, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  203000, Reward:    26.413 [  81.221], Avg:   -86.724 (0.500) <0-05:29:00> ({'r_t':   -79.3940, 'eps':     0.5005, 'len': 22036.9630, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  204000, Reward:   -27.318 [  31.869], Avg:   -86.434 (0.001) <0-05:31:10> ({'r_t': -1298.6451, 'eps':     0.0005, 'len': 22104.6430, 'dyn_loss':     0.1118, 'dot_loss':     0.0612, 'ddot_loss':     0.1347, 'rew_loss':     9.9818, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  205000, Reward:   -28.735 [  58.557], Avg:   -86.154 (0.500) <0-05:32:52> ({'r_t':  -219.4007, 'eps':     0.5005, 'len': 22211.8240, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  206000, Reward:     5.286 [  54.535], Avg:   -85.712 (0.001) <0-05:35:00> ({'r_t': -1348.4870, 'eps':     0.0005, 'len': 22299.8430, 'dyn_loss':     0.1014, 'dot_loss':     0.0566, 'ddot_loss':     0.1252, 'rew_loss':     9.8014, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  207000, Reward:   -13.111 [  85.126], Avg:   -85.363 (0.500) <0-05:36:52> ({'r_t':  -112.7709, 'eps':     0.5005, 'len': 22407.9440, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  208000, Reward:    25.197 [  69.750], Avg:   -84.834 (0.001) <0-05:39:09> ({'r_t': -1484.2698, 'eps':     0.0005, 'len': 22484.2660, 'dyn_loss':     0.1111, 'dot_loss':     0.0634, 'ddot_loss':     0.1410, 'rew_loss':    10.1851, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  209000, Reward:    -7.387 [  91.866], Avg:   -84.465 (0.500) <0-05:41:01> ({'r_t':   -92.0287, 'eps':     0.5005, 'len': 22592.5270, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  210000, Reward:   -14.484 [  77.571], Avg:   -84.134 (0.001) <0-05:43:14> ({'r_t': -1332.5721, 'eps':     0.0005, 'len': 22668.4690, 'dyn_loss':     0.0974, 'dot_loss':     0.0516, 'ddot_loss':     0.1139, 'rew_loss':     9.4530, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  211000, Reward:    17.039 [  44.655], Avg:   -83.656 (0.500) <0-05:45:06> ({'r_t':  -177.5382, 'eps':     0.5005, 'len': 22782.4180, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  212000, Reward:    -5.883 [  93.934], Avg:   -83.291 (0.001) <0-05:47:22> ({'r_t': -1352.2353, 'eps':     0.0005, 'len': 22856.4860, 'dyn_loss':     0.1104, 'dot_loss':     0.0618, 'ddot_loss':     0.1368, 'rew_loss':     9.9966, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  213000, Reward:     5.602 [  74.140], Avg:   -82.876 (0.500) <0-05:49:13> ({'r_t':   -69.9166, 'eps':     0.5005, 'len': 22958.5540, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  214000, Reward:     5.397 [  54.622], Avg:   -82.465 (0.001) <0-05:51:30> ({'r_t': -1268.2822, 'eps':     0.0005, 'len': 23027.4040, 'dyn_loss':     0.1030, 'dot_loss':     0.0586, 'ddot_loss':     0.1298, 'rew_loss':     9.7637, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  215000, Reward:   -40.219 [  99.013], Avg:   -82.270 (0.500) <0-05:53:22> ({'r_t':  -241.8744, 'eps':     0.5005, 'len': 23137.0220, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  216000, Reward:     0.389 [  82.776], Avg:   -81.889 (0.001) <0-05:55:38> ({'r_t': -1371.9520, 'eps':     0.0005, 'len': 23221.0040, 'dyn_loss':     0.1059, 'dot_loss':     0.0595, 'ddot_loss':     0.1317, 'rew_loss':     9.5708, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  217000, Reward:   -43.225 [  63.833], Avg:   -81.712 (0.500) <0-05:57:30> ({'r_t':  -212.6765, 'eps':     0.5005, 'len': 23330.1730, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  218000, Reward:    -6.162 [  57.154], Avg:   -81.367 (0.001) <0-05:59:46> ({'r_t': -1280.8719, 'eps':     0.0005, 'len': 23405.4410, 'dyn_loss':     0.1074, 'dot_loss':     0.0589, 'ddot_loss':     0.1296, 'rew_loss':     9.7157, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  219000, Reward:   -15.179 [  52.124], Avg:   -81.066 (0.500) <0-06:01:37> ({'r_t':  -182.7584, 'eps':     0.5005, 'len': 23510.0080, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  220000, Reward:   -21.676 [  87.049], Avg:   -80.797 (0.001) <0-06:03:55> ({'r_t': -1340.5546, 'eps':     0.0005, 'len': 23585.3220, 'dyn_loss':     0.1158, 'dot_loss':     0.0671, 'ddot_loss':     0.1490, 'rew_loss':    10.3319, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  221000, Reward:   -22.123 [  68.266], Avg:   -80.533 (0.500) <0-06:05:47> ({'r_t':  -129.3013, 'eps':     0.5005, 'len': 23686.6890, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  222000, Reward:    13.817 [  59.559], Avg:   -80.110 (0.001) <0-06:08:09> ({'r_t': -1410.0545, 'eps':     0.0005, 'len': 23753.9850, 'dyn_loss':     0.1157, 'dot_loss':     0.0675, 'ddot_loss':     0.1504, 'rew_loss':    10.3689, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  223000, Reward:     8.354 [  63.526], Avg:   -79.715 (0.500) <0-06:10:01> ({'r_t':  -131.6215, 'eps':     0.5005, 'len': 23866.3800, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  224000, Reward:    -3.018 [  74.254], Avg:   -79.374 (0.001) <0-06:12:19> ({'r_t': -1459.8837, 'eps':     0.0005, 'len': 23946.7810, 'dyn_loss':     0.1077, 'dot_loss':     0.0612, 'ddot_loss':     0.1354, 'rew_loss':     9.8575, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  225000, Reward:   -17.145 [  86.884], Avg:   -79.098 (0.500) <0-06:14:11> ({'r_t':  -119.5973, 'eps':     0.5005, 'len': 24047.8740, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  226000, Reward:    -0.084 [  75.026], Avg:   -78.750 (0.001) <0-06:16:28> ({'r_t': -1147.4468, 'eps':     0.0005, 'len': 24111.1820, 'dyn_loss':     0.1074, 'dot_loss':     0.0586, 'ddot_loss':     0.1292, 'rew_loss':     9.6741, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  227000, Reward:    -9.622 [  55.748], Avg:   -78.447 (0.500) <0-06:18:19> ({'r_t':   -71.0149, 'eps':     0.5005, 'len': 24209.3700, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  228000, Reward:    17.541 [  94.935], Avg:   -78.028 (0.001) <0-06:20:34> ({'r_t': -1328.3618, 'eps':     0.0005, 'len': 24279.5870, 'dyn_loss':     0.1011, 'dot_loss':     0.0575, 'ddot_loss':     0.1271, 'rew_loss':     9.5630, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  229000, Reward:   -26.594 [  55.645], Avg:   -77.804 (0.500) <0-06:22:26> ({'r_t':   -83.3571, 'eps':     0.5005, 'len': 24378.3580, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  230000, Reward:    25.003 [  75.341], Avg:   -77.359 (0.001) <0-06:24:44> ({'r_t': -1391.5308, 'eps':     0.0005, 'len': 24449.8640, 'dyn_loss':     0.1121, 'dot_loss':     0.0638, 'ddot_loss':     0.1414, 'rew_loss':     9.8796, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  231000, Reward:   -23.695 [  57.443], Avg:   -77.128 (0.500) <0-06:26:36> ({'r_t':  -157.1699, 'eps':     0.5005, 'len': 24568.5520, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  232000, Reward:    29.936 [  75.369], Avg:   -76.669 (0.001) <0-06:28:55> ({'r_t': -1360.8770, 'eps':     0.0005, 'len': 24649.5620, 'dyn_loss':     0.1119, 'dot_loss':     0.0630, 'ddot_loss':     0.1393, 'rew_loss':     9.8475, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  233000, Reward:    46.825 [  93.070], Avg:   -76.141 (0.500) <0-06:30:47> ({'r_t':   -95.2379, 'eps':     0.5005, 'len': 24761.3280, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  234000, Reward:   -32.897 [  62.212], Avg:   -75.957 (0.001) <0-06:33:04> ({'r_t': -1182.0714, 'eps':     0.0005, 'len': 24841.7880, 'dyn_loss':     0.1111, 'dot_loss':     0.0644, 'ddot_loss':     0.1423, 'rew_loss':     9.8218, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  235000, Reward:   -21.221 [  27.993], Avg:   -75.725 (0.500) <0-06:34:56> ({'r_t':  -173.9723, 'eps':     0.5005, 'len': 24942.7430, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  236000, Reward:    32.311 [  62.857], Avg:   -75.269 (0.001) <0-06:37:12> ({'r_t': -1422.0056, 'eps':     0.0005, 'len': 25015.8570, 'dyn_loss':     0.0967, 'dot_loss':     0.0534, 'ddot_loss':     0.1178, 'rew_loss':     8.7948, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  237000, Reward:   -26.857 [  51.897], Avg:   -75.066 (0.500) <0-06:39:06> ({'r_t':   -53.6842, 'eps':     0.5005, 'len': 25115.9220, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  238000, Reward:    12.410 [  54.780], Avg:   -74.700 (0.001) <0-06:41:24> ({'r_t': -1332.8689, 'eps':     0.0005, 'len': 25189.2900, 'dyn_loss':     0.1078, 'dot_loss':     0.0592, 'ddot_loss':     0.1308, 'rew_loss':     9.5355, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  239000, Reward:   -17.574 [  54.483], Avg:   -74.462 (0.500) <0-06:43:18> ({'r_t':  -155.1695, 'eps':     0.5005, 'len': 25295.6650, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  240000, Reward:    -3.959 [  65.544], Avg:   -74.169 (0.001) <0-06:45:34> ({'r_t': -1323.0738, 'eps':     0.0005, 'len': 25373.6170, 'dyn_loss':     0.1074, 'dot_loss':     0.0577, 'ddot_loss':     0.1278, 'rew_loss':     9.5951, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  241000, Reward:     7.562 [  88.659], Avg:   -73.831 (0.500) <0-06:47:27> ({'r_t':  -103.3106, 'eps':     0.5005, 'len': 25478.5400, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  242000, Reward:   -10.669 [  54.783], Avg:   -73.571 (0.001) <0-06:49:46> ({'r_t': -1367.3791, 'eps':     0.0005, 'len': 25551.5220, 'dyn_loss':     0.1023, 'dot_loss':     0.0559, 'ddot_loss':     0.1239, 'rew_loss':     9.4710, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  243000, Reward:   -22.115 [  68.446], Avg:   -73.360 (0.500) <0-06:51:39> ({'r_t':   -98.7663, 'eps':     0.5005, 'len': 25652.6870, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  244000, Reward:   -22.782 [  55.205], Avg:   -73.154 (0.001) <0-06:54:02> ({'r_t': -1525.3373, 'eps':     0.0005, 'len': 25724.5050, 'dyn_loss':     0.1150, 'dot_loss':     0.0647, 'ddot_loss':     0.1436, 'rew_loss':     9.9531, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  245000, Reward:   -47.876 [  80.350], Avg:   -73.051 (0.500) <0-06:55:55> ({'r_t':  -193.2260, 'eps':     0.5005, 'len': 25843.1530, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  246000, Reward:   -28.187 [  63.517], Avg:   -72.870 (0.001) <0-06:58:14> ({'r_t': -1261.9282, 'eps':     0.0005, 'len': 25934.1750, 'dyn_loss':     0.1060, 'dot_loss':     0.0582, 'ddot_loss':     0.1284, 'rew_loss':     9.5563, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  247000, Reward:    -2.808 [  54.600], Avg:   -72.587 (0.500) <0-07:00:07> ({'r_t':   -85.1388, 'eps':     0.5005, 'len': 26048.4910, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  248000, Reward:    -7.214 [  48.807], Avg:   -72.325 (0.001) <0-07:02:23> ({'r_t': -1441.6620, 'eps':     0.0005, 'len': 26122.6150, 'dyn_loss':     0.1045, 'dot_loss':     0.0576, 'ddot_loss':     0.1271, 'rew_loss':     9.6764, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  249000, Reward:   -12.918 [  51.300], Avg:   -72.087 (0.500) <0-07:04:17> ({'r_t':  -103.9915, 'eps':     0.5005, 'len': 26236.0270, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  250000, Reward:    27.024 [  85.502], Avg:   -71.692 (0.001) <0-07:06:33> ({'r_t': -1330.8506, 'eps':     0.0005, 'len': 26304.0080, 'dyn_loss':     0.0942, 'dot_loss':     0.0531, 'ddot_loss':     0.1174, 'rew_loss':     8.7268, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  251000, Reward:   -12.195 [ 103.601], Avg:   -71.456 (0.500) <0-07:08:27> ({'r_t':   -48.1276, 'eps':     0.5005, 'len': 26413.1330, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  252000, Reward:     8.695 [  96.505], Avg:   -71.139 (0.001) <0-07:10:44> ({'r_t': -1381.6786, 'eps':     0.0005, 'len': 26480.1890, 'dyn_loss':     0.1039, 'dot_loss':     0.0551, 'ddot_loss':     0.1213, 'rew_loss':     9.1328, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  253000, Reward:    -1.231 [  77.369], Avg:   -70.864 (0.500) <0-07:12:35> ({'r_t':  -125.8296, 'eps':     0.5005, 'len': 26580.5720, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  254000, Reward:    -2.859 [  76.119], Avg:   -70.597 (0.001) <0-07:14:53> ({'r_t': -1431.3783, 'eps':     0.0005, 'len': 26660.7970, 'dyn_loss':     0.1023, 'dot_loss':     0.0590, 'ddot_loss':     0.1304, 'rew_loss':     9.3842, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  255000, Reward:    -1.948 [ 101.540], Avg:   -70.329 (0.500) <0-07:16:44> ({'r_t':   -48.6909, 'eps':     0.5005, 'len': 26769.8820, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  256000, Reward:   -16.564 [  29.232], Avg:   -70.120 (0.001) <0-07:19:01> ({'r_t': -1417.7375, 'eps':     0.0005, 'len': 26835.8290, 'dyn_loss':     0.1052, 'dot_loss':     0.0595, 'ddot_loss':     0.1315, 'rew_loss':     9.2729, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  257000, Reward:   -28.038 [  81.768], Avg:   -69.957 (0.500) <0-07:20:52> ({'r_t':   -83.1176, 'eps':     0.5005, 'len': 26936.8760, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  258000, Reward:    14.898 [  79.820], Avg:   -69.629 (0.001) <0-07:23:09> ({'r_t': -1193.7721, 'eps':     0.0005, 'len': 27004.5780, 'dyn_loss':     0.1067, 'dot_loss':     0.0604, 'ddot_loss':     0.1337, 'rew_loss':     9.2771, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  259000, Reward:    26.897 [  98.929], Avg:   -69.258 (0.500) <0-07:24:59> ({'r_t':  -103.9059, 'eps':     0.5005, 'len': 27112.8280, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  260000, Reward:   -14.697 [ 100.365], Avg:   -69.049 (0.001) <0-07:27:23> ({'r_t': -1413.4297, 'eps':     0.0005, 'len': 27192.1820, 'dyn_loss':     0.1134, 'dot_loss':     0.0632, 'ddot_loss':     0.1395, 'rew_loss':     9.4990, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  261000, Reward:   -27.947 [  50.412], Avg:   -68.892 (0.500) <0-07:29:15> ({'r_t':   -99.4120, 'eps':     0.5005, 'len': 27301.4550, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  262000, Reward:   -44.715 [  81.726], Avg:   -68.800 (0.001) <0-07:31:30> ({'r_t': -1486.4031, 'eps':     0.0005, 'len': 27373.9970, 'dyn_loss':     0.0922, 'dot_loss':     0.0508, 'ddot_loss':     0.1124, 'rew_loss':     8.5038, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  263000, Reward:    -3.741 [  84.006], Avg:   -68.554 (0.500) <0-07:33:21> ({'r_t':  -116.0906, 'eps':     0.5005, 'len': 27480.6240, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  264000, Reward:    28.223 [  62.246], Avg:   -68.188 (0.001) <0-07:35:41> ({'r_t': -1236.8780, 'eps':     0.0005, 'len': 27551.4710, 'dyn_loss':     0.1047, 'dot_loss':     0.0589, 'ddot_loss':     0.1298, 'rew_loss':     9.1210, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  265000, Reward:     3.776 [  75.217], Avg:   -67.918 (0.500) <0-07:37:32> ({'r_t':  -106.3973, 'eps':     0.5005, 'len': 27655.7830, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  266000, Reward:    27.203 [  52.173], Avg:   -67.562 (0.001) <0-07:39:48> ({'r_t': -1228.4154, 'eps':     0.0005, 'len': 27731.3270, 'dyn_loss':     0.1055, 'dot_loss':     0.0600, 'ddot_loss':     0.1325, 'rew_loss':     9.1464, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  267000, Reward:   -10.530 [  70.777], Avg:   -67.349 (0.500) <0-07:41:39> ({'r_t':   -98.3334, 'eps':     0.5005, 'len': 27831.6770, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  268000, Reward:   -15.468 [  49.252], Avg:   -67.156 (0.001) <0-07:43:56> ({'r_t': -1405.7077, 'eps':     0.0005, 'len': 27908.3260, 'dyn_loss':     0.1041, 'dot_loss':     0.0568, 'ddot_loss':     0.1251, 'rew_loss':     8.9075, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  269000, Reward:   -30.309 [  76.445], Avg:   -67.019 (0.500) <0-07:45:46> ({'r_t':  -119.6056, 'eps':     0.5005, 'len': 28021.2380, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  270000, Reward:   -19.592 [  76.724], Avg:   -66.844 (0.001) <0-07:48:06> ({'r_t': -1488.4389, 'eps':     0.0005, 'len': 28107.5100, 'dyn_loss':     0.1196, 'dot_loss':     0.0692, 'ddot_loss':     0.1532, 'rew_loss':     9.8271, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  271000, Reward:   -29.659 [ 104.213], Avg:   -66.708 (0.500) <0-07:49:53> ({'r_t':   -79.9318, 'eps':     0.5005, 'len': 28212.7120, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  272000, Reward:   -14.815 [  78.679], Avg:   -66.518 (0.001) <0-07:52:07> ({'r_t': -1280.1176, 'eps':     0.0005, 'len': 28283.1050, 'dyn_loss':     0.1219, 'dot_loss':     0.0695, 'ddot_loss':     0.1543, 'rew_loss':     9.9025, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  273000, Reward:   -19.550 [  82.008], Avg:   -66.346 (0.500) <0-07:53:48> ({'r_t':  -155.4192, 'eps':     0.5005, 'len': 28395.1470, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  274000, Reward:    -7.026 [  59.591], Avg:   -66.131 (0.001) <0-07:55:57> ({'r_t': -1208.0163, 'eps':     0.0005, 'len': 28466.0370, 'dyn_loss':     0.1042, 'dot_loss':     0.0586, 'ddot_loss':     0.1299, 'rew_loss':     8.9420, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  275000, Reward:   -17.433 [  71.489], Avg:   -65.954 (0.500) <0-07:57:38> ({'r_t':  -198.9504, 'eps':     0.5005, 'len': 28576.7830, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  276000, Reward:   -15.002 [  84.817], Avg:   -65.770 (0.001) <0-07:59:48> ({'r_t': -1452.6521, 'eps':     0.0005, 'len': 28662.0090, 'dyn_loss':     0.1070, 'dot_loss':     0.0595, 'ddot_loss':     0.1314, 'rew_loss':     9.1595, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  277000, Reward:     3.981 [  81.719], Avg:   -65.519 (0.500) <0-08:01:29> ({'r_t':  -127.9129, 'eps':     0.5005, 'len': 28776.3610, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  278000, Reward:     7.735 [  80.382], Avg:   -65.257 (0.001) <0-08:03:39> ({'r_t': -1269.2509, 'eps':     0.0005, 'len': 28858.3760, 'dyn_loss':     0.1065, 'dot_loss':     0.0599, 'ddot_loss':     0.1327, 'rew_loss':     9.0708, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  279000, Reward:    -8.628 [  52.974], Avg:   -65.054 (0.500) <0-08:05:21> ({'r_t':  -140.8255, 'eps':     0.5005, 'len': 28967.3750, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  280000, Reward:   -44.612 [  70.392], Avg:   -64.982 (0.001) <0-08:07:31> ({'r_t': -1252.5373, 'eps':     0.0005, 'len': 29054.0000, 'dyn_loss':     0.1068, 'dot_loss':     0.0605, 'ddot_loss':     0.1344, 'rew_loss':     9.1260, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  281000, Reward:    10.090 [  79.717], Avg:   -64.715 (0.500) <0-08:09:12> ({'r_t':  -113.5658, 'eps':     0.5005, 'len': 29170.7530, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  282000, Reward:   -21.229 [  65.494], Avg:   -64.562 (0.001) <0-08:11:16> ({'r_t': -1409.5632, 'eps':     0.0005, 'len': 29259.7280, 'dyn_loss':     0.0927, 'dot_loss':     0.0506, 'ddot_loss':     0.1117, 'rew_loss':     8.3384, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  283000, Reward:     5.045 [  61.143], Avg:   -64.317 (0.500) <0-08:12:57> ({'r_t':  -193.6293, 'eps':     0.5005, 'len': 29376.9320, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  284000, Reward:   -13.523 [  53.334], Avg:   -64.139 (0.001) <0-08:15:10> ({'r_t': -1415.6296, 'eps':     0.0005, 'len': 29467.5090, 'dyn_loss':     0.1085, 'dot_loss':     0.0611, 'ddot_loss':     0.1356, 'rew_loss':     9.2572, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  285000, Reward:   -20.755 [  50.824], Avg:   -63.987 (0.500) <0-08:16:51> ({'r_t':  -136.0354, 'eps':     0.5005, 'len': 29582.2660, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  286000, Reward:    20.776 [  69.967], Avg:   -63.691 (0.001) <0-08:18:58> ({'r_t': -1389.7593, 'eps':     0.0005, 'len': 29657.1240, 'dyn_loss':     0.0979, 'dot_loss':     0.0546, 'ddot_loss':     0.1206, 'rew_loss':     8.5780, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  287000, Reward:    -7.720 [  82.762], Avg:   -63.497 (0.500) <0-08:20:38> ({'r_t':  -245.7940, 'eps':     0.5005, 'len': 29782.5330, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  288000, Reward:    -6.626 [  62.256], Avg:   -63.300 (0.001) <0-08:22:48> ({'r_t': -1326.7391, 'eps':     0.0005, 'len': 29873.6830, 'dyn_loss':     0.0964, 'dot_loss':     0.0538, 'ddot_loss':     0.1187, 'rew_loss':     8.4787, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  289000, Reward:    16.161 [  77.610], Avg:   -63.026 (0.500) <0-08:24:28> ({'r_t':  -150.7069, 'eps':     0.5005, 'len': 29980.9170, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  290000, Reward:   -24.369 [  95.201], Avg:   -62.894 (0.001) <0-08:26:37> ({'r_t': -1367.3623, 'eps':     0.0005, 'len': 30056.3140, 'dyn_loss':     0.1025, 'dot_loss':     0.0562, 'ddot_loss':     0.1234, 'rew_loss':     8.6727, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  291000, Reward:    19.608 [  58.095], Avg:   -62.611 (0.500) <0-08:28:17> ({'r_t':   -92.0656, 'eps':     0.5005, 'len': 30164.1380, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  292000, Reward:    19.280 [  68.920], Avg:   -62.331 (0.001) <0-08:30:27> ({'r_t': -1387.5433, 'eps':     0.0005, 'len': 30233.4680, 'dyn_loss':     0.1084, 'dot_loss':     0.0620, 'ddot_loss':     0.1375, 'rew_loss':     8.8494, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  293000, Reward:   -12.368 [  67.615], Avg:   -62.162 (0.500) <0-08:32:08> ({'r_t':  -192.9225, 'eps':     0.5005, 'len': 30348.2730, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  294000, Reward:   -14.768 [  77.118], Avg:   -62.001 (0.001) <0-08:34:19> ({'r_t': -1238.4119, 'eps':     0.0005, 'len': 30434.9460, 'dyn_loss':     0.1090, 'dot_loss':     0.0629, 'ddot_loss':     0.1395, 'rew_loss':     9.0006, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  295000, Reward:   -64.155 [  60.535], Avg:   -62.008 (0.500) <0-08:36:00> ({'r_t':  -209.5908, 'eps':     0.5005, 'len': 30546.6030, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  296000, Reward:    -7.478 [  47.463], Avg:   -61.825 (0.001) <0-08:38:16> ({'r_t': -1422.2313, 'eps':     0.0005, 'len': 30630.6200, 'dyn_loss':     0.1096, 'dot_loss':     0.0623, 'ddot_loss':     0.1380, 'rew_loss':     8.9576, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  297000, Reward:   -21.171 [  74.353], Avg:   -61.688 (0.500) <0-08:39:57> ({'r_t':  -163.0641, 'eps':     0.5005, 'len': 30748.1830, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  298000, Reward:   -11.789 [  59.650], Avg:   -61.521 (0.001) <0-08:42:06> ({'r_t': -1238.7731, 'eps':     0.0005, 'len': 30842.0250, 'dyn_loss':     0.1013, 'dot_loss':     0.0573, 'ddot_loss':     0.1268, 'rew_loss':     8.9084, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  299000, Reward:   -37.228 [  29.872], Avg:   -61.440 (0.500) <0-08:43:13> ({'r_t':  -239.2947, 'eps':     0.5005, 'len': 30963.3610, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  300000, Reward:    -2.143 [ 101.684], Avg:   -61.243 (0.001) <0-08:45:24> ({'r_t': -1171.7452, 'eps':     0.0005, 'len': 31057.4560, 'dyn_loss':     0.1050, 'dot_loss':     0.0610, 'ddot_loss':     0.1351, 'rew_loss':     8.9292, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  301000, Reward:   -27.772 [  44.602], Avg:   -61.132 (0.500) <0-08:47:05> ({'r_t':  -190.7277, 'eps':     0.5005, 'len': 31177.7230, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  302000, Reward:   -11.118 [  78.374], Avg:   -60.967 (0.001) <0-08:49:13> ({'r_t': -1336.8656, 'eps':     0.0005, 'len': 31257.2040, 'dyn_loss':     0.0923, 'dot_loss':     0.0517, 'ddot_loss':     0.1140, 'rew_loss':     8.3376, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  303000, Reward:   -16.858 [  62.739], Avg:   -60.822 (0.500) <0-08:50:55> ({'r_t':  -135.8571, 'eps':     0.5005, 'len': 31372.9740, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  304000, Reward:   -12.339 [  66.357], Avg:   -60.663 (0.001) <0-08:53:04> ({'r_t': -1545.4310, 'eps':     0.0005, 'len': 31464.7500, 'dyn_loss':     0.1008, 'dot_loss':     0.0570, 'ddot_loss':     0.1256, 'rew_loss':     8.4422, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  305000, Reward:     9.150 [  76.762], Avg:   -60.435 (0.500) <0-08:54:46> ({'r_t':   -63.5909, 'eps':     0.5005, 'len': 31578.2590, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  306000, Reward:    -3.619 [  62.947], Avg:   -60.250 (0.001) <0-08:56:56> ({'r_t': -1440.0499, 'eps':     0.0005, 'len': 31665.8330, 'dyn_loss':     0.1050, 'dot_loss':     0.0590, 'ddot_loss':     0.1307, 'rew_loss':     8.6743, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  307000, Reward:    22.749 [  75.314], Avg:   -59.981 (0.500) <0-08:58:37> ({'r_t':  -122.4236, 'eps':     0.5005, 'len': 31777.6000, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  308000, Reward:    12.931 [  70.148], Avg:   -59.745 (0.001) <0-09:00:47> ({'r_t': -1358.6887, 'eps':     0.0005, 'len': 31856.8630, 'dyn_loss':     0.0972, 'dot_loss':     0.0565, 'ddot_loss':     0.1254, 'rew_loss':     8.4550, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  309000, Reward:    12.313 [  61.779], Avg:   -59.512 (0.500) <0-09:02:28> ({'r_t':  -125.2902, 'eps':     0.5005, 'len': 31970.4390, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  310000, Reward:     9.590 [  69.942], Avg:   -59.290 (0.001) <0-09:04:37> ({'r_t': -1432.4233, 'eps':     0.0005, 'len': 32053.3900, 'dyn_loss':     0.0886, 'dot_loss':     0.0490, 'ddot_loss':     0.1083, 'rew_loss':     8.0323, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  311000, Reward:   -11.905 [  39.094], Avg:   -59.138 (0.500) <0-09:06:18> ({'r_t':  -228.9628, 'eps':     0.5005, 'len': 32175.5680, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  312000, Reward:   -49.657 [  64.012], Avg:   -59.108 (0.001) <0-09:08:25> ({'r_t': -1415.4908, 'eps':     0.0005, 'len': 32258.9160, 'dyn_loss':     0.0964, 'dot_loss':     0.0533, 'ddot_loss':     0.1179, 'rew_loss':     8.3300, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  313000, Reward:   -46.957 [  45.958], Avg:   -59.069 (0.500) <0-09:10:18> ({'r_t':  -197.0344, 'eps':     0.5005, 'len': 32370.5180, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  314000, Reward:     6.191 [  69.839], Avg:   -58.862 (0.001) <0-09:12:39> ({'r_t': -1256.1271, 'eps':     0.0005, 'len': 32464.3170, 'dyn_loss':     0.1024, 'dot_loss':     0.0563, 'ddot_loss':     0.1246, 'rew_loss':     8.4519, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  315000, Reward:    -5.302 [  80.311], Avg:   -58.692 (0.500) <0-09:14:39> ({'r_t':  -193.0750, 'eps':     0.5005, 'len': 32580.6490, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  316000, Reward:    -1.804 [  63.133], Avg:   -58.513 (0.001) <0-09:16:58> ({'r_t': -1423.0447, 'eps':     0.0005, 'len': 32666.8480, 'dyn_loss':     0.1004, 'dot_loss':     0.0546, 'ddot_loss':     0.1209, 'rew_loss':     8.5722, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  317000, Reward:   -17.956 [  61.686], Avg:   -58.385 (0.500) <0-09:18:45> ({'r_t':  -184.8606, 'eps':     0.5005, 'len': 32778.4060, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  318000, Reward:     3.910 [  72.078], Avg:   -58.190 (0.001) <0-09:21:08> ({'r_t': -1368.2083, 'eps':     0.0005, 'len': 32862.7620, 'dyn_loss':     0.1136, 'dot_loss':     0.0659, 'ddot_loss':     0.1465, 'rew_loss':     9.0115, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  319000, Reward:   -18.894 [  72.607], Avg:   -58.067 (0.500) <0-09:22:57> ({'r_t':  -261.2959, 'eps':     0.5005, 'len': 32979.7340, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  320000, Reward:   -11.435 [  83.880], Avg:   -57.922 (0.001) <0-09:25:09> ({'r_t': -1442.3988, 'eps':     0.0005, 'len': 33064.6500, 'dyn_loss':     0.0941, 'dot_loss':     0.0522, 'ddot_loss':     0.1152, 'rew_loss':     8.2189, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  321000, Reward:   -34.294 [  56.321], Avg:   -57.849 (0.500) <0-09:26:55> ({'r_t':  -201.0489, 'eps':     0.5005, 'len': 33179.4780, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  322000, Reward:   -10.823 [  65.121], Avg:   -57.703 (0.001) <0-09:29:03> ({'r_t': -1348.5632, 'eps':     0.0005, 'len': 33261.6960, 'dyn_loss':     0.0870, 'dot_loss':     0.0480, 'ddot_loss':     0.1065, 'rew_loss':     7.8667, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  323000, Reward:   -47.974 [  62.830], Avg:   -57.673 (0.500) <0-09:30:53> ({'r_t':  -221.5896, 'eps':     0.5005, 'len': 33371.0600, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  324000, Reward:    11.485 [  73.667], Avg:   -57.460 (0.001) <0-09:33:08> ({'r_t': -1476.7088, 'eps':     0.0005, 'len': 33456.5370, 'dyn_loss':     0.0928, 'dot_loss':     0.0527, 'ddot_loss':     0.1168, 'rew_loss':     8.1470, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  325000, Reward:     7.285 [  75.443], Avg:   -57.262 (0.500) <0-09:35:06> ({'r_t':  -192.8138, 'eps':     0.5005, 'len': 33577.2220, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  326000, Reward:   -12.859 [  45.786], Avg:   -57.126 (0.001) <0-09:38:02> ({'r_t': -1316.8166, 'eps':     0.0005, 'len': 33657.4090, 'dyn_loss':     0.1030, 'dot_loss':     0.0587, 'ddot_loss':     0.1305, 'rew_loss':     8.8333, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  327000, Reward:   -31.081 [  43.173], Avg:   -57.047 (0.500) <0-09:40:33> ({'r_t':  -148.2319, 'eps':     0.5005, 'len': 33767.5280, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  328000, Reward:   -11.069 [  64.302], Avg:   -56.907 (0.001) <0-09:43:58> ({'r_t': -1366.1816, 'eps':     0.0005, 'len': 33849.5840, 'dyn_loss':     0.1006, 'dot_loss':     0.0566, 'ddot_loss':     0.1258, 'rew_loss':     8.2971, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  329000, Reward:     3.336 [  85.981], Avg:   -56.724 (0.500) <0-09:46:10> ({'r_t':  -134.5563, 'eps':     0.5005, 'len': 33959.8150, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  330000, Reward:   -24.911 [  58.024], Avg:   -56.628 (0.001) <0-09:48:57> ({'r_t': -1258.8345, 'eps':     0.0005, 'len': 34032.3750, 'dyn_loss':     0.0975, 'dot_loss':     0.0556, 'ddot_loss':     0.1236, 'rew_loss':     8.5546, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  331000, Reward:     9.494 [  73.548], Avg:   -56.429 (0.500) <0-09:51:32> ({'r_t':  -252.6050, 'eps':     0.5005, 'len': 34151.2180, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  332000, Reward:   -16.843 [  46.563], Avg:   -56.310 (0.001) <0-09:54:33> ({'r_t': -1225.8697, 'eps':     0.0005, 'len': 34250.0210, 'dyn_loss':     0.0950, 'dot_loss':     0.0516, 'ddot_loss':     0.1138, 'rew_loss':     8.1253, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  333000, Reward:   -19.073 [  64.143], Avg:   -56.199 (0.500) <0-09:57:14> ({'r_t':  -188.7538, 'eps':     0.5005, 'len': 34358.2410, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  334000, Reward:   -14.340 [  45.890], Avg:   -56.074 (0.001) <0-09:59:25> ({'r_t': -1458.0983, 'eps':     0.0005, 'len': 34445.1880, 'dyn_loss':     0.0989, 'dot_loss':     0.0535, 'ddot_loss':     0.1173, 'rew_loss':     8.3905, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  335000, Reward:    15.027 [  65.725], Avg:   -55.862 (0.500) <0-10:01:07> ({'r_t':  -171.4257, 'eps':     0.5005, 'len': 34558.5480, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  336000, Reward:   -17.885 [  77.461], Avg:   -55.749 (0.001) <0-10:03:19> ({'r_t': -1475.8336, 'eps':     0.0005, 'len': 34641.7510, 'dyn_loss':     0.1040, 'dot_loss':     0.0594, 'ddot_loss':     0.1324, 'rew_loss':     8.6427, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  337000, Reward:    -0.209 [  95.304], Avg:   -55.585 (0.500) <0-10:05:01> ({'r_t':  -105.0406, 'eps':     0.5005, 'len': 34760.8730, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  338000, Reward:    -5.337 [  81.305], Avg:   -55.437 (0.001) <0-10:07:12> ({'r_t': -1397.7993, 'eps':     0.0005, 'len': 34842.0170, 'dyn_loss':     0.1028, 'dot_loss':     0.0567, 'ddot_loss':     0.1254, 'rew_loss':     8.4184, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  339000, Reward:    30.180 [  96.213], Avg:   -55.185 (0.500) <0-10:09:04> ({'r_t':  -199.8098, 'eps':     0.5005, 'len': 34964.6360, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  340000, Reward:    28.707 [ 105.096], Avg:   -54.939 (0.001) <0-10:11:00> ({'r_t': -1579.2687, 'eps':     0.0005, 'len': 35061.8290, 'dyn_loss':     0.0863, 'dot_loss':     0.0473, 'ddot_loss':     0.1044, 'rew_loss':     7.7300, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  341000, Reward:    -9.799 [ 109.359], Avg:   -54.807 (0.500) <0-10:12:26> ({'r_t':  -109.6006, 'eps':     0.5005, 'len': 35179.4390, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  342000, Reward:     4.634 [  74.130], Avg:   -54.634 (0.001) <0-10:14:32> ({'r_t': -1387.6759, 'eps':     0.0005, 'len': 35255.9040, 'dyn_loss':     0.0750, 'dot_loss':     0.0392, 'ddot_loss':     0.0860, 'rew_loss':     7.3383, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  343000, Reward:   -25.739 [  48.885], Avg:   -54.550 (0.500) <0-10:16:13> ({'r_t':   -95.4457, 'eps':     0.5005, 'len': 35371.9780, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  344000, Reward:     0.955 [  59.334], Avg:   -54.389 (0.001) <0-10:18:23> ({'r_t': -1448.7665, 'eps':     0.0005, 'len': 35454.3210, 'dyn_loss':     0.1000, 'dot_loss':     0.0568, 'ddot_loss':     0.1259, 'rew_loss':     8.4183, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  345000, Reward:   -12.119 [  65.754], Avg:   -54.267 (0.500) <0-10:20:05> ({'r_t':  -198.2363, 'eps':     0.5005, 'len': 35569.2350, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  346000, Reward:     1.963 [  54.862], Avg:   -54.105 (0.001) <0-10:22:15> ({'r_t': -1521.8582, 'eps':     0.0005, 'len': 35658.5270, 'dyn_loss':     0.0930, 'dot_loss':     0.0521, 'ddot_loss':     0.1155, 'rew_loss':     7.9639, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  347000, Reward:   -28.590 [  41.556], Avg:   -54.031 (0.500) <0-10:23:56> ({'r_t':  -164.1469, 'eps':     0.5005, 'len': 35779.5180, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  348000, Reward:    -1.558 [  68.895], Avg:   -53.881 (0.001) <0-10:26:09> ({'r_t': -1427.4297, 'eps':     0.0005, 'len': 35878.1820, 'dyn_loss':     0.1020, 'dot_loss':     0.0569, 'ddot_loss':     0.1262, 'rew_loss':     8.3818, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  349000, Reward:    12.215 [  67.649], Avg:   -53.692 (0.500) <0-10:27:50> ({'r_t':  -128.4926, 'eps':     0.5005, 'len': 35993.8730, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  350000, Reward:     6.974 [  86.263], Avg:   -53.519 (0.001) <0-10:30:00> ({'r_t': -1221.7545, 'eps':     0.0005, 'len': 36064.6650, 'dyn_loss':     0.0942, 'dot_loss':     0.0529, 'ddot_loss':     0.1167, 'rew_loss':     8.4022, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  351000, Reward:     5.790 [  89.550], Avg:   -53.351 (0.500) <0-10:31:41> ({'r_t':   -73.9227, 'eps':     0.5005, 'len': 36176.3080, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  352000, Reward:    -0.187 [  88.800], Avg:   -53.200 (0.001) <0-10:33:55> ({'r_t': -1407.7552, 'eps':     0.0005, 'len': 36261.8340, 'dyn_loss':     0.1025, 'dot_loss':     0.0603, 'ddot_loss':     0.1344, 'rew_loss':     8.4122, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  353000, Reward:    -9.076 [  75.771], Avg:   -53.075 (0.500) <0-10:35:36> ({'r_t':  -211.9899, 'eps':     0.5005, 'len': 36389.2480, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  354000, Reward:    -1.852 [  47.151], Avg:   -52.931 (0.001) <0-10:37:49> ({'r_t': -1329.0714, 'eps':     0.0005, 'len': 36486.4170, 'dyn_loss':     0.0981, 'dot_loss':     0.0565, 'ddot_loss':     0.1259, 'rew_loss':     8.2122, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  355000, Reward:    36.332 [  76.739], Avg:   -52.680 (0.500) <0-10:39:30> ({'r_t':  -244.3699, 'eps':     0.5005, 'len': 36608.0800, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  356000, Reward:   -17.573 [  81.880], Avg:   -52.582 (0.001) <0-10:41:42> ({'r_t': -1636.7367, 'eps':     0.0005, 'len': 36703.0190, 'dyn_loss':     0.0973, 'dot_loss':     0.0533, 'ddot_loss':     0.1179, 'rew_loss':     7.9431, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  357000, Reward:     4.841 [  66.644], Avg:   -52.422 (0.500) <0-10:43:22> ({'r_t':  -117.1251, 'eps':     0.5005, 'len': 36818.9370, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  358000, Reward:    27.728 [  82.994], Avg:   -52.198 (0.001) <0-10:45:33> ({'r_t': -1340.3565, 'eps':     0.0005, 'len': 36897.0170, 'dyn_loss':     0.0916, 'dot_loss':     0.0516, 'ddot_loss':     0.1147, 'rew_loss':     7.8487, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  359000, Reward:     2.750 [  90.753], Avg:   -52.046 (0.500) <0-10:47:14> ({'r_t':  -151.5893, 'eps':     0.5005, 'len': 37009.8670, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  360000, Reward:   -13.080 [  85.213], Avg:   -51.938 (0.001) <0-10:49:21> ({'r_t': -1387.9008, 'eps':     0.0005, 'len': 37097.1960, 'dyn_loss':     0.0897, 'dot_loss':     0.0494, 'ddot_loss':     0.1090, 'rew_loss':     7.6710, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  361000, Reward:   -30.805 [  31.226], Avg:   -51.880 (0.500) <0-10:50:27> ({'r_t':  -233.8634, 'eps':     0.5005, 'len': 37211.8680, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  362000, Reward:    27.880 [  79.189], Avg:   -51.660 (0.001) <0-10:52:38> ({'r_t': -1392.4705, 'eps':     0.0005, 'len': 37299.9540, 'dyn_loss':     0.0977, 'dot_loss':     0.0554, 'ddot_loss':     0.1228, 'rew_loss':     8.2197, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  363000, Reward:   -31.687 [  90.374], Avg:   -51.605 (0.500) <0-10:54:19> ({'r_t':   -92.8742, 'eps':     0.5005, 'len': 37411.4590, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  364000, Reward:    10.799 [ 105.740], Avg:   -51.434 (0.001) <0-10:56:33> ({'r_t': -1409.4454, 'eps':     0.0005, 'len': 37496.4200, 'dyn_loss':     0.1001, 'dot_loss':     0.0543, 'ddot_loss':     0.1205, 'rew_loss':     8.0726, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  365000, Reward:   -14.931 [  98.240], Avg:   -51.334 (0.500) <0-10:58:14> ({'r_t':   -93.8377, 'eps':     0.5005, 'len': 37609.6220, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  366000, Reward:    -1.383 [  50.419], Avg:   -51.198 (0.001) <0-11:00:26> ({'r_t': -1432.6491, 'eps':     0.0005, 'len': 37696.1810, 'dyn_loss':     0.0932, 'dot_loss':     0.0514, 'ddot_loss':     0.1137, 'rew_loss':     8.0312, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  367000, Reward:   -57.910 [  47.024], Avg:   -51.216 (0.500) <0-11:01:22> ({'r_t':  -267.7367, 'eps':     0.5005, 'len': 37824.2380, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  368000, Reward:   -10.361 [  55.957], Avg:   -51.106 (0.001) <0-11:03:32> ({'r_t': -1521.1989, 'eps':     0.0005, 'len': 37928.2100, 'dyn_loss':     0.0963, 'dot_loss':     0.0546, 'ddot_loss':     0.1210, 'rew_loss':     8.0694, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  369000, Reward:    16.080 [  77.215], Avg:   -50.924 (0.500) <0-11:05:13> ({'r_t':  -211.6320, 'eps':     0.5005, 'len': 38047.7890, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  370000, Reward:    -1.356 [  67.857], Avg:   -50.790 (0.001) <0-11:07:24> ({'r_t': -1301.3799, 'eps':     0.0005, 'len': 38140.0600, 'dyn_loss':     0.0957, 'dot_loss':     0.0536, 'ddot_loss':     0.1192, 'rew_loss':     8.0763, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  371000, Reward:   -33.690 [  65.240], Avg:   -50.744 (0.500) <0-11:09:06> ({'r_t':  -233.7772, 'eps':     0.5005, 'len': 38260.6300, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  372000, Reward:   -47.368 [  56.965], Avg:   -50.735 (0.001) <0-11:10:39> ({'r_t': -1227.5550, 'eps':     0.0005, 'len': 38352.2260, 'dyn_loss':     0.1069, 'dot_loss':     0.0617, 'ddot_loss':     0.1371, 'rew_loss':     8.5572, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  373000, Reward:   -49.532 [  51.891], Avg:   -50.732 (0.500) <0-11:11:36> ({'r_t':  -212.1706, 'eps':     0.5005, 'len': 38471.0530, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  374000, Reward:   -15.980 [  53.014], Avg:   -50.640 (0.001) <0-11:13:46> ({'r_t': -1527.2900, 'eps':     0.0005, 'len': 38567.5720, 'dyn_loss':     0.0984, 'dot_loss':     0.0547, 'ddot_loss':     0.1213, 'rew_loss':     8.3031, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  375000, Reward:     4.275 [  71.635], Avg:   -50.493 (0.500) <0-11:15:27> ({'r_t':   -87.1534, 'eps':     0.5005, 'len': 38681.3950, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  376000, Reward:   -31.786 [  47.459], Avg:   -50.444 (0.001) <0-11:17:39> ({'r_t': -1234.4577, 'eps':     0.0005, 'len': 38747.9700, 'dyn_loss':     0.0953, 'dot_loss':     0.0528, 'ddot_loss':     0.1169, 'rew_loss':     8.2530, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  377000, Reward:    -8.622 [  74.476], Avg:   -50.333 (0.500) <0-11:18:49> ({'r_t':  -196.3278, 'eps':     0.5005, 'len': 38862.6330, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  378000, Reward:   -18.606 [  43.991], Avg:   -50.249 (0.001) <0-11:20:58> ({'r_t': -1492.0642, 'eps':     0.0005, 'len': 38954.6130, 'dyn_loss':     0.0946, 'dot_loss':     0.0525, 'ddot_loss':     0.1165, 'rew_loss':     8.0484, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  379000, Reward:   -15.833 [  55.563], Avg:   -50.159 (0.500) <0-11:22:39> ({'r_t':  -100.5023, 'eps':     0.5005, 'len': 39074.2710, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  380000, Reward:    -9.897 [  52.309], Avg:   -50.053 (0.001) <0-11:24:51> ({'r_t': -1204.1572, 'eps':     0.0005, 'len': 39157.8690, 'dyn_loss':     0.0976, 'dot_loss':     0.0562, 'ddot_loss':     0.1250, 'rew_loss':     8.1230, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  381000, Reward:   -50.903 [  66.200], Avg:   -50.055 (0.500) <0-11:26:33> ({'r_t':   -80.1009, 'eps':     0.5005, 'len': 39269.4710, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  382000, Reward:    27.670 [ 102.089], Avg:   -49.853 (0.001) <0-11:28:43> ({'r_t': -1440.6113, 'eps':     0.0005, 'len': 39344.1400, 'dyn_loss':     0.0965, 'dot_loss':     0.0528, 'ddot_loss':     0.1163, 'rew_loss':     8.2323, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  383000, Reward:    26.039 [  86.401], Avg:   -49.655 (0.500) <0-11:30:24> ({'r_t':  -113.9929, 'eps':     0.5005, 'len': 39461.9890, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  384000, Reward:    -0.416 [  72.704], Avg:   -49.527 (0.001) <0-11:32:40> ({'r_t': -1304.8432, 'eps':     0.0005, 'len': 39544.9390, 'dyn_loss':     0.1063, 'dot_loss':     0.0603, 'ddot_loss':     0.1338, 'rew_loss':     8.4796, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  385000, Reward:   -20.148 [  79.103], Avg:   -49.451 (0.500) <0-11:34:04> ({'r_t':  -102.7028, 'eps':     0.5005, 'len': 39650.3920, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  386000, Reward:   -26.166 [  43.552], Avg:   -49.391 (0.001) <0-11:36:15> ({'r_t': -1380.5139, 'eps':     0.0005, 'len': 39720.5960, 'dyn_loss':     0.0941, 'dot_loss':     0.0526, 'ddot_loss':     0.1165, 'rew_loss':     8.0081, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  387000, Reward:     4.479 [  69.753], Avg:   -49.252 (0.500) <0-11:37:56> ({'r_t':  -162.9647, 'eps':     0.5005, 'len': 39841.5870, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  388000, Reward:     8.916 [  67.780], Avg:   -49.102 (0.001) <0-11:40:07> ({'r_t': -1415.9337, 'eps':     0.0005, 'len': 39929.1400, 'dyn_loss':     0.0872, 'dot_loss':     0.0485, 'ddot_loss':     0.1078, 'rew_loss':     7.6259, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  389000, Reward:   -33.039 [  58.435], Avg:   -49.061 (0.500) <0-11:41:47> ({'r_t':  -118.6894, 'eps':     0.5005, 'len': 40046.1390, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  390000, Reward:   -11.584 [  81.067], Avg:   -48.965 (0.001) <0-11:43:30> ({'r_t': -1252.8474, 'eps':     0.0005, 'len': 40118.9520, 'dyn_loss':     0.0915, 'dot_loss':     0.0494, 'ddot_loss':     0.1090, 'rew_loss':     7.6139, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  391000, Reward:    -3.297 [  63.151], Avg:   -48.849 (0.500) <0-11:45:10> ({'r_t':  -127.3111, 'eps':     0.5005, 'len': 40229.0250, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  392000, Reward:   -16.439 [  45.151], Avg:   -48.766 (0.001) <0-11:47:21> ({'r_t': -1380.3912, 'eps':     0.0005, 'len': 40315.2430, 'dyn_loss':     0.0936, 'dot_loss':     0.0522, 'ddot_loss':     0.1152, 'rew_loss':     7.9277, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  393000, Reward:   -32.626 [  72.837], Avg:   -48.725 (0.500) <0-11:49:02> ({'r_t':  -127.5597, 'eps':     0.5005, 'len': 40432.8070, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  394000, Reward:    18.634 [  80.613], Avg:   -48.555 (0.001) <0-11:51:16> ({'r_t': -1302.0969, 'eps':     0.0005, 'len': 40518.2760, 'dyn_loss':     0.0939, 'dot_loss':     0.0538, 'ddot_loss':     0.1195, 'rew_loss':     7.8730, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  395000, Reward:   -15.272 [  67.567], Avg:   -48.471 (0.500) <0-11:52:57> ({'r_t':  -144.7950, 'eps':     0.5005, 'len': 40635.1100, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  396000, Reward:   -16.454 [  49.660], Avg:   -48.390 (0.001) <0-11:55:06> ({'r_t': -1241.2858, 'eps':     0.0005, 'len': 40716.1980, 'dyn_loss':     0.0838, 'dot_loss':     0.0459, 'ddot_loss':     0.1017, 'rew_loss':     7.4170, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  397000, Reward:    -6.041 [  61.080], Avg:   -48.284 (0.500) <0-11:56:46> ({'r_t':  -212.1539, 'eps':     0.5005, 'len': 40833.2190, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  398000, Reward:     1.389 [ 100.976], Avg:   -48.159 (0.001) <0-11:59:01> ({'r_t': -1324.9829, 'eps':     0.0005, 'len': 40909.4150, 'dyn_loss':     0.0904, 'dot_loss':     0.0506, 'ddot_loss':     0.1126, 'rew_loss':     7.5892, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  399000, Reward:   -12.122 [  49.863], Avg:   -48.069 (0.500) <0-12:00:42> ({'r_t':  -218.4092, 'eps':     0.5005, 'len': 41032.4520, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  400000, Reward:   -26.883 [  62.115], Avg:   -48.016 (0.001) <0-12:02:55> ({'r_t': -1353.9553, 'eps':     0.0005, 'len': 41122.3360, 'dyn_loss':     0.0952, 'dot_loss':     0.0537, 'ddot_loss':     0.1195, 'rew_loss':     8.1239, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  401000, Reward:   -31.108 [  68.760], Avg:   -47.974 (0.500) <0-12:04:36> ({'r_t':  -254.8410, 'eps':     0.5005, 'len': 41238.3380, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  402000, Reward:    11.532 [  55.367], Avg:   -47.827 (0.001) <0-12:06:42> ({'r_t': -1376.8389, 'eps':     0.0005, 'len': 41330.9100, 'dyn_loss':     0.0840, 'dot_loss':     0.0469, 'ddot_loss':     0.1036, 'rew_loss':     7.4740, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  403000, Reward:    29.225 [  73.675], Avg:   -47.636 (0.500) <0-12:08:23> ({'r_t':  -115.1289, 'eps':     0.5005, 'len': 41443.5070, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  404000, Reward:   -45.044 [  47.717], Avg:   -47.629 (0.001) <0-12:10:02> ({'r_t': -1373.6502, 'eps':     0.0005, 'len': 41531.8700, 'dyn_loss':     0.0944, 'dot_loss':     0.0516, 'ddot_loss':     0.1140, 'rew_loss':     7.6050, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  405000, Reward:   -49.345 [  61.407], Avg:   -47.634 (0.500) <0-12:11:09> ({'r_t':  -182.4482, 'eps':     0.5005, 'len': 41651.8840, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  406000, Reward:   -15.652 [  64.859], Avg:   -47.555 (0.001) <0-12:13:17> ({'r_t': -1468.5137, 'eps':     0.0005, 'len': 41740.9570, 'dyn_loss':     0.0870, 'dot_loss':     0.0485, 'ddot_loss':     0.1071, 'rew_loss':     7.3731, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  407000, Reward:   -32.914 [  54.166], Avg:   -47.519 (0.500) <0-12:14:58> ({'r_t':   -65.7224, 'eps':     0.5005, 'len': 41852.6590, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  408000, Reward:   -19.298 [  50.649], Avg:   -47.450 (0.001) <0-12:17:09> ({'r_t': -1445.7260, 'eps':     0.0005, 'len': 41938.8640, 'dyn_loss':     0.0932, 'dot_loss':     0.0523, 'ddot_loss':     0.1162, 'rew_loss':     7.9181, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  409000, Reward:   -24.681 [  69.394], Avg:   -47.395 (0.500) <0-12:18:49> ({'r_t':  -280.0580, 'eps':     0.5005, 'len': 42067.2900, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  410000, Reward:     9.151 [  70.953], Avg:   -47.257 (0.001) <0-12:21:01> ({'r_t': -1390.3834, 'eps':     0.0005, 'len': 42167.7180, 'dyn_loss':     0.0904, 'dot_loss':     0.0509, 'ddot_loss':     0.1128, 'rew_loss':     7.4598, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  411000, Reward:   -37.004 [  47.092], Avg:   -47.232 (0.500) <0-12:21:56> ({'r_t':  -203.3287, 'eps':     0.5005, 'len': 42301.5610, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  412000, Reward:   -27.134 [  43.878], Avg:   -47.184 (0.001) <0-12:23:23> ({'r_t': -1288.2390, 'eps':     0.0005, 'len': 42400.6310, 'dyn_loss':     0.0863, 'dot_loss':     0.0491, 'ddot_loss':     0.1088, 'rew_loss':     7.6947, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  413000, Reward:   -14.590 [  49.308], Avg:   -47.105 (0.500) <0-12:25:03> ({'r_t':  -218.3192, 'eps':     0.5005, 'len': 42529.6500, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  414000, Reward:     9.518 [  72.372], Avg:   -46.968 (0.001) <0-12:27:12> ({'r_t': -1413.7126, 'eps':     0.0005, 'len': 42630.4470, 'dyn_loss':     0.0887, 'dot_loss':     0.0500, 'ddot_loss':     0.1109, 'rew_loss':     7.6513, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  415000, Reward:   -35.982 [  77.000], Avg:   -46.942 (0.500) <0-12:28:52> ({'r_t':  -205.8502, 'eps':     0.5005, 'len': 42751.2140, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  416000, Reward:    -6.225 [  83.995], Avg:   -46.844 (0.001) <0-12:31:02> ({'r_t': -1260.4603, 'eps':     0.0005, 'len': 42836.0610, 'dyn_loss':     0.0939, 'dot_loss':     0.0511, 'ddot_loss':     0.1131, 'rew_loss':     7.8698, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  417000, Reward:    -8.128 [  82.127], Avg:   -46.752 (0.500) <0-12:32:42> ({'r_t':  -168.9746, 'eps':     0.5005, 'len': 42951.2530, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  418000, Reward:     7.177 [  80.161], Avg:   -46.623 (0.001) <0-12:34:52> ({'r_t': -1453.1169, 'eps':     0.0005, 'len': 43042.5050, 'dyn_loss':     0.0903, 'dot_loss':     0.0509, 'ddot_loss':     0.1131, 'rew_loss':     7.6532, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  419000, Reward:    -2.972 [  74.846], Avg:   -46.519 (0.500) <0-12:36:33> ({'r_t':  -230.5370, 'eps':     0.5005, 'len': 43159.3870, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  420000, Reward:   -14.894 [  86.176], Avg:   -46.444 (0.001) <0-12:38:43> ({'r_t': -1486.8311, 'eps':     0.0005, 'len': 43245.8570, 'dyn_loss':     0.0952, 'dot_loss':     0.0533, 'ddot_loss':     0.1179, 'rew_loss':     7.9336, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  421000, Reward:    -5.833 [  86.637], Avg:   -46.348 (0.500) <0-12:40:23> ({'r_t':   -45.5276, 'eps':     0.5005, 'len': 43357.1580, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  422000, Reward:   -12.648 [  77.012], Avg:   -46.268 (0.001) <0-12:42:34> ({'r_t': -1237.3286, 'eps':     0.0005, 'len': 43411.1090, 'dyn_loss':     0.0913, 'dot_loss':     0.0511, 'ddot_loss':     0.1135, 'rew_loss':     7.7805, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  423000, Reward:   -13.584 [  65.745], Avg:   -46.191 (0.500) <0-12:44:15> ({'r_t':  -248.0406, 'eps':     0.5005, 'len': 43535.1630, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  424000, Reward:   -19.192 [  89.921], Avg:   -46.127 (0.001) <0-12:46:25> ({'r_t': -1427.7948, 'eps':     0.0005, 'len': 43630.9910, 'dyn_loss':     0.0860, 'dot_loss':     0.0481, 'ddot_loss':     0.1068, 'rew_loss':     7.5834, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  425000, Reward:   -43.046 [  71.041], Avg:   -46.120 (0.500) <0-12:48:06> ({'r_t':  -153.5965, 'eps':     0.5005, 'len': 43747.6680, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  426000, Reward:    25.602 [ 106.844], Avg:   -45.952 (0.001) <0-12:50:15> ({'r_t': -1470.0729, 'eps':     0.0005, 'len': 43837.7520, 'dyn_loss':     0.0865, 'dot_loss':     0.0477, 'ddot_loss':     0.1052, 'rew_loss':     7.3286, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  427000, Reward:   -19.593 [  26.116], Avg:   -45.891 (0.500) <0-12:51:55> ({'r_t':   -84.9747, 'eps':     0.5005, 'len': 43947.6730, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  428000, Reward:   -28.414 [  42.857], Avg:   -45.850 (0.001) <0-12:54:03> ({'r_t': -1331.2183, 'eps':     0.0005, 'len': 44023.6530, 'dyn_loss':     0.0853, 'dot_loss':     0.0477, 'ddot_loss':     0.1061, 'rew_loss':     7.5505, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  429000, Reward:    -4.857 [ 103.363], Avg:   -45.755 (0.500) <0-12:55:35> ({'r_t':  -197.8776, 'eps':     0.5005, 'len': 44147.8100, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  430000, Reward:    15.971 [  79.521], Avg:   -45.611 (0.001) <0-12:57:44> ({'r_t': -1518.9328, 'eps':     0.0005, 'len': 44245.3380, 'dyn_loss':     0.0870, 'dot_loss':     0.0477, 'ddot_loss':     0.1057, 'rew_loss':     7.5234, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  431000, Reward:   -12.472 [  75.438], Avg:   -45.535 (0.500) <0-12:59:24> ({'r_t':  -215.3485, 'eps':     0.5005, 'len': 44372.8380, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  432000, Reward:    -2.102 [  87.678], Avg:   -45.434 (0.001) <0-13:01:40> ({'r_t': -1494.4055, 'eps':     0.0005, 'len': 44468.1340, 'dyn_loss':     0.0916, 'dot_loss':     0.0509, 'ddot_loss':     0.1129, 'rew_loss':     7.3794, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  433000, Reward:   -42.551 [  85.416], Avg:   -45.428 (0.500) <0-13:03:20> ({'r_t':  -148.5931, 'eps':     0.5005, 'len': 44590.5500, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  434000, Reward:   -14.984 [  49.405], Avg:   -45.358 (0.001) <0-13:05:33> ({'r_t': -1187.5585, 'eps':     0.0005, 'len': 44678.6470, 'dyn_loss':     0.0882, 'dot_loss':     0.0499, 'ddot_loss':     0.1106, 'rew_loss':     7.4738, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  435000, Reward:   -18.484 [  74.091], Avg:   -45.296 (0.500) <0-13:06:59> ({'r_t':  -135.1575, 'eps':     0.5005, 'len': 44786.1390, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  436000, Reward:     0.004 [  72.283], Avg:   -45.192 (0.001) <0-13:09:05> ({'r_t': -1294.9280, 'eps':     0.0005, 'len': 44866.8640, 'dyn_loss':     0.0830, 'dot_loss':     0.0471, 'ddot_loss':     0.1046, 'rew_loss':     7.5097, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  437000, Reward:   -11.499 [  77.743], Avg:   -45.116 (0.500) <0-13:10:46> ({'r_t':  -172.9331, 'eps':     0.5005, 'len': 44985.7090, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  438000, Reward:    14.954 [ 107.511], Avg:   -44.979 (0.001) <0-13:13:00> ({'r_t': -1510.4446, 'eps':     0.0005, 'len': 45075.4650, 'dyn_loss':     0.1018, 'dot_loss':     0.0588, 'ddot_loss':     0.1307, 'rew_loss':     8.2138, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  439000, Reward:     2.273 [  69.123], Avg:   -44.871 (0.500) <0-13:14:41> ({'r_t':  -154.7948, 'eps':     0.5005, 'len': 45195.8260, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  440000, Reward:   -14.707 [  60.043], Avg:   -44.803 (0.001) <0-13:16:52> ({'r_t': -1348.7016, 'eps':     0.0005, 'len': 45270.5890, 'dyn_loss':     0.0900, 'dot_loss':     0.0509, 'ddot_loss':     0.1127, 'rew_loss':     7.7750, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  441000, Reward:   -19.684 [  92.022], Avg:   -44.746 (0.500) <0-13:18:32> ({'r_t':  -135.0980, 'eps':     0.5005, 'len': 45379.5850, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  442000, Reward:    30.678 [  88.939], Avg:   -44.576 (0.001) <0-13:20:45> ({'r_t': -1361.6300, 'eps':     0.0005, 'len': 45461.9770, 'dyn_loss':     0.0927, 'dot_loss':     0.0546, 'ddot_loss':     0.1221, 'rew_loss':     7.7838, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  443000, Reward:   -10.689 [  77.006], Avg:   -44.499 (0.500) <0-13:22:26> ({'r_t':  -214.2831, 'eps':     0.5005, 'len': 45581.2530, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  444000, Reward:   -24.583 [  68.164], Avg:   -44.455 (0.001) <0-13:24:39> ({'r_t': -1329.2168, 'eps':     0.0005, 'len': 45663.6360, 'dyn_loss':     0.0983, 'dot_loss':     0.0567, 'ddot_loss':     0.1258, 'rew_loss':     8.1227, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  445000, Reward:   -37.817 [  59.572], Avg:   -44.440 (0.500) <0-13:26:20> ({'r_t':  -321.5578, 'eps':     0.5005, 'len': 45797.1460, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  446000, Reward:   -47.722 [  76.672], Avg:   -44.447 (0.001) <0-13:28:30> ({'r_t': -1605.3852, 'eps':     0.0005, 'len': 45902.9660, 'dyn_loss':     0.0895, 'dot_loss':     0.0500, 'ddot_loss':     0.1106, 'rew_loss':     7.7846, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  447000, Reward:   -38.819 [  21.529], Avg:   -44.435 (0.500) <0-13:29:24> ({'r_t':  -213.0778, 'eps':     0.5005, 'len': 46030.2910, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  448000, Reward:     6.192 [  90.525], Avg:   -44.322 (0.001) <0-13:31:04> ({'r_t': -1405.1582, 'eps':     0.0005, 'len': 46130.5920, 'dyn_loss':     0.0842, 'dot_loss':     0.0456, 'ddot_loss':     0.1008, 'rew_loss':     7.2036, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  449000, Reward:   -25.796 [  63.821], Avg:   -44.281 (0.500) <0-13:32:02> ({'r_t':  -181.2480, 'eps':     0.5005, 'len': 46261.7920, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  450000, Reward:   -45.818 [  45.972], Avg:   -44.284 (0.001) <0-13:33:27> ({'r_t': -1450.1747, 'eps':     0.0005, 'len': 46364.8300, 'dyn_loss':     0.0867, 'dot_loss':     0.0492, 'ddot_loss':     0.1091, 'rew_loss':     7.4497, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  451000, Reward:    -2.474 [  96.381], Avg:   -44.192 (0.500) <0-13:35:06> ({'r_t':  -210.7283, 'eps':     0.5005, 'len': 46483.6860, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  452000, Reward:   -19.956 [  78.011], Avg:   -44.138 (0.001) <0-13:37:16> ({'r_t': -1420.5056, 'eps':     0.0005, 'len': 46581.8000, 'dyn_loss':     0.0894, 'dot_loss':     0.0492, 'ddot_loss':     0.1087, 'rew_loss':     7.5351, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  453000, Reward:    -8.989 [  59.152], Avg:   -44.061 (0.500) <0-13:38:56> ({'r_t':  -252.9032, 'eps':     0.5005, 'len': 46696.2310, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  454000, Reward:   -12.040 [  53.781], Avg:   -43.990 (0.001) <0-13:41:10> ({'r_t': -1480.3886, 'eps':     0.0005, 'len': 46789.1010, 'dyn_loss':     0.1030, 'dot_loss':     0.0575, 'ddot_loss':     0.1272, 'rew_loss':     8.0674, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  455000, Reward:     5.343 [  65.307], Avg:   -43.882 (0.500) <0-13:42:50> ({'r_t':  -114.2436, 'eps':     0.5005, 'len': 46903.4910, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  456000, Reward:   -17.349 [  65.289], Avg:   -43.824 (0.001) <0-13:44:56> ({'r_t': -1550.1980, 'eps':     0.0005, 'len': 47005.3280, 'dyn_loss':     0.0769, 'dot_loss':     0.0418, 'ddot_loss':     0.0923, 'rew_loss':     6.8857, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  457000, Reward:   -13.125 [  77.209], Avg:   -43.757 (0.500) <0-13:46:37> ({'r_t':  -229.0598, 'eps':     0.5005, 'len': 47132.9660, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  458000, Reward:    25.056 [ 106.504], Avg:   -43.607 (0.001) <0-13:48:44> ({'r_t': -1408.9977, 'eps':     0.0005, 'len': 47231.6840, 'dyn_loss':     0.0880, 'dot_loss':     0.0487, 'ddot_loss':     0.1075, 'rew_loss':     7.4675, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  459000, Reward:   -22.708 [  83.792], Avg:   -43.562 (0.500) <0-13:50:24> ({'r_t':   -28.9432, 'eps':     0.5005, 'len': 47337.5020, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  460000, Reward:   -26.277 [  42.038], Avg:   -43.524 (0.001) <0-13:51:52> ({'r_t': -1220.6541, 'eps':     0.0005, 'len': 47412.3440, 'dyn_loss':     0.0832, 'dot_loss':     0.0459, 'ddot_loss':     0.1016, 'rew_loss':     7.1277, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  461000, Reward:    15.715 [ 104.282], Avg:   -43.396 (0.500) <0-13:53:36> ({'r_t':  -171.5047, 'eps':     0.5005, 'len': 47525.1350, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  462000, Reward:     5.438 [  96.638], Avg:   -43.291 (0.001) <0-13:55:53> ({'r_t': -1323.7844, 'eps':     0.0005, 'len': 47612.6330, 'dyn_loss':     0.0872, 'dot_loss':     0.0476, 'ddot_loss':     0.1054, 'rew_loss':     7.4996, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  463000, Reward:   -22.011 [  63.358], Avg:   -43.245 (0.500) <0-13:57:47> ({'r_t':  -162.3578, 'eps':     0.5005, 'len': 47722.9840, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  464000, Reward:     1.084 [  78.242], Avg:   -43.149 (0.001) <0-14:00:06> ({'r_t': -1382.1925, 'eps':     0.0005, 'len': 47809.4550, 'dyn_loss':     0.0794, 'dot_loss':     0.0427, 'ddot_loss':     0.0944, 'rew_loss':     6.9531, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  465000, Reward:   -20.289 [  57.302], Avg:   -43.100 (0.500) <0-14:01:51> ({'r_t':  -120.0970, 'eps':     0.5005, 'len': 47920.3830, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  466000, Reward:   -18.596 [  52.146], Avg:   -43.048 (0.001) <0-14:04:11> ({'r_t': -1213.5056, 'eps':     0.0005, 'len': 48000.5720, 'dyn_loss':     0.0936, 'dot_loss':     0.0500, 'ddot_loss':     0.1100, 'rew_loss':     7.6063, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  467000, Reward:   -31.332 [  48.745], Avg:   -43.023 (0.500) <0-14:05:17> ({'r_t':  -276.1451, 'eps':     0.5005, 'len': 48123.1600, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  468000, Reward:    11.819 [  75.744], Avg:   -42.906 (0.001) <0-14:07:41> ({'r_t': -1241.2646, 'eps':     0.0005, 'len': 48223.1360, 'dyn_loss':     0.0854, 'dot_loss':     0.0465, 'ddot_loss':     0.1027, 'rew_loss':     7.1947, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  469000, Reward:    -1.564 [ 102.461], Avg:   -42.818 (0.500) <0-14:09:27> ({'r_t':  -310.2748, 'eps':     0.5005, 'len': 48344.7340, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  470000, Reward:    -3.724 [  90.412], Avg:   -42.735 (0.001) <0-14:11:50> ({'r_t': -1460.2435, 'eps':     0.0005, 'len': 48448.0430, 'dyn_loss':     0.0907, 'dot_loss':     0.0508, 'ddot_loss':     0.1126, 'rew_loss':     7.6977, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  471000, Reward:    13.405 [  76.373], Avg:   -42.616 (0.500) <0-14:13:36> ({'r_t':  -183.0005, 'eps':     0.5005, 'len': 48569.0130, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  472000, Reward:   -35.467 [  35.253], Avg:   -42.601 (0.001) <0-14:15:12> ({'r_t': -1339.5890, 'eps':     0.0005, 'len': 48660.2640, 'dyn_loss':     0.0948, 'dot_loss':     0.0535, 'ddot_loss':     0.1186, 'rew_loss':     7.7630, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  473000, Reward:   -24.888 [  52.621], Avg:   -42.563 (0.500) <0-14:17:05> ({'r_t':  -281.4949, 'eps':     0.5005, 'len': 48785.5270, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  474000, Reward:   -17.706 [  47.215], Avg:   -42.511 (0.001) <0-14:18:40> ({'r_t': -1372.7833, 'eps':     0.0005, 'len': 48882.4460, 'dyn_loss':     0.0876, 'dot_loss':     0.0472, 'ddot_loss':     0.1041, 'rew_loss':     7.4713, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  475000, Reward:   -12.143 [  64.238], Avg:   -42.447 (0.500) <0-14:20:32> ({'r_t':  -189.2011, 'eps':     0.5005, 'len': 49004.0580, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  476000, Reward:    17.888 [  72.060], Avg:   -42.321 (0.001) <0-14:22:47> ({'r_t': -1325.3178, 'eps':     0.0005, 'len': 49091.3140, 'dyn_loss':     0.0878, 'dot_loss':     0.0487, 'ddot_loss':     0.1081, 'rew_loss':     7.5302, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  477000, Reward:   -17.582 [  70.934], Avg:   -42.269 (0.500) <0-14:24:27> ({'r_t':  -174.6732, 'eps':     0.5005, 'len': 49214.1220, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  478000, Reward:   -33.360 [  58.559], Avg:   -42.250 (0.001) <0-14:26:38> ({'r_t': -1511.8900, 'eps':     0.0005, 'len': 49305.0390, 'dyn_loss':     0.0862, 'dot_loss':     0.0484, 'ddot_loss':     0.1072, 'rew_loss':     7.1838, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  479000, Reward:   -24.728 [  52.078], Avg:   -42.214 (0.500) <0-14:28:19> ({'r_t':  -254.8736, 'eps':     0.5005, 'len': 49427.8330, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  480000, Reward:   -25.313 [  77.689], Avg:   -42.179 (0.001) <0-14:30:28> ({'r_t': -1388.9006, 'eps':     0.0005, 'len': 49524.6070, 'dyn_loss':     0.0864, 'dot_loss':     0.0480, 'ddot_loss':     0.1062, 'rew_loss':     7.4564, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  481000, Reward:   -45.348 [  38.014], Avg:   -42.185 (0.500) <0-14:32:08> ({'r_t':  -360.2153, 'eps':     0.5005, 'len': 49648.6850, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  482000, Reward:   -10.503 [  95.815], Avg:   -42.120 (0.001) <0-14:34:21> ({'r_t': -1535.3929, 'eps':     0.0005, 'len': 49762.7560, 'dyn_loss':     0.0969, 'dot_loss':     0.0541, 'ddot_loss':     0.1206, 'rew_loss':     8.2454, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  483000, Reward:   -23.246 [  57.460], Avg:   -42.081 (0.500) <0-14:36:02> ({'r_t':  -168.5373, 'eps':     0.5005, 'len': 49894.5800, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  484000, Reward:   -23.341 [  68.675], Avg:   -42.042 (0.001) <0-14:38:12> ({'r_t': -1381.6777, 'eps':     0.0005, 'len': 49992.1380, 'dyn_loss':     0.0814, 'dot_loss':     0.0449, 'ddot_loss':     0.0995, 'rew_loss':     7.3681, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  485000, Reward:    -4.312 [  51.335], Avg:   -41.965 (0.500) <0-14:39:52> ({'r_t':  -183.9084, 'eps':     0.5005, 'len': 50112.2210, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  486000, Reward:    26.216 [  95.810], Avg:   -41.825 (0.001) <0-14:42:03> ({'r_t': -1413.9517, 'eps':     0.0005, 'len': 50187.5090, 'dyn_loss':     0.0900, 'dot_loss':     0.0512, 'ddot_loss':     0.1135, 'rew_loss':     7.7195, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  487000, Reward:    21.044 [  78.606], Avg:   -41.696 (0.500) <0-14:43:43> ({'r_t':   -92.0382, 'eps':     0.5005, 'len': 50303.0820, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  488000, Reward:    -8.009 [  45.617], Avg:   -41.627 (0.001) <0-14:45:55> ({'r_t': -1451.7343, 'eps':     0.0005, 'len': 50393.6540, 'dyn_loss':     0.0928, 'dot_loss':     0.0524, 'ddot_loss':     0.1162, 'rew_loss':     7.7760, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  489000, Reward:   -17.683 [  83.178], Avg:   -41.578 (0.500) <0-14:47:38> ({'r_t':  -179.9382, 'eps':     0.5005, 'len': 50513.1000, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  490000, Reward:   -23.616 [  31.633], Avg:   -41.541 (0.001) <0-14:49:47> ({'r_t': -1298.1094, 'eps':     0.0005, 'len': 50606.1770, 'dyn_loss':     0.0796, 'dot_loss':     0.0439, 'ddot_loss':     0.0978, 'rew_loss':     7.1245, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  491000, Reward:    -4.595 [  84.178], Avg:   -41.466 (0.500) <0-14:51:29> ({'r_t':  -179.1830, 'eps':     0.5005, 'len': 50726.3070, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  492000, Reward:    16.553 [  84.999], Avg:   -41.349 (0.001) <0-14:53:44> ({'r_t': -1385.1635, 'eps':     0.0005, 'len': 50820.1990, 'dyn_loss':     0.0948, 'dot_loss':     0.0551, 'ddot_loss':     0.1230, 'rew_loss':     7.7848, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  493000, Reward:   -32.091 [  87.705], Avg:   -41.330 (0.500) <0-14:55:26> ({'r_t':   -97.4264, 'eps':     0.5005, 'len': 50931.5930, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  494000, Reward:   -62.955 [  69.491], Avg:   -41.374 (0.001) <0-14:57:38> ({'r_t': -1465.8929, 'eps':     0.0005, 'len': 51015.8420, 'dyn_loss':     0.0881, 'dot_loss':     0.0478, 'ddot_loss':     0.1061, 'rew_loss':     7.3167, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  495000, Reward:   -23.039 [  84.734], Avg:   -41.337 (0.500) <0-14:59:20> ({'r_t':  -270.1287, 'eps':     0.5005, 'len': 51144.9600, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  496000, Reward:   -15.919 [  58.709], Avg:   -41.285 (0.001) <0-15:01:35> ({'r_t': -1264.3719, 'eps':     0.0005, 'len': 51234.1680, 'dyn_loss':     0.0949, 'dot_loss':     0.0528, 'ddot_loss':     0.1172, 'rew_loss':     7.9026, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  497000, Reward:   -35.483 [  68.156], Avg:   -41.274 (0.500) <0-15:03:17> ({'r_t':  -170.0823, 'eps':     0.5005, 'len': 51345.7550, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  498000, Reward:     7.500 [  59.656], Avg:   -41.176 (0.001) <0-15:05:30> ({'r_t': -1250.7048, 'eps':     0.0005, 'len': 51423.3660, 'dyn_loss':     0.0839, 'dot_loss':     0.0473, 'ddot_loss':     0.1048, 'rew_loss':     7.0512, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  499000, Reward:   -21.269 [  54.816], Avg:   -41.136 (0.500) <0-15:07:12> ({'r_t':  -143.6153, 'eps':     0.5005, 'len': 51541.5440, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  500000, Reward:     7.565 [ 104.643], Avg:   -41.039 (0.001) <0-15:09:24> ({'r_t': -1341.7893, 'eps':     0.0005, 'len': 51627.6660, 'dyn_loss':     0.0881, 'dot_loss':     0.0496, 'ddot_loss':     0.1107, 'rew_loss':     7.6825, 'lr':   6.95e-05, 'eps_e':     0.0005, 'lr_e':   6.95e-05})
