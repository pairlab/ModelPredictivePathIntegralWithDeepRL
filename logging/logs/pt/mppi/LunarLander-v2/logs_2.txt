Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: LunarLander-v2, Date: 07/06/2020 15:55:50
CPU: 20 Core, 0.0GHz, 377.59 GB, Linux-4.14.175-llgrid-10ms-x86_64-with-debian-buster-sid
GPU 0: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
Git URL: https://github.com/shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 78eaab65753a45444c8c1759c8997485b5d39aaa
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 2000
   TARGET_UPDATE_RATE = 0.0004
   BATCH_SIZE = 250
   DYN_EPOCHS = 1
   TRAIN_EVERY = 2000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 100
      HORIZON = 40
      LAMBDA = 0.1
      COV = 0.5
   dynamics_size = 8
   state_size = (8,)
   action_size = [4]
   env_name = LunarLander-v2
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.98
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fa96176f860> 
	env = <GymEnv<TimeLimit<LunarLander<LunarLander-v2>>>> 
		env = <TimeLimit<LunarLander<LunarLander-v2>>> 
			env = <LunarLander<LunarLander-v2>> 
				np_random = RandomState(MT19937)
				viewer = None
				world = b2World(autoClearForces=True,
				        bodies=[b2Body(active=True,
				                      angle=0.0,
				                      angularDamping=0.0,
				                      angularVelocity=0.0,
				                      awake=True,
				                      bullet=False,
				                      contacts=[],
				                      fixedRotation=False,...  )],
				        bodyCount=4,
				        contactCount=0,
				        contactFilter=None,
				        contactListener=ContactDetector(),
				        contactManager=b2ContactManager(allocator=<Swig Object of type 'b2BlockAllocator *' at 0x7fa959159b10>,
				                                        broadPhase=proxyCount=14,),
				                                        contactCount=0,
				                                        contactFilter=b2ContactFilter(),
				                                        contactList=None,
				                                        contactListener=b2ContactListener(),
				                                        ),
				        contacts=[],
				        continuousPhysics=True,
				        destructionListener=None,
				        gravity=b2Vec2(0,-10),
				        jointCount=2,
				        joints=[b2RevoluteJoint(active=True,
				                               anchorA=b2Vec2(9.99511,13.3157),
				                               anchorB=b2Vec2(9.99511,13.3157),
				                               angle=0.5420570373535156,
				                               bodyA=b2Body(active=True,...  )],
				        locked=False,
				        proxyCount=14,
				        renderer=None,
				        subStepping=False,
				        warmStarting=True,
				        )
				moon = b2Body(active=True,
				       angle=0.0,
				       angularDamping=0.0,
				       angularVelocity=0.0,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.0,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.0,
				                                      awake=True,...  )],
				       inertia=0.0,
				       joints=[],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(0,0),
				       localCenter=b2Vec2(0,0),
				       mass=0.0,
				       massData=I=0.0,center=b2Vec2(0,0),mass=0.0,),
				       position=b2Vec2(0,0),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159d50> >,angle=0.0,position=b2Vec2(0,0),),
				       type=0,
				       userData=None,
				       worldCenter=b2Vec2(0,0),
				       )
				lander = b2Body(active=True,
				       angle=0.0005738087929785252,
				       angularDamping=0.0,
				       angularVelocity=0.028076617047190666,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.0005738087929785252,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028076617047190666,...  )],
				       inertia=0.8333148956298828,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.99511,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.247901,-1.189),
				       localCenter=b2Vec2(0,0.101307),
				       mass=4.816666603088379,
				       massData=I=0.8333148956298828,center=b2Vec2(0,0.101307),mass=4.816666603088379,),
				       position=b2Vec2(9.99511,13.3157),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159d20> >,angle=0.0005738087929785252,position=b2Vec2(9.99511,13.3157),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.99505,13.417),
				       )
				particles = []
				prev_reward = None
				observation_space = Box(8,) 
					dtype = float32
					shape = (8,)
					low = [-inf -inf -inf -inf -inf -inf -inf -inf]
					high = [ inf  inf  inf  inf  inf  inf  inf  inf]
					bounded_below = [False False False False False False False False]
					bounded_above = [False False False False False False False False]
					np_random = RandomState(MT19937)
				action_space = Discrete(4) 
					n = 4
					shape = ()
					dtype = int64
					np_random = RandomState(MT19937)
				game_over = False
				prev_shaping = -157.40318587399
				helipad_x1 = 8.0
				helipad_x2 = 12.0
				helipad_y = 3.3333333333333335
				sky_polys = [[(0.0, 2.9520688988065116), (2.0, 1.278570138065217), (2.0, 13.333333333333334), (0.0, 13.333333333333334)], [(2.0, 1.278570138065217), (4.0, 2.0783339397118548), (4.0, 13.333333333333334), (2.0, 13.333333333333334)], [(4.0, 2.0783339397118548), (6.0, 2.3815799008277643), (6.0, 13.333333333333334), (4.0, 13.333333333333334)], [(6.0, 2.3815799008277643), (8.0, 3.3000000000000003), (8.0, 13.333333333333334), (6.0, 13.333333333333334)], [(8.0, 3.3000000000000003), (10.0, 3.3000000000000003), (10.0, 13.333333333333334), (8.0, 13.333333333333334)], [(10.0, 3.3000000000000003), (12.0, 3.3000000000000003), (12.0, 13.333333333333334), (10.0, 13.333333333333334)], [(12.0, 3.3000000000000003), (14.0, 3.143882237388496), (14.0, 13.333333333333334), (12.0, 13.333333333333334)], [(14.0, 3.143882237388496), (16.0, 3.9720707555936667), (16.0, 13.333333333333334), (14.0, 13.333333333333334)], [(16.0, 3.9720707555936667), (18.0, 3.633645375158525), (18.0, 13.333333333333334), (16.0, 13.333333333333334)], [(18.0, 3.633645375158525), (20.0, 4.544841799339087), (20.0, 13.333333333333334), (18.0, 13.333333333333334)]]
				legs = [b2Body(active=True,
				       angle=0.49263086915016174,
				       angularDamping=0.0,
				       angularVelocity=0.028074592351913452,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.49263086915016174,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028074592351913452,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.99511,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.227296,-1.17114),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(10.8663,13.1023),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159c30> >,angle=0.49263086915016174,position=b2Vec2(10.8663,13.1023),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.8663,13.1023),
				       ), b2Body(active=True,
				       angle=-0.4914216995239258,
				       angularDamping=0.0,
				       angularVelocity=0.028067708015441895,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.4914216995239258,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028067708015441895,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.9951,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.227296,-1.20685),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(9.1242,13.1013),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159d80> >,angle=-0.4914216697216034,position=b2Vec2(9.1242,13.1013),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.1242,13.1013),
				       )]
				drawlist = [b2Body(active=True,
				       angle=0.0005738087929785252,
				       angularDamping=0.0,
				       angularVelocity=0.028076617047190666,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.0005738087929785252,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028076617047190666,...  )],
				       inertia=0.8333148956298828,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.99511,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.247901,-1.189),
				       localCenter=b2Vec2(0,0.101307),
				       mass=4.816666603088379,
				       massData=I=0.8333148956298828,center=b2Vec2(0,0.101307),mass=4.816666603088379,),
				       position=b2Vec2(9.99511,13.3157),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159d50> >,angle=0.0005738087929785252,position=b2Vec2(9.99511,13.3157),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.99505,13.417),
				       ), b2Body(active=True,
				       angle=0.49263086915016174,
				       angularDamping=0.0,
				       angularVelocity=0.028074592351913452,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=0.49263086915016174,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028074592351913452,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.99511,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.227296,-1.17114),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(10.8663,13.1023),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159c00> >,angle=0.49263086915016174,position=b2Vec2(10.8663,13.1023),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(10.8663,13.1023),
				       ), b2Body(active=True,
				       angle=-0.4914216995239258,
				       angularDamping=0.0,
				       angularVelocity=0.028067708015441895,
				       awake=True,
				       bullet=False,
				       contacts=[],
				       fixedRotation=False,
				       fixtures=[b2Fixture(body=b2Body(active=True,
				                                      angle=-0.4914216995239258,
				                                      angularDamping=0.0,
				                                      angularVelocity=0.028067708015441895,...  )],
				       inertia=0.0017909470479935408,
				       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,
				                                                anchorA=b2Vec2(9.99511,13.3157),
				                                                anchorB=b2Vec2(9.9951,13.3157),...  )],
				       linearDamping=0.0,
				       linearVelocity=b2Vec2(-0.227296,-1.20685),
				       localCenter=b2Vec2(0,0),
				       mass=0.07111112028360367,
				       massData=I=0.0017909470479935408,center=b2Vec2(0,0),mass=0.07111112028360367,),
				       position=b2Vec2(9.1242,13.1013),
				       sleepingAllowed=True,
				       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x7fa959159e40> >,angle=-0.4914216697216034,position=b2Vec2(9.1242,13.1013),),
				       type=2,
				       userData=None,
				       worldCenter=b2Vec2(9.1242,13.1013),
				       )]
				spec = EnvSpec(LunarLander-v2) 
					id = LunarLander-v2
					entry_point = gym.envs.box2d:LunarLander
					reward_threshold = 200
					nondeterministic = False
					max_episode_steps = 1000
				verbose = 0
			action_space = Discrete(4) 
				n = 4
				shape = ()
				dtype = int64
				np_random = RandomState(MT19937)
			observation_space = Box(8,) 
				dtype = float32
				shape = (8,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False]
				bounded_above = [False False False False False False False False]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		action_space = Discrete(4) 
			n = 4
			shape = ()
			dtype = int64
			np_random = RandomState(MT19937)
		observation_space = Box(8,) 
			dtype = float32
			shape = (8,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False]
			bounded_above = [False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fa96133d710> 
			observation_space = Box(8,) 
				dtype = float32
				shape = (8,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False]
				bounded_above = [False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (8,)
	action_size = [4]
	action_space = Discrete(4) 
		n = 4
		shape = ()
		dtype = int64
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.MPIConnection object at 0x7fa96133d7b8> 
		root = 0
		rank = 0
		cluster = <list len=16>
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fa96133d7f0> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fa96133d828> 
		state_size = (8,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fa96133d860> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fa96133d898> 
			size = [4]
			dt = 0.2
			action = [-0.172 -0.002  0.464 -1.000]
			daction_dt = [-0.224  0.080 -0.478 -1.016]
		discrete = True
		action_size = [4]
		state_size = (8,)
		config = <src.utils.config.Config object at 0x7fa96b0efe48> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 2000
			TARGET_UPDATE_RATE = 0.0004
			BATCH_SIZE = 250
			DYN_EPOCHS = 1
			TRAIN_EVERY = 2000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fa98796cc50> 
				NSAMPLES = 100
				HORIZON = 40
				LAMBDA = 0.1
				COV = 0.5
			dynamics_size = 8
			state_size = (8,)
			action_size = [4]
			env_name = LunarLander-v2
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fa985f16e80> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.98
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fa96133d8d0> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fa96133d940> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fa96b0efe48> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 2000
				TARGET_UPDATE_RATE = 0.0004
				BATCH_SIZE = 250
				DYN_EPOCHS = 1
				TRAIN_EVERY = 2000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fa98796cc50> 
					NSAMPLES = 100
					HORIZON = 40
					LAMBDA = 0.1
					COV = 0.5
				dynamics_size = 8
				state_size = (8,)
				action_size = [4]
				env_name = LunarLander-v2
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = []
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fa985f16e80> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.98
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fa96133d978> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=20, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(20, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=8, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fa96133d9e8> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fa96b0efe48> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = 500
						MAX_BUFFER_SIZE = 1000000
						REPLAY_BATCH_SIZE = 2000
						TARGET_UPDATE_RATE = 0.0004
						BATCH_SIZE = 250
						DYN_EPOCHS = 1
						TRAIN_EVERY = 2000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fa98796cc50> 
							NSAMPLES = 100
							HORIZON = 40
							LAMBDA = 0.1
							COV = 0.5
						dynamics_size = 8
						state_size = (8,)
						action_size = [4]
						env_name = LunarLander-v2
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = []
						tcp_rank = 0
						num_envs = 1
						nsteps = 500000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fa985f16e80> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.98
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (8,)
					action_size = [4]
					discrete = True
					dyn_index = 8
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa96133dd68>
				state_size = (8,)
				action_size = [4]
			mu = [ 0.000  0.000  0.000  0.000]
			cov = [[ 0.500  0.000  0.000  0.000]
			 [ 0.000  0.500  0.000  0.000]
			 [ 0.000  0.000  0.500  0.000]
			 [ 0.000  0.000  0.000  0.500]]
			icov = [[ 2.000  0.000  0.000  0.000]
			 [ 0.000  2.000  0.000  0.000]
			 [ 0.000  0.000  2.000  0.000]
			 [ 0.000  0.000  0.000  2.000]]
			lamda = 0.1
			horizon = 40
			nsamples = 100
			action_size = [4]
			control = [[[ 0.038 -0.571  0.564 -0.084]
			  [-0.382 -0.848 -0.094 -0.674]
			  [-0.295 -0.783  0.694 -0.255]
			  [-0.893  0.130 -0.370  0.032]
			  [-0.737  0.037  0.097 -0.210]
			  [-0.331  0.850 -0.879  0.495]
			  [-0.516  0.763 -0.782 -0.834]
			  [-0.315  0.287 -0.270  0.683]
			  [ 0.430 -0.595  0.628 -0.389]
			  [-0.500  0.783  0.512  0.692]
			  [-0.090  0.372 -0.223 -0.616]
			  [ 0.706  0.265  0.460  0.638]
			  [-0.685 -0.391 -0.349 -0.453]
			  [ 0.810  0.915 -0.021 -0.821]
			  [ 0.345 -0.664  0.291 -0.774]
			  [-0.733 -0.669 -0.628  0.727]
			  [-0.016  0.012 -0.046  0.548]
			  [-0.825 -0.417  0.624 -0.719]
			  [-0.282 -0.751 -0.275 -0.846]
			  [ 0.503  0.215  0.495 -0.470]
			  [ 0.540 -0.326 -0.802  0.969]
			  [ 0.647  0.967 -0.792 -0.741]
			  [ 0.913 -0.167  0.323 -0.968]
			  [-0.662 -0.463  0.334 -0.429]
			  [ 0.223  0.938 -0.241  0.448]
			  [-0.099 -0.498 -0.969 -0.457]
			  [ 0.766  0.318  0.202  0.584]
			  [ 0.789  0.946  0.445 -0.212]
			  [ 0.481  0.071  0.072  0.280]
			  [-0.683  0.496  0.144 -0.327]
			  [-0.555 -0.620 -0.060 -0.242]
			  [ 0.025  0.033 -0.517 -0.223]
			  [ 0.780  0.627 -0.315  0.427]
			  [ 0.879  0.279 -0.638  0.188]
			  [-0.588  0.024  0.293  0.974]
			  [ 0.637  0.780  0.840 -0.522]
			  [-0.354 -0.776 -0.526 -0.385]
			  [ 0.288 -0.076  0.269  0.984]
			  [ 0.911 -0.747  0.729  0.381]
			  [ 0.714  0.740  0.525  0.540]]]
			noise = [[[[-0.263  0.578 -0.518  0.119]
			   [-0.575 -0.016  0.619 -0.345]
			   [ 0.514 -1.158 -0.216  1.020]
			   ...
			   [-0.294 -0.768  0.575  0.923]
			   [ 0.530  0.477  0.171  0.519]
			   [-0.464 -0.367  0.318  1.605]]
			
			  [[-1.513  0.450 -0.930  1.242]
			   [ 0.032  0.078  0.036  1.116]
			   [ 0.156 -0.583  0.009  0.299]
			   ...
			   [ 0.691 -0.522  0.243  0.161]
			   [ 0.429 -0.106 -0.911  0.430]
			   [-0.602  0.329  0.860 -0.059]]
			
			  [[ 1.527 -0.096  0.786  0.621]
			   [-1.739 -0.338  0.440 -0.915]
			   [ 0.023  0.380 -1.162  1.018]
			   ...
			   [-0.223  0.857 -0.117 -0.201]
			   [ 0.148  0.430 -2.530  0.843]
			   [ 0.283 -0.128  0.813 -0.424]]
			
			  ...
			
			  [[-0.280  1.300  0.371  0.174]
			   [ 1.055  0.309  0.791 -1.522]
			   [ 0.282  0.757  0.570 -0.069]
			   ...
			   [-0.513  0.719 -0.422 -0.338]
			   [ 1.081 -0.017  0.837  0.639]
			   [-0.099 -1.344  0.412 -0.038]]
			
			  [[ 0.439 -1.076 -0.182 -0.618]
			   [ 0.451 -2.048  0.952 -0.473]
			   [-1.406  0.139  1.040  0.968]
			   ...
			   [-0.228  0.280  0.751  0.950]
			   [ 0.649  0.379 -1.717 -1.259]
			   [ 0.489 -0.867  0.592  1.930]]
			
			  [[ 0.404  0.863  0.302  0.088]
			   [ 0.913 -0.010  0.690 -0.134]
			   [-0.057 -0.567  0.353 -0.546]
			   ...
			   [-0.916 -1.000 -0.868  0.243]
			   [ 0.440 -0.999  0.270  0.649]
			   [-0.212  0.042 -0.046  0.982]]]]
			init_cost = [[ 1.359e+01 -5.092e+00  1.384e+00  3.300e+00 -4.462e+00 -1.725e+00  6.079e+00 -5.845e+00  3.876e+00 -4.231e+00  6.170e+00  1.745e+01  7.101e+00  1.886e+01  1.305e+01  8.710e+00  5.840e+00 -2.411e+00  9.180e+00 -1.405e+01 -8.359e+00 -2.219e+01  7.941e-01  1.552e+01  7.032e+00 -1.835e+01  1.663e+01  1.384e+01 -9.258e+00 -4.147e+00 -6.287e+00  1.069e-02 -6.114e-01  2.654e+01 -4.989e+00 -5.322e+00  8.619e+00  4.179e+00 -2.038e+01  6.213e+00  1.140e+01 -3.894e+00  3.497e+00 -3.507e+00  1.024e+01  1.974e+01 -9.390e+00 -8.994e+00  5.069e+00 -1.903e+01  8.589e+00 -7.566e+00 -1.573e+01 -2.684e+00 -1.978e+00 -2.791e-01  8.701e+00  1.283e+00  6.655e+00 -2.690e+00 -6.124e+00 -7.433e+00 -1.860e+01 -4.753e+00 -1.058e+01 -9.139e+00  1.019e+01  2.491e+00 -1.331e+00 -6.307e-01 -2.344e+00 -1.110e+01 -7.399e+00  1.192e+01 -1.103e+01  1.156e+01 -5.347e+00 -1.462e+01  1.375e+00  9.858e+00  8.620e+00 -1.046e+01  9.323e+00  1.922e+00 -1.386e+01  2.253e+00 -6.105e+00 -4.555e+00  1.783e+01 -3.378e+00  1.048e+01 -8.743e+00  5.221e+00  5.830e+00 -2.446e+00 -8.315e+00  4.234e+00  3.743e+00  1.168e+01 -8.450e+00]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fa96133dda0> 
			buffer = deque([], maxlen=1000000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fa961365630> 
		size = [4]
		dt = 0.2
		action = [ 1.000  0.607  0.650 -0.563]
		daction_dt = [-0.981  0.652 -0.729 -1.155]
	discrete = True
	action_size = [4]
	state_size = (8,)
	config = <src.utils.config.Config object at 0x7fa96b0efe48> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 2000
		TARGET_UPDATE_RATE = 0.0004
		BATCH_SIZE = 250
		DYN_EPOCHS = 1
		TRAIN_EVERY = 2000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fa98796cc50> 
			NSAMPLES = 100
			HORIZON = 40
			LAMBDA = 0.1
			COV = 0.5
		dynamics_size = 8
		state_size = (8,)
		action_size = [4]
		env_name = LunarLander-v2
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fa985f16e80> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.98
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fa9613654e0> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		controls = np.clip(self.control[:,None,:,:] + self.noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls[...,:horizon,:], x, numpy=True)
		costs = -np.sum(rewards, -1) #+ self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control += np.sum(weights[:,:,None,None]*self.noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[1, self.horizon, *self.action_size]).repeat(batch_size, 0)
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[1, self.nsamples, self.horizon]).repeat(batch_size, 0)
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def partition(self, x):
		if self.config.NUM_STEPS is None:
			return x[None,...]
		num_splits = x.shape[0]//self.config.NUM_STEPS
		if num_splits == 0:
			arr = np.zeros([self.config.NUM_STEPS, *x.shape[1:]])
			arr[-x.shape[0]:] = x
			num_splits = 1
			x = arr
		arr = x[:num_splits*self.config.NUM_STEPS].reshape(num_splits, self.config.NUM_STEPS, *x.shape[1:])
		return arr

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: np.stack(x)[None], zip(*buffer))
			buffer.clear()
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.TRAIN_EVERY)/self.config.TRAIN_EVERY if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:  -163.277 [ 135.992], Avg:  -163.277 (1.000) <0-00:00:00> ({'r_t':    -0.5228, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:  -238.024 [ 107.582], Avg:  -200.651 (1.000) <0-00:00:06> ({'r_t': -2835.3900, 'eps':     1.0000, 'len':    80.9040, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward:  -219.174 [ 125.600], Avg:  -206.825 (1.000) <0-00:00:13> ({'r_t': -2993.6377, 'eps':     1.0000, 'len':   260.6570, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward:  -165.727 [  48.351], Avg:  -196.550 (1.000) <0-00:00:20> ({'r_t': -3113.2492, 'eps':     1.0000, 'len':   440.2210, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward:  -170.586 [ 100.986], Avg:  -191.358 (1.000) <0-00:00:27> ({'r_t': -3248.3532, 'eps':     1.0000, 'len':   625.2740, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward:  -160.536 [  78.819], Avg:  -186.221 (1.000) <0-00:00:33> ({'r_t': -2983.6356, 'eps':     1.0000, 'len':   807.6720, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward:  -145.991 [ 140.104], Avg:  -180.473 (1.000) <0-00:00:39> ({'r_t': -3079.6037, 'eps':     1.0000, 'len':   991.6800, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward:  -142.324 [  41.528], Avg:  -175.705 (1.000) <0-00:00:47> ({'r_t': -3176.9743, 'eps':     1.0000, 'len':  1172.6460, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward:  -162.307 [  90.635], Avg:  -174.216 (1.000) <0-00:00:54> ({'r_t': -3063.0822, 'eps':     1.0000, 'len':  1347.8270, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward:  -189.538 [ 112.896], Avg:  -175.748 (1.000) <0-00:01:01> ({'r_t': -3135.2138, 'eps':     1.0000, 'len':  1530.3530, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward:  -190.077 [ 104.663], Avg:  -177.051 (1.000) <0-00:01:08> ({'r_t': -3128.9709, 'eps':     1.0000, 'len':  1714.6640, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward:  -165.740 [  97.838], Avg:  -176.108 (1.000) <0-00:01:14> ({'r_t': -2833.1701, 'eps':     1.0000, 'len':  1892.7960, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward:  -203.465 [ 108.274], Avg:  -178.213 (0.001) <0-00:01:53> ({'r_t': -3023.9042, 'eps':     0.0005, 'len':  2072.7670, 'dyn_loss': 15230.6133, 'dot_loss':   193.3833, 'ddot_loss':    21.5157, 'rew_loss':    17.3337, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   13000, Reward:  -202.007 [  95.905], Avg:  -179.912 (0.500) <0-00:02:32> ({'r_t': -2361.3976, 'eps':     0.5005, 'len':  2254.7140, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   14000, Reward:  -231.224 [  91.855], Avg:  -183.333 (0.001) <0-00:03:20> ({'r_t': -2252.4264, 'eps':     0.0005, 'len':  2426.0360, 'dyn_loss':   204.2581, 'dot_loss':    23.2554, 'ddot_loss':     8.0089, 'rew_loss':    15.2129, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   15000, Reward:  -167.785 [ 131.829], Avg:  -182.361 (0.500) <0-00:03:58> ({'r_t': -2418.5422, 'eps':     0.5005, 'len':  2607.3070, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   16000, Reward:  -268.719 [ 116.066], Avg:  -187.441 (0.001) <0-00:04:46> ({'r_t': -2488.4579, 'eps':     0.0005, 'len':  2789.2550, 'dyn_loss':    82.5045, 'dot_loss':    11.4774, 'ddot_loss':     4.6033, 'rew_loss':    13.8901, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   17000, Reward:  -253.081 [ 107.982], Avg:  -191.088 (0.500) <0-00:05:23> ({'r_t': -2584.4978, 'eps':     0.5005, 'len':  2973.4650, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   18000, Reward:  -235.805 [  85.850], Avg:  -193.441 (0.001) <0-00:06:11> ({'r_t': -2595.7286, 'eps':     0.0005, 'len':  3164.1870, 'dyn_loss':    47.7396, 'dot_loss':     7.1830, 'ddot_loss':     3.1253, 'rew_loss':    13.9877, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   19000, Reward:  -231.867 [ 141.671], Avg:  -195.363 (0.500) <0-00:06:49> ({'r_t': -2902.2418, 'eps':     0.5005, 'len':  3353.8560, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   20000, Reward:  -208.637 [ 100.108], Avg:  -195.995 (0.001) <0-00:07:37> ({'r_t': -2623.5269, 'eps':     0.0005, 'len':  3542.8010, 'dyn_loss':    32.6083, 'dot_loss':     5.1189, 'ddot_loss':     2.3507, 'rew_loss':    13.6851, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   21000, Reward:  -238.780 [  82.893], Avg:  -197.940 (0.500) <0-00:08:14> ({'r_t': -3022.4736, 'eps':     0.5005, 'len':  3730.6490, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   22000, Reward:  -305.855 [  93.700], Avg:  -202.632 (0.001) <0-00:09:01> ({'r_t': -2591.7060, 'eps':     0.0005, 'len':  3922.9510, 'dyn_loss':    24.2924, 'dot_loss':     3.9016, 'ddot_loss':     1.8672, 'rew_loss':    13.9895, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   23000, Reward:  -253.954 [ 122.329], Avg:  -204.770 (0.500) <0-00:09:38> ({'r_t': -3309.3360, 'eps':     0.5005, 'len':  4108.0530, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   24000, Reward:  -299.561 [  96.456], Avg:  -208.562 (0.001) <0-00:10:24> ({'r_t': -2434.6060, 'eps':     0.0005, 'len':  4295.8900, 'dyn_loss':    19.1956, 'dot_loss':     3.1174, 'ddot_loss':     1.5542, 'rew_loss':    14.7490, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   25000, Reward:  -221.852 [ 128.541], Avg:  -209.073 (0.500) <0-00:11:01> ({'r_t': -3067.9530, 'eps':     0.5005, 'len':  4479.1460, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   26000, Reward:  -243.460 [  71.102], Avg:  -210.346 (0.001) <0-00:11:47> ({'r_t': -2512.0679, 'eps':     0.0005, 'len':  4667.2570, 'dyn_loss':    15.7468, 'dot_loss':     2.5768, 'ddot_loss':     1.3164, 'rew_loss':    13.0515, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   27000, Reward:  -257.247 [  80.344], Avg:  -212.021 (0.500) <0-00:12:24> ({'r_t': -3267.2410, 'eps':     0.5005, 'len':  4847.2440, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   28000, Reward:  -311.613 [ 121.210], Avg:  -215.456 (0.001) <0-00:13:10> ({'r_t': -2545.1655, 'eps':     0.0005, 'len':  5035.8900, 'dyn_loss':    13.1851, 'dot_loss':     2.1688, 'ddot_loss':     1.1352, 'rew_loss':    11.1353, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   29000, Reward:  -282.603 [ 135.266], Avg:  -217.694 (0.500) <0-00:13:47> ({'r_t': -3401.0240, 'eps':     0.5005, 'len':  5219.9020, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   30000, Reward:  -331.661 [ 105.107], Avg:  -221.370 (0.001) <0-00:14:33> ({'r_t': -2674.2746, 'eps':     0.0005, 'len':  5401.8190, 'dyn_loss':    11.4644, 'dot_loss':     1.8807, 'ddot_loss':     1.0075, 'rew_loss':    11.7698, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   31000, Reward:  -338.849 [ 114.292], Avg:  -225.041 (0.500) <0-00:15:10> ({'r_t': -3831.8229, 'eps':     0.5005, 'len':  5587.1550, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   32000, Reward:  -313.851 [ 104.294], Avg:  -227.733 (0.001) <0-00:15:56> ({'r_t': -2688.4718, 'eps':     0.0005, 'len':  5774.0470, 'dyn_loss':     9.9026, 'dot_loss':     1.6281, 'ddot_loss':     0.8936, 'rew_loss':    10.8042, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   33000, Reward:  -341.204 [ 107.913], Avg:  -231.070 (0.500) <0-00:16:32> ({'r_t': -4385.9193, 'eps':     0.5005, 'len':  5959.5470, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   34000, Reward:  -340.650 [  79.154], Avg:  -234.201 (0.001) <0-00:17:18> ({'r_t': -2686.5336, 'eps':     0.0005, 'len':  6154.0030, 'dyn_loss':     8.8488, 'dot_loss':     1.4445, 'ddot_loss':     0.8112, 'rew_loss':    10.8552, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   35000, Reward:  -264.624 [ 144.414], Avg:  -235.046 (0.500) <0-00:17:55> ({'r_t': -3952.3557, 'eps':     0.5005, 'len':  6334.8650, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   36000, Reward:  -347.471 [  84.542], Avg:  -238.085 (0.001) <0-00:18:40> ({'r_t': -2758.3510, 'eps':     0.0005, 'len':  6519.1580, 'dyn_loss':     7.8936, 'dot_loss':     1.2867, 'ddot_loss':     0.7390, 'rew_loss':    11.4803, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   37000, Reward:  -314.842 [  88.565], Avg:  -240.104 (0.500) <0-00:19:17> ({'r_t': -4151.6051, 'eps':     0.5005, 'len':  6708.5860, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   38000, Reward:  -359.847 [ 128.305], Avg:  -243.175 (0.001) <0-00:20:02> ({'r_t': -2850.3265, 'eps':     0.0005, 'len':  6905.7390, 'dyn_loss':     7.0969, 'dot_loss':     1.1530, 'ddot_loss':     0.6752, 'rew_loss':    10.3629, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   39000, Reward:  -321.050 [  89.174], Avg:  -245.122 (0.500) <0-00:20:38> ({'r_t': -4177.9105, 'eps':     0.5005, 'len':  7098.8520, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   40000, Reward:  -315.262 [ 100.956], Avg:  -246.832 (0.001) <0-00:21:24> ({'r_t': -2707.2939, 'eps':     0.0005, 'len':  7289.5620, 'dyn_loss':     6.4201, 'dot_loss':     1.0385, 'ddot_loss':     0.6210, 'rew_loss':    10.4900, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   41000, Reward:  -338.338 [ 104.336], Avg:  -249.011 (0.500) <0-00:22:09> ({'r_t': -3369.9013, 'eps':     0.5005, 'len':  7468.0900, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   42000, Reward:  -335.579 [ 113.205], Avg:  -251.024 (0.001) <0-00:23:23> ({'r_t': -2398.3332, 'eps':     0.0005, 'len':  7640.9220, 'dyn_loss':     5.8734, 'dot_loss':     0.9476, 'ddot_loss':     0.5771, 'rew_loss':     9.9945, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   43000, Reward:  -283.084 [ 116.543], Avg:  -251.753 (0.500) <0-00:24:48> ({'r_t': -3814.5615, 'eps':     0.5005, 'len':  7821.3120, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   44000, Reward:  -279.703 [ 110.869], Avg:  -252.374 (0.001) <0-00:26:23> ({'r_t': -2424.1871, 'eps':     0.0005, 'len':  8003.3510, 'dyn_loss':     5.3577, 'dot_loss':     0.8592, 'ddot_loss':     0.5347, 'rew_loss':     9.8457, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   45000, Reward:  -306.757 [ 107.476], Avg:  -253.556 (0.500) <0-00:27:49> ({'r_t': -2280.9287, 'eps':     0.5005, 'len':  8165.8800, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   46000, Reward:  -257.737 [ 148.767], Avg:  -253.645 (0.001) <0-00:29:29> ({'r_t': -2093.3460, 'eps':     0.0005, 'len':  8316.3050, 'dyn_loss':     4.8756, 'dot_loss':     0.7834, 'ddot_loss':     0.4979, 'rew_loss':     9.5800, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   47000, Reward:  -238.062 [ 105.591], Avg:  -253.321 (0.500) <0-00:30:53> ({'r_t': -1985.9289, 'eps':     0.5005, 'len':  8470.3850, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   48000, Reward:  -332.850 [ 141.152], Avg:  -254.944 (0.001) <0-00:32:40> ({'r_t': -2067.1495, 'eps':     0.0005, 'len':  8612.6780, 'dyn_loss':     4.5018, 'dot_loss':     0.7188, 'ddot_loss':     0.4750, 'rew_loss':    10.0441, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   49000, Reward:  -258.137 [ 128.153], Avg:  -255.008 (0.500) <0-00:34:03> ({'r_t': -2088.5502, 'eps':     0.5005, 'len':  8758.1660, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   50000, Reward:  -288.115 [ 129.497], Avg:  -255.657 (0.001) <0-00:35:44> ({'r_t': -2132.0009, 'eps':     0.0005, 'len':  8895.0240, 'dyn_loss':     4.0768, 'dot_loss':     0.6510, 'ddot_loss':     0.4301, 'rew_loss':     9.0141, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   51000, Reward:  -267.871 [ 107.632], Avg:  -255.892 (0.500) <0-00:37:02> ({'r_t': -1830.3045, 'eps':     0.5005, 'len':  9030.1250, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   52000, Reward:  -260.860 [ 119.686], Avg:  -255.985 (0.001) <0-00:38:46> ({'r_t': -2186.3988, 'eps':     0.0005, 'len':  9159.4910, 'dyn_loss':     3.7474, 'dot_loss':     0.5942, 'ddot_loss':     0.4019, 'rew_loss':     8.6892, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   53000, Reward:  -237.596 [ 144.843], Avg:  -255.645 (0.500) <0-00:40:21> ({'r_t': -1778.1022, 'eps':     0.5005, 'len':  9300.8190, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   54000, Reward:  -326.685 [ 123.945], Avg:  -256.936 (0.001) <0-00:42:07> ({'r_t': -2159.7481, 'eps':     0.0005, 'len':  9431.3020, 'dyn_loss':     3.4232, 'dot_loss':     0.5425, 'ddot_loss':     0.3753, 'rew_loss':     8.3788, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   55000, Reward:  -198.020 [ 107.339], Avg:  -255.884 (0.500) <0-00:43:43> ({'r_t': -1661.1996, 'eps':     0.5005, 'len':  9567.4880, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   56000, Reward:  -209.837 [ 112.229], Avg:  -255.077 (0.001) <0-00:45:38> ({'r_t': -2151.5919, 'eps':     0.0005, 'len':  9694.9300, 'dyn_loss':     3.2263, 'dot_loss':     0.4981, 'ddot_loss':     0.3511, 'rew_loss':     8.4572, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   57000, Reward:  -197.620 [ 107.400], Avg:  -254.086 (0.500) <0-00:47:10> ({'r_t': -1838.1543, 'eps':     0.5005, 'len':  9830.5800, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   58000, Reward:  -167.548 [ 101.264], Avg:  -252.619 (0.001) <0-00:48:56> ({'r_t': -2181.3128, 'eps':     0.0005, 'len':  9951.5890, 'dyn_loss':     2.9266, 'dot_loss':     0.4551, 'ddot_loss':     0.3327, 'rew_loss':     9.0183, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   59000, Reward:  -225.757 [ 112.477], Avg:  -252.171 (0.500) <0-00:50:16> ({'r_t': -1611.3784, 'eps':     0.5005, 'len': 10092.4750, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   60000, Reward:  -245.257 [ 143.316], Avg:  -252.058 (0.001) <0-00:52:37> ({'r_t': -2347.6756, 'eps':     0.0005, 'len': 10222.8590, 'dyn_loss':     2.7413, 'dot_loss':     0.4157, 'ddot_loss':     0.3101, 'rew_loss':     8.5480, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   61000, Reward:  -187.696 [ 147.311], Avg:  -251.020 (0.500) <0-00:54:10> ({'r_t': -1601.4307, 'eps':     0.5005, 'len': 10360.8310, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   62000, Reward:  -211.713 [ 144.198], Avg:  -250.396 (0.001) <0-00:57:05> ({'r_t': -2236.1793, 'eps':     0.0005, 'len': 10479.7480, 'dyn_loss':     2.5034, 'dot_loss':     0.3762, 'ddot_loss':     0.2884, 'rew_loss':     8.3209, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   63000, Reward:  -225.203 [ 138.073], Avg:  -250.002 (0.500) <0-00:58:32> ({'r_t': -1769.7960, 'eps':     0.5005, 'len': 10617.4170, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   64000, Reward:  -149.414 [ 146.649], Avg:  -248.455 (0.001) <0-01:00:26> ({'r_t': -2341.0155, 'eps':     0.0005, 'len': 10748.0840, 'dyn_loss':     2.3413, 'dot_loss':     0.3436, 'ddot_loss':     0.2698, 'rew_loss':     8.6460, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   65000, Reward:  -163.594 [ 124.164], Avg:  -247.169 (0.500) <0-01:02:49> ({'r_t': -1313.9912, 'eps':     0.5005, 'len': 10879.6330, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   66000, Reward:  -199.711 [ 156.522], Avg:  -246.461 (0.001) <0-01:05:28> ({'r_t': -2144.7747, 'eps':     0.0005, 'len': 10997.6670, 'dyn_loss':     2.1803, 'dot_loss':     0.3157, 'ddot_loss':     0.2599, 'rew_loss':     8.8041, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   67000, Reward:  -146.342 [  90.509], Avg:  -244.988 (0.500) <0-01:07:05> ({'r_t':  -797.3864, 'eps':     0.5005, 'len': 11113.4810, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   68000, Reward:  -123.943 [ 101.255], Avg:  -243.234 (0.001) <0-01:10:05> ({'r_t': -1907.0605, 'eps':     0.0005, 'len': 11211.4840, 'dyn_loss':     1.9829, 'dot_loss':     0.2862, 'ddot_loss':     0.2437, 'rew_loss':     8.6465, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   69000, Reward:  -187.696 [ 106.800], Avg:  -242.441 (0.500) <0-01:12:39> ({'r_t':  -849.7879, 'eps':     0.5005, 'len': 11329.0220, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   70000, Reward:  -154.413 [  91.543], Avg:  -241.201 (0.001) <0-01:15:37> ({'r_t': -1772.6410, 'eps':     0.0005, 'len': 11429.4020, 'dyn_loss':     1.7846, 'dot_loss':     0.2622, 'ddot_loss':     0.2287, 'rew_loss':     7.8367, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   71000, Reward:  -147.160 [  94.014], Avg:  -239.895 (0.500) <0-01:17:31> ({'r_t':  -782.7370, 'eps':     0.5005, 'len': 11543.4940, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   72000, Reward:   -92.737 [  98.893], Avg:  -237.879 (0.001) <0-01:20:26> ({'r_t': -1772.0408, 'eps':     0.0005, 'len': 11641.5960, 'dyn_loss':     1.6126, 'dot_loss':     0.2402, 'ddot_loss':     0.2161, 'rew_loss':     8.0053, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   73000, Reward:  -202.060 [ 114.647], Avg:  -237.395 (0.500) <0-01:22:12> ({'r_t':  -616.8743, 'eps':     0.5005, 'len': 11753.8270, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   74000, Reward:  -134.057 [  90.924], Avg:  -236.017 (0.001) <0-01:25:16> ({'r_t': -1627.1462, 'eps':     0.0005, 'len': 11841.2580, 'dyn_loss':     1.3965, 'dot_loss':     0.2179, 'ddot_loss':     0.2032, 'rew_loss':     7.9243, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   75000, Reward:  -160.142 [ 105.237], Avg:  -235.019 (0.500) <0-01:27:40> ({'r_t':  -661.4982, 'eps':     0.5005, 'len': 11951.7630, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   76000, Reward:   -92.437 [  79.596], Avg:  -233.167 (0.001) <0-01:29:59> ({'r_t': -1568.9298, 'eps':     0.0005, 'len': 12051.2030, 'dyn_loss':     1.2476, 'dot_loss':     0.1966, 'ddot_loss':     0.1875, 'rew_loss':     7.7519, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   77000, Reward:  -107.421 [  53.771], Avg:  -231.555 (0.500) <0-01:31:29> ({'r_t':  -543.1859, 'eps':     0.5005, 'len': 12166.0770, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   78000, Reward:  -120.421 [  92.279], Avg:  -230.148 (0.001) <0-01:34:25> ({'r_t': -1492.5032, 'eps':     0.0005, 'len': 12253.5640, 'dyn_loss':     1.1159, 'dot_loss':     0.1809, 'ddot_loss':     0.1836, 'rew_loss':     8.2052, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   79000, Reward:  -122.261 [  72.712], Avg:  -228.800 (0.500) <0-01:37:06> ({'r_t':  -436.2735, 'eps':     0.5005, 'len': 12362.1250, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   80000, Reward:   -74.301 [  62.986], Avg:  -226.892 (0.001) <0-01:39:41> ({'r_t': -1471.0567, 'eps':     0.0005, 'len': 12451.9190, 'dyn_loss':     0.9337, 'dot_loss':     0.1621, 'ddot_loss':     0.1691, 'rew_loss':     8.1072, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   81000, Reward:  -115.910 [  95.739], Avg:  -225.539 (0.500) <0-01:41:38> ({'r_t':  -413.3264, 'eps':     0.5005, 'len': 12562.6100, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   82000, Reward:   -66.464 [  88.159], Avg:  -223.622 (0.001) <0-01:44:41> ({'r_t': -1450.3302, 'eps':     0.0005, 'len': 12647.9020, 'dyn_loss':     0.8476, 'dot_loss':     0.1510, 'ddot_loss':     0.1691, 'rew_loss':     8.3906, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   83000, Reward:  -108.260 [  96.268], Avg:  -222.249 (0.500) <0-01:46:55> ({'r_t':  -276.3042, 'eps':     0.5005, 'len': 12752.3340, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   84000, Reward:   -59.886 [  74.696], Avg:  -220.339 (0.001) <0-01:49:53> ({'r_t': -1521.7652, 'eps':     0.0005, 'len': 12831.3200, 'dyn_loss':     0.7371, 'dot_loss':     0.1386, 'ddot_loss':     0.1651, 'rew_loss':     8.6811, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   85000, Reward:   -39.236 [  69.472], Avg:  -218.233 (0.500) <0-01:52:24> ({'r_t':  -289.5827, 'eps':     0.5005, 'len': 12931.8640, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   86000, Reward:   -97.091 [ 100.883], Avg:  -216.840 (0.001) <0-01:55:29> ({'r_t': -1453.6588, 'eps':     0.0005, 'len': 13001.5630, 'dyn_loss':     0.5656, 'dot_loss':     0.1178, 'ddot_loss':     0.1382, 'rew_loss':     7.7131, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   87000, Reward:   -54.180 [  60.308], Avg:  -214.992 (0.500) <0-01:58:05> ({'r_t':  -213.7110, 'eps':     0.5005, 'len': 13099.3600, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   88000, Reward:    -9.348 [  54.210], Avg:  -212.681 (0.001) <0-02:01:10> ({'r_t': -1353.0762, 'eps':     0.0005, 'len': 13164.8120, 'dyn_loss':     0.4925, 'dot_loss':     0.1101, 'ddot_loss':     0.1379, 'rew_loss':     8.1177, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   89000, Reward:   -32.141 [  47.334], Avg:  -210.675 (0.500) <0-02:03:47> ({'r_t':  -151.3380, 'eps':     0.5005, 'len': 13263.8190, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   90000, Reward:    16.225 [  73.722], Avg:  -208.182 (0.001) <0-02:06:59> ({'r_t': -1473.2375, 'eps':     0.0005, 'len': 13342.3500, 'dyn_loss':     0.4129, 'dot_loss':     0.0970, 'ddot_loss':     0.1261, 'rew_loss':     7.9287, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   91000, Reward:    -5.545 [  59.839], Avg:  -205.979 (0.500) <0-02:09:29> ({'r_t':  -121.1696, 'eps':     0.5005, 'len': 13439.3150, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   92000, Reward:    26.594 [ 100.829], Avg:  -203.479 (0.001) <0-02:12:37> ({'r_t': -1473.1183, 'eps':     0.0005, 'len': 13501.7730, 'dyn_loss':     0.3576, 'dot_loss':     0.0891, 'ddot_loss':     0.1221, 'rew_loss':     7.8050, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   93000, Reward:     9.612 [ 124.401], Avg:  -201.212 (0.500) <0-02:15:08> ({'r_t':   -53.1677, 'eps':     0.5005, 'len': 13592.1130, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   94000, Reward:    -9.461 [  66.459], Avg:  -199.193 (0.001) <0-02:18:11> ({'r_t': -1415.0870, 'eps':     0.0005, 'len': 13661.7600, 'dyn_loss':     0.3074, 'dot_loss':     0.0805, 'ddot_loss':     0.1152, 'rew_loss':     8.3721, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   95000, Reward:   -33.247 [  78.026], Avg:  -197.465 (0.500) <0-02:20:46> ({'r_t':   -21.9744, 'eps':     0.5005, 'len': 13757.6510, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   96000, Reward:   -37.910 [  77.465], Avg:  -195.820 (0.001) <0-02:23:57> ({'r_t': -1263.8328, 'eps':     0.0005, 'len': 13825.6920, 'dyn_loss':     0.2850, 'dot_loss':     0.0771, 'ddot_loss':     0.1159, 'rew_loss':     8.2900, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   97000, Reward:   -25.360 [  52.279], Avg:  -194.080 (0.500) <0-02:26:34> ({'r_t':  -112.1308, 'eps':     0.5005, 'len': 13918.1840, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:   98000, Reward:   -10.412 [  74.562], Avg:  -192.225 (0.001) <0-02:29:51> ({'r_t': -1420.4236, 'eps':     0.0005, 'len': 13984.5580, 'dyn_loss':     0.2284, 'dot_loss':     0.0653, 'ddot_loss':     0.1005, 'rew_loss':     7.6449, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:   99000, Reward:   -19.924 [  34.448], Avg:  -190.502 (0.500) <0-02:31:53> ({'r_t':   -67.4710, 'eps':     0.5005, 'len': 14084.8540, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  100000, Reward:   -17.082 [  61.735], Avg:  -188.785 (0.001) <0-02:35:05> ({'r_t': -1391.1391, 'eps':     0.0005, 'len': 14157.2040, 'dyn_loss':     0.2050, 'dot_loss':     0.0603, 'ddot_loss':     0.0963, 'rew_loss':     8.3916, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  101000, Reward:   -49.655 [  84.268], Avg:  -187.421 (0.500) <0-02:37:34> ({'r_t':  -104.8357, 'eps':     0.5005, 'len': 14259.8900, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  102000, Reward:   -40.061 [  42.743], Avg:  -185.990 (0.001) <0-02:40:11> ({'r_t': -1442.0714, 'eps':     0.0005, 'len': 14334.0350, 'dyn_loss':     0.1779, 'dot_loss':     0.0552, 'ddot_loss':     0.0915, 'rew_loss':     8.1424, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  103000, Reward:   -37.776 [  41.732], Avg:  -184.565 (0.500) <0-02:42:00> ({'r_t':  -149.9795, 'eps':     0.5005, 'len': 14448.7140, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  104000, Reward:   -12.500 [ 112.389], Avg:  -182.927 (0.001) <0-02:45:13> ({'r_t': -1239.4523, 'eps':     0.0005, 'len': 14524.8680, 'dyn_loss':     0.1740, 'dot_loss':     0.0554, 'ddot_loss':     0.0961, 'rew_loss':     8.1213, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  105000, Reward:   -21.613 [  40.956], Avg:  -181.405 (0.500) <0-02:47:49> ({'r_t':  -104.0499, 'eps':     0.5005, 'len': 14630.3430, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  106000, Reward:   -10.194 [  58.908], Avg:  -179.805 (0.001) <0-02:51:05> ({'r_t': -1290.2937, 'eps':     0.0005, 'len': 14710.5370, 'dyn_loss':     0.1508, 'dot_loss':     0.0506, 'ddot_loss':     0.0903, 'rew_loss':     8.3900, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  107000, Reward:    -7.104 [  51.300], Avg:  -178.206 (0.500) <0-02:53:32> ({'r_t':  -190.8830, 'eps':     0.5005, 'len': 14827.7970, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  108000, Reward:     4.356 [  62.158], Avg:  -176.531 (0.001) <0-02:56:49> ({'r_t': -1209.1594, 'eps':     0.0005, 'len': 14907.8760, 'dyn_loss':     0.1308, 'dot_loss':     0.0423, 'ddot_loss':     0.0760, 'rew_loss':     7.6525, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  109000, Reward:   -32.092 [  22.643], Avg:  -175.218 (0.500) <0-02:58:12> ({'r_t':   -94.7019, 'eps':     0.5005, 'len': 15014.2730, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  110000, Reward:   -31.330 [  86.819], Avg:  -173.921 (0.001) <0-03:01:05> ({'r_t': -1321.0238, 'eps':     0.0005, 'len': 15093.4530, 'dyn_loss':     0.1285, 'dot_loss':     0.0422, 'ddot_loss':     0.0782, 'rew_loss':     7.6797, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  111000, Reward:   -34.065 [  56.303], Avg:  -172.673 (0.500) <0-03:03:10> ({'r_t':  -148.8217, 'eps':     0.5005, 'len': 15203.4830, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  112000, Reward:    11.761 [  47.917], Avg:  -171.040 (0.001) <0-03:05:55> ({'r_t': -1085.0239, 'eps':     0.0005, 'len': 15282.2370, 'dyn_loss':     0.1022, 'dot_loss':     0.0346, 'ddot_loss':     0.0651, 'rew_loss':     7.4760, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  113000, Reward:    24.237 [  42.419], Avg:  -169.327 (0.500) <0-03:07:57> ({'r_t':   -22.4815, 'eps':     0.5005, 'len': 15380.8650, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  114000, Reward:   -25.920 [  32.682], Avg:  -168.080 (0.001) <0-03:10:49> ({'r_t': -1492.3149, 'eps':     0.0005, 'len': 15445.6100, 'dyn_loss':     0.1123, 'dot_loss':     0.0403, 'ddot_loss':     0.0787, 'rew_loss':     7.9215, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  115000, Reward:   -28.222 [  60.441], Avg:  -166.875 (0.500) <0-03:12:51> ({'r_t':   -66.1728, 'eps':     0.5005, 'len': 15552.0220, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  116000, Reward:    13.613 [  42.226], Avg:  -165.332 (0.001) <0-03:15:43> ({'r_t': -1246.5764, 'eps':     0.0005, 'len': 15608.5100, 'dyn_loss':     0.1092, 'dot_loss':     0.0375, 'ddot_loss':     0.0735, 'rew_loss':     8.4007, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  117000, Reward:   -13.028 [  53.474], Avg:  -164.041 (0.500) <0-03:17:47> ({'r_t':   -46.1827, 'eps':     0.5005, 'len': 15700.6150, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  118000, Reward:   -12.040 [  33.024], Avg:  -162.764 (0.001) <0-03:20:39> ({'r_t': -1118.3625, 'eps':     0.0005, 'len': 15757.9640, 'dyn_loss':     0.1202, 'dot_loss':     0.0444, 'ddot_loss':     0.0894, 'rew_loss':     9.2733, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  119000, Reward:   -24.929 [  55.483], Avg:  -161.615 (0.500) <0-03:22:44> ({'r_t':   -89.6990, 'eps':     0.5005, 'len': 15854.3690, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  120000, Reward:   -35.675 [  87.915], Avg:  -160.575 (0.001) <0-03:25:37> ({'r_t': -1358.7149, 'eps':     0.0005, 'len': 15927.0820, 'dyn_loss':     0.1175, 'dot_loss':     0.0438, 'ddot_loss':     0.0885, 'rew_loss':     9.2530, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  121000, Reward:   -27.980 [  73.758], Avg:  -159.488 (0.500) <0-03:27:39> ({'r_t':  -137.1691, 'eps':     0.5005, 'len': 16029.8470, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  122000, Reward:   -48.174 [  86.977], Avg:  -158.583 (0.001) <0-03:30:32> ({'r_t': -1079.9533, 'eps':     0.0005, 'len': 16093.3450, 'dyn_loss':     0.1084, 'dot_loss':     0.0412, 'ddot_loss':     0.0834, 'rew_loss':     8.8161, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  123000, Reward:   -41.220 [  80.557], Avg:  -157.636 (0.500) <0-03:32:38> ({'r_t':   -53.9298, 'eps':     0.5005, 'len': 16180.5490, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  124000, Reward:   -68.385 [ 104.840], Avg:  -156.922 (0.001) <0-03:35:36> ({'r_t': -1290.2734, 'eps':     0.0005, 'len': 16242.0630, 'dyn_loss':     0.1050, 'dot_loss':     0.0417, 'ddot_loss':     0.0858, 'rew_loss':     8.9031, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  125000, Reward:   -23.611 [  49.670], Avg:  -155.864 (0.500) <0-03:37:45> ({'r_t':   -82.1605, 'eps':     0.5005, 'len': 16339.5760, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  126000, Reward:   -19.676 [  51.880], Avg:  -154.792 (0.001) <0-03:40:42> ({'r_t': -1235.4116, 'eps':     0.0005, 'len': 16400.3280, 'dyn_loss':     0.1147, 'dot_loss':     0.0473, 'ddot_loss':     0.0984, 'rew_loss':    10.2149, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  127000, Reward:   -76.901 [  86.675], Avg:  -154.183 (0.500) <0-03:42:51> ({'r_t':   -18.5044, 'eps':     0.5005, 'len': 16493.2420, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  128000, Reward:   -77.317 [  99.850], Avg:  -153.588 (0.001) <0-03:45:55> ({'r_t': -1365.2412, 'eps':     0.0005, 'len': 16556.5810, 'dyn_loss':     0.1097, 'dot_loss':     0.0460, 'ddot_loss':     0.0966, 'rew_loss':     9.5728, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  129000, Reward:   -73.244 [  81.219], Avg:  -152.970 (0.500) <0-03:48:02> ({'r_t':  -115.4687, 'eps':     0.5005, 'len': 16650.4220, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  130000, Reward:   -87.298 [ 114.974], Avg:  -152.468 (0.001) <0-03:51:01> ({'r_t': -1322.5539, 'eps':     0.0005, 'len': 16714.8200, 'dyn_loss':     0.0940, 'dot_loss':     0.0389, 'ddot_loss':     0.0815, 'rew_loss':     8.8600, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  131000, Reward:   -34.130 [  68.022], Avg:  -151.572 (0.500) <0-03:53:03> ({'r_t':   -57.9008, 'eps':     0.5005, 'len': 16804.8010, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  132000, Reward:   -38.019 [  75.208], Avg:  -150.718 (0.001) <0-03:56:00> ({'r_t': -1386.6017, 'eps':     0.0005, 'len': 16872.2180, 'dyn_loss':     0.1012, 'dot_loss':     0.0444, 'ddot_loss':     0.0938, 'rew_loss':     9.4989, 'lr':     0.0001, 'eps_e':     0.0005, 'lr_e':     0.0001})
Step:  133000, Reward:   -66.237 [  89.673], Avg:  -150.087 (0.500) <0-03:58:03> ({'r_t':  -128.1040, 'eps':     0.5005, 'len': 16971.1900, 'lr':     0.0001, 'eps_e':     0.5005, 'lr_e':     0.0001})
Step:  134000, Reward:   -43.385 [  73.968], Avg:  -149.297 (0.001) <0-04:01:10> ({'r_t': -1159.1550, 'eps':     0.0005, 'len': 17027.0880, 'dyn_loss':     0.1080, 'dot_loss':     0.0477, 'ddot_loss':     0.1002, 'rew_loss':     9.7621, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  135000, Reward:   -33.098 [  72.796], Avg:  -148.443 (0.500) <0-04:03:18> ({'r_t':  -117.3842, 'eps':     0.5005, 'len': 17125.1310, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  136000, Reward:   -10.664 [  55.234], Avg:  -147.437 (0.001) <0-04:06:14> ({'r_t': -1182.7273, 'eps':     0.0005, 'len': 17188.9050, 'dyn_loss':     0.1063, 'dot_loss':     0.0445, 'ddot_loss':     0.0933, 'rew_loss':     9.5551, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  137000, Reward:   -27.062 [  43.180], Avg:  -146.565 (0.500) <0-04:08:21> ({'r_t':  -100.5822, 'eps':     0.5005, 'len': 17278.9420, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  138000, Reward:   -41.173 [  74.864], Avg:  -145.807 (0.001) <0-04:11:19> ({'r_t': -1404.2006, 'eps':     0.0005, 'len': 17350.2150, 'dyn_loss':     0.1089, 'dot_loss':     0.0495, 'ddot_loss':     0.1051, 'rew_loss':    10.0118, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  139000, Reward:   -59.665 [ 108.940], Avg:  -145.191 (0.500) <0-04:12:50> ({'r_t':  -176.0530, 'eps':     0.5005, 'len': 17452.9420, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  140000, Reward:   -29.767 [  69.099], Avg:  -144.373 (0.001) <0-04:14:42> ({'r_t': -1426.3527, 'eps':     0.0005, 'len': 17527.1240, 'dyn_loss':     0.0940, 'dot_loss':     0.0406, 'ddot_loss':     0.0852, 'rew_loss':     9.1157, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  141000, Reward:   -29.461 [  72.836], Avg:  -143.563 (0.500) <0-04:15:59> ({'r_t':  -144.3566, 'eps':     0.5005, 'len': 17623.6090, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  142000, Reward:   -32.658 [  63.203], Avg:  -142.788 (0.001) <0-04:17:53> ({'r_t': -1316.5454, 'eps':     0.0005, 'len': 17690.5700, 'dyn_loss':     0.1137, 'dot_loss':     0.0546, 'ddot_loss':     0.1167, 'rew_loss':    10.3032, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  143000, Reward:   -53.453 [  83.600], Avg:  -142.167 (0.500) <0-04:19:10> ({'r_t':  -139.4749, 'eps':     0.5005, 'len': 17787.7950, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  144000, Reward:   -40.243 [  96.193], Avg:  -141.464 (0.001) <0-04:20:58> ({'r_t': -1244.5049, 'eps':     0.0005, 'len': 17844.8360, 'dyn_loss':     0.0853, 'dot_loss':     0.0397, 'ddot_loss':     0.0848, 'rew_loss':     8.8402, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  145000, Reward:   -45.350 [  93.238], Avg:  -140.806 (0.500) <0-04:22:18> ({'r_t':  -101.6159, 'eps':     0.5005, 'len': 17943.1430, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  146000, Reward:   -10.004 [  81.113], Avg:  -139.916 (0.001) <0-04:24:10> ({'r_t': -1300.5409, 'eps':     0.0005, 'len': 18012.7960, 'dyn_loss':     0.0955, 'dot_loss':     0.0428, 'ddot_loss':     0.0911, 'rew_loss':     9.2060, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  147000, Reward:   -28.808 [  84.376], Avg:  -139.166 (0.500) <0-04:25:26> ({'r_t':   -74.7735, 'eps':     0.5005, 'len': 18114.3050, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  148000, Reward:   -26.943 [  85.628], Avg:  -138.412 (0.001) <0-04:27:12> ({'r_t': -1439.6718, 'eps':     0.0005, 'len': 18176.0850, 'dyn_loss':     0.1024, 'dot_loss':     0.0474, 'ddot_loss':     0.1016, 'rew_loss':     9.7367, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  149000, Reward:   -24.021 [  50.903], Avg:  -137.650 (0.500) <0-04:28:27> ({'r_t':   -91.0187, 'eps':     0.5005, 'len': 18278.5940, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  150000, Reward:    -2.584 [  78.372], Avg:  -136.755 (0.001) <0-04:30:23> ({'r_t': -1196.8525, 'eps':     0.0005, 'len': 18347.8170, 'dyn_loss':     0.1151, 'dot_loss':     0.0576, 'ddot_loss':     0.1239, 'rew_loss':    10.4766, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  151000, Reward:   -26.901 [ 118.576], Avg:  -136.033 (0.500) <0-04:31:47> ({'r_t':   -75.9571, 'eps':     0.5005, 'len': 18445.9520, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  152000, Reward:    13.503 [  97.811], Avg:  -135.055 (0.001) <0-04:33:45> ({'r_t': -1133.1328, 'eps':     0.0005, 'len': 18501.9030, 'dyn_loss':     0.1097, 'dot_loss':     0.0556, 'ddot_loss':     0.1198, 'rew_loss':    10.1122, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  153000, Reward:   -15.940 [  85.549], Avg:  -134.282 (0.500) <0-04:35:18> ({'r_t':     3.2777, 'eps':     0.5005, 'len': 18585.6450, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  154000, Reward:   -49.853 [  78.649], Avg:  -133.737 (0.001) <0-04:37:15> ({'r_t': -1400.0976, 'eps':     0.0005, 'len': 18654.1610, 'dyn_loss':     0.1110, 'dot_loss':     0.0575, 'ddot_loss':     0.1249, 'rew_loss':    10.2931, 'lr':   9.80e-05, 'eps_e':     0.0005, 'lr_e':   9.80e-05})
Step:  155000, Reward:   -40.541 [  37.562], Avg:  -133.140 (0.500) <0-04:38:30> ({'r_t':  -234.8983, 'eps':     0.5005, 'len': 18760.9800, 'lr':   9.80e-05, 'eps_e':     0.5005, 'lr_e':   9.80e-05})
Step:  156000, Reward:   -15.475 [  47.952], Avg:  -132.390 (0.001) <0-04:40:30> ({'r_t': -1153.6189, 'eps':     0.0005, 'len': 18828.4100, 'dyn_loss':     0.1224, 'dot_loss':     0.0645, 'ddot_loss':     0.1401, 'rew_loss':    11.0269, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  157000, Reward:   -21.043 [  70.637], Avg:  -131.686 (0.500) <0-04:41:57> ({'r_t':  -180.9573, 'eps':     0.5005, 'len': 18929.4360, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  158000, Reward:    10.606 [  32.109], Avg:  -130.791 (0.001) <0-04:43:49> ({'r_t': -1464.9324, 'eps':     0.0005, 'len': 18995.7810, 'dyn_loss':     0.1171, 'dot_loss':     0.0609, 'ddot_loss':     0.1325, 'rew_loss':    10.7966, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  159000, Reward:   -56.470 [  75.821], Avg:  -130.326 (0.500) <0-04:45:07> ({'r_t':  -116.0563, 'eps':     0.5005, 'len': 19093.2290, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  160000, Reward:   -13.269 [  76.237], Avg:  -129.599 (0.001) <0-04:47:11> ({'r_t': -1302.7598, 'eps':     0.0005, 'len': 19161.3930, 'dyn_loss':     0.1181, 'dot_loss':     0.0597, 'ddot_loss':     0.1303, 'rew_loss':    10.7800, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  161000, Reward:   -27.282 [  52.376], Avg:  -128.967 (0.500) <0-04:48:33> ({'r_t':   -90.6787, 'eps':     0.5005, 'len': 19262.3810, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  162000, Reward:   -32.955 [  92.215], Avg:  -128.378 (0.001) <0-04:50:25> ({'r_t': -1172.6569, 'eps':     0.0005, 'len': 19329.6190, 'dyn_loss':     0.0957, 'dot_loss':     0.0493, 'ddot_loss':     0.1079, 'rew_loss':     9.7178, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  163000, Reward:   -11.595 [  37.488], Avg:  -127.666 (0.500) <0-04:51:46> ({'r_t':   -59.5167, 'eps':     0.5005, 'len': 19428.8380, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  164000, Reward:   -39.093 [  82.675], Avg:  -127.130 (0.001) <0-04:53:37> ({'r_t': -1351.2820, 'eps':     0.0005, 'len': 19492.1990, 'dyn_loss':     0.1089, 'dot_loss':     0.0539, 'ddot_loss':     0.1177, 'rew_loss':    10.0804, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  165000, Reward:   -14.366 [  50.222], Avg:  -126.450 (0.500) <0-04:54:53> ({'r_t':  -175.3498, 'eps':     0.5005, 'len': 19595.8750, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  166000, Reward:    -3.038 [  50.912], Avg:  -125.711 (0.001) <0-04:56:49> ({'r_t': -1373.3897, 'eps':     0.0005, 'len': 19666.1000, 'dyn_loss':     0.1210, 'dot_loss':     0.0639, 'ddot_loss':     0.1394, 'rew_loss':    10.3611, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  167000, Reward:   -28.960 [  71.382], Avg:  -125.135 (0.500) <0-04:58:07> ({'r_t':   -30.6332, 'eps':     0.5005, 'len': 19763.2450, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  168000, Reward:    -4.521 [  56.142], Avg:  -124.422 (0.001) <0-05:00:01> ({'r_t': -1458.5514, 'eps':     0.0005, 'len': 19830.7150, 'dyn_loss':     0.1095, 'dot_loss':     0.0568, 'ddot_loss':     0.1240, 'rew_loss':     9.8694, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  169000, Reward:   -46.707 [  88.890], Avg:  -123.964 (0.500) <0-05:01:16> ({'r_t':   -89.3533, 'eps':     0.5005, 'len': 19938.0790, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  170000, Reward:   -38.921 [  81.061], Avg:  -123.467 (0.001) <0-05:03:12> ({'r_t': -1247.2313, 'eps':     0.0005, 'len': 20001.4980, 'dyn_loss':     0.0998, 'dot_loss':     0.0514, 'ddot_loss':     0.1120, 'rew_loss':     9.4428, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  171000, Reward:   -37.230 [  63.695], Avg:  -122.966 (0.500) <0-05:04:27> ({'r_t':   -73.3232, 'eps':     0.5005, 'len': 20100.9540, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  172000, Reward:    -2.085 [  88.653], Avg:  -122.267 (0.001) <0-05:06:20> ({'r_t': -1203.6361, 'eps':     0.0005, 'len': 20161.4910, 'dyn_loss':     0.1067, 'dot_loss':     0.0571, 'ddot_loss':     0.1249, 'rew_loss':    10.0657, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  173000, Reward:   -18.254 [ 102.000], Avg:  -121.669 (0.500) <0-05:07:36> ({'r_t':   -62.0668, 'eps':     0.5005, 'len': 20259.9440, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  174000, Reward:   -18.911 [  39.520], Avg:  -121.082 (0.001) <0-05:09:31> ({'r_t': -1393.0809, 'eps':     0.0005, 'len': 20328.3500, 'dyn_loss':     0.1109, 'dot_loss':     0.0600, 'ddot_loss':     0.1319, 'rew_loss':    10.4327, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  175000, Reward:   -41.347 [  72.768], Avg:  -120.629 (0.500) <0-05:10:48> ({'r_t':  -106.5563, 'eps':     0.5005, 'len': 20431.0310, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  176000, Reward:     0.238 [  34.711], Avg:  -119.946 (0.001) <0-05:12:43> ({'r_t': -1493.1592, 'eps':     0.0005, 'len': 20506.7200, 'dyn_loss':     0.1028, 'dot_loss':     0.0545, 'ddot_loss':     0.1200, 'rew_loss':     9.5991, 'lr':   9.60e-05, 'eps_e':     0.0005, 'lr_e':   9.60e-05})
Step:  177000, Reward:   -20.077 [  84.052], Avg:  -119.385 (0.500) <0-05:14:03> ({'r_t':  -157.6516, 'eps':     0.5005, 'len': 20619.3790, 'lr':   9.60e-05, 'eps_e':     0.5005, 'lr_e':   9.60e-05})
Step:  178000, Reward:    -5.420 [  49.964], Avg:  -118.748 (0.001) <0-05:16:26> ({'r_t': -1356.8306, 'eps':     0.0005, 'len': 20685.1170, 'dyn_loss':     0.1101, 'dot_loss':     0.0566, 'ddot_loss':     0.1238, 'rew_loss':     9.8260, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  179000, Reward:   -28.393 [  56.595], Avg:  -118.246 (0.500) <0-05:18:20> ({'r_t':  -140.9042, 'eps':     0.5005, 'len': 20786.7540, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  180000, Reward:   -51.717 [  91.707], Avg:  -117.879 (0.001) <0-05:21:23> ({'r_t': -1296.4974, 'eps':     0.0005, 'len': 20848.3570, 'dyn_loss':     0.1211, 'dot_loss':     0.0649, 'ddot_loss':     0.1424, 'rew_loss':    10.5102, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  181000, Reward:   -37.453 [  80.896], Avg:  -117.437 (0.500) <0-05:23:17> ({'r_t':  -154.0637, 'eps':     0.5005, 'len': 20948.4170, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  182000, Reward:   -17.937 [  66.091], Avg:  -116.893 (0.001) <0-05:26:19> ({'r_t': -1305.1809, 'eps':     0.0005, 'len': 21016.8970, 'dyn_loss':     0.1100, 'dot_loss':     0.0606, 'ddot_loss':     0.1335, 'rew_loss':    10.1790, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  183000, Reward:    -9.776 [  69.993], Avg:  -116.311 (0.500) <0-05:28:14> ({'r_t':  -204.7813, 'eps':     0.5005, 'len': 21126.3180, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  184000, Reward:     4.531 [  62.766], Avg:  -115.658 (0.001) <0-05:31:17> ({'r_t': -1201.9605, 'eps':     0.0005, 'len': 21191.0130, 'dyn_loss':     0.1221, 'dot_loss':     0.0684, 'ddot_loss':     0.1508, 'rew_loss':    11.0894, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  185000, Reward:   -13.759 [  62.204], Avg:  -115.110 (0.500) <0-05:33:17> ({'r_t':  -104.7039, 'eps':     0.5005, 'len': 21290.3100, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  186000, Reward:    -9.825 [  82.936], Avg:  -114.547 (0.001) <0-05:36:50> ({'r_t': -1055.5603, 'eps':     0.0005, 'len': 21348.7350, 'dyn_loss':     0.1292, 'dot_loss':     0.0729, 'ddot_loss':     0.1612, 'rew_loss':    11.0260, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  187000, Reward:    -7.637 [  54.516], Avg:  -113.978 (0.500) <0-05:39:09> ({'r_t':  -119.0908, 'eps':     0.5005, 'len': 21437.2320, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  188000, Reward:     3.172 [  44.650], Avg:  -113.359 (0.001) <0-05:42:42> ({'r_t': -1355.4682, 'eps':     0.0005, 'len': 21507.1310, 'dyn_loss':     0.1202, 'dot_loss':     0.0673, 'ddot_loss':     0.1485, 'rew_loss':    10.7226, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  189000, Reward:   -15.777 [  44.006], Avg:  -112.845 (0.500) <0-05:45:01> ({'r_t':  -129.2856, 'eps':     0.5005, 'len': 21608.7050, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  190000, Reward:   -10.670 [  77.366], Avg:  -112.310 (0.001) <0-05:48:35> ({'r_t': -1294.0288, 'eps':     0.0005, 'len': 21673.6600, 'dyn_loss':     0.1268, 'dot_loss':     0.0713, 'ddot_loss':     0.1577, 'rew_loss':    10.9686, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  191000, Reward:    -9.293 [  56.331], Avg:  -111.773 (0.500) <0-05:50:56> ({'r_t':   -70.2379, 'eps':     0.5005, 'len': 21768.5850, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  192000, Reward:   -21.960 [  35.337], Avg:  -111.308 (0.001) <0-05:54:29> ({'r_t': -1205.3688, 'eps':     0.0005, 'len': 21836.7710, 'dyn_loss':     0.1093, 'dot_loss':     0.0596, 'ddot_loss':     0.1312, 'rew_loss':     9.9901, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  193000, Reward:   -45.693 [  74.649], Avg:  -110.970 (0.500) <0-05:56:50> ({'r_t':  -157.2385, 'eps':     0.5005, 'len': 21942.6270, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  194000, Reward:   -76.781 [ 106.059], Avg:  -110.795 (0.001) <0-06:00:29> ({'r_t': -1138.9374, 'eps':     0.0005, 'len': 22005.4290, 'dyn_loss':     0.1284, 'dot_loss':     0.0735, 'ddot_loss':     0.1630, 'rew_loss':    11.1785, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  195000, Reward:   -19.418 [  78.866], Avg:  -110.328 (0.500) <0-06:02:47> ({'r_t':  -151.3969, 'eps':     0.5005, 'len': 22105.0780, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  196000, Reward:     4.907 [  64.930], Avg:  -109.743 (0.001) <0-06:06:17> ({'r_t': -1339.6436, 'eps':     0.0005, 'len': 22177.9660, 'dyn_loss':     0.1076, 'dot_loss':     0.0578, 'ddot_loss':     0.1274, 'rew_loss':     9.9872, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  197000, Reward:   -40.456 [ 102.250], Avg:  -109.393 (0.500) <0-06:08:30> ({'r_t':  -135.3436, 'eps':     0.5005, 'len': 22279.0280, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  198000, Reward:   -17.655 [  74.273], Avg:  -108.932 (0.001) <0-06:12:04> ({'r_t': -1216.1398, 'eps':     0.0005, 'len': 22346.9230, 'dyn_loss':     0.1273, 'dot_loss':     0.0752, 'ddot_loss':     0.1673, 'rew_loss':    11.4545, 'lr':   9.41e-05, 'eps_e':     0.0005, 'lr_e':   9.41e-05})
Step:  199000, Reward:   -33.536 [  72.768], Avg:  -108.555 (0.500) <0-06:14:20> ({'r_t':  -161.8101, 'eps':     0.5005, 'len': 22441.8150, 'lr':   9.41e-05, 'eps_e':     0.5005, 'lr_e':   9.41e-05})
Step:  200000, Reward:   -42.693 [  83.755], Avg:  -108.228 (0.001) <0-06:17:53> ({'r_t': -1281.4601, 'eps':     0.0005, 'len': 22513.7360, 'dyn_loss':     0.1098, 'dot_loss':     0.0640, 'ddot_loss':     0.1427, 'rew_loss':    10.1446, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  201000, Reward:   -15.975 [  92.783], Avg:  -107.771 (0.500) <0-06:20:10> ({'r_t':  -189.0790, 'eps':     0.5005, 'len': 22618.5860, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  202000, Reward:   -27.211 [  53.697], Avg:  -107.374 (0.001) <0-06:23:45> ({'r_t': -1464.8372, 'eps':     0.0005, 'len': 22697.9720, 'dyn_loss':     0.1156, 'dot_loss':     0.0661, 'ddot_loss':     0.1459, 'rew_loss':    10.8308, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  203000, Reward:   -48.030 [  65.881], Avg:  -107.083 (0.500) <0-06:26:06> ({'r_t':  -196.4888, 'eps':     0.5005, 'len': 22802.0160, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  204000, Reward:   -12.475 [ 110.788], Avg:  -106.622 (0.001) <0-06:29:41> ({'r_t': -1200.5330, 'eps':     0.0005, 'len': 22864.0080, 'dyn_loss':     0.1103, 'dot_loss':     0.0617, 'ddot_loss':     0.1364, 'rew_loss':    10.1648, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  205000, Reward:   -63.514 [  82.820], Avg:  -106.413 (0.500) <0-06:31:58> ({'r_t':   -50.2781, 'eps':     0.5005, 'len': 22954.8190, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  206000, Reward:   -40.533 [  80.611], Avg:  -106.094 (0.001) <0-06:35:37> ({'r_t': -1549.3435, 'eps':     0.0005, 'len': 23028.2720, 'dyn_loss':     0.1138, 'dot_loss':     0.0653, 'ddot_loss':     0.1452, 'rew_loss':    10.1180, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  207000, Reward:   -59.306 [  95.819], Avg:  -105.869 (0.500) <0-06:37:58> ({'r_t':  -128.7898, 'eps':     0.5005, 'len': 23135.6510, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  208000, Reward:   -29.237 [  52.422], Avg:  -105.503 (0.001) <0-06:41:38> ({'r_t': -1301.2522, 'eps':     0.0005, 'len': 23199.7760, 'dyn_loss':     0.1254, 'dot_loss':     0.0731, 'ddot_loss':     0.1617, 'rew_loss':    10.8610, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  209000, Reward:   -45.291 [  79.050], Avg:  -105.216 (0.500) <0-06:43:59> ({'r_t':  -139.1417, 'eps':     0.5005, 'len': 23302.1860, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  210000, Reward:   -18.046 [  66.637], Avg:  -104.803 (0.001) <0-06:47:33> ({'r_t': -1321.7856, 'eps':     0.0005, 'len': 23376.9390, 'dyn_loss':     0.1059, 'dot_loss':     0.0590, 'ddot_loss':     0.1300, 'rew_loss':     9.8078, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  211000, Reward:   -70.122 [  65.115], Avg:  -104.639 (0.500) <0-06:49:49> ({'r_t':  -115.0694, 'eps':     0.5005, 'len': 23480.0090, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  212000, Reward:    13.578 [  83.215], Avg:  -104.084 (0.001) <0-06:53:17> ({'r_t': -1387.7427, 'eps':     0.0005, 'len': 23549.1880, 'dyn_loss':     0.1204, 'dot_loss':     0.0687, 'ddot_loss':     0.1522, 'rew_loss':    10.7156, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  213000, Reward:     1.724 [  67.555], Avg:  -103.590 (0.500) <0-06:55:32> ({'r_t':   -48.1674, 'eps':     0.5005, 'len': 23652.7340, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  214000, Reward:   -31.165 [  37.417], Avg:  -103.253 (0.001) <0-06:59:08> ({'r_t': -1386.8235, 'eps':     0.0005, 'len': 23722.1520, 'dyn_loss':     0.1218, 'dot_loss':     0.0705, 'ddot_loss':     0.1561, 'rew_loss':    10.6611, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  215000, Reward:   -43.347 [  51.871], Avg:  -102.976 (0.500) <0-07:01:23> ({'r_t':  -118.9522, 'eps':     0.5005, 'len': 23831.2050, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  216000, Reward:     3.533 [  81.666], Avg:  -102.485 (0.001) <0-07:04:55> ({'r_t': -1263.5151, 'eps':     0.0005, 'len': 23895.7050, 'dyn_loss':     0.1210, 'dot_loss':     0.0699, 'ddot_loss':     0.1551, 'rew_loss':    10.6588, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  217000, Reward:    -5.884 [  80.349], Avg:  -102.042 (0.500) <0-07:07:11> ({'r_t':   -85.8685, 'eps':     0.5005, 'len': 23996.8490, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  218000, Reward:    -7.301 [  50.132], Avg:  -101.609 (0.001) <0-07:10:56> ({'r_t': -1130.1296, 'eps':     0.0005, 'len': 24066.3630, 'dyn_loss':     0.1345, 'dot_loss':     0.0779, 'ddot_loss':     0.1723, 'rew_loss':    11.1801, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  219000, Reward:   -46.441 [  76.548], Avg:  -101.358 (0.500) <0-07:13:12> ({'r_t':  -135.8784, 'eps':     0.5005, 'len': 24165.1750, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  220000, Reward:   -15.473 [  70.787], Avg:  -100.970 (0.001) <0-07:16:43> ({'r_t': -1377.2856, 'eps':     0.0005, 'len': 24233.7610, 'dyn_loss':     0.1149, 'dot_loss':     0.0634, 'ddot_loss':     0.1392, 'rew_loss':    10.1651, 'lr':   9.22e-05, 'eps_e':     0.0005, 'lr_e':   9.22e-05})
Step:  221000, Reward:   -46.770 [  58.248], Avg:  -100.726 (0.500) <0-07:19:01> ({'r_t':   -89.9732, 'eps':     0.5005, 'len': 24335.2200, 'lr':   9.22e-05, 'eps_e':     0.5005, 'lr_e':   9.22e-05})
Step:  222000, Reward:   -71.797 [  83.250], Avg:  -100.596 (0.001) <0-07:22:41> ({'r_t': -1310.7237, 'eps':     0.0005, 'len': 24401.4280, 'dyn_loss':     0.1045, 'dot_loss':     0.0576, 'ddot_loss':     0.1264, 'rew_loss':     9.5401, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  223000, Reward:   -36.950 [  42.319], Avg:  -100.312 (0.500) <0-07:25:02> ({'r_t':  -120.5263, 'eps':     0.5005, 'len': 24502.8150, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  224000, Reward:   -45.579 [  25.973], Avg:  -100.068 (0.001) <0-07:28:46> ({'r_t': -1195.3312, 'eps':     0.0005, 'len': 24579.4140, 'dyn_loss':     0.1192, 'dot_loss':     0.0666, 'ddot_loss':     0.1472, 'rew_loss':    10.0949, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  225000, Reward:   -38.278 [  74.323], Avg:   -99.795 (0.500) <0-07:31:05> ({'r_t':  -145.8754, 'eps':     0.5005, 'len': 24684.1100, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  226000, Reward:   -24.412 [  57.227], Avg:   -99.463 (0.001) <0-07:34:40> ({'r_t': -1425.7486, 'eps':     0.0005, 'len': 24765.4030, 'dyn_loss':     0.1185, 'dot_loss':     0.0687, 'ddot_loss':     0.1521, 'rew_loss':    10.5309, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  227000, Reward:   -80.474 [  86.516], Avg:   -99.380 (0.500) <0-07:36:30> ({'r_t':  -131.2085, 'eps':     0.5005, 'len': 24880.1670, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  228000, Reward:    -5.350 [  69.894], Avg:   -98.969 (0.001) <0-07:40:02> ({'r_t': -1322.7730, 'eps':     0.0005, 'len': 24955.4380, 'dyn_loss':     0.1028, 'dot_loss':     0.0567, 'ddot_loss':     0.1250, 'rew_loss':     9.6708, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  229000, Reward:   -60.872 [  36.723], Avg:   -98.803 (0.500) <0-07:41:29> ({'r_t':  -165.4973, 'eps':     0.5005, 'len': 25062.8930, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  230000, Reward:   -48.185 [  57.820], Avg:   -98.584 (0.001) <0-07:45:01> ({'r_t': -1483.3971, 'eps':     0.0005, 'len': 25136.5410, 'dyn_loss':     0.1138, 'dot_loss':     0.0649, 'ddot_loss':     0.1432, 'rew_loss':    10.1352, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  231000, Reward:   -44.990 [  54.311], Avg:   -98.353 (0.500) <0-07:47:19> ({'r_t':  -127.2779, 'eps':     0.5005, 'len': 25236.3400, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  232000, Reward:   -34.650 [  58.862], Avg:   -98.080 (0.001) <0-07:51:03> ({'r_t': -1305.2701, 'eps':     0.0005, 'len': 25301.8630, 'dyn_loss':     0.1229, 'dot_loss':     0.0711, 'ddot_loss':     0.1573, 'rew_loss':    10.7516, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  233000, Reward:   -20.011 [  70.013], Avg:   -97.746 (0.500) <0-07:53:18> ({'r_t':  -218.1607, 'eps':     0.5005, 'len': 25411.3960, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  234000, Reward:   -31.150 [  92.216], Avg:   -97.463 (0.001) <0-07:56:55> ({'r_t': -1367.8211, 'eps':     0.0005, 'len': 25488.4560, 'dyn_loss':     0.1204, 'dot_loss':     0.0695, 'ddot_loss':     0.1542, 'rew_loss':    10.5641, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  235000, Reward:   -41.093 [  59.256], Avg:   -97.224 (0.500) <0-07:59:08> ({'r_t':   -73.0882, 'eps':     0.5005, 'len': 25591.8660, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  236000, Reward:   -15.713 [  58.480], Avg:   -96.880 (0.001) <0-08:02:44> ({'r_t': -1315.1573, 'eps':     0.0005, 'len': 25657.6970, 'dyn_loss':     0.1230, 'dot_loss':     0.0729, 'ddot_loss':     0.1618, 'rew_loss':    10.7923, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  237000, Reward:   -18.043 [  44.795], Avg:   -96.549 (0.500) <0-08:05:02> ({'r_t':  -110.0029, 'eps':     0.5005, 'len': 25767.6990, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  238000, Reward:   -39.281 [  59.886], Avg:   -96.309 (0.001) <0-08:08:43> ({'r_t': -1273.2553, 'eps':     0.0005, 'len': 25845.3750, 'dyn_loss':     0.1210, 'dot_loss':     0.0676, 'ddot_loss':     0.1494, 'rew_loss':    10.4818, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  239000, Reward:   -27.983 [  32.766], Avg:   -96.025 (0.500) <0-08:11:04> ({'r_t':  -204.9596, 'eps':     0.5005, 'len': 25958.0510, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  240000, Reward:   -28.252 [  34.445], Avg:   -95.743 (0.001) <0-08:14:46> ({'r_t': -1231.8930, 'eps':     0.0005, 'len': 26028.5950, 'dyn_loss':     0.1163, 'dot_loss':     0.0660, 'ddot_loss':     0.1451, 'rew_loss':    10.0376, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  241000, Reward:   -29.679 [  52.996], Avg:   -95.470 (0.500) <0-08:17:03> ({'r_t':  -218.9483, 'eps':     0.5005, 'len': 26140.1410, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  242000, Reward:   -43.664 [  55.122], Avg:   -95.257 (0.001) <0-08:20:42> ({'r_t': -1353.4496, 'eps':     0.0005, 'len': 26219.7100, 'dyn_loss':     0.1226, 'dot_loss':     0.0698, 'ddot_loss':     0.1540, 'rew_loss':    10.2292, 'lr':   9.04e-05, 'eps_e':     0.0005, 'lr_e':   9.04e-05})
Step:  243000, Reward:   -27.765 [  46.903], Avg:   -94.981 (0.500) <0-08:23:04> ({'r_t':  -157.3192, 'eps':     0.5005, 'len': 26328.0730, 'lr':   9.04e-05, 'eps_e':     0.5005, 'lr_e':   9.04e-05})
Step:  244000, Reward:   -57.518 [  64.998], Avg:   -94.828 (0.001) <0-08:25:53> ({'r_t': -1568.1835, 'eps':     0.0005, 'len': 26408.1800, 'dyn_loss':     0.1173, 'dot_loss':     0.0663, 'ddot_loss':     0.1460, 'rew_loss':     9.9826, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  245000, Reward:   -37.424 [  61.841], Avg:   -94.594 (0.500) <0-08:28:12> ({'r_t':  -212.6024, 'eps':     0.5005, 'len': 26528.6360, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  246000, Reward:   -34.470 [  64.165], Avg:   -94.351 (0.001) <0-08:31:58> ({'r_t': -1286.5427, 'eps':     0.0005, 'len': 26607.4040, 'dyn_loss':     0.1216, 'dot_loss':     0.0696, 'ddot_loss':     0.1537, 'rew_loss':    10.2637, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  247000, Reward:    -4.308 [  54.475], Avg:   -93.988 (0.500) <0-08:34:20> ({'r_t':  -170.0491, 'eps':     0.5005, 'len': 26718.8220, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  248000, Reward:   -28.189 [  47.595], Avg:   -93.724 (0.001) <0-08:37:55> ({'r_t': -1197.4129, 'eps':     0.0005, 'len': 26789.5970, 'dyn_loss':     0.1150, 'dot_loss':     0.0654, 'ddot_loss':     0.1443, 'rew_loss':     9.9072, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  249000, Reward:   -48.905 [  51.805], Avg:   -93.544 (0.500) <0-08:40:14> ({'r_t':  -256.7976, 'eps':     0.5005, 'len': 26900.7780, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  250000, Reward:   -35.292 [  32.263], Avg:   -93.312 (0.001) <0-08:43:54> ({'r_t': -1275.5414, 'eps':     0.0005, 'len': 26980.7570, 'dyn_loss':     0.1108, 'dot_loss':     0.0607, 'ddot_loss':     0.1335, 'rew_loss':     9.3820, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  251000, Reward:   -15.741 [  37.602], Avg:   -93.004 (0.500) <0-08:46:15> ({'r_t':  -158.6184, 'eps':     0.5005, 'len': 27079.8080, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  252000, Reward:   -30.855 [  59.790], Avg:   -92.759 (0.001) <0-08:49:52> ({'r_t': -1280.2300, 'eps':     0.0005, 'len': 27149.5890, 'dyn_loss':     0.1161, 'dot_loss':     0.0657, 'ddot_loss':     0.1446, 'rew_loss':    10.0842, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  253000, Reward:   -18.714 [  41.260], Avg:   -92.467 (0.500) <0-08:52:08> ({'r_t':  -167.8955, 'eps':     0.5005, 'len': 27256.6620, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  254000, Reward:   -61.376 [  74.445], Avg:   -92.345 (0.001) <0-08:55:47> ({'r_t': -1094.3691, 'eps':     0.0005, 'len': 27329.9880, 'dyn_loss':     0.1125, 'dot_loss':     0.0641, 'ddot_loss':     0.1416, 'rew_loss':     9.6504, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  255000, Reward:   -28.450 [  57.665], Avg:   -92.096 (0.500) <0-08:58:00> ({'r_t':  -235.5974, 'eps':     0.5005, 'len': 27427.1370, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  256000, Reward:   -11.904 [  65.580], Avg:   -91.784 (0.001) <0-09:01:43> ({'r_t': -1392.3662, 'eps':     0.0005, 'len': 27508.1800, 'dyn_loss':     0.1197, 'dot_loss':     0.0698, 'ddot_loss':     0.1538, 'rew_loss':    10.2632, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  257000, Reward:   -34.977 [  58.923], Avg:   -91.563 (0.500) <0-09:04:00> ({'r_t':  -251.6650, 'eps':     0.5005, 'len': 27632.5850, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  258000, Reward:   -20.661 [  58.716], Avg:   -91.290 (0.001) <0-09:07:32> ({'r_t': -1511.8806, 'eps':     0.0005, 'len': 27728.9610, 'dyn_loss':     0.1167, 'dot_loss':     0.0665, 'ddot_loss':     0.1467, 'rew_loss':     9.8869, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  259000, Reward:   -29.042 [  65.533], Avg:   -91.050 (0.500) <0-09:09:44> ({'r_t':  -140.1593, 'eps':     0.5005, 'len': 27842.4290, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  260000, Reward:   -24.871 [  68.833], Avg:   -90.797 (0.001) <0-09:13:19> ({'r_t': -1358.2695, 'eps':     0.0005, 'len': 27916.6510, 'dyn_loss':     0.1155, 'dot_loss':     0.0639, 'ddot_loss':     0.1404, 'rew_loss':     9.5101, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  261000, Reward:   -22.926 [  54.215], Avg:   -90.538 (0.500) <0-09:15:32> ({'r_t':  -139.0255, 'eps':     0.5005, 'len': 28015.8700, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  262000, Reward:   -41.186 [  60.821], Avg:   -90.350 (0.001) <0-09:19:04> ({'r_t': -1460.2204, 'eps':     0.0005, 'len': 28088.2450, 'dyn_loss':     0.1222, 'dot_loss':     0.0690, 'ddot_loss':     0.1517, 'rew_loss':    10.3356, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  263000, Reward:   -30.274 [  62.111], Avg:   -90.122 (0.500) <0-09:21:20> ({'r_t':  -223.8349, 'eps':     0.5005, 'len': 28202.3780, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  264000, Reward:   -20.814 [  71.487], Avg:   -89.861 (0.001) <0-09:25:00> ({'r_t': -1352.1955, 'eps':     0.0005, 'len': 28291.3590, 'dyn_loss':     0.1267, 'dot_loss':     0.0751, 'ddot_loss':     0.1661, 'rew_loss':    10.3670, 'lr':   8.86e-05, 'eps_e':     0.0005, 'lr_e':   8.86e-05})
Step:  265000, Reward:   -46.262 [  63.667], Avg:   -89.697 (0.500) <0-09:27:18> ({'r_t':  -139.6549, 'eps':     0.5005, 'len': 28407.3930, 'lr':   8.86e-05, 'eps_e':     0.5005, 'lr_e':   8.86e-05})
Step:  266000, Reward:   -22.609 [  45.929], Avg:   -89.446 (0.001) <0-09:30:55> ({'r_t': -1243.5802, 'eps':     0.0005, 'len': 28479.4130, 'dyn_loss':     0.1109, 'dot_loss':     0.0618, 'ddot_loss':     0.1365, 'rew_loss':     9.6951, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  267000, Reward:   -33.953 [  72.153], Avg:   -89.239 (0.500) <0-09:33:11> ({'r_t':  -173.7392, 'eps':     0.5005, 'len': 28586.0670, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  268000, Reward:   -35.351 [  62.056], Avg:   -89.038 (0.001) <0-09:36:50> ({'r_t': -1282.5353, 'eps':     0.0005, 'len': 28654.1830, 'dyn_loss':     0.1150, 'dot_loss':     0.0666, 'ddot_loss':     0.1473, 'rew_loss':     9.8323, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  269000, Reward:   -52.388 [  83.839], Avg:   -88.903 (0.500) <0-09:39:08> ({'r_t':  -185.6555, 'eps':     0.5005, 'len': 28757.6220, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  270000, Reward:   -19.574 [  66.525], Avg:   -88.647 (0.001) <0-09:42:49> ({'r_t': -1387.1216, 'eps':     0.0005, 'len': 28841.0480, 'dyn_loss':     0.1233, 'dot_loss':     0.0715, 'ddot_loss':     0.1577, 'rew_loss':    10.3342, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  271000, Reward:   -59.617 [  38.930], Avg:   -88.540 (0.500) <0-09:44:09> ({'r_t':  -172.5858, 'eps':     0.5005, 'len': 28947.9600, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  272000, Reward:   -22.351 [  67.258], Avg:   -88.298 (0.001) <0-09:47:53> ({'r_t': -1335.1291, 'eps':     0.0005, 'len': 29016.3930, 'dyn_loss':     0.1171, 'dot_loss':     0.0654, 'ddot_loss':     0.1439, 'rew_loss':     9.8032, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  273000, Reward:   -19.392 [  59.352], Avg:   -88.046 (0.500) <0-09:50:08> ({'r_t':  -105.5197, 'eps':     0.5005, 'len': 29125.4180, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  274000, Reward:   -22.196 [  57.333], Avg:   -87.807 (0.001) <0-09:53:59> ({'r_t': -1231.8983, 'eps':     0.0005, 'len': 29192.9960, 'dyn_loss':     0.1243, 'dot_loss':     0.0710, 'ddot_loss':     0.1568, 'rew_loss':    10.1724, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  275000, Reward:   -15.177 [  58.569], Avg:   -87.544 (0.500) <0-09:56:13> ({'r_t':  -198.7732, 'eps':     0.5005, 'len': 29300.9060, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  276000, Reward:   -31.997 [  22.088], Avg:   -87.343 (0.001) <0-09:59:05> ({'r_t': -1446.4348, 'eps':     0.0005, 'len': 29383.0420, 'dyn_loss':     0.1243, 'dot_loss':     0.0735, 'ddot_loss':     0.1630, 'rew_loss':    10.0200, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  277000, Reward:   -35.339 [  28.191], Avg:   -87.156 (0.500) <0-10:00:27> ({'r_t':  -175.3673, 'eps':     0.5005, 'len': 29499.4630, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  278000, Reward:   -26.183 [  65.756], Avg:   -86.937 (0.001) <0-10:04:10> ({'r_t': -1294.0174, 'eps':     0.0005, 'len': 29578.1010, 'dyn_loss':     0.1204, 'dot_loss':     0.0698, 'ddot_loss':     0.1543, 'rew_loss':     9.7796, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  279000, Reward:   -74.801 [  68.218], Avg:   -86.894 (0.500) <0-10:06:27> ({'r_t':  -246.5205, 'eps':     0.5005, 'len': 29687.4790, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  280000, Reward:    16.036 [ 110.659], Avg:   -86.528 (0.001) <0-10:10:05> ({'r_t': -1323.9292, 'eps':     0.0005, 'len': 29772.2490, 'dyn_loss':     0.1113, 'dot_loss':     0.0612, 'ddot_loss':     0.1348, 'rew_loss':     9.2665, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  281000, Reward:     6.894 [  87.733], Avg:   -86.196 (0.500) <0-10:12:23> ({'r_t':  -190.6648, 'eps':     0.5005, 'len': 29881.4290, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  282000, Reward:    13.558 [  65.120], Avg:   -85.844 (0.001) <0-10:16:06> ({'r_t': -1405.8099, 'eps':     0.0005, 'len': 29961.0630, 'dyn_loss':     0.1113, 'dot_loss':     0.0647, 'ddot_loss':     0.1435, 'rew_loss':     9.6161, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  283000, Reward:    -6.366 [  65.372], Avg:   -85.564 (0.500) <0-10:18:25> ({'r_t':  -108.0403, 'eps':     0.5005, 'len': 30068.1610, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  284000, Reward:   -27.368 [  35.368], Avg:   -85.360 (0.001) <0-10:22:08> ({'r_t': -1171.3540, 'eps':     0.0005, 'len': 30124.8430, 'dyn_loss':     0.1115, 'dot_loss':     0.0635, 'ddot_loss':     0.1404, 'rew_loss':     9.4462, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  285000, Reward:   -45.018 [  86.460], Avg:   -85.219 (0.500) <0-10:24:26> ({'r_t':  -146.7496, 'eps':     0.5005, 'len': 30231.2090, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  286000, Reward:   -17.141 [  46.418], Avg:   -84.982 (0.001) <0-10:28:14> ({'r_t': -1286.3964, 'eps':     0.0005, 'len': 30304.4920, 'dyn_loss':     0.1169, 'dot_loss':     0.0649, 'ddot_loss':     0.1432, 'rew_loss':     9.4994, 'lr':   8.68e-05, 'eps_e':     0.0005, 'lr_e':   8.68e-05})
Step:  287000, Reward:   -10.141 [  56.511], Avg:   -84.722 (0.500) <0-10:30:30> ({'r_t':  -158.5094, 'eps':     0.5005, 'len': 30416.1880, 'lr':   8.68e-05, 'eps_e':     0.5005, 'lr_e':   8.68e-05})
Step:  288000, Reward:   -24.867 [  67.408], Avg:   -84.515 (0.001) <0-10:34:08> ({'r_t': -1228.9594, 'eps':     0.0005, 'len': 30487.8120, 'dyn_loss':     0.1114, 'dot_loss':     0.0619, 'ddot_loss':     0.1365, 'rew_loss':     9.2903, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  289000, Reward:   -30.644 [  78.245], Avg:   -84.329 (0.500) <0-10:36:27> ({'r_t':  -203.4640, 'eps':     0.5005, 'len': 30599.9110, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  290000, Reward:   -65.239 [  87.911], Avg:   -84.263 (0.001) <0-10:40:15> ({'r_t': -1291.8479, 'eps':     0.0005, 'len': 30684.6440, 'dyn_loss':     0.1225, 'dot_loss':     0.0722, 'ddot_loss':     0.1599, 'rew_loss':     9.9983, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  291000, Reward:   -45.218 [  70.875], Avg:   -84.130 (0.500) <0-10:41:57> ({'r_t':  -174.2453, 'eps':     0.5005, 'len': 30795.1590, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  292000, Reward:    11.220 [  61.685], Avg:   -83.804 (0.001) <0-10:45:41> ({'r_t': -1265.0346, 'eps':     0.0005, 'len': 30876.0770, 'dyn_loss':     0.1142, 'dot_loss':     0.0632, 'ddot_loss':     0.1385, 'rew_loss':     9.7399, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  293000, Reward:   -44.796 [  37.350], Avg:   -83.671 (0.500) <0-10:48:00> ({'r_t':  -169.1655, 'eps':     0.5005, 'len': 30985.8620, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  294000, Reward:   -17.754 [  74.409], Avg:   -83.448 (0.001) <0-10:51:52> ({'r_t': -1285.2148, 'eps':     0.0005, 'len': 31064.5370, 'dyn_loss':     0.1222, 'dot_loss':     0.0713, 'ddot_loss':     0.1575, 'rew_loss':     9.8511, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  295000, Reward:    -5.363 [  69.418], Avg:   -83.184 (0.500) <0-10:54:10> ({'r_t':  -214.7480, 'eps':     0.5005, 'len': 31176.9470, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  296000, Reward:   -43.776 [  57.899], Avg:   -83.052 (0.001) <0-10:57:56> ({'r_t': -1227.0973, 'eps':     0.0005, 'len': 31252.3740, 'dyn_loss':     0.1125, 'dot_loss':     0.0653, 'ddot_loss':     0.1447, 'rew_loss':     9.1832, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  297000, Reward:   -20.252 [  48.823], Avg:   -82.841 (0.500) <0-11:00:17> ({'r_t':  -106.5523, 'eps':     0.5005, 'len': 31353.6650, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  298000, Reward:    -3.043 [  69.484], Avg:   -82.574 (0.001) <0-11:03:59> ({'r_t': -1346.0291, 'eps':     0.0005, 'len': 31432.3010, 'dyn_loss':     0.1105, 'dot_loss':     0.0603, 'ddot_loss':     0.1324, 'rew_loss':     9.5382, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  299000, Reward:   -12.070 [ 108.062], Avg:   -82.339 (0.500) <0-11:06:15> ({'r_t':  -212.6162, 'eps':     0.5005, 'len': 31543.7210, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  300000, Reward:   -16.845 [  39.254], Avg:   -82.121 (0.001) <0-11:10:01> ({'r_t': -1317.9025, 'eps':     0.0005, 'len': 31621.9830, 'dyn_loss':     0.1080, 'dot_loss':     0.0613, 'ddot_loss':     0.1353, 'rew_loss':     9.1555, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  301000, Reward:   -41.081 [  41.633], Avg:   -81.985 (0.500) <0-11:12:21> ({'r_t':  -110.2032, 'eps':     0.5005, 'len': 31729.1970, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  302000, Reward:   -53.250 [  69.316], Avg:   -81.891 (0.001) <0-11:16:09> ({'r_t': -1257.1560, 'eps':     0.0005, 'len': 31803.4000, 'dyn_loss':     0.1183, 'dot_loss':     0.0695, 'ddot_loss':     0.1538, 'rew_loss':     9.7823, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  303000, Reward:   -64.514 [  25.428], Avg:   -81.833 (0.500) <0-11:17:47> ({'r_t':  -182.0280, 'eps':     0.5005, 'len': 31917.1610, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  304000, Reward:   -40.586 [  56.060], Avg:   -81.698 (0.001) <0-11:20:41> ({'r_t': -1426.2284, 'eps':     0.0005, 'len': 32000.2450, 'dyn_loss':     0.1133, 'dot_loss':     0.0635, 'ddot_loss':     0.1402, 'rew_loss':     9.5729, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  305000, Reward:   -13.027 [  74.256], Avg:   -81.474 (0.500) <0-11:23:03> ({'r_t':  -207.2616, 'eps':     0.5005, 'len': 32119.7850, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  306000, Reward:   -19.881 [  72.843], Avg:   -81.273 (0.001) <0-11:26:50> ({'r_t': -1284.3807, 'eps':     0.0005, 'len': 32210.6830, 'dyn_loss':     0.1161, 'dot_loss':     0.0680, 'ddot_loss':     0.1507, 'rew_loss':     9.4805, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  307000, Reward:   -28.164 [  75.500], Avg:   -81.101 (0.500) <0-11:29:10> ({'r_t':   -72.9184, 'eps':     0.5005, 'len': 32311.0000, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  308000, Reward:   -33.804 [  76.994], Avg:   -80.948 (0.001) <0-11:32:57> ({'r_t': -1364.4433, 'eps':     0.0005, 'len': 32380.6700, 'dyn_loss':     0.1133, 'dot_loss':     0.0636, 'ddot_loss':     0.1405, 'rew_loss':     9.5340, 'lr':   8.51e-05, 'eps_e':     0.0005, 'lr_e':   8.51e-05})
Step:  309000, Reward:   -28.120 [  46.997], Avg:   -80.777 (0.500) <0-11:35:10> ({'r_t':  -251.1527, 'eps':     0.5005, 'len': 32496.9230, 'lr':   8.51e-05, 'eps_e':     0.5005, 'lr_e':   8.51e-05})
Step:  310000, Reward:   -16.707 [  34.535], Avg:   -80.571 (0.001) <0-11:38:54> ({'r_t': -1272.0791, 'eps':     0.0005, 'len': 32591.3790, 'dyn_loss':     0.1142, 'dot_loss':     0.0652, 'ddot_loss':     0.1441, 'rew_loss':     9.5851, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  311000, Reward:   -34.152 [  54.372], Avg:   -80.422 (0.500) <0-11:41:13> ({'r_t':  -140.8550, 'eps':     0.5005, 'len': 32706.7050, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  312000, Reward:   -50.106 [  43.525], Avg:   -80.326 (0.001) <0-11:44:58> ({'r_t': -1219.8629, 'eps':     0.0005, 'len': 32776.1830, 'dyn_loss':     0.1059, 'dot_loss':     0.0600, 'ddot_loss':     0.1322, 'rew_loss':     9.0141, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  313000, Reward:   -35.190 [  42.872], Avg:   -80.182 (0.500) <0-11:47:17> ({'r_t':  -255.3919, 'eps':     0.5005, 'len': 32891.8470, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  314000, Reward:   -12.738 [  69.570], Avg:   -79.968 (0.001) <0-11:50:56> ({'r_t': -1286.0054, 'eps':     0.0005, 'len': 32985.1810, 'dyn_loss':     0.1055, 'dot_loss':     0.0621, 'ddot_loss':     0.1375, 'rew_loss':     9.0805, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  315000, Reward:   -30.508 [  57.921], Avg:   -79.811 (0.500) <0-11:53:16> ({'r_t':  -100.5399, 'eps':     0.5005, 'len': 33093.7410, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  316000, Reward:   -46.183 [  63.706], Avg:   -79.705 (0.001) <0-11:56:59> ({'r_t': -1421.6972, 'eps':     0.0005, 'len': 33166.7150, 'dyn_loss':     0.1072, 'dot_loss':     0.0620, 'ddot_loss':     0.1372, 'rew_loss':     9.3107, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  317000, Reward:   -39.807 [  68.438], Avg:   -79.580 (0.500) <0-11:59:16> ({'r_t':  -168.0057, 'eps':     0.5005, 'len': 33280.7590, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  318000, Reward:     1.504 [  61.249], Avg:   -79.325 (0.001) <0-12:03:04> ({'r_t': -1492.4433, 'eps':     0.0005, 'len': 33374.7010, 'dyn_loss':     0.1162, 'dot_loss':     0.0681, 'ddot_loss':     0.1512, 'rew_loss':     9.4294, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  319000, Reward:   -19.574 [  72.298], Avg:   -79.139 (0.500) <0-12:05:17> ({'r_t':  -131.9101, 'eps':     0.5005, 'len': 33486.5300, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  320000, Reward:   -31.170 [  49.698], Avg:   -78.989 (0.001) <0-12:08:58> ({'r_t': -1337.3282, 'eps':     0.0005, 'len': 33551.6110, 'dyn_loss':     0.1061, 'dot_loss':     0.0606, 'ddot_loss':     0.1342, 'rew_loss':     8.9134, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  321000, Reward:   -42.768 [  62.290], Avg:   -78.877 (0.500) <0-12:11:10> ({'r_t':  -221.4774, 'eps':     0.5005, 'len': 33659.8820, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  322000, Reward:   -19.867 [  68.847], Avg:   -78.694 (0.001) <0-12:14:51> ({'r_t': -1304.4518, 'eps':     0.0005, 'len': 33734.2250, 'dyn_loss':     0.1090, 'dot_loss':     0.0611, 'ddot_loss':     0.1342, 'rew_loss':     9.1390, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  323000, Reward:   -31.616 [  75.211], Avg:   -78.549 (0.500) <0-12:17:07> ({'r_t':   -94.2042, 'eps':     0.5005, 'len': 33843.7110, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  324000, Reward:     1.241 [  45.944], Avg:   -78.303 (0.001) <0-12:20:41> ({'r_t': -1169.1574, 'eps':     0.0005, 'len': 33909.5180, 'dyn_loss':     0.1080, 'dot_loss':     0.0622, 'ddot_loss':     0.1374, 'rew_loss':     9.5667, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  325000, Reward:    -1.463 [  61.187], Avg:   -78.068 (0.500) <0-12:22:53> ({'r_t':   -34.7068, 'eps':     0.5005, 'len': 34015.4080, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  326000, Reward:   -41.926 [  64.967], Avg:   -77.957 (0.001) <0-12:25:54> ({'r_t': -1188.6764, 'eps':     0.0005, 'len': 34081.5120, 'dyn_loss':     0.1127, 'dot_loss':     0.0659, 'ddot_loss':     0.1464, 'rew_loss':     9.3198, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  327000, Reward:     7.166 [  75.220], Avg:   -77.698 (0.500) <0-12:28:09> ({'r_t':   -88.5061, 'eps':     0.5005, 'len': 34192.4470, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  328000, Reward:   -17.186 [  39.196], Avg:   -77.514 (0.001) <0-12:31:48> ({'r_t': -1335.2616, 'eps':     0.0005, 'len': 34264.3480, 'dyn_loss':     0.1043, 'dot_loss':     0.0606, 'ddot_loss':     0.1340, 'rew_loss':     8.9197, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  329000, Reward:   -27.116 [  34.476], Avg:   -77.361 (0.500) <0-12:34:04> ({'r_t':   -81.4268, 'eps':     0.5005, 'len': 34366.5260, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  330000, Reward:   -34.615 [  21.398], Avg:   -77.232 (0.001) <0-12:37:47> ({'r_t': -1441.5489, 'eps':     0.0005, 'len': 34445.9370, 'dyn_loss':     0.1164, 'dot_loss':     0.0661, 'ddot_loss':     0.1460, 'rew_loss':     9.7651, 'lr':   8.34e-05, 'eps_e':     0.0005, 'lr_e':   8.34e-05})
Step:  331000, Reward:   -44.248 [  45.006], Avg:   -77.132 (0.500) <0-12:40:05> ({'r_t':  -249.4926, 'eps':     0.5005, 'len': 34566.3420, 'lr':   8.34e-05, 'eps_e':     0.5005, 'lr_e':   8.34e-05})
Step:  332000, Reward:     6.518 [  66.679], Avg:   -76.881 (0.001) <0-12:43:34> ({'r_t': -1567.3631, 'eps':     0.0005, 'len': 34659.8180, 'dyn_loss':     0.0957, 'dot_loss':     0.0536, 'ddot_loss':     0.1182, 'rew_loss':     8.4685, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  333000, Reward:   -19.067 [  68.084], Avg:   -76.708 (0.500) <0-12:45:41> ({'r_t':   -97.2704, 'eps':     0.5005, 'len': 34770.2130, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  334000, Reward:   -23.847 [  65.753], Avg:   -76.550 (0.001) <0-12:49:24> ({'r_t': -1356.1172, 'eps':     0.0005, 'len': 34841.2160, 'dyn_loss':     0.1120, 'dot_loss':     0.0634, 'ddot_loss':     0.1400, 'rew_loss':     9.0355, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  335000, Reward:   -25.906 [  47.321], Avg:   -76.400 (0.500) <0-12:51:35> ({'r_t':  -160.4084, 'eps':     0.5005, 'len': 34959.9310, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  336000, Reward:   -73.334 [  53.962], Avg:   -76.391 (0.001) <0-12:54:34> ({'r_t': -1159.7329, 'eps':     0.0005, 'len': 35037.9420, 'dyn_loss':     0.1091, 'dot_loss':     0.0626, 'ddot_loss':     0.1385, 'rew_loss':     8.9134, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  337000, Reward:   -23.480 [  42.445], Avg:   -76.234 (0.500) <0-12:56:47> ({'r_t':  -124.7059, 'eps':     0.5005, 'len': 35147.3090, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  338000, Reward:   -33.215 [  39.453], Avg:   -76.107 (0.001) <0-13:00:25> ({'r_t': -1431.4738, 'eps':     0.0005, 'len': 35230.2990, 'dyn_loss':     0.1056, 'dot_loss':     0.0599, 'ddot_loss':     0.1329, 'rew_loss':     8.9563, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  339000, Reward:   -58.658 [  29.056], Avg:   -76.056 (0.500) <0-13:01:44> ({'r_t':  -355.5974, 'eps':     0.5005, 'len': 35362.0540, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  340000, Reward:   -36.733 [  71.038], Avg:   -75.940 (0.001) <0-13:05:26> ({'r_t': -1586.8007, 'eps':     0.0005, 'len': 35465.8720, 'dyn_loss':     0.0998, 'dot_loss':     0.0564, 'ddot_loss':     0.1242, 'rew_loss':     8.6211, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  341000, Reward:   -19.260 [  60.036], Avg:   -75.775 (0.500) <0-13:07:44> ({'r_t':  -165.7160, 'eps':     0.5005, 'len': 35578.9940, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  342000, Reward:   -62.670 [  54.995], Avg:   -75.737 (0.001) <0-13:11:28> ({'r_t': -1397.1146, 'eps':     0.0005, 'len': 35663.8490, 'dyn_loss':     0.1081, 'dot_loss':     0.0617, 'ddot_loss':     0.1362, 'rew_loss':     9.1258, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  343000, Reward:   -41.973 [  48.217], Avg:   -75.638 (0.500) <0-13:13:47> ({'r_t':  -253.1479, 'eps':     0.5005, 'len': 35785.7710, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  344000, Reward:   -34.693 [  50.819], Avg:   -75.520 (0.001) <0-13:17:24> ({'r_t': -1272.3928, 'eps':     0.0005, 'len': 35883.0890, 'dyn_loss':     0.0943, 'dot_loss':     0.0528, 'ddot_loss':     0.1160, 'rew_loss':     8.3122, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  345000, Reward:   -29.837 [  88.372], Avg:   -75.388 (0.500) <0-13:19:36> ({'r_t':  -200.1733, 'eps':     0.5005, 'len': 35999.3000, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  346000, Reward:   -40.656 [  73.316], Avg:   -75.288 (0.001) <0-13:23:14> ({'r_t': -1377.9631, 'eps':     0.0005, 'len': 36089.0100, 'dyn_loss':     0.1044, 'dot_loss':     0.0588, 'ddot_loss':     0.1298, 'rew_loss':     8.6974, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  347000, Reward:   -20.133 [  93.179], Avg:   -75.129 (0.500) <0-13:25:29> ({'r_t':  -129.4779, 'eps':     0.5005, 'len': 36196.1220, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  348000, Reward:   -35.582 [  62.335], Avg:   -75.016 (0.001) <0-13:29:11> ({'r_t': -1422.0538, 'eps':     0.0005, 'len': 36283.6810, 'dyn_loss':     0.1092, 'dot_loss':     0.0642, 'ddot_loss':     0.1413, 'rew_loss':     8.9064, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  349000, Reward:   -45.511 [  67.616], Avg:   -74.931 (0.500) <0-13:31:25> ({'r_t':  -103.0104, 'eps':     0.5005, 'len': 36394.9130, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  350000, Reward:     7.923 [  78.243], Avg:   -74.695 (0.001) <0-13:35:08> ({'r_t': -1339.4306, 'eps':     0.0005, 'len': 36464.6560, 'dyn_loss':     0.1153, 'dot_loss':     0.0688, 'ddot_loss':     0.1525, 'rew_loss':     9.4790, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  351000, Reward:    10.174 [  80.443], Avg:   -74.454 (0.500) <0-13:37:25> ({'r_t':   -42.3518, 'eps':     0.5005, 'len': 36562.0130, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  352000, Reward:   -40.356 [  90.313], Avg:   -74.358 (0.001) <0-13:41:03> ({'r_t': -1311.5277, 'eps':     0.0005, 'len': 36633.8910, 'dyn_loss':     0.1050, 'dot_loss':     0.0609, 'ddot_loss':     0.1348, 'rew_loss':     8.9413, 'lr':   8.17e-05, 'eps_e':     0.0005, 'lr_e':   8.17e-05})
Step:  353000, Reward:   -29.230 [  66.709], Avg:   -74.230 (0.500) <0-13:43:19> ({'r_t':  -170.9110, 'eps':     0.5005, 'len': 36752.7110, 'lr':   8.17e-05, 'eps_e':     0.5005, 'lr_e':   8.17e-05})
Step:  354000, Reward:   -18.694 [  84.627], Avg:   -74.074 (0.001) <0-13:47:01> ({'r_t': -1253.1438, 'eps':     0.0005, 'len': 36839.5780, 'dyn_loss':     0.1066, 'dot_loss':     0.0608, 'ddot_loss':     0.1346, 'rew_loss':     8.8073, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  355000, Reward:   -30.809 [  46.675], Avg:   -73.952 (0.500) <0-13:49:15> ({'r_t':   -86.4550, 'eps':     0.5005, 'len': 36940.1530, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  356000, Reward:   -56.404 [  49.775], Avg:   -73.903 (0.001) <0-13:52:18> ({'r_t': -1371.0449, 'eps':     0.0005, 'len': 37005.7400, 'dyn_loss':     0.0962, 'dot_loss':     0.0537, 'ddot_loss':     0.1176, 'rew_loss':     8.5317, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  357000, Reward:   -17.714 [  54.552], Avg:   -73.746 (0.500) <0-13:54:35> ({'r_t':  -145.7030, 'eps':     0.5005, 'len': 37116.4480, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  358000, Reward:    -6.936 [  77.810], Avg:   -73.560 (0.001) <0-13:58:23> ({'r_t': -1291.4615, 'eps':     0.0005, 'len': 37185.9370, 'dyn_loss':     0.1131, 'dot_loss':     0.0659, 'ddot_loss':     0.1456, 'rew_loss':     9.2480, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  359000, Reward:    -5.018 [ 103.478], Avg:   -73.370 (0.500) <0-14:00:37> ({'r_t':  -139.9226, 'eps':     0.5005, 'len': 37292.6680, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  360000, Reward:    10.643 [  68.902], Avg:   -73.137 (0.001) <0-14:04:28> ({'r_t': -1245.2776, 'eps':     0.0005, 'len': 37368.3230, 'dyn_loss':     0.1148, 'dot_loss':     0.0659, 'ddot_loss':     0.1460, 'rew_loss':     9.1353, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  361000, Reward:     1.291 [  79.725], Avg:   -72.931 (0.500) <0-14:06:44> ({'r_t':  -136.9762, 'eps':     0.5005, 'len': 37472.4580, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  362000, Reward:    -4.618 [  56.674], Avg:   -72.743 (0.001) <0-14:10:21> ({'r_t': -1423.4416, 'eps':     0.0005, 'len': 37542.4560, 'dyn_loss':     0.1041, 'dot_loss':     0.0607, 'ddot_loss':     0.1343, 'rew_loss':     8.7699, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  363000, Reward:   -46.692 [  55.280], Avg:   -72.672 (0.500) <0-14:11:44> ({'r_t':  -192.7637, 'eps':     0.5005, 'len': 37652.7880, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  364000, Reward:   -34.944 [  50.128], Avg:   -72.568 (0.001) <0-14:15:36> ({'r_t': -1484.7654, 'eps':     0.0005, 'len': 37733.5550, 'dyn_loss':     0.1057, 'dot_loss':     0.0610, 'ddot_loss':     0.1343, 'rew_loss':     8.6210, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  365000, Reward:   -15.940 [  60.035], Avg:   -72.414 (0.500) <0-14:17:52> ({'r_t':  -219.6524, 'eps':     0.5005, 'len': 37851.3760, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  366000, Reward:   -28.953 [  45.666], Avg:   -72.295 (0.001) <0-14:21:33> ({'r_t': -1242.3447, 'eps':     0.0005, 'len': 37938.0900, 'dyn_loss':     0.1029, 'dot_loss':     0.0606, 'ddot_loss':     0.1345, 'rew_loss':     8.9890, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  367000, Reward:   -52.358 [  59.700], Avg:   -72.241 (0.500) <0-14:23:47> ({'r_t':  -114.5809, 'eps':     0.5005, 'len': 38036.2540, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  368000, Reward:   -20.924 [  73.658], Avg:   -72.102 (0.001) <0-14:27:23> ({'r_t': -1451.4584, 'eps':     0.0005, 'len': 38105.0340, 'dyn_loss':     0.1036, 'dot_loss':     0.0584, 'ddot_loss':     0.1286, 'rew_loss':     8.8645, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  369000, Reward:    -9.137 [  84.867], Avg:   -71.932 (0.500) <0-14:29:39> ({'r_t':  -160.0236, 'eps':     0.5005, 'len': 38216.1000, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  370000, Reward:   -16.709 [  54.990], Avg:   -71.783 (0.001) <0-14:33:16> ({'r_t': -1538.9281, 'eps':     0.0005, 'len': 38297.8300, 'dyn_loss':     0.1007, 'dot_loss':     0.0551, 'ddot_loss':     0.1209, 'rew_loss':     8.3650, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  371000, Reward:   -38.509 [  88.578], Avg:   -71.693 (0.500) <0-14:35:34> ({'r_t':  -124.1498, 'eps':     0.5005, 'len': 38406.6840, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  372000, Reward:   -12.185 [  57.791], Avg:   -71.534 (0.001) <0-14:39:25> ({'r_t': -1170.4711, 'eps':     0.0005, 'len': 38481.9410, 'dyn_loss':     0.1046, 'dot_loss':     0.0597, 'ddot_loss':     0.1324, 'rew_loss':     8.6569, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  373000, Reward:    -2.027 [  84.005], Avg:   -71.348 (0.500) <0-14:41:40> ({'r_t':  -183.5273, 'eps':     0.5005, 'len': 38591.1850, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  374000, Reward:   -25.630 [  45.663], Avg:   -71.226 (0.001) <0-14:45:22> ({'r_t': -1456.7285, 'eps':     0.0005, 'len': 38679.5230, 'dyn_loss':     0.1062, 'dot_loss':     0.0611, 'ddot_loss':     0.1350, 'rew_loss':     8.7148, 'lr':   8.01e-05, 'eps_e':     0.0005, 'lr_e':   8.01e-05})
Step:  375000, Reward:   -40.032 [  46.570], Avg:   -71.143 (0.500) <0-14:47:39> ({'r_t':  -223.5268, 'eps':     0.5005, 'len': 38798.9640, 'lr':   8.01e-05, 'eps_e':     0.5005, 'lr_e':   8.01e-05})
Step:  376000, Reward:     1.244 [  92.276], Avg:   -70.951 (0.001) <0-14:51:27> ({'r_t': -1399.5403, 'eps':     0.0005, 'len': 38898.2030, 'dyn_loss':     0.1173, 'dot_loss':     0.0669, 'ddot_loss':     0.1475, 'rew_loss':     9.3501, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  377000, Reward:   -19.448 [  78.761], Avg:   -70.815 (0.500) <0-14:53:42> ({'r_t':  -188.9363, 'eps':     0.5005, 'len': 39015.3120, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  378000, Reward:     4.001 [  75.271], Avg:   -70.617 (0.001) <0-14:57:21> ({'r_t': -1331.4857, 'eps':     0.0005, 'len': 39086.7450, 'dyn_loss':     0.1042, 'dot_loss':     0.0594, 'ddot_loss':     0.1310, 'rew_loss':     8.9086, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  379000, Reward:     1.508 [  68.968], Avg:   -70.428 (0.500) <0-14:59:36> ({'r_t':  -213.7205, 'eps':     0.5005, 'len': 39201.9330, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  380000, Reward:   -40.040 [  54.220], Avg:   -70.348 (0.001) <0-15:03:23> ({'r_t': -1236.1086, 'eps':     0.0005, 'len': 39293.3340, 'dyn_loss':     0.1060, 'dot_loss':     0.0618, 'ddot_loss':     0.1372, 'rew_loss':     8.7087, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  381000, Reward:   -25.447 [  53.124], Avg:   -70.230 (0.500) <0-15:05:41> ({'r_t':  -235.3769, 'eps':     0.5005, 'len': 39406.4300, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  382000, Reward:    -9.017 [  72.890], Avg:   -70.071 (0.001) <0-15:09:32> ({'r_t': -1216.3538, 'eps':     0.0005, 'len': 39487.5070, 'dyn_loss':     0.1038, 'dot_loss':     0.0605, 'ddot_loss':     0.1341, 'rew_loss':     8.5262, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  383000, Reward:   -23.347 [  69.423], Avg:   -69.949 (0.500) <0-15:10:54> ({'r_t':  -164.4360, 'eps':     0.5005, 'len': 39604.2780, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  384000, Reward:   -23.464 [  49.806], Avg:   -69.828 (0.001) <0-15:13:14> ({'r_t': -1270.3224, 'eps':     0.0005, 'len': 39678.9010, 'dyn_loss':     0.1013, 'dot_loss':     0.0594, 'ddot_loss':     0.1319, 'rew_loss':     9.1676, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  385000, Reward:   -29.618 [  50.601], Avg:   -69.724 (0.500) <0-15:14:33> ({'r_t':  -161.5172, 'eps':     0.5005, 'len': 39785.9670, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  386000, Reward:   -11.254 [  57.271], Avg:   -69.573 (0.001) <0-15:16:51> ({'r_t': -1395.1861, 'eps':     0.0005, 'len': 39869.3790, 'dyn_loss':     0.0994, 'dot_loss':     0.0566, 'ddot_loss':     0.1253, 'rew_loss':     8.6609, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  387000, Reward:   -45.425 [  62.683], Avg:   -69.511 (0.500) <0-15:18:10> ({'r_t':  -133.6545, 'eps':     0.5005, 'len': 39976.6560, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  388000, Reward:   -38.539 [  55.935], Avg:   -69.431 (0.001) <0-15:20:32> ({'r_t': -1360.8673, 'eps':     0.0005, 'len': 40060.7940, 'dyn_loss':     0.1133, 'dot_loss':     0.0655, 'ddot_loss':     0.1453, 'rew_loss':     9.0596, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  389000, Reward:   -51.169 [  36.073], Avg:   -69.384 (0.500) <0-15:21:18> ({'r_t':  -277.4502, 'eps':     0.5005, 'len': 40185.9670, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  390000, Reward:     6.881 [  65.310], Avg:   -69.189 (0.001) <0-15:23:36> ({'r_t': -1434.6659, 'eps':     0.0005, 'len': 40277.9120, 'dyn_loss':     0.1093, 'dot_loss':     0.0632, 'ddot_loss':     0.1395, 'rew_loss':     8.8865, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  391000, Reward:   -12.660 [  87.409], Avg:   -69.045 (0.500) <0-15:24:55> ({'r_t':  -183.5732, 'eps':     0.5005, 'len': 40386.7760, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  392000, Reward:   -23.384 [  36.764], Avg:   -68.929 (0.001) <0-15:27:14> ({'r_t': -1360.5301, 'eps':     0.0005, 'len': 40464.7040, 'dyn_loss':     0.1095, 'dot_loss':     0.0641, 'ddot_loss':     0.1419, 'rew_loss':     8.6803, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  393000, Reward:    -3.350 [  55.980], Avg:   -68.762 (0.500) <0-15:28:34> ({'r_t':   -86.5342, 'eps':     0.5005, 'len': 40570.3070, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  394000, Reward:   -27.390 [  95.269], Avg:   -68.658 (0.001) <0-15:30:57> ({'r_t': -1236.6190, 'eps':     0.0005, 'len': 40641.0000, 'dyn_loss':     0.1129, 'dot_loss':     0.0648, 'ddot_loss':     0.1433, 'rew_loss':     9.0461, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  395000, Reward:   -68.825 [  86.197], Avg:   -68.658 (0.500) <0-15:32:16> ({'r_t':  -209.7772, 'eps':     0.5005, 'len': 40755.3600, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  396000, Reward:   -31.590 [  63.619], Avg:   -68.565 (0.001) <0-15:34:33> ({'r_t': -1409.9247, 'eps':     0.0005, 'len': 40842.5450, 'dyn_loss':     0.1063, 'dot_loss':     0.0618, 'ddot_loss':     0.1367, 'rew_loss':     8.9347, 'lr':   7.85e-05, 'eps_e':     0.0005, 'lr_e':   7.85e-05})
Step:  397000, Reward:   -42.183 [  67.433], Avg:   -68.498 (0.500) <0-15:35:52> ({'r_t':  -232.3458, 'eps':     0.5005, 'len': 40957.9790, 'lr':   7.85e-05, 'eps_e':     0.5005, 'lr_e':   7.85e-05})
Step:  398000, Reward:   -61.923 [  68.343], Avg:   -68.482 (0.001) <0-15:37:50> ({'r_t': -1334.6571, 'eps':     0.0005, 'len': 41042.9280, 'dyn_loss':     0.1014, 'dot_loss':     0.0600, 'ddot_loss':     0.1332, 'rew_loss':     8.5310, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  399000, Reward:   -24.964 [  32.910], Avg:   -68.373 (0.500) <0-15:39:10> ({'r_t':  -189.2733, 'eps':     0.5005, 'len': 41161.0760, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  400000, Reward:   -16.167 [  88.972], Avg:   -68.243 (0.001) <0-15:41:37> ({'r_t': -1340.7628, 'eps':     0.0005, 'len': 41243.7620, 'dyn_loss':     0.1042, 'dot_loss':     0.0613, 'ddot_loss':     0.1367, 'rew_loss':     8.6001, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  401000, Reward:   -22.984 [  60.633], Avg:   -68.130 (0.500) <0-15:43:09> ({'r_t':  -179.4059, 'eps':     0.5005, 'len': 41349.5290, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  402000, Reward:   -58.218 [  90.456], Avg:   -68.106 (0.001) <0-15:46:02> ({'r_t': -1209.4776, 'eps':     0.0005, 'len': 41412.5400, 'dyn_loss':     0.1071, 'dot_loss':     0.0623, 'ddot_loss':     0.1377, 'rew_loss':     8.6052, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  403000, Reward:   -51.926 [  96.289], Avg:   -68.066 (0.500) <0-15:47:57> ({'r_t':  -163.7254, 'eps':     0.5005, 'len': 41521.8800, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  404000, Reward:   -25.065 [  52.210], Avg:   -67.959 (0.001) <0-15:50:52> ({'r_t': -1401.1405, 'eps':     0.0005, 'len': 41601.3580, 'dyn_loss':     0.1115, 'dot_loss':     0.0659, 'ddot_loss':     0.1462, 'rew_loss':     8.9856, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  405000, Reward:   -31.883 [ 130.324], Avg:   -67.871 (0.500) <0-15:52:22> ({'r_t':  -292.2880, 'eps':     0.5005, 'len': 41719.9460, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  406000, Reward:   -28.736 [  55.615], Avg:   -67.774 (0.001) <0-15:55:10> ({'r_t': -1378.1253, 'eps':     0.0005, 'len': 41816.4680, 'dyn_loss':     0.1025, 'dot_loss':     0.0600, 'ddot_loss':     0.1331, 'rew_loss':     8.7702, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  407000, Reward:   -26.051 [  67.825], Avg:   -67.672 (0.500) <0-15:56:40> ({'r_t':  -232.7889, 'eps':     0.5005, 'len': 41935.2940, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  408000, Reward:   -12.980 [  76.470], Avg:   -67.538 (0.001) <0-15:59:20> ({'r_t': -1304.2442, 'eps':     0.0005, 'len': 42016.7040, 'dyn_loss':     0.1024, 'dot_loss':     0.0611, 'ddot_loss':     0.1354, 'rew_loss':     8.7361, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  409000, Reward:   -20.719 [  96.557], Avg:   -67.424 (0.500) <0-16:00:51> ({'r_t':  -199.5268, 'eps':     0.5005, 'len': 42119.9640, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  410000, Reward:   -39.384 [  53.191], Avg:   -67.356 (0.001) <0-16:03:41> ({'r_t': -1311.5565, 'eps':     0.0005, 'len': 42199.1010, 'dyn_loss':     0.1011, 'dot_loss':     0.0589, 'ddot_loss':     0.1307, 'rew_loss':     8.6241, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  411000, Reward:   -37.253 [  44.393], Avg:   -67.283 (0.500) <0-16:05:12> ({'r_t':  -170.0785, 'eps':     0.5005, 'len': 42314.2510, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  412000, Reward:   -19.849 [  33.414], Avg:   -67.168 (0.001) <0-16:07:58> ({'r_t': -1057.2724, 'eps':     0.0005, 'len': 42392.4600, 'dyn_loss':     0.1148, 'dot_loss':     0.0676, 'ddot_loss':     0.1496, 'rew_loss':     9.1175, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  413000, Reward:     4.428 [  58.205], Avg:   -66.995 (0.500) <0-16:09:48> ({'r_t':  -136.6135, 'eps':     0.5005, 'len': 42494.8990, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  414000, Reward:    -6.339 [  81.346], Avg:   -66.849 (0.001) <0-16:12:37> ({'r_t': -1222.0085, 'eps':     0.0005, 'len': 42575.6530, 'dyn_loss':     0.0976, 'dot_loss':     0.0571, 'ddot_loss':     0.1260, 'rew_loss':     8.2525, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  415000, Reward:   -21.276 [  57.044], Avg:   -66.739 (0.500) <0-16:14:06> ({'r_t':  -161.7709, 'eps':     0.5005, 'len': 42686.1150, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  416000, Reward:   -32.240 [  29.029], Avg:   -66.657 (0.001) <0-16:16:23> ({'r_t': -1378.1379, 'eps':     0.0005, 'len': 42763.4420, 'dyn_loss':     0.0866, 'dot_loss':     0.0472, 'ddot_loss':     0.1039, 'rew_loss':     7.8433, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  417000, Reward:   -20.053 [  65.348], Avg:   -66.545 (0.500) <0-16:17:53> ({'r_t':  -229.6829, 'eps':     0.5005, 'len': 42876.0760, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  418000, Reward:   -22.658 [  74.791], Avg:   -66.440 (0.001) <0-16:20:47> ({'r_t': -1384.0840, 'eps':     0.0005, 'len': 42974.0070, 'dyn_loss':     0.1054, 'dot_loss':     0.0615, 'ddot_loss':     0.1364, 'rew_loss':     8.8799, 'lr':   7.69e-05, 'eps_e':     0.0005, 'lr_e':   7.69e-05})
Step:  419000, Reward:   -52.326 [  68.318], Avg:   -66.407 (0.500) <0-16:22:17> ({'r_t':  -148.1104, 'eps':     0.5005, 'len': 43078.8680, 'lr':   7.69e-05, 'eps_e':     0.5005, 'lr_e':   7.69e-05})
Step:  420000, Reward:   -20.144 [  53.419], Avg:   -66.297 (0.001) <0-16:25:07> ({'r_t': -1463.0680, 'eps':     0.0005, 'len': 43158.0890, 'dyn_loss':     0.1053, 'dot_loss':     0.0604, 'ddot_loss':     0.1337, 'rew_loss':     8.6284, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  421000, Reward:   -12.480 [  83.984], Avg:   -66.169 (0.500) <0-16:26:41> ({'r_t':  -179.8229, 'eps':     0.5005, 'len': 43270.6570, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  422000, Reward:   -32.426 [  62.840], Avg:   -66.090 (0.001) <0-16:29:39> ({'r_t': -1484.8866, 'eps':     0.0005, 'len': 43357.9920, 'dyn_loss':     0.1088, 'dot_loss':     0.0628, 'ddot_loss':     0.1391, 'rew_loss':     8.7449, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  423000, Reward:   -24.345 [  51.886], Avg:   -65.991 (0.500) <0-16:31:07> ({'r_t':  -123.0650, 'eps':     0.5005, 'len': 43472.7150, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  424000, Reward:    -2.776 [  73.423], Avg:   -65.842 (0.001) <0-16:34:05> ({'r_t': -1456.7048, 'eps':     0.0005, 'len': 43544.5160, 'dyn_loss':     0.1065, 'dot_loss':     0.0628, 'ddot_loss':     0.1390, 'rew_loss':     8.5792, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  425000, Reward:   -65.340 [  89.966], Avg:   -65.841 (0.500) <0-16:35:34> ({'r_t':  -228.5235, 'eps':     0.5005, 'len': 43658.2650, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  426000, Reward:   -11.865 [  55.097], Avg:   -65.715 (0.001) <0-16:38:20> ({'r_t': -1314.4769, 'eps':     0.0005, 'len': 43757.0850, 'dyn_loss':     0.1002, 'dot_loss':     0.0568, 'ddot_loss':     0.1253, 'rew_loss':     8.2264, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  427000, Reward:   -47.808 [  63.720], Avg:   -65.673 (0.500) <0-16:39:49> ({'r_t':  -141.0450, 'eps':     0.5005, 'len': 43866.9650, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  428000, Reward:   -19.197 [  61.552], Avg:   -65.565 (0.001) <0-16:42:03> ({'r_t': -1299.9733, 'eps':     0.0005, 'len': 43943.3210, 'dyn_loss':     0.1096, 'dot_loss':     0.0628, 'ddot_loss':     0.1389, 'rew_loss':     8.8094, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  429000, Reward:    -7.780 [  81.276], Avg:   -65.430 (0.500) <0-16:43:33> ({'r_t':  -199.8709, 'eps':     0.5005, 'len': 44065.6240, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  430000, Reward:    18.005 [  63.001], Avg:   -65.237 (0.001) <0-16:46:22> ({'r_t': -1338.7128, 'eps':     0.0005, 'len': 44164.0600, 'dyn_loss':     0.1015, 'dot_loss':     0.0575, 'ddot_loss':     0.1270, 'rew_loss':     8.0641, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  431000, Reward:     2.418 [  70.236], Avg:   -65.080 (0.500) <0-16:47:52> ({'r_t':  -149.9434, 'eps':     0.5005, 'len': 44271.1930, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  432000, Reward:   -26.604 [  53.964], Avg:   -64.991 (0.001) <0-16:50:45> ({'r_t': -1365.7507, 'eps':     0.0005, 'len': 44345.9920, 'dyn_loss':     0.1110, 'dot_loss':     0.0654, 'ddot_loss':     0.1450, 'rew_loss':     8.9075, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  433000, Reward:   -54.972 [  32.890], Avg:   -64.968 (0.500) <0-16:51:39> ({'r_t':  -297.0130, 'eps':     0.5005, 'len': 44478.5870, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  434000, Reward:   -10.222 [  54.164], Avg:   -64.842 (0.001) <0-16:54:19> ({'r_t': -1153.6254, 'eps':     0.0005, 'len': 44576.6190, 'dyn_loss':     0.0913, 'dot_loss':     0.0518, 'ddot_loss':     0.1145, 'rew_loss':     7.9146, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  435000, Reward:   -45.350 [  44.322], Avg:   -64.798 (0.500) <0-16:55:49> ({'r_t':  -147.1508, 'eps':     0.5005, 'len': 44684.4630, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  436000, Reward:     5.904 [ 108.273], Avg:   -64.636 (0.001) <0-16:58:55> ({'r_t': -1153.6098, 'eps':     0.0005, 'len': 44762.2440, 'dyn_loss':     0.1041, 'dot_loss':     0.0603, 'ddot_loss':     0.1338, 'rew_loss':     8.6139, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  437000, Reward:   -17.567 [  80.669], Avg:   -64.528 (0.500) <0-17:00:23> ({'r_t':  -177.1513, 'eps':     0.5005, 'len': 44872.9960, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  438000, Reward:   -30.183 [  89.721], Avg:   -64.450 (0.001) <0-17:03:17> ({'r_t': -1460.9331, 'eps':     0.0005, 'len': 44957.7080, 'dyn_loss':     0.1077, 'dot_loss':     0.0620, 'ddot_loss':     0.1368, 'rew_loss':     8.7675, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  439000, Reward:   -45.179 [  67.549], Avg:   -64.406 (0.500) <0-17:04:46> ({'r_t':  -227.0867, 'eps':     0.5005, 'len': 45073.3290, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  440000, Reward:     2.972 [  66.129], Avg:   -64.254 (0.001) <0-17:07:36> ({'r_t': -1337.5704, 'eps':     0.0005, 'len': 45160.7380, 'dyn_loss':     0.0977, 'dot_loss':     0.0564, 'ddot_loss':     0.1252, 'rew_loss':     8.4017, 'lr':   7.54e-05, 'eps_e':     0.0005, 'lr_e':   7.54e-05})
Step:  441000, Reward:   -18.156 [  48.582], Avg:   -64.149 (0.500) <0-17:09:05> ({'r_t':  -107.3939, 'eps':     0.5005, 'len': 45271.1040, 'lr':   7.54e-05, 'eps_e':     0.5005, 'lr_e':   7.54e-05})
Step:  442000, Reward:    17.029 [  73.094], Avg:   -63.966 (0.001) <0-17:11:58> ({'r_t': -1231.7026, 'eps':     0.0005, 'len': 45340.8790, 'dyn_loss':     0.1029, 'dot_loss':     0.0598, 'ddot_loss':     0.1324, 'rew_loss':     8.5056, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  443000, Reward:   -28.586 [  63.625], Avg:   -63.886 (0.500) <0-17:13:26> ({'r_t':  -165.9580, 'eps':     0.5005, 'len': 45459.1430, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  444000, Reward:    15.797 [  84.356], Avg:   -63.707 (0.001) <0-17:16:22> ({'r_t': -1271.7929, 'eps':     0.0005, 'len': 45547.9630, 'dyn_loss':     0.1016, 'dot_loss':     0.0597, 'ddot_loss':     0.1325, 'rew_loss':     8.5119, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  445000, Reward:   -57.729 [  90.955], Avg:   -63.694 (0.500) <0-17:17:52> ({'r_t':  -193.7249, 'eps':     0.5005, 'len': 45658.4340, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  446000, Reward:   -28.253 [  77.990], Avg:   -63.615 (0.001) <0-17:20:32> ({'r_t': -1303.3714, 'eps':     0.0005, 'len': 45745.1540, 'dyn_loss':     0.1017, 'dot_loss':     0.0597, 'ddot_loss':     0.1323, 'rew_loss':     8.6253, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  447000, Reward:     1.470 [  70.418], Avg:   -63.469 (0.500) <0-17:22:00> ({'r_t':  -175.3088, 'eps':     0.5005, 'len': 45861.5270, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  448000, Reward:   -15.883 [  53.005], Avg:   -63.363 (0.001) <0-17:24:42> ({'r_t': -1463.0011, 'eps':     0.0005, 'len': 45967.2500, 'dyn_loss':     0.1048, 'dot_loss':     0.0605, 'ddot_loss':     0.1337, 'rew_loss':     8.5720, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  449000, Reward:   -17.770 [  56.356], Avg:   -63.262 (0.500) <0-17:26:11> ({'r_t':  -222.0055, 'eps':     0.5005, 'len': 46088.2690, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  450000, Reward:   -10.916 [  88.633], Avg:   -63.146 (0.001) <0-17:28:56> ({'r_t': -1370.1098, 'eps':     0.0005, 'len': 46180.0860, 'dyn_loss':     0.1061, 'dot_loss':     0.0609, 'ddot_loss':     0.1348, 'rew_loss':     8.6384, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  451000, Reward:   -17.590 [  71.195], Avg:   -63.045 (0.500) <0-17:30:26> ({'r_t':   -82.9861, 'eps':     0.5005, 'len': 46296.1830, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  452000, Reward:     2.286 [  78.903], Avg:   -62.901 (0.001) <0-17:33:15> ({'r_t': -1198.2015, 'eps':     0.0005, 'len': 46375.2440, 'dyn_loss':     0.1001, 'dot_loss':     0.0575, 'ddot_loss':     0.1275, 'rew_loss':     8.3484, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  453000, Reward:   -23.406 [  47.311], Avg:   -62.814 (0.500) <0-17:34:45> ({'r_t':  -156.2799, 'eps':     0.5005, 'len': 46495.9170, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  454000, Reward:   -28.646 [  84.421], Avg:   -62.739 (0.001) <0-17:37:39> ({'r_t': -1451.1494, 'eps':     0.0005, 'len': 46575.6030, 'dyn_loss':     0.1013, 'dot_loss':     0.0577, 'ddot_loss':     0.1268, 'rew_loss':     8.3241, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  455000, Reward:    -8.966 [  48.087], Avg:   -62.621 (0.500) <0-17:39:11> ({'r_t':  -200.2731, 'eps':     0.5005, 'len': 46686.1320, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  456000, Reward:   -38.995 [  58.839], Avg:   -62.569 (0.001) <0-17:42:05> ({'r_t': -1383.6804, 'eps':     0.0005, 'len': 46763.7650, 'dyn_loss':     0.0982, 'dot_loss':     0.0571, 'ddot_loss':     0.1260, 'rew_loss':     8.0611, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  457000, Reward:   -52.251 [  65.170], Avg:   -62.547 (0.500) <0-17:43:54> ({'r_t':  -281.4189, 'eps':     0.5005, 'len': 46884.6200, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  458000, Reward:   -33.955 [  53.289], Avg:   -62.484 (0.001) <0-17:46:45> ({'r_t': -1258.2474, 'eps':     0.0005, 'len': 46959.7970, 'dyn_loss':     0.1075, 'dot_loss':     0.0623, 'ddot_loss':     0.1382, 'rew_loss':     8.8113, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  459000, Reward:   -23.394 [  64.108], Avg:   -62.399 (0.500) <0-17:48:13> ({'r_t':  -273.0288, 'eps':     0.5005, 'len': 47074.6600, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  460000, Reward:   -41.514 [  44.836], Avg:   -62.354 (0.001) <0-17:51:10> ({'r_t': -1407.9997, 'eps':     0.0005, 'len': 47171.6240, 'dyn_loss':     0.1028, 'dot_loss':     0.0610, 'ddot_loss':     0.1351, 'rew_loss':     8.3057, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  461000, Reward:   -18.593 [  69.083], Avg:   -62.259 (0.500) <0-17:52:38> ({'r_t':  -225.5156, 'eps':     0.5005, 'len': 47298.6560, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  462000, Reward:   -46.935 [  51.327], Avg:   -62.226 (0.001) <0-17:55:19> ({'r_t': -1362.0093, 'eps':     0.0005, 'len': 47387.3650, 'dyn_loss':     0.0982, 'dot_loss':     0.0563, 'ddot_loss':     0.1249, 'rew_loss':     8.4667, 'lr':   7.39e-05, 'eps_e':     0.0005, 'lr_e':   7.39e-05})
Step:  463000, Reward:   -20.284 [  52.804], Avg:   -62.136 (0.500) <0-17:56:48> ({'r_t':  -216.7123, 'eps':     0.5005, 'len': 47497.4740, 'lr':   7.39e-05, 'eps_e':     0.5005, 'lr_e':   7.39e-05})
Step:  464000, Reward:   -20.076 [  50.370], Avg:   -62.045 (0.001) <0-17:59:38> ({'r_t': -1441.4896, 'eps':     0.0005, 'len': 47589.6840, 'dyn_loss':     0.0999, 'dot_loss':     0.0574, 'ddot_loss':     0.1271, 'rew_loss':     8.1260, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  465000, Reward:   -29.354 [  58.909], Avg:   -61.975 (0.500) <0-18:01:07> ({'r_t':  -218.4649, 'eps':     0.5005, 'len': 47712.2350, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  466000, Reward:   -29.957 [  72.906], Avg:   -61.907 (0.001) <0-18:03:57> ({'r_t': -1379.3854, 'eps':     0.0005, 'len': 47811.1800, 'dyn_loss':     0.0980, 'dot_loss':     0.0543, 'ddot_loss':     0.1197, 'rew_loss':     8.3440, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  467000, Reward:   -13.310 [  49.721], Avg:   -61.803 (0.500) <0-18:05:29> ({'r_t':  -280.0301, 'eps':     0.5005, 'len': 47936.4420, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  468000, Reward:   -47.938 [  58.800], Avg:   -61.773 (0.001) <0-18:08:31> ({'r_t': -1325.9869, 'eps':     0.0005, 'len': 48031.1940, 'dyn_loss':     0.1102, 'dot_loss':     0.0654, 'ddot_loss':     0.1455, 'rew_loss':     8.8091, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  469000, Reward:   -39.703 [  43.147], Avg:   -61.726 (0.500) <0-18:09:27> ({'r_t':  -195.5564, 'eps':     0.5005, 'len': 48148.0220, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  470000, Reward:     3.352 [  55.687], Avg:   -61.588 (0.001) <0-18:12:13> ({'r_t': -1427.4642, 'eps':     0.0005, 'len': 48232.6830, 'dyn_loss':     0.1015, 'dot_loss':     0.0559, 'ddot_loss':     0.1234, 'rew_loss':     8.3338, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  471000, Reward:   -12.897 [  68.116], Avg:   -61.485 (0.500) <0-18:13:42> ({'r_t':  -281.2495, 'eps':     0.5005, 'len': 48358.7150, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  472000, Reward:   -31.162 [  45.067], Avg:   -61.421 (0.001) <0-18:16:29> ({'r_t': -1521.7396, 'eps':     0.0005, 'len': 48454.8910, 'dyn_loss':     0.0993, 'dot_loss':     0.0564, 'ddot_loss':     0.1253, 'rew_loss':     8.3835, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  473000, Reward:   -45.334 [ 108.522], Avg:   -61.387 (0.500) <0-18:17:58> ({'r_t':  -312.9516, 'eps':     0.5005, 'len': 48585.3690, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  474000, Reward:    -6.373 [  81.100], Avg:   -61.271 (0.001) <0-18:20:47> ({'r_t': -1343.6156, 'eps':     0.0005, 'len': 48687.6950, 'dyn_loss':     0.1049, 'dot_loss':     0.0602, 'ddot_loss':     0.1334, 'rew_loss':     8.4286, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  475000, Reward:   -19.602 [  38.860], Avg:   -61.184 (0.500) <0-18:22:30> ({'r_t':  -157.5865, 'eps':     0.5005, 'len': 48804.9820, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  476000, Reward:   -16.785 [ 107.867], Avg:   -61.091 (0.001) <0-18:24:53> ({'r_t': -1260.9347, 'eps':     0.0005, 'len': 48891.0410, 'dyn_loss':     0.1014, 'dot_loss':     0.0603, 'ddot_loss':     0.1341, 'rew_loss':     8.3582, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  477000, Reward:   -42.741 [  62.270], Avg:   -61.052 (0.500) <0-18:26:22> ({'r_t':  -120.6713, 'eps':     0.5005, 'len': 48998.4090, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  478000, Reward:   -23.380 [  56.189], Avg:   -60.974 (0.001) <0-18:29:11> ({'r_t': -1468.9625, 'eps':     0.0005, 'len': 49085.5460, 'dyn_loss':     0.1039, 'dot_loss':     0.0587, 'ddot_loss':     0.1298, 'rew_loss':     8.3233, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  479000, Reward:   -47.273 [  36.029], Avg:   -60.945 (0.500) <0-18:30:19> ({'r_t':  -119.9742, 'eps':     0.5005, 'len': 49191.4620, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  480000, Reward:   -16.246 [  68.207], Avg:   -60.852 (0.001) <0-18:33:13> ({'r_t': -1588.1028, 'eps':     0.0005, 'len': 49273.7410, 'dyn_loss':     0.0974, 'dot_loss':     0.0580, 'ddot_loss':     0.1282, 'rew_loss':     8.0118, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  481000, Reward:   -16.568 [  63.382], Avg:   -60.760 (0.500) <0-18:34:43> ({'r_t':  -184.4043, 'eps':     0.5005, 'len': 49387.9860, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  482000, Reward:   -40.102 [  59.045], Avg:   -60.717 (0.001) <0-18:37:31> ({'r_t': -1299.0349, 'eps':     0.0005, 'len': 49469.9100, 'dyn_loss':     0.0998, 'dot_loss':     0.0562, 'ddot_loss':     0.1244, 'rew_loss':     8.4855, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  483000, Reward:   -21.552 [  81.918], Avg:   -60.637 (0.500) <0-18:38:59> ({'r_t':  -398.4403, 'eps':     0.5005, 'len': 49598.8300, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  484000, Reward:   -27.212 [  61.465], Avg:   -60.568 (0.001) <0-18:41:41> ({'r_t': -1521.4035, 'eps':     0.0005, 'len': 49698.6720, 'dyn_loss':     0.0890, 'dot_loss':     0.0502, 'ddot_loss':     0.1103, 'rew_loss':     7.6661, 'lr':   7.24e-05, 'eps_e':     0.0005, 'lr_e':   7.24e-05})
Step:  485000, Reward:   -15.491 [  71.120], Avg:   -60.475 (0.500) <0-18:43:11> ({'r_t':  -229.9287, 'eps':     0.5005, 'len': 49823.7380, 'lr':   7.24e-05, 'eps_e':     0.5005, 'lr_e':   7.24e-05})
Step:  486000, Reward:   -22.819 [  49.093], Avg:   -60.398 (0.001) <0-18:45:58> ({'r_t': -1317.3539, 'eps':     0.0005, 'len': 49915.9810, 'dyn_loss':     0.0982, 'dot_loss':     0.0569, 'ddot_loss':     0.1261, 'rew_loss':     8.3821, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  487000, Reward:   -45.559 [  50.994], Avg:   -60.367 (0.500) <0-18:47:26> ({'r_t':  -263.0082, 'eps':     0.5005, 'len': 50039.6670, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  488000, Reward:   -25.088 [  71.672], Avg:   -60.295 (0.001) <0-18:50:14> ({'r_t': -1565.7525, 'eps':     0.0005, 'len': 50140.6940, 'dyn_loss':     0.0995, 'dot_loss':     0.0567, 'ddot_loss':     0.1255, 'rew_loss':     8.0774, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  489000, Reward:    -9.257 [  50.516], Avg:   -60.191 (0.500) <0-18:51:42> ({'r_t':  -201.5517, 'eps':     0.5005, 'len': 50268.0800, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  490000, Reward:    14.272 [  80.060], Avg:   -60.039 (0.001) <0-18:54:23> ({'r_t': -1506.2623, 'eps':     0.0005, 'len': 50368.7190, 'dyn_loss':     0.0902, 'dot_loss':     0.0520, 'ddot_loss':     0.1153, 'rew_loss':     7.8130, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  491000, Reward:   -41.823 [  31.169], Avg:   -60.002 (0.500) <0-18:55:51> ({'r_t':  -247.0313, 'eps':     0.5005, 'len': 50499.4470, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  492000, Reward:   -41.984 [  61.168], Avg:   -59.966 (0.001) <0-18:58:41> ({'r_t': -1377.1106, 'eps':     0.0005, 'len': 50603.8950, 'dyn_loss':     0.0949, 'dot_loss':     0.0545, 'ddot_loss':     0.1208, 'rew_loss':     7.9665, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  493000, Reward:   -41.052 [  62.840], Avg:   -59.927 (0.500) <0-19:00:11> ({'r_t':  -222.6313, 'eps':     0.5005, 'len': 50727.3080, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  494000, Reward:   -44.916 [  52.397], Avg:   -59.897 (0.001) <0-19:02:50> ({'r_t': -1337.9838, 'eps':     0.0005, 'len': 50813.9060, 'dyn_loss':     0.0961, 'dot_loss':     0.0542, 'ddot_loss':     0.1195, 'rew_loss':     8.2668, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  495000, Reward:   -42.889 [  48.165], Avg:   -59.863 (0.500) <0-19:04:21> ({'r_t':  -234.4632, 'eps':     0.5005, 'len': 50929.2060, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  496000, Reward:   -32.286 [  54.306], Avg:   -59.807 (0.001) <0-19:07:14> ({'r_t': -1443.4558, 'eps':     0.0005, 'len': 51020.6620, 'dyn_loss':     0.1069, 'dot_loss':     0.0616, 'ddot_loss':     0.1367, 'rew_loss':     8.6943, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  497000, Reward:    -7.731 [  52.764], Avg:   -59.703 (0.500) <0-19:08:51> ({'r_t':  -236.1345, 'eps':     0.5005, 'len': 51143.9140, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  498000, Reward:   -11.277 [  79.240], Avg:   -59.606 (0.001) <0-19:11:34> ({'r_t': -1339.7203, 'eps':     0.0005, 'len': 51238.5810, 'dyn_loss':     0.0966, 'dot_loss':     0.0554, 'ddot_loss':     0.1226, 'rew_loss':     7.9604, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
Step:  499000, Reward:   -31.495 [  57.382], Avg:   -59.549 (0.500) <0-19:13:02> ({'r_t':  -220.3086, 'eps':     0.5005, 'len': 51369.7160, 'lr':   7.09e-05, 'eps_e':     0.5005, 'lr_e':   7.09e-05})
Step:  500000, Reward:   -17.050 [  61.996], Avg:   -59.465 (0.001) <0-19:15:38> ({'r_t': -1421.4881, 'eps':     0.0005, 'len': 51460.1530, 'dyn_loss':     0.0896, 'dot_loss':     0.0507, 'ddot_loss':     0.1116, 'rew_loss':     7.9846, 'lr':   7.09e-05, 'eps_e':     0.0005, 'lr_e':   7.09e-05})
