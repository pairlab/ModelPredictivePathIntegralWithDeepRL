Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: Pendulum-v0, Date: 08/06/2020 02:14:40
CPU: 20 Core, 0.0GHz, 377.59 GB, Linux-4.14.175-llgrid-10ms-x86_64-with-debian-buster-sid
GPU 0: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
Git URL: https://github.com/shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: dfadcfaa5da451b9a2ea3569848592f6da9848be
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 1000
   TARGET_UPDATE_RATE = 0.0004
   TRAIN_EVERY = 1000
   BATCH_SIZE = 250
   EPS_CYCLE = 10000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 1000
      HORIZON = 20
      LAMBDA = 0.1
      COV = 1
   dynamics_size = 3
   state_size = (3,)
   action_size = (1,)
   env_name = Pendulum-v0
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.98
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fc89fd9df60> 
	env = <GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>> 
		env = <TimeLimit<PendulumEnv<Pendulum-v0>>> 
			env = <PendulumEnv<Pendulum-v0>> 
				max_speed = 8
				max_torque = 2.0
				dt = 0.05
				g = 10.0
				m = 1.0
				l = 1.0
				viewer = None
				action_space = Box(1,) 
					dtype = float32
					shape = (1,)
					low = [-2.000]
					high = [ 2.000]
					bounded_below = [ True]
					bounded_above = [ True]
					np_random = RandomState(MT19937)
				observation_space = Box(3,) 
					dtype = float32
					shape = (3,)
					low = [-1.000 -1.000 -8.000]
					high = [ 1.000  1.000  8.000]
					bounded_below = [ True  True  True]
					bounded_above = [ True  True  True]
					np_random = RandomState(MT19937)
				np_random = RandomState(MT19937)
				spec = EnvSpec(Pendulum-v0) 
					id = Pendulum-v0
					entry_point = gym.envs.classic_control:PendulumEnv
					reward_threshold = None
					nondeterministic = False
					max_episode_steps = 200
				verbose = 0
			action_space = Box(1,) 
				dtype = float32
				shape = (1,)
				low = [-2.000]
				high = [ 2.000]
				bounded_below = [ True]
				bounded_above = [ True]
				np_random = RandomState(MT19937)
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		action_space = Box(1,) 
			dtype = float32
			shape = (1,)
			low = [-2.000]
			high = [ 2.000]
			bounded_below = [ True]
			bounded_above = [ True]
			np_random = RandomState(MT19937)
		observation_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -8.000]
			high = [ 1.000  1.000  8.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fc89fdb3b70> 
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
	state_size = (3,)
	action_size = (1,)
	action_space = Box(1,) 
		dtype = float32
		shape = (1,)
		low = [-2.000]
		high = [ 2.000]
		bounded_below = [ True]
		bounded_above = [ True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.MPIConnection object at 0x7fc89fd3c240> 
		root = 0
		rank = 0
		cluster = <list len=16>
	num_envs = 16
	max_steps = 200,
agent: <src.models.wrappers.ParallelAgent object at 0x7fc89fd3c278> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fc89fd4d9b0> 
		state_size = (3,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7fc89fd5bdd8> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fc89fd5be10> 
			size = (1,)
			dt = 0.2
			action = [ 0.531]
			daction_dt = [-1.291]
		discrete = False
		action_size = (1,)
		state_size = (3,)
		config = <src.utils.config.Config object at 0x7fc8a008bc18> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 1000
			TARGET_UPDATE_RATE = 0.0004
			TRAIN_EVERY = 1000
			BATCH_SIZE = 250
			EPS_CYCLE = 10000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7fc8c5f32160> 
				NSAMPLES = 1000
				HORIZON = 20
				LAMBDA = 0.1
				COV = 1
			dynamics_size = 3
			state_size = (3,)
			action_size = (1,)
			env_name = Pendulum-v0
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7fc8c4477a90> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.98
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7fc89fd5be48> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7fc89fd5beb8> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7fc8a008bc18> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 1000
				TARGET_UPDATE_RATE = 0.0004
				TRAIN_EVERY = 1000
				BATCH_SIZE = 250
				EPS_CYCLE = 10000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7fc8c5f32160> 
					NSAMPLES = 1000
					HORIZON = 20
					LAMBDA = 0.1
					COV = 1
				dynamics_size = 3
				state_size = (3,)
				action_size = (1,)
				env_name = Pendulum-v0
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = []
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7fc8c4477a90> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.98
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7fc89fd5bef0> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=7, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(7, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=3, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7fc89fd5bf60> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7fc8a008bc18> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = 500
						MAX_BUFFER_SIZE = 1000000
						REPLAY_BATCH_SIZE = 1000
						TARGET_UPDATE_RATE = 0.0004
						TRAIN_EVERY = 1000
						BATCH_SIZE = 250
						EPS_CYCLE = 10000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7fc8c5f32160> 
							NSAMPLES = 1000
							HORIZON = 20
							LAMBDA = 0.1
							COV = 1
						dynamics_size = 3
						state_size = (3,)
						action_size = (1,)
						env_name = Pendulum-v0
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = []
						tcp_rank = 0
						num_envs = 1
						nsteps = 500000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7fc8c4477a90> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.98
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (3,)
					action_size = (1,)
					discrete = False
					dyn_index = 3
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fc89fd68320>
				state_size = (3,)
				action_size = (1,)
			mu = [ 0.000]
			cov = [[ 1.000]]
			icov = [[ 1.000]]
			lamda = 0.1
			horizon = 20
			nsamples = 1000
			action_size = (1,)
			control = [[[ 0.107]
			  [-0.931]
			  [-0.372]
			  [-0.436]
			  [ 0.412]
			  [-0.196]
			  [ 0.236]
			  [ 0.034]
			  [-0.656]
			  [ 0.987]
			  [ 0.826]
			  [ 0.354]
			  [-0.849]
			  [ 0.357]
			  [ 0.717]
			  [ 0.936]
			  [ 0.377]
			  [ 0.279]
			  [ 0.574]
			  [ 0.131]]]
			noise = [[[[-0.552]
			   [ 0.309]
			   [ 0.500]
			   ...
			   [ 1.820]
			   [-1.595]
			   [ 1.099]]
			
			  [[-0.329]
			   [-0.444]
			   [-0.407]
			   ...
			   [ 0.765]
			   [ 0.349]
			   [-0.210]]
			
			  [[ 1.268]
			   [-0.741]
			   [-0.597]
			   ...
			   [-0.619]
			   [ 1.824]
			   [-0.294]]
			
			  ...
			
			  [[-0.773]
			   [ 0.592]
			   [-1.293]
			   ...
			   [ 1.881]
			   [-0.069]
			   [-0.996]]
			
			  [[-1.322]
			   [ 0.260]
			   [-0.417]
			   ...
			   [ 1.475]
			   [-1.483]
			   [ 1.598]]
			
			  [[-0.079]
			   [-0.907]
			   [-3.181]
			   ...
			   [ 0.337]
			   [ 0.290]
			   [-2.316]]]]
			init_cost = [[-6.850e-01 -6.636e-01  4.556e+00 -2.524e+00 -2.895e+00  3.634e+00 -1.023e+00 -2.584e+00 -1.310e+00 -5.399e+00  2.318e+00 -4.393e+00  1.234e+00 -7.987e-01  3.002e+00 -2.096e+00  9.194e-01  1.732e+00 -5.909e-01 -3.953e+00 -1.615e+00 -4.682e-01  9.217e-01 -3.461e+00  9.176e-01 -2.819e-01 -1.766e+00  1.724e+00  5.051e-01  2.217e+00 -1.439e+00 -2.828e+00 -3.769e-01  3.035e+00 -5.104e-01  4.833e-01 -8.779e-01  3.186e+00 -2.338e+00 -3.335e+00 -9.736e-01 -2.049e+00 -2.085e+00 -2.577e+00 -1.749e+00  1.925e-01  2.139e+00  1.632e+00 -2.068e+00  4.773e+00  4.246e+00  7.580e-01  1.014e+00 -4.706e+00  5.173e+00  6.755e-01  1.119e+00 -2.427e+00 -1.536e+00 -1.520e+00 -9.254e-01 -4.723e-01 -3.108e+00 -4.315e+00  3.148e+00  8.606e-01  8.332e-01 -2.407e-02 -1.321e+00  3.507e+00 -2.101e-01 -2.497e+00  5.865e+00  5.391e-01  4.564e+00  2.083e+00  2.182e+00  2.814e+00 -1.295e+00  4.022e-01 -5.289e+00  5.213e-01 -1.784e-01  2.329e+00 -1.154e+00  3.372e-01 -1.460e+00  2.129e+00 -1.553e+00 -3.417e+00  4.867e-01 -1.121e+00 -2.078e-01  1.437e+00 -1.934e+00  7.086e-01  3.119e+00 -1.195e+00  3.032e+00  1.514e+00 -4.034e+00  7.386e+00  1.394e+00 -9.146e-01  4.990e-01 -3.224e+00 -1.616e-01 -2.166e-01  1.921e+00 -2.392e-01 -2.680e-01 -5.064e-02 -1.829e+00 -1.981e+00  3.419e+00  4.982e+00  2.989e+00  7.131e-01 -2.798e+00  1.387e+00 -3.100e-01  2.324e+00  5.995e+00 -4.102e+00  1.945e-01 -4.527e-01  9.971e-01  3.243e-01 -4.102e-01 -9.660e-01 -1.547e+00  3.593e+00 -1.495e+00 -7.951e-01  2.444e+00 -8.833e-01  3.287e+00  6.257e-01  2.903e-01  2.325e+00  1.577e+00 -9.646e-01  1.853e+00 -2.875e+00  2.265e+00  1.252e+00 -1.873e+00 -9.091e+00 -1.904e+00  1.655e-01 -3.545e+00 -1.805e+00 -2.019e+00 -1.354e+00  9.389e-01  5.987e+00 -1.198e+00  4.877e-01 -4.044e+00 -2.963e+00 -2.625e+00 -4.047e+00 -2.128e+00  2.797e+00 -6.892e-01 -2.682e+00  7.992e-01 -1.750e+00 -5.136e+00  1.954e+00  3.524e+00 -7.321e-01  1.478e-01  1.664e+00 -5.742e+00  3.116e+00 -5.033e+00 -4.084e+00  1.751e+00 -2.384e+00 -3.944e-01
			   1.906e+00 -2.614e+00  2.283e-01  9.492e-01  1.268e+00 -3.675e+00  5.153e-02  5.618e+00 -8.374e-01 -2.404e-01 -1.167e+00 -4.509e+00 -4.292e-02 -6.711e+00  3.293e+00 -3.146e+00 -1.162e+00  3.908e+00  2.318e+00 -2.103e+00  4.641e-01  1.655e+00  1.674e+00  1.739e+00 -1.059e-01 -6.651e-01 -1.597e+00 -7.548e-01 -8.656e-01  1.169e+00 -4.258e+00 -3.571e+00  6.642e-01 -4.600e+00 -5.324e-01 -1.072e+00 -9.129e-01  4.841e+00 -2.806e+00 -1.371e+00  1.821e+00 -1.892e+00 -3.688e+00  1.028e+00 -1.564e+00  6.625e-01 -6.943e+00  5.553e+00  4.157e+00  6.195e-01 -6.370e+00 -2.842e+00 -2.297e+00 -1.687e+00 -1.688e+00  1.862e+00  1.611e+00  2.415e+00 -9.512e-01 -9.445e-01 -1.466e+00  9.138e-01 -3.184e-01  1.198e-01 -3.752e+00  7.501e+00  5.346e+00 -2.915e-02  4.467e+00 -6.762e-01  1.098e+00  3.436e+00 -8.264e-01  1.064e-01 -1.731e+00 -4.463e+00 -1.804e-01  2.794e+00  1.077e+00 -6.018e-01  5.137e-01 -1.834e+00 -4.632e-01 -2.653e+00 -1.490e+00 -3.819e+00 -1.619e+00  1.035e-01  1.174e+00 -1.681e+00 -1.457e+00 -1.316e+00  1.865e+00 -2.569e-01 -4.852e+00 -6.960e-01 -6.942e-01  1.086e+00  5.363e+00  3.511e-01  1.753e+00  4.441e+00  9.441e-01 -5.867e-01  5.613e+00  6.100e-01 -1.620e+00  2.737e+00  1.800e+00  5.197e-01  1.211e+00 -5.052e-01  2.229e+00 -1.491e+00  6.404e-01 -6.241e-01 -6.050e+00  1.616e+00 -2.275e+00  1.460e+00 -1.082e+00  3.506e+00 -1.066e+00 -3.065e+00  4.619e+00  1.124e+00  2.714e+00  9.377e-01  8.380e-01 -1.595e+00 -3.130e+00  3.043e+00  8.633e-01  1.130e+00  2.563e+00 -1.345e-02 -4.617e+00 -1.816e+00 -1.597e+00  8.139e-01  3.576e+00  4.933e-01 -4.300e+00  2.066e+00 -5.863e-01 -2.015e-01 -3.544e+00 -2.438e+00 -1.975e+00  1.305e-01 -7.612e-01  1.872e+00  1.736e+00  2.049e+00  2.216e-01  2.822e-01  1.992e+00  8.716e-01 -1.882e+00  4.605e+00  5.671e-01 -3.115e+00 -9.064e-01 -2.529e-02 -5.374e-01  2.661e+00  4.968e+00  1.775e+00 -4.800e+00  1.016e+00  6.990e+00  4.908e+00 -2.672e+00 -7.639e-01 -4.410e+00 -3.569e+00 -3.239e+00  1.718e+00  2.024e+00  2.151e+00 -1.358e+00
			  -3.011e+00 -4.501e+00  2.679e+00 -2.310e+00 -2.052e-01  4.107e+00 -1.505e+00  2.089e+00  3.472e+00 -1.845e+00  5.761e+00  3.386e+00  7.536e-02 -1.444e+00  2.088e+00  1.554e+00 -4.143e+00  5.549e+00  2.607e+00  1.442e+00 -7.713e-01  4.059e+00 -2.406e+00  2.525e+00  1.977e+00  1.562e+00 -1.592e+00  3.153e+00 -3.701e-01 -6.420e-01  1.582e+00 -2.432e+00 -1.886e+00 -5.392e+00 -3.583e+00  1.088e+00  2.158e+00  2.821e-01  1.167e+00 -1.089e-01 -6.092e-01  1.511e+00  1.041e-01  2.882e+00  1.607e+00  2.173e+00  3.503e-01  3.766e+00 -9.582e-01 -7.753e-01  1.359e+00 -4.303e-01  1.026e+00 -4.024e-02 -1.069e+00  9.392e-01  3.246e-01  3.262e+00 -2.560e+00  1.707e+00 -7.051e-01 -2.066e+00 -6.066e-01 -3.793e-01  2.087e-02 -5.596e-01 -2.615e+00 -2.713e-01 -3.460e+00 -5.448e-01  2.867e+00 -3.905e+00  2.578e+00  2.678e+00  4.261e+00  1.262e-01 -2.982e+00  4.736e+00 -6.104e+00  4.266e+00 -3.298e+00 -5.281e+00  5.314e+00  4.939e+00 -2.125e+00 -3.161e-02 -1.873e-01 -1.903e+00 -4.274e+00  9.080e-01 -1.266e-01 -1.210e+00 -4.160e+00  6.000e-01  1.116e+00 -8.451e-01  2.202e+00  2.878e+00  2.793e+00 -4.414e+00  9.272e-01  1.789e+00  1.324e+00  1.316e+00  7.022e-01  1.360e+00 -2.609e+00  3.089e+00 -2.483e+00 -3.601e+00  1.072e+00  2.593e+00 -4.275e-01  1.121e-01 -2.513e+00  5.001e+00 -6.837e-01 -1.635e-01  3.363e+00  2.570e+00  2.125e-01  8.472e-02  5.315e-01  4.921e+00  2.892e+00 -1.481e+00  3.172e+00 -4.926e-01 -2.813e+00 -2.448e+00  2.800e+00 -8.685e-01  6.225e-01  3.410e+00 -4.240e-01  8.925e-01 -7.078e+00 -2.498e-01  5.001e+00  2.441e+00  8.293e-01  3.733e-02 -5.398e-01 -5.492e+00  1.280e+00  1.747e+00  1.838e+00 -3.053e+00 -1.454e+00 -2.576e+00 -3.781e-01 -4.454e+00  1.897e+00  2.505e+00 -6.860e-01  4.459e+00 -2.447e+00  3.463e+00  1.123e+00  9.375e-01  2.518e-01 -1.681e+00 -1.681e-01  2.799e+00 -1.005e+00  1.072e+00  9.987e-01  4.482e+00 -3.121e+00  1.874e+00  6.575e-02 -3.410e+00  2.887e+00 -4.279e+00  1.269e+00 -3.720e+00  3.199e+00  3.920e+00 -2.525e-01 -4.368e+00  3.809e+00
			   6.056e+00 -5.524e-01  1.910e+00  5.422e+00  1.444e+00  1.779e+00 -3.013e-01  1.540e+00  3.411e+00  2.578e+00 -6.273e-01  3.723e+00  1.026e+00  2.051e+00 -6.412e+00  4.365e-01 -8.343e-01  1.514e-01  2.224e-01  2.732e+00  3.421e+00 -5.206e-01 -3.229e+00  1.256e+00  1.562e+00 -8.989e-01  1.468e+00  4.531e+00  1.048e+00  3.152e+00  4.127e-01 -2.577e+00 -1.007e+00  9.600e-01 -5.910e-01 -3.062e+00  9.553e-01  2.480e+00  2.710e+00  2.404e+00 -1.392e+00 -9.322e-01 -5.508e+00 -5.989e-01  1.031e+00 -2.686e+00 -1.624e-01 -1.011e-01  4.120e-01  2.333e+00 -3.575e+00  1.201e-01  8.641e-01  8.157e-01 -5.433e-01  1.033e+00 -2.092e+00  1.268e+00 -1.071e+00 -3.366e+00 -2.073e+00 -6.799e-01 -5.956e+00 -4.231e-01  3.382e+00  1.676e+00 -4.808e+00  3.714e+00 -4.023e+00 -1.809e+00 -4.727e+00 -1.019e+00 -7.813e-01  1.527e+00  1.528e+00 -2.223e+00 -2.358e+00  1.301e+00 -7.619e-01 -4.080e-01 -2.077e-01  4.066e+00 -3.117e+00 -2.936e+00 -2.160e+00  4.241e+00 -3.396e+00 -1.076e+00 -2.402e+00  3.591e+00  2.463e+00 -3.211e+00  6.781e-01 -8.721e-01  5.642e+00  1.912e+00 -6.289e-01 -1.586e+00  2.667e+00 -1.277e+00 -1.516e+00 -7.918e-01  3.776e+00 -2.892e+00 -3.220e+00  2.816e+00 -5.472e-01 -3.343e-01 -1.218e-01  3.629e+00  4.556e+00 -1.648e+00  2.750e+00 -4.775e+00 -1.440e+00 -8.873e-01 -2.687e+00 -3.214e-01 -6.432e+00 -2.396e+00  1.127e+00 -2.219e+00  3.271e+00 -2.660e+00  3.358e+00 -3.511e+00 -7.481e-01 -3.909e+00  1.409e+00  2.419e-01  1.678e+00 -2.472e+00 -1.364e+00 -5.443e-01 -2.655e-01  2.897e+00 -3.106e+00  2.878e+00  2.953e+00 -1.123e+00  5.772e+00  2.100e+00  1.706e+00  3.918e+00  1.338e+00 -3.742e+00  5.315e-01 -2.637e+00  1.095e+00 -9.199e-02 -2.212e+00 -8.000e-01 -1.490e+00 -4.198e+00  4.349e+00  4.927e-01 -3.368e+00 -2.261e+00 -2.907e+00  3.876e+00 -3.722e-01  6.249e-02 -4.972e-01 -1.540e+00 -2.288e+00 -2.640e+00 -3.511e+00 -1.291e+00  4.860e-01  7.601e-01  5.367e+00  2.762e+00  8.355e-01 -4.575e+00  2.701e+00  2.292e-01 -2.781e+00 -2.506e-01  5.757e-01 -4.913e+00  6.137e-01
			  -3.158e+00 -3.746e-01  4.663e+00  1.666e+00 -9.102e-01 -1.213e-02  1.416e+00 -2.312e+00 -2.409e+00 -1.176e+00  5.167e+00 -5.673e+00  2.195e+00 -1.007e+00  7.577e-01 -3.123e+00 -2.920e+00  2.105e+00 -9.917e-01  6.993e-01 -9.383e-01 -4.566e-01 -4.733e+00 -2.721e+00 -8.408e-01 -5.913e+00 -1.154e+00  7.341e-01 -3.847e+00 -1.805e-01  2.614e+00  6.229e+00  2.050e+00 -5.936e+00  2.927e+00 -2.700e+00 -4.966e+00  1.242e+00 -2.137e+00  7.265e-01  1.139e+00 -5.832e+00  4.452e-01 -5.702e+00 -2.106e-01 -2.214e+00 -3.858e+00  3.559e+00  2.974e+00 -7.419e-01  7.310e-02 -6.935e-01 -1.864e-01  5.387e-01  7.733e-01 -1.572e-01 -7.541e+00  5.038e+00 -2.599e+00 -7.534e-01  6.495e-01 -2.714e-01  1.596e+00  1.923e+00  1.662e+00 -3.122e+00 -1.770e+00 -1.232e+00 -8.488e-01 -2.250e+00 -1.013e+00  1.728e+00  2.781e+00  1.139e+00  2.149e+00 -4.808e-02 -1.639e-01  2.870e+00  1.903e+00  3.758e-01 -2.554e+00  5.270e+00 -1.874e+00  2.971e+00 -9.489e-01  5.899e-01  1.017e+00 -1.730e-01  8.771e-01 -4.111e+00 -9.838e-01  2.933e+00  2.302e+00 -2.890e+00 -2.041e+00 -1.432e+00 -1.900e+00 -2.107e+00 -1.734e-01 -1.577e+00 -4.959e+00 -1.968e+00 -2.232e+00 -2.425e+00  2.322e+00 -1.093e+00  1.584e+00  4.980e-01 -2.609e+00 -2.545e+00 -5.117e+00 -2.972e+00 -3.726e-01  2.160e+00  2.998e+00  1.502e+00 -2.999e+00 -1.134e+00  1.770e+00 -3.467e+00  7.264e-01 -2.876e+00  4.693e-03 -1.059e+00 -6.949e-01  2.574e-01  8.228e+00  1.061e+00  1.091e+00  1.353e+00 -1.039e+00 -2.379e+00 -2.044e+00  1.031e+00 -1.701e+00 -3.090e+00  4.054e+00  2.274e+00  8.220e-01  1.300e+00  7.927e+00  4.084e+00  1.357e+00  2.435e+00 -8.197e-01  1.284e-01 -2.333e+00 -2.292e+00  4.457e+00 -4.739e+00  3.731e+00  2.924e+00  3.967e+00 -2.908e+00  1.112e+00 -3.408e+00  2.517e+00  4.931e+00  1.485e+00  3.819e+00  5.399e+00 -1.226e+00 -2.628e+00 -3.135e+00  2.175e-01 -3.667e-01  2.379e+00  2.552e+00  1.019e+00 -5.605e-01  4.573e+00  7.193e-01  5.047e+00 -3.883e+00  1.411e+00 -2.319e+00 -2.547e+00  3.725e+00  3.702e-01  2.014e+00  5.958e-01
			  -2.305e+00  4.463e-01  1.916e+00  3.349e+00  2.142e+00  2.795e-01 -3.826e+00 -8.677e-01  4.374e-01  9.368e-01  8.030e-01  7.858e-01 -1.257e+00  1.801e-01  1.263e-01 -1.557e+00 -2.046e+00  3.201e+00  2.699e+00  1.749e+00 -4.162e-01 -4.476e+00 -4.718e-01  6.653e-01 -3.975e+00  3.244e+00 -2.318e+00  3.195e-01 -3.617e-01 -7.543e-01 -3.819e-01  5.920e+00  1.150e+00 -4.750e+00 -3.021e+00 -6.697e-01  7.204e+00 -2.552e+00  8.760e-01 -1.609e-01  4.063e+00  2.090e+00  3.815e+00  5.922e-01 -5.004e+00 -2.990e+00 -2.106e+00  2.985e+00  1.401e+00  2.261e+00  2.807e+00 -2.724e+00  2.871e+00  3.684e+00  2.512e+00 -1.640e+00 -2.913e+00  3.196e+00  2.229e-02 -2.324e+00  1.296e+00 -9.917e-01 -3.587e+00  3.312e+00  8.509e-01 -1.721e+00  1.536e+00 -5.538e-01  5.477e-01  4.349e-01 -2.805e-01 -8.221e-01 -3.424e-01  2.378e+00 -1.023e+00 -2.873e+00 -1.752e+00 -5.891e+00 -3.371e+00 -1.771e+00  1.273e+00  6.830e+00  1.489e+00 -4.319e-01  2.577e-02 -2.168e-01  3.781e+00  2.895e+00  3.511e+00  5.720e-01 -3.091e+00  6.211e+00  2.875e+00  1.266e+00  2.780e+00]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fc89fd68358> 
			buffer = deque([], maxlen=1000000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fc89fd68438> 
		size = (1,)
		dt = 0.2
		action = [ 0.147]
		daction_dt = [-1.545]
	discrete = False
	action_size = (1,)
	state_size = (3,)
	config = <src.utils.config.Config object at 0x7fc8a008bc18> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 1000
		TARGET_UPDATE_RATE = 0.0004
		TRAIN_EVERY = 1000
		BATCH_SIZE = 250
		EPS_CYCLE = 10000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7fc8c5f32160> 
			NSAMPLES = 1000
			HORIZON = 20
			LAMBDA = 0.1
			COV = 1
		dynamics_size = 3
		state_size = (3,)
		action_size = (1,)
		env_name = Pendulum-v0
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7fc8c4477a90> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.98
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7fc89fd68470> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		noise = self.noise[...,:horizon,:] * max(eps if eps else 0, 0.1)
		controls = np.clip(self.control[:,None,:horizon,:] + noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1)# + self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control[...,:horizon,:] += np.sum(weights[:,:,None,None]*noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: self.to_tensor(x)[None], zip(*buffer))
			buffer.clear()
			values = self.network.envmodel.network.reward(actions, states, next_states)[0]
			rewards = self.compute_gae(0*values[-1], rewards.transpose(0,1), dones.transpose(0,1), values)[0].transpose(0,1)
			states, actions, next_states, rewards, dones = map(lambda x: x.cpu().numpy(), [states, actions, next_states, rewards, dones])
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.EPS_CYCLE)/self.config.EPS_CYCLE if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward: -1511.864 [ 109.029], Avg: -1511.864 (1.000) <0-00:00:00> ({'r_t':    -2.5049, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward: -1496.313 [  77.913], Avg: -1504.088 (1.000) <0-00:00:24> ({'r_t': -6232.6525, 'eps':     1.0000, 'len':    32.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    2000, Reward: -1526.302 [  80.590], Avg: -1511.493 (1.000) <0-00:00:49> ({'r_t': -6317.6402, 'eps':     1.0000, 'len':   112.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    3000, Reward: -1522.560 [ 100.121], Avg: -1514.260 (1.000) <0-00:01:13> ({'r_t': -6193.5430, 'eps':     1.0000, 'len':   192.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    4000, Reward: -1497.552 [  83.881], Avg: -1510.918 (1.000) <0-00:01:38> ({'r_t': -6211.7048, 'eps':     1.0000, 'len':   272.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    5000, Reward: -1529.472 [  63.785], Avg: -1514.010 (1.000) <0-00:02:02> ({'r_t': -6059.8326, 'eps':     1.0000, 'len':   352.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    6000, Reward: -1521.394 [  83.458], Avg: -1515.065 (1.000) <0-00:02:27> ({'r_t': -6140.2621, 'eps':     1.0000, 'len':   432.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    7000, Reward: -1516.254 [  65.044], Avg: -1515.214 (1.000) <0-00:02:51> ({'r_t': -6163.7535, 'eps':     1.0000, 'len':   512.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    8000, Reward: -1516.537 [  64.073], Avg: -1515.361 (1.000) <0-00:03:16> ({'r_t': -5985.0943, 'eps':     1.0000, 'len':   592.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    9000, Reward: -1535.657 [  63.279], Avg: -1517.390 (1.000) <0-00:03:40> ({'r_t': -6222.4590, 'eps':     1.0000, 'len':   672.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   10000, Reward: -1465.166 [ 201.616], Avg: -1512.643 (1.000) <0-00:04:05> ({'r_t': -6252.2199, 'eps':     1.0000, 'len':   752.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   11000, Reward: -1476.776 [  94.147], Avg: -1509.654 (1.000) <0-00:04:29> ({'r_t': -6164.5140, 'eps':     1.0000, 'len':   832.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   12000, Reward: -1533.590 [  75.100], Avg: -1511.495 (1.000) <0-00:04:54> ({'r_t': -6150.5288, 'eps':     1.0000, 'len':   912.1600, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:   13000, Reward: -1670.791 [  70.266], Avg: -1522.873 (0.300) <0-00:05:47> ({'r_t': -6085.3576, 'eps':     0.3001, 'len':   992.1600, 'dyn_loss':    33.8286, 'dot_loss':     1.9901, 'ddot_loss':     0.5788, 'rew_loss':  5595.6953, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:   14000, Reward: -1540.155 [ 119.722], Avg: -1524.026 (0.400) <0-00:07:55> ({'r_t': -8616.2728, 'eps':     0.4001, 'len':  1072.1600, 'dyn_loss':    11.3776, 'dot_loss':     0.6628, 'ddot_loss':     0.3302, 'rew_loss':  3165.4226, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:   15000, Reward:  -975.921 [ 255.866], Avg: -1489.769 (0.500) <0-00:09:52> ({'r_t': -7397.9346, 'eps':     0.5001, 'len':  1152.1600, 'dyn_loss':     7.7022, 'dot_loss':     0.5210, 'ddot_loss':     0.3123, 'rew_loss':  2140.7532, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:   16000, Reward:  -208.204 [ 145.325], Avg: -1414.383 (0.600) <0-00:11:38> ({'r_t': -6296.4296, 'eps':     0.6001, 'len':  1232.1600, 'dyn_loss':     4.7957, 'dot_loss':     0.4260, 'ddot_loss':     0.3007, 'rew_loss':  1752.9136, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:   17000, Reward:  -206.497 [ 112.712], Avg: -1347.278 (0.700) <0-00:13:12> ({'r_t': -4842.8428, 'eps':     0.7001, 'len':  1312.1600, 'dyn_loss':     3.0055, 'dot_loss':     0.3636, 'ddot_loss':     0.3030, 'rew_loss':  1218.8436, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:   18000, Reward:  -174.064 [  93.207], Avg: -1285.530 (0.800) <0-00:14:34> ({'r_t': -5319.6178, 'eps':     0.8001, 'len':  1392.1600, 'dyn_loss':     1.8893, 'dot_loss':     0.3118, 'ddot_loss':     0.3046, 'rew_loss':  1178.2858, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:   19000, Reward:  -191.556 [  89.099], Avg: -1230.831 (0.900) <0-00:15:46> ({'r_t': -5528.0253, 'eps':     0.9001, 'len':  1472.1600, 'dyn_loss':     1.2562, 'dot_loss':     0.2697, 'ddot_loss':     0.2989, 'rew_loss':  1275.9823, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:   20000, Reward:  -173.761 [  73.483], Avg: -1180.495 (0.000) <0-00:16:47> ({'r_t': -6016.9122, 'eps':     0.0001, 'len':  1552.1600, 'dyn_loss':     0.8558, 'dot_loss':     0.2262, 'ddot_loss':     0.2788, 'rew_loss':  1451.5139, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:   21000, Reward:  -214.573 [ 103.338], Avg: -1136.589 (0.100) <0-00:19:31> ({'r_t':  -833.7464, 'eps':     0.1001, 'len':  1632.1600, 'dyn_loss':     0.6119, 'dot_loss':     0.1808, 'ddot_loss':     0.2446, 'rew_loss':  1437.3040, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:   22000, Reward:  -191.210 [  86.273], Avg: -1095.486 (0.200) <0-00:22:03> ({'r_t':  -783.0902, 'eps':     0.2001, 'len':  1712.1600, 'dyn_loss':     0.4849, 'dot_loss':     0.1560, 'ddot_loss':     0.2261, 'rew_loss':  1294.0046, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:   23000, Reward:  -174.739 [  99.875], Avg: -1057.121 (0.300) <0-00:24:47> ({'r_t':  -936.2370, 'eps':     0.3001, 'len':  1792.1600, 'dyn_loss':     0.3874, 'dot_loss':     0.1300, 'ddot_loss':     0.2014, 'rew_loss':  1312.6981, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:   24000, Reward:  -179.213 [  95.146], Avg: -1022.005 (0.400) <0-00:27:20> ({'r_t': -1793.1169, 'eps':     0.4001, 'len':  1872.1600, 'dyn_loss':     0.3358, 'dot_loss':     0.1117, 'ddot_loss':     0.1829, 'rew_loss':  1202.9966, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:   25000, Reward:  -237.870 [ 100.512], Avg:  -991.846 (0.500) <0-00:29:41> ({'r_t': -2596.3019, 'eps':     0.5001, 'len':  1952.1600, 'dyn_loss':     0.3066, 'dot_loss':     0.0950, 'ddot_loss':     0.1627, 'rew_loss':  1197.7667, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:   26000, Reward:  -170.934 [  82.113], Avg:  -961.442 (0.600) <0-00:31:50> ({'r_t': -3206.6972, 'eps':     0.6001, 'len':  2032.1600, 'dyn_loss':     0.2882, 'dot_loss':     0.0834, 'ddot_loss':     0.1478, 'rew_loss':  1123.1407, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:   27000, Reward:  -191.501 [  92.863], Avg:  -933.944 (0.700) <0-00:33:48> ({'r_t': -4013.5488, 'eps':     0.7001, 'len':  2112.1600, 'dyn_loss':     0.2642, 'dot_loss':     0.0746, 'ddot_loss':     0.1370, 'rew_loss':  1253.2767, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:   28000, Reward:  -182.133 [ 100.323], Avg:  -908.019 (0.800) <0-00:35:34> ({'r_t': -4388.5246, 'eps':     0.8001, 'len':  2192.1600, 'dyn_loss':     0.2451, 'dot_loss':     0.0656, 'ddot_loss':     0.1243, 'rew_loss':  1267.1438, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:   29000, Reward:  -224.012 [ 117.772], Avg:  -885.219 (0.900) <0-00:37:09> ({'r_t': -5585.4005, 'eps':     0.9001, 'len':  2272.1600, 'dyn_loss':     0.2206, 'dot_loss':     0.0567, 'ddot_loss':     0.1110, 'rew_loss':  1361.9763, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:   30000, Reward:  -198.710 [ 106.432], Avg:  -863.074 (0.000) <0-00:38:34> ({'r_t': -6100.6645, 'eps':     0.0001, 'len':  2352.1600, 'dyn_loss':     0.2083, 'dot_loss':     0.0509, 'ddot_loss':     0.1020, 'rew_loss':  1548.3665, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:   31000, Reward:  -198.551 [  91.674], Avg:  -842.307 (0.100) <0-00:41:41> ({'r_t':  -816.7045, 'eps':     0.1001, 'len':  2432.1600, 'dyn_loss':     0.1929, 'dot_loss':     0.0455, 'ddot_loss':     0.0934, 'rew_loss':  1553.1445, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:   32000, Reward:  -166.086 [  86.965], Avg:  -821.816 (0.200) <0-00:44:37> ({'r_t':  -955.5897, 'eps':     0.2001, 'len':  2512.1600, 'dyn_loss':     0.1770, 'dot_loss':     0.0401, 'ddot_loss':     0.0838, 'rew_loss':  1496.8086, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:   33000, Reward:  -213.117 [  82.804], Avg:  -803.913 (0.300) <0-00:47:21> ({'r_t': -1832.9279, 'eps':     0.3001, 'len':  2592.1600, 'dyn_loss':     0.1711, 'dot_loss':     0.0359, 'ddot_loss':     0.0763, 'rew_loss':  1454.9572, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:   34000, Reward:  -173.523 [ 110.122], Avg:  -785.902 (0.400) <0-00:49:54> ({'r_t': -2047.6664, 'eps':     0.4001, 'len':  2672.1600, 'dyn_loss':     0.1686, 'dot_loss':     0.0334, 'ddot_loss':     0.0714, 'rew_loss':  1391.2529, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:   35000, Reward:  -185.844 [ 125.747], Avg:  -769.233 (0.500) <0-00:52:15> ({'r_t': -2562.4091, 'eps':     0.5001, 'len':  2752.1600, 'dyn_loss':     0.1731, 'dot_loss':     0.0311, 'ddot_loss':     0.0665, 'rew_loss':  1322.0580, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:   36000, Reward:  -169.640 [  86.748], Avg:  -753.028 (0.600) <0-00:54:25> ({'r_t': -3260.6211, 'eps':     0.6001, 'len':  2832.1600, 'dyn_loss':     0.1657, 'dot_loss':     0.0286, 'ddot_loss':     0.0619, 'rew_loss':  1376.2355, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:   37000, Reward:  -229.723 [ 109.871], Avg:  -739.257 (0.700) <0-00:56:22> ({'r_t': -3952.0842, 'eps':     0.7001, 'len':  2912.1600, 'dyn_loss':     0.1612, 'dot_loss':     0.0272, 'ddot_loss':     0.0598, 'rew_loss':  1417.7013, 'lr':   9.80e-05, 'eps_e':     0.7001, 'lr_e':   9.80e-05})
Step:   38000, Reward:  -193.439 [  78.231], Avg:  -725.262 (0.800) <0-00:58:08> ({'r_t': -4575.4401, 'eps':     0.8001, 'len':  2992.1600, 'dyn_loss':     0.1545, 'dot_loss':     0.0253, 'ddot_loss':     0.0562, 'rew_loss':  1421.7251, 'lr':   9.80e-05, 'eps_e':     0.8001, 'lr_e':   9.80e-05})
Step:   39000, Reward:  -188.508 [ 112.812], Avg:  -711.843 (0.900) <0-00:59:42> ({'r_t': -5335.2453, 'eps':     0.9001, 'len':  3072.1600, 'dyn_loss':     0.1568, 'dot_loss':     0.0243, 'ddot_loss':     0.0542, 'rew_loss':  1473.1952, 'lr':   9.80e-05, 'eps_e':     0.9001, 'lr_e':   9.80e-05})
Step:   40000, Reward:  -171.587 [  86.039], Avg:  -698.666 (0.000) <0-01:01:07> ({'r_t': -6010.3325, 'eps':     0.0001, 'len':  3152.1600, 'dyn_loss':     0.1460, 'dot_loss':     0.0229, 'ddot_loss':     0.0518, 'rew_loss':  1526.2430, 'lr':   9.80e-05, 'eps_e':     0.0001, 'lr_e':   9.80e-05})
Step:   41000, Reward:  -186.038 [  97.231], Avg:  -686.460 (0.100) <0-01:04:14> ({'r_t':  -814.8109, 'eps':     0.1001, 'len':  3232.1600, 'dyn_loss':     0.1386, 'dot_loss':     0.0209, 'ddot_loss':     0.0476, 'rew_loss':  1531.4036, 'lr':   9.80e-05, 'eps_e':     0.1001, 'lr_e':   9.80e-05})
Step:   42000, Reward:  -224.233 [  95.324], Avg:  -675.711 (0.200) <0-01:07:09> ({'r_t':  -906.1245, 'eps':     0.2001, 'len':  3312.1600, 'dyn_loss':     0.1320, 'dot_loss':     0.0198, 'ddot_loss':     0.0455, 'rew_loss':  1497.3339, 'lr':   9.80e-05, 'eps_e':     0.2001, 'lr_e':   9.80e-05})
Step:   43000, Reward:  -178.010 [ 111.478], Avg:  -664.400 (0.300) <0-01:09:53> ({'r_t': -1707.7350, 'eps':     0.3001, 'len':  3392.1600, 'dyn_loss':     0.1255, 'dot_loss':     0.0186, 'ddot_loss':     0.0432, 'rew_loss':  1538.1003, 'lr':   9.80e-05, 'eps_e':     0.3001, 'lr_e':   9.80e-05})
Step:   44000, Reward:  -233.077 [ 112.603], Avg:  -654.815 (0.400) <0-01:12:25> ({'r_t': -1954.6116, 'eps':     0.4001, 'len':  3472.1600, 'dyn_loss':     0.1282, 'dot_loss':     0.0178, 'ddot_loss':     0.0410, 'rew_loss':  1480.4563, 'lr':   9.80e-05, 'eps_e':     0.4001, 'lr_e':   9.80e-05})
Step:   45000, Reward:  -190.913 [  93.963], Avg:  -644.730 (0.500) <0-01:14:46> ({'r_t': -2672.8830, 'eps':     0.5001, 'len':  3552.1600, 'dyn_loss':     0.1330, 'dot_loss':     0.0177, 'ddot_loss':     0.0406, 'rew_loss':  1462.8560, 'lr':   9.80e-05, 'eps_e':     0.5001, 'lr_e':   9.80e-05})
Step:   46000, Reward:  -175.682 [  93.665], Avg:  -634.750 (0.600) <0-01:16:55> ({'r_t': -3180.5961, 'eps':     0.6001, 'len':  3632.1600, 'dyn_loss':     0.1244, 'dot_loss':     0.0170, 'ddot_loss':     0.0395, 'rew_loss':  1514.8646, 'lr':   9.80e-05, 'eps_e':     0.6001, 'lr_e':   9.80e-05})
Step:   47000, Reward:  -168.547 [  74.848], Avg:  -625.037 (0.700) <0-01:18:53> ({'r_t': -3849.2166, 'eps':     0.7001, 'len':  3712.1600, 'dyn_loss':     0.1318, 'dot_loss':     0.0167, 'ddot_loss':     0.0386, 'rew_loss':  1512.7025, 'lr':   9.80e-05, 'eps_e':     0.7001, 'lr_e':   9.80e-05})
Step:   48000, Reward:  -160.974 [  77.813], Avg:  -615.567 (0.800) <0-01:20:39> ({'r_t': -4698.9975, 'eps':     0.8001, 'len':  3792.1600, 'dyn_loss':     0.1274, 'dot_loss':     0.0161, 'ddot_loss':     0.0378, 'rew_loss':  1570.7012, 'lr':   9.60e-05, 'eps_e':     0.8001, 'lr_e':   9.60e-05})
Step:   49000, Reward:  -194.059 [  80.853], Avg:  -607.137 (0.900) <0-01:22:13> ({'r_t': -5186.9315, 'eps':     0.9001, 'len':  3872.1600, 'dyn_loss':     0.1320, 'dot_loss':     0.0163, 'ddot_loss':     0.0380, 'rew_loss':  1548.9923, 'lr':   9.60e-05, 'eps_e':     0.9001, 'lr_e':   9.60e-05})
Step:   50000, Reward:  -224.448 [ 127.201], Avg:  -599.633 (0.000) <0-01:23:37> ({'r_t': -6037.8342, 'eps':     0.0001, 'len':  3952.1600, 'dyn_loss':     0.1278, 'dot_loss':     0.0156, 'ddot_loss':     0.0364, 'rew_loss':  1554.3774, 'lr':   9.60e-05, 'eps_e':     0.0001, 'lr_e':   9.60e-05})
Step:   51000, Reward:  -215.986 [  83.733], Avg:  -592.255 (0.100) <0-01:26:44> ({'r_t':  -936.1665, 'eps':     0.1001, 'len':  4032.1600, 'dyn_loss':     0.1234, 'dot_loss':     0.0152, 'ddot_loss':     0.0359, 'rew_loss':  1619.4366, 'lr':   9.60e-05, 'eps_e':     0.1001, 'lr_e':   9.60e-05})
Step:   52000, Reward:  -212.641 [ 102.336], Avg:  -585.093 (0.200) <0-01:29:40> ({'r_t':  -924.9884, 'eps':     0.2001, 'len':  4112.1600, 'dyn_loss':     0.1225, 'dot_loss':     0.0149, 'ddot_loss':     0.0354, 'rew_loss':  1523.0177, 'lr':   9.60e-05, 'eps_e':     0.2001, 'lr_e':   9.60e-05})
Step:   53000, Reward:  -183.756 [  56.547], Avg:  -577.660 (0.300) <0-01:32:24> ({'r_t': -1454.4930, 'eps':     0.3001, 'len':  4192.1600, 'dyn_loss':     0.1185, 'dot_loss':     0.0144, 'ddot_loss':     0.0342, 'rew_loss':  1493.8994, 'lr':   9.60e-05, 'eps_e':     0.3001, 'lr_e':   9.60e-05})
Step:   54000, Reward:  -208.973 [  88.100], Avg:  -570.957 (0.400) <0-01:34:57> ({'r_t': -2126.9130, 'eps':     0.4001, 'len':  4272.1600, 'dyn_loss':     0.1134, 'dot_loss':     0.0138, 'ddot_loss':     0.0332, 'rew_loss':  1535.2952, 'lr':   9.60e-05, 'eps_e':     0.4001, 'lr_e':   9.60e-05})
Step:   55000, Reward:  -188.106 [  93.931], Avg:  -564.120 (0.500) <0-01:37:18> ({'r_t': -2623.3898, 'eps':     0.5001, 'len':  4352.1600, 'dyn_loss':     0.1179, 'dot_loss':     0.0140, 'ddot_loss':     0.0334, 'rew_loss':  1540.3639, 'lr':   9.60e-05, 'eps_e':     0.5001, 'lr_e':   9.60e-05})
Step:   56000, Reward:  -195.781 [ 102.916], Avg:  -557.658 (0.600) <0-01:39:09> ({'r_t': -3242.5302, 'eps':     0.6001, 'len':  4432.1600, 'dyn_loss':     0.1179, 'dot_loss':     0.0141, 'ddot_loss':     0.0336, 'rew_loss':  1421.4197, 'lr':   9.60e-05, 'eps_e':     0.6001, 'lr_e':   9.60e-05})
Step:   57000, Reward:  -146.552 [  56.063], Avg:  -550.570 (0.700) <0-01:40:43> ({'r_t': -3832.0369, 'eps':     0.7001, 'len':  4512.1600, 'dyn_loss':     0.1179, 'dot_loss':     0.0139, 'ddot_loss':     0.0333, 'rew_loss':  1436.3083, 'lr':   9.60e-05, 'eps_e':     0.7001, 'lr_e':   9.60e-05})
Step:   58000, Reward:  -202.000 [ 103.764], Avg:  -544.662 (0.800) <0-01:42:05> ({'r_t': -4509.6479, 'eps':     0.8001, 'len':  4592.1600, 'dyn_loss':     0.1162, 'dot_loss':     0.0136, 'ddot_loss':     0.0328, 'rew_loss':  1494.9844, 'lr':   9.60e-05, 'eps_e':     0.8001, 'lr_e':   9.60e-05})
Step:   59000, Reward:  -173.854 [ 110.123], Avg:  -538.482 (0.900) <0-01:43:16> ({'r_t': -5317.8813, 'eps':     0.9001, 'len':  4672.1600, 'dyn_loss':     0.1203, 'dot_loss':     0.0138, 'ddot_loss':     0.0335, 'rew_loss':  1551.4277, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:   60000, Reward:  -176.589 [ 100.966], Avg:  -532.549 (0.000) <0-01:44:18> ({'r_t': -6066.3380, 'eps':     0.0001, 'len':  4752.1600, 'dyn_loss':     0.1210, 'dot_loss':     0.0138, 'ddot_loss':     0.0333, 'rew_loss':  1634.6777, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:   61000, Reward:  -132.237 [  41.557], Avg:  -526.093 (0.100) <0-01:47:01> ({'r_t': -1013.6098, 'eps':     0.1001, 'len':  4832.1600, 'dyn_loss':     0.1159, 'dot_loss':     0.0134, 'ddot_loss':     0.0326, 'rew_loss':  1532.7952, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:   62000, Reward:  -209.246 [  89.746], Avg:  -521.064 (0.200) <0-01:49:33> ({'r_t':  -976.4066, 'eps':     0.2001, 'len':  4912.1600, 'dyn_loss':     0.1126, 'dot_loss':     0.0130, 'ddot_loss':     0.0316, 'rew_loss':  1494.2028, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:   63000, Reward:  -188.503 [ 105.138], Avg:  -515.867 (0.300) <0-01:51:53> ({'r_t': -1464.4174, 'eps':     0.3001, 'len':  4992.1600, 'dyn_loss':     0.1107, 'dot_loss':     0.0130, 'ddot_loss':     0.0315, 'rew_loss':  1484.0990, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:   64000, Reward:  -181.015 [ 105.152], Avg:  -510.716 (0.400) <0-01:54:02> ({'r_t': -2067.5776, 'eps':     0.4001, 'len':  5072.1600, 'dyn_loss':     0.1135, 'dot_loss':     0.0132, 'ddot_loss':     0.0323, 'rew_loss':  1541.2764, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:   65000, Reward:  -200.465 [ 109.340], Avg:  -506.015 (0.500) <0-01:56:00> ({'r_t': -2737.6277, 'eps':     0.5001, 'len':  5152.1600, 'dyn_loss':     0.1185, 'dot_loss':     0.0135, 'ddot_loss':     0.0327, 'rew_loss':  1509.3339, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:   66000, Reward:  -182.366 [  79.618], Avg:  -501.184 (0.600) <0-01:57:46> ({'r_t': -3281.4926, 'eps':     0.6001, 'len':  5232.1600, 'dyn_loss':     0.1098, 'dot_loss':     0.0129, 'ddot_loss':     0.0315, 'rew_loss':  1459.2357, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:   67000, Reward:  -177.762 [  73.671], Avg:  -496.428 (0.700) <0-01:59:20> ({'r_t': -4098.6881, 'eps':     0.7001, 'len':  5312.1600, 'dyn_loss':     0.1095, 'dot_loss':     0.0126, 'ddot_loss':     0.0312, 'rew_loss':  1610.3309, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:   68000, Reward:  -221.163 [  95.870], Avg:  -492.439 (0.800) <0-02:00:43> ({'r_t': -4574.7149, 'eps':     0.8001, 'len':  5392.1600, 'dyn_loss':     0.1142, 'dot_loss':     0.0129, 'ddot_loss':     0.0315, 'rew_loss':  1509.0226, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:   69000, Reward:  -182.065 [  79.079], Avg:  -488.005 (0.900) <0-02:01:54> ({'r_t': -5210.2947, 'eps':     0.9001, 'len':  5472.1600, 'dyn_loss':     0.1098, 'dot_loss':     0.0128, 'ddot_loss':     0.0317, 'rew_loss':  1594.4052, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:   70000, Reward:  -177.396 [  71.648], Avg:  -483.630 (0.000) <0-02:02:56> ({'r_t': -5957.9789, 'eps':     0.0001, 'len':  5552.1600, 'dyn_loss':     0.1118, 'dot_loss':     0.0129, 'ddot_loss':     0.0318, 'rew_loss':  1555.8445, 'lr':   9.22e-05, 'eps_e':     0.0001, 'lr_e':   9.22e-05})
Step:   71000, Reward:  -199.366 [ 109.663], Avg:  -479.682 (0.100) <0-02:05:39> ({'r_t':  -963.2013, 'eps':     0.1001, 'len':  5632.1600, 'dyn_loss':     0.1057, 'dot_loss':     0.0122, 'ddot_loss':     0.0304, 'rew_loss':  1613.0458, 'lr':   9.22e-05, 'eps_e':     0.1001, 'lr_e':   9.22e-05})
Step:   72000, Reward:  -150.491 [  63.599], Avg:  -475.172 (0.200) <0-02:08:10> ({'r_t': -1103.5852, 'eps':     0.2001, 'len':  5712.1600, 'dyn_loss':     0.1128, 'dot_loss':     0.0128, 'ddot_loss':     0.0319, 'rew_loss':  1705.6438, 'lr':   9.22e-05, 'eps_e':     0.2001, 'lr_e':   9.22e-05})
Step:   73000, Reward:  -200.914 [  82.559], Avg:  -471.466 (0.300) <0-02:10:31> ({'r_t': -1595.7159, 'eps':     0.3001, 'len':  5792.1600, 'dyn_loss':     0.0997, 'dot_loss':     0.0119, 'ddot_loss':     0.0301, 'rew_loss':  1645.3630, 'lr':   9.22e-05, 'eps_e':     0.3001, 'lr_e':   9.22e-05})
Step:   74000, Reward:  -303.430 [ 324.912], Avg:  -469.226 (0.400) <0-02:12:40> ({'r_t': -1968.0883, 'eps':     0.4001, 'len':  5872.1600, 'dyn_loss':     0.1087, 'dot_loss':     0.0121, 'ddot_loss':     0.0301, 'rew_loss':  1604.2266, 'lr':   9.22e-05, 'eps_e':     0.4001, 'lr_e':   9.22e-05})
Step:   75000, Reward:  -170.670 [  80.370], Avg:  -465.297 (0.500) <0-02:14:37> ({'r_t': -2975.7787, 'eps':     0.5001, 'len':  5952.1600, 'dyn_loss':     0.0976, 'dot_loss':     0.0115, 'ddot_loss':     0.0295, 'rew_loss':  1684.6597, 'lr':   9.22e-05, 'eps_e':     0.5001, 'lr_e':   9.22e-05})
Step:   76000, Reward:  -149.418 [  39.832], Avg:  -461.195 (0.600) <0-02:16:23> ({'r_t': -3279.3963, 'eps':     0.6001, 'len':  6032.1600, 'dyn_loss':     0.1114, 'dot_loss':     0.0120, 'ddot_loss':     0.0295, 'rew_loss':  1547.1243, 'lr':   9.22e-05, 'eps_e':     0.6001, 'lr_e':   9.22e-05})
Step:   77000, Reward:  -177.062 [  97.980], Avg:  -457.552 (0.700) <0-02:17:57> ({'r_t': -4034.4571, 'eps':     0.7001, 'len':  6112.1600, 'dyn_loss':     0.1053, 'dot_loss':     0.0122, 'ddot_loss':     0.0301, 'rew_loss':  1579.6691, 'lr':   9.22e-05, 'eps_e':     0.7001, 'lr_e':   9.22e-05})
Step:   78000, Reward:  -213.849 [ 101.120], Avg:  -454.468 (0.800) <0-02:19:20> ({'r_t': -4536.1969, 'eps':     0.8001, 'len':  6192.1600, 'dyn_loss':     0.1085, 'dot_loss':     0.0122, 'ddot_loss':     0.0305, 'rew_loss':  1607.0004, 'lr':   9.22e-05, 'eps_e':     0.8001, 'lr_e':   9.22e-05})
Step:   79000, Reward:  -160.019 [  73.250], Avg:  -450.787 (0.900) <0-02:20:31> ({'r_t': -5376.6113, 'eps':     0.9001, 'len':  6272.1600, 'dyn_loss':     0.1080, 'dot_loss':     0.0122, 'ddot_loss':     0.0302, 'rew_loss':  1572.1024, 'lr':   9.22e-05, 'eps_e':     0.9001, 'lr_e':   9.22e-05})
Step:   80000, Reward:  -178.102 [  87.237], Avg:  -447.420 (0.000) <0-02:21:33> ({'r_t': -6016.0216, 'eps':     0.0001, 'len':  6352.1600, 'dyn_loss':     0.1046, 'dot_loss':     0.0120, 'ddot_loss':     0.0301, 'rew_loss':  1643.6141, 'lr':   9.22e-05, 'eps_e':     0.0001, 'lr_e':   9.22e-05})
Step:   81000, Reward:  -211.275 [ 106.739], Avg:  -444.541 (0.100) <0-02:24:16> ({'r_t':  -944.4937, 'eps':     0.1001, 'len':  6432.1600, 'dyn_loss':     0.1021, 'dot_loss':     0.0118, 'ddot_loss':     0.0298, 'rew_loss':  1625.0403, 'lr':   9.04e-05, 'eps_e':     0.1001, 'lr_e':   9.04e-05})
Step:   82000, Reward:  -188.778 [  77.837], Avg:  -441.459 (0.200) <0-02:26:47> ({'r_t': -1048.6312, 'eps':     0.2001, 'len':  6512.1600, 'dyn_loss':     0.1064, 'dot_loss':     0.0116, 'ddot_loss':     0.0293, 'rew_loss':  1697.0576, 'lr':   9.04e-05, 'eps_e':     0.2001, 'lr_e':   9.04e-05})
Step:   83000, Reward:  -161.828 [  49.267], Avg:  -438.130 (0.300) <0-02:29:08> ({'r_t': -1429.7249, 'eps':     0.3001, 'len':  6592.1600, 'dyn_loss':     0.1075, 'dot_loss':     0.0119, 'ddot_loss':     0.0299, 'rew_loss':  1619.7324, 'lr':   9.04e-05, 'eps_e':     0.3001, 'lr_e':   9.04e-05})
Step:   84000, Reward:  -219.448 [  97.342], Avg:  -435.557 (0.400) <0-02:31:16> ({'r_t': -2036.2712, 'eps':     0.4001, 'len':  6672.1600, 'dyn_loss':     0.1055, 'dot_loss':     0.0120, 'ddot_loss':     0.0304, 'rew_loss':  1625.1953, 'lr':   9.04e-05, 'eps_e':     0.4001, 'lr_e':   9.04e-05})
Step:   85000, Reward:  -182.374 [  98.777], Avg:  -432.613 (0.500) <0-02:33:13> ({'r_t': -2555.2685, 'eps':     0.5001, 'len':  6752.1600, 'dyn_loss':     0.1001, 'dot_loss':     0.0113, 'ddot_loss':     0.0287, 'rew_loss':  1566.5686, 'lr':   9.04e-05, 'eps_e':     0.5001, 'lr_e':   9.04e-05})
Step:   86000, Reward:  -169.079 [  72.794], Avg:  -429.584 (0.600) <0-02:34:59> ({'r_t': -3222.6978, 'eps':     0.6001, 'len':  6832.1600, 'dyn_loss':     0.1036, 'dot_loss':     0.0116, 'ddot_loss':     0.0291, 'rew_loss':  1566.5292, 'lr':   9.04e-05, 'eps_e':     0.6001, 'lr_e':   9.04e-05})
Step:   87000, Reward:  -182.869 [  94.367], Avg:  -426.781 (0.700) <0-02:36:33> ({'r_t': -4213.8831, 'eps':     0.7001, 'len':  6912.1600, 'dyn_loss':     0.1108, 'dot_loss':     0.0120, 'ddot_loss':     0.0298, 'rew_loss':  1559.3927, 'lr':   9.04e-05, 'eps_e':     0.7001, 'lr_e':   9.04e-05})
Step:   88000, Reward:  -196.188 [  86.102], Avg:  -424.190 (0.800) <0-02:37:56> ({'r_t': -4750.7070, 'eps':     0.8001, 'len':  6992.1600, 'dyn_loss':     0.1088, 'dot_loss':     0.0116, 'ddot_loss':     0.0291, 'rew_loss':  1630.4243, 'lr':   9.04e-05, 'eps_e':     0.8001, 'lr_e':   9.04e-05})
Step:   89000, Reward:  -206.503 [  81.876], Avg:  -421.771 (0.900) <0-02:39:07> ({'r_t': -5302.2665, 'eps':     0.9001, 'len':  7072.1600, 'dyn_loss':     0.1028, 'dot_loss':     0.0115, 'ddot_loss':     0.0292, 'rew_loss':  1719.0490, 'lr':   9.04e-05, 'eps_e':     0.9001, 'lr_e':   9.04e-05})
Step:   90000, Reward:  -221.019 [  76.546], Avg:  -419.565 (0.000) <0-02:40:09> ({'r_t': -6051.4961, 'eps':     0.0001, 'len':  7152.1600, 'dyn_loss':     0.1042, 'dot_loss':     0.0113, 'ddot_loss':     0.0284, 'rew_loss':  1644.0670, 'lr':   9.04e-05, 'eps_e':     0.0001, 'lr_e':   9.04e-05})
Step:   91000, Reward:  -140.362 [  51.606], Avg:  -416.530 (0.100) <0-02:42:52> ({'r_t':  -935.2975, 'eps':     0.1001, 'len':  7232.1600, 'dyn_loss':     0.1017, 'dot_loss':     0.0111, 'ddot_loss':     0.0280, 'rew_loss':  1631.2592, 'lr':   9.04e-05, 'eps_e':     0.1001, 'lr_e':   9.04e-05})
Step:   92000, Reward:  -198.214 [  95.290], Avg:  -414.183 (0.200) <0-02:45:27> ({'r_t': -1229.5554, 'eps':     0.2001, 'len':  7312.1600, 'dyn_loss':     0.0966, 'dot_loss':     0.0111, 'ddot_loss':     0.0286, 'rew_loss':  1701.6066, 'lr':   8.86e-05, 'eps_e':     0.2001, 'lr_e':   8.86e-05})
Step:   93000, Reward:  -201.313 [  96.452], Avg:  -411.918 (0.300) <0-02:47:47> ({'r_t': -1560.0326, 'eps':     0.3001, 'len':  7392.1600, 'dyn_loss':     0.0987, 'dot_loss':     0.0108, 'ddot_loss':     0.0275, 'rew_loss':  1611.7488, 'lr':   8.86e-05, 'eps_e':     0.3001, 'lr_e':   8.86e-05})
Step:   94000, Reward:  -165.680 [  83.270], Avg:  -409.326 (0.400) <0-02:49:56> ({'r_t': -1887.5968, 'eps':     0.4001, 'len':  7472.1600, 'dyn_loss':     0.1015, 'dot_loss':     0.0111, 'ddot_loss':     0.0286, 'rew_loss':  1676.2295, 'lr':   8.86e-05, 'eps_e':     0.4001, 'lr_e':   8.86e-05})
Step:   95000, Reward:  -192.442 [ 119.763], Avg:  -407.067 (0.500) <0-02:51:53> ({'r_t': -2453.5318, 'eps':     0.5001, 'len':  7552.1600, 'dyn_loss':     0.0987, 'dot_loss':     0.0112, 'ddot_loss':     0.0281, 'rew_loss':  1504.6204, 'lr':   8.86e-05, 'eps_e':     0.5001, 'lr_e':   8.86e-05})
Step:   96000, Reward:  -210.148 [  99.076], Avg:  -405.037 (0.600) <0-02:53:39> ({'r_t': -3239.0865, 'eps':     0.6001, 'len':  7632.1600, 'dyn_loss':     0.1023, 'dot_loss':     0.0113, 'ddot_loss':     0.0283, 'rew_loss':  1565.9116, 'lr':   8.86e-05, 'eps_e':     0.6001, 'lr_e':   8.86e-05})
Step:   97000, Reward:  -167.429 [ 114.618], Avg:  -402.612 (0.700) <0-02:55:14> ({'r_t': -4049.0900, 'eps':     0.7001, 'len':  7712.1600, 'dyn_loss':     0.1020, 'dot_loss':     0.0113, 'ddot_loss':     0.0285, 'rew_loss':  1656.6276, 'lr':   8.86e-05, 'eps_e':     0.7001, 'lr_e':   8.86e-05})
Step:   98000, Reward:  -201.148 [  79.635], Avg:  -400.577 (0.800) <0-02:56:36> ({'r_t': -4618.2351, 'eps':     0.8001, 'len':  7792.1600, 'dyn_loss':     0.1049, 'dot_loss':     0.0114, 'ddot_loss':     0.0287, 'rew_loss':  1607.0422, 'lr':   8.86e-05, 'eps_e':     0.8001, 'lr_e':   8.86e-05})
Step:   99000, Reward:  -173.954 [ 107.478], Avg:  -398.311 (0.900) <0-02:57:48> ({'r_t': -5298.1239, 'eps':     0.9001, 'len':  7872.1600, 'dyn_loss':     0.1034, 'dot_loss':     0.0112, 'ddot_loss':     0.0282, 'rew_loss':  1611.9927, 'lr':   8.86e-05, 'eps_e':     0.9001, 'lr_e':   8.86e-05})
Step:  100000, Reward:  -238.698 [ 129.687], Avg:  -396.731 (0.000) <0-02:58:50> ({'r_t': -5989.0309, 'eps':     0.0001, 'len':  7952.1600, 'dyn_loss':     0.1036, 'dot_loss':     0.0109, 'ddot_loss':     0.0282, 'rew_loss':  1656.9954, 'lr':   8.86e-05, 'eps_e':     0.0001, 'lr_e':   8.86e-05})
Step:  101000, Reward:  -177.123 [ 123.685], Avg:  -394.578 (0.100) <0-03:01:33> ({'r_t':  -957.7863, 'eps':     0.1001, 'len':  8032.1600, 'dyn_loss':     0.1003, 'dot_loss':     0.0108, 'ddot_loss':     0.0279, 'rew_loss':  1650.7828, 'lr':   8.86e-05, 'eps_e':     0.1001, 'lr_e':   8.86e-05})
Step:  102000, Reward:  -189.142 [ 100.427], Avg:  -392.583 (0.200) <0-03:04:04> ({'r_t': -1083.0959, 'eps':     0.2001, 'len':  8112.1600, 'dyn_loss':     0.0997, 'dot_loss':     0.0111, 'ddot_loss':     0.0283, 'rew_loss':  1576.0402, 'lr':   8.86e-05, 'eps_e':     0.2001, 'lr_e':   8.86e-05})
Step:  103000, Reward:  -183.799 [  70.562], Avg:  -390.576 (0.300) <0-03:06:24> ({'r_t': -1570.6420, 'eps':     0.3001, 'len':  8192.1600, 'dyn_loss':     0.1017, 'dot_loss':     0.0111, 'ddot_loss':     0.0284, 'rew_loss':  1642.4667, 'lr':   8.68e-05, 'eps_e':     0.3001, 'lr_e':   8.68e-05})
Step:  104000, Reward:  -153.407 [  74.920], Avg:  -388.317 (0.400) <0-03:08:33> ({'r_t': -1816.3678, 'eps':     0.4001, 'len':  8272.1600, 'dyn_loss':     0.1006, 'dot_loss':     0.0109, 'ddot_loss':     0.0275, 'rew_loss':  1597.3770, 'lr':   8.68e-05, 'eps_e':     0.4001, 'lr_e':   8.68e-05})
Step:  105000, Reward:  -221.428 [ 110.383], Avg:  -386.743 (0.500) <0-03:10:30> ({'r_t': -2681.8179, 'eps':     0.5001, 'len':  8352.1600, 'dyn_loss':     0.0983, 'dot_loss':     0.0111, 'ddot_loss':     0.0281, 'rew_loss':  1611.2874, 'lr':   8.68e-05, 'eps_e':     0.5001, 'lr_e':   8.68e-05})
Step:  106000, Reward:  -233.396 [  86.079], Avg:  -385.309 (0.600) <0-03:12:16> ({'r_t': -3193.1428, 'eps':     0.6001, 'len':  8432.1600, 'dyn_loss':     0.1057, 'dot_loss':     0.0116, 'ddot_loss':     0.0289, 'rew_loss':  1570.6974, 'lr':   8.68e-05, 'eps_e':     0.6001, 'lr_e':   8.68e-05})
Step:  107000, Reward:  -201.643 [  77.993], Avg:  -383.609 (0.700) <0-03:13:50> ({'r_t': -3861.9692, 'eps':     0.7001, 'len':  8512.1600, 'dyn_loss':     0.1019, 'dot_loss':     0.0112, 'ddot_loss':     0.0282, 'rew_loss':  1640.1958, 'lr':   8.68e-05, 'eps_e':     0.7001, 'lr_e':   8.68e-05})
Step:  108000, Reward:  -164.976 [  87.656], Avg:  -381.603 (0.800) <0-03:15:14> ({'r_t': -4716.1069, 'eps':     0.8001, 'len':  8592.1600, 'dyn_loss':     0.1013, 'dot_loss':     0.0111, 'ddot_loss':     0.0282, 'rew_loss':  1619.6823, 'lr':   8.68e-05, 'eps_e':     0.8001, 'lr_e':   8.68e-05})
Step:  109000, Reward:  -198.786 [  90.249], Avg:  -379.941 (0.900) <0-03:16:25> ({'r_t': -5452.8816, 'eps':     0.9001, 'len':  8672.1600, 'dyn_loss':     0.1019, 'dot_loss':     0.0111, 'ddot_loss':     0.0279, 'rew_loss':  1626.2585, 'lr':   8.68e-05, 'eps_e':     0.9001, 'lr_e':   8.68e-05})
Step:  110000, Reward:  -170.571 [  91.685], Avg:  -378.055 (0.000) <0-03:17:27> ({'r_t': -6250.6831, 'eps':     0.0001, 'len':  8752.1600, 'dyn_loss':     0.0986, 'dot_loss':     0.0108, 'ddot_loss':     0.0277, 'rew_loss':  1638.3979, 'lr':   8.68e-05, 'eps_e':     0.0001, 'lr_e':   8.68e-05})
Step:  111000, Reward:  -218.046 [ 124.354], Avg:  -376.626 (0.100) <0-03:20:10> ({'r_t':  -822.0027, 'eps':     0.1001, 'len':  8832.1600, 'dyn_loss':     0.0968, 'dot_loss':     0.0110, 'ddot_loss':     0.0283, 'rew_loss':  1567.1931, 'lr':   8.68e-05, 'eps_e':     0.1001, 'lr_e':   8.68e-05})
Step:  112000, Reward:  -188.485 [ 103.590], Avg:  -374.961 (0.200) <0-03:22:42> ({'r_t':  -995.5416, 'eps':     0.2001, 'len':  8912.1600, 'dyn_loss':     0.1013, 'dot_loss':     0.0107, 'ddot_loss':     0.0276, 'rew_loss':  1642.7059, 'lr':   8.68e-05, 'eps_e':     0.2001, 'lr_e':   8.68e-05})
Step:  113000, Reward:  -150.611 [  78.096], Avg:  -372.993 (0.300) <0-03:25:02> ({'r_t': -1486.6293, 'eps':     0.3001, 'len':  8992.1600, 'dyn_loss':     0.0951, 'dot_loss':     0.0107, 'ddot_loss':     0.0272, 'rew_loss':  1617.6644, 'lr':   8.68e-05, 'eps_e':     0.3001, 'lr_e':   8.68e-05})
Step:  114000, Reward:  -197.225 [ 102.272], Avg:  -371.465 (0.400) <0-03:27:10> ({'r_t': -2058.1936, 'eps':     0.4001, 'len':  9072.1600, 'dyn_loss':     0.0960, 'dot_loss':     0.0106, 'ddot_loss':     0.0271, 'rew_loss':  1623.8276, 'lr':   8.51e-05, 'eps_e':     0.4001, 'lr_e':   8.51e-05})
Step:  115000, Reward:  -192.213 [  82.365], Avg:  -369.919 (0.500) <0-03:29:08> ({'r_t': -2424.1970, 'eps':     0.5001, 'len':  9152.1600, 'dyn_loss':     0.0980, 'dot_loss':     0.0107, 'ddot_loss':     0.0275, 'rew_loss':  1561.7689, 'lr':   8.51e-05, 'eps_e':     0.5001, 'lr_e':   8.51e-05})
Step:  116000, Reward:  -201.219 [  80.711], Avg:  -368.478 (0.600) <0-03:30:54> ({'r_t': -3366.9934, 'eps':     0.6001, 'len':  9232.1600, 'dyn_loss':     0.0989, 'dot_loss':     0.0105, 'ddot_loss':     0.0269, 'rew_loss':  1593.9272, 'lr':   8.51e-05, 'eps_e':     0.6001, 'lr_e':   8.51e-05})
Step:  117000, Reward:  -169.706 [ 101.361], Avg:  -366.793 (0.700) <0-03:32:28> ({'r_t': -3919.3679, 'eps':     0.7001, 'len':  9312.1600, 'dyn_loss':     0.0968, 'dot_loss':     0.0107, 'ddot_loss':     0.0276, 'rew_loss':  1657.0472, 'lr':   8.51e-05, 'eps_e':     0.7001, 'lr_e':   8.51e-05})
Step:  118000, Reward:  -178.907 [  82.937], Avg:  -365.214 (0.800) <0-03:33:51> ({'r_t': -4658.6424, 'eps':     0.8001, 'len':  9392.1600, 'dyn_loss':     0.0988, 'dot_loss':     0.0108, 'ddot_loss':     0.0277, 'rew_loss':  1589.7898, 'lr':   8.51e-05, 'eps_e':     0.8001, 'lr_e':   8.51e-05})
Step:  119000, Reward:  -179.207 [  73.991], Avg:  -363.664 (0.900) <0-03:35:02> ({'r_t': -5739.2287, 'eps':     0.9001, 'len':  9472.1600, 'dyn_loss':     0.1027, 'dot_loss':     0.0110, 'ddot_loss':     0.0280, 'rew_loss':  1734.1440, 'lr':   8.51e-05, 'eps_e':     0.9001, 'lr_e':   8.51e-05})
Step:  120000, Reward:  -202.784 [ 109.127], Avg:  -362.335 (0.000) <0-03:36:04> ({'r_t': -6148.9818, 'eps':     0.0001, 'len':  9552.1600, 'dyn_loss':     0.0997, 'dot_loss':     0.0111, 'ddot_loss':     0.0283, 'rew_loss':  1674.7858, 'lr':   8.51e-05, 'eps_e':     0.0001, 'lr_e':   8.51e-05})
Step:  121000, Reward:  -147.153 [  73.283], Avg:  -360.571 (0.100) <0-03:38:47> ({'r_t':  -989.8423, 'eps':     0.1001, 'len':  9632.1600, 'dyn_loss':     0.0948, 'dot_loss':     0.0106, 'ddot_loss':     0.0276, 'rew_loss':  1694.4608, 'lr':   8.51e-05, 'eps_e':     0.1001, 'lr_e':   8.51e-05})
Step:  122000, Reward:  -217.671 [ 110.818], Avg:  -359.409 (0.200) <0-03:41:19> ({'r_t': -1084.2309, 'eps':     0.2001, 'len':  9712.1600, 'dyn_loss':     0.0932, 'dot_loss':     0.0103, 'ddot_loss':     0.0270, 'rew_loss':  1711.1813, 'lr':   8.51e-05, 'eps_e':     0.2001, 'lr_e':   8.51e-05})
Step:  123000, Reward:  -166.394 [  85.229], Avg:  -357.852 (0.300) <0-03:43:39> ({'r_t': -1420.5229, 'eps':     0.3001, 'len':  9792.1600, 'dyn_loss':     0.0938, 'dot_loss':     0.0107, 'ddot_loss':     0.0277, 'rew_loss':  1645.3177, 'lr':   8.51e-05, 'eps_e':     0.3001, 'lr_e':   8.51e-05})
Step:  124000, Reward:  -200.368 [ 121.154], Avg:  -356.593 (0.400) <0-03:45:48> ({'r_t': -2147.7022, 'eps':     0.4001, 'len':  9872.1600, 'dyn_loss':     0.1002, 'dot_loss':     0.0110, 'ddot_loss':     0.0284, 'rew_loss':  1717.0266, 'lr':   8.51e-05, 'eps_e':     0.4001, 'lr_e':   8.51e-05})
Step:  125000, Reward:  -229.171 [  84.909], Avg:  -355.581 (0.500) <0-03:47:45> ({'r_t': -2487.5705, 'eps':     0.5001, 'len':  9952.1600, 'dyn_loss':     0.0906, 'dot_loss':     0.0105, 'ddot_loss':     0.0273, 'rew_loss':  1616.4141, 'lr':   8.34e-05, 'eps_e':     0.5001, 'lr_e':   8.34e-05})
Step:  126000, Reward:  -172.327 [  94.976], Avg:  -354.138 (0.600) <0-03:49:31> ({'r_t': -3422.7011, 'eps':     0.6001, 'len': 10032.1600, 'dyn_loss':     0.0975, 'dot_loss':     0.0109, 'ddot_loss':     0.0273, 'rew_loss':  1553.9257, 'lr':   8.34e-05, 'eps_e':     0.6001, 'lr_e':   8.34e-05})
Step:  127000, Reward:  -215.380 [  80.785], Avg:  -353.054 (0.700) <0-03:51:06> ({'r_t': -3851.9476, 'eps':     0.7001, 'len': 10112.1600, 'dyn_loss':     0.0974, 'dot_loss':     0.0108, 'ddot_loss':     0.0279, 'rew_loss':  1683.8042, 'lr':   8.34e-05, 'eps_e':     0.7001, 'lr_e':   8.34e-05})
Step:  128000, Reward:  -169.706 [  67.815], Avg:  -351.633 (0.800) <0-03:52:29> ({'r_t': -4652.5927, 'eps':     0.8001, 'len': 10192.1600, 'dyn_loss':     0.0958, 'dot_loss':     0.0105, 'ddot_loss':     0.0271, 'rew_loss':  1657.2625, 'lr':   8.34e-05, 'eps_e':     0.8001, 'lr_e':   8.34e-05})
Step:  129000, Reward:  -194.373 [  94.316], Avg:  -350.423 (0.900) <0-03:53:40> ({'r_t': -5392.1725, 'eps':     0.9001, 'len': 10272.1600, 'dyn_loss':     0.0918, 'dot_loss':     0.0103, 'ddot_loss':     0.0269, 'rew_loss':  1665.9801, 'lr':   8.34e-05, 'eps_e':     0.9001, 'lr_e':   8.34e-05})
Step:  130000, Reward:  -202.692 [  94.417], Avg:  -349.296 (0.000) <0-03:54:42> ({'r_t': -6139.2091, 'eps':     0.0001, 'len': 10352.1600, 'dyn_loss':     0.0962, 'dot_loss':     0.0105, 'ddot_loss':     0.0274, 'rew_loss':  1775.5803, 'lr':   8.34e-05, 'eps_e':     0.0001, 'lr_e':   8.34e-05})
Step:  131000, Reward:  -153.697 [  59.456], Avg:  -347.814 (0.100) <0-03:57:26> ({'r_t':  -975.8502, 'eps':     0.1001, 'len': 10432.1600, 'dyn_loss':     0.0977, 'dot_loss':     0.0104, 'ddot_loss':     0.0273, 'rew_loss':  1715.8521, 'lr':   8.34e-05, 'eps_e':     0.1001, 'lr_e':   8.34e-05})
Step:  132000, Reward:  -162.749 [  79.048], Avg:  -346.422 (0.200) <0-03:59:57> ({'r_t': -1132.8155, 'eps':     0.2001, 'len': 10512.1600, 'dyn_loss':     0.0961, 'dot_loss':     0.0106, 'ddot_loss':     0.0276, 'rew_loss':  1650.5427, 'lr':   8.34e-05, 'eps_e':     0.2001, 'lr_e':   8.34e-05})
Step:  133000, Reward:  -177.102 [  72.022], Avg:  -345.159 (0.300) <0-04:02:18> ({'r_t': -1559.8703, 'eps':     0.3001, 'len': 10592.1600, 'dyn_loss':     0.0921, 'dot_loss':     0.0104, 'ddot_loss':     0.0274, 'rew_loss':  1693.7045, 'lr':   8.34e-05, 'eps_e':     0.3001, 'lr_e':   8.34e-05})
Step:  134000, Reward:  -225.917 [  68.531], Avg:  -344.275 (0.400) <0-04:04:26> ({'r_t': -1884.0289, 'eps':     0.4001, 'len': 10672.1600, 'dyn_loss':     0.0958, 'dot_loss':     0.0105, 'ddot_loss':     0.0271, 'rew_loss':  1601.9824, 'lr':   8.34e-05, 'eps_e':     0.4001, 'lr_e':   8.34e-05})
Step:  135000, Reward:  -264.631 [  98.332], Avg:  -343.690 (0.500) <0-04:06:24> ({'r_t': -2716.0815, 'eps':     0.5001, 'len': 10752.1600, 'dyn_loss':     0.0937, 'dot_loss':     0.0106, 'ddot_loss':     0.0275, 'rew_loss':  1644.2153, 'lr':   8.34e-05, 'eps_e':     0.5001, 'lr_e':   8.34e-05})
Step:  136000, Reward:  -252.396 [ 400.033], Avg:  -343.023 (0.600) <0-04:08:10> ({'r_t': -3192.5234, 'eps':     0.6001, 'len': 10832.1600, 'dyn_loss':     0.0926, 'dot_loss':     0.0104, 'ddot_loss':     0.0269, 'rew_loss':  1602.3344, 'lr':   8.17e-05, 'eps_e':     0.6001, 'lr_e':   8.17e-05})
Step:  137000, Reward:  -276.846 [ 392.184], Avg:  -342.544 (0.700) <0-04:09:44> ({'r_t': -3800.4041, 'eps':     0.7001, 'len': 10912.1600, 'dyn_loss':     0.0915, 'dot_loss':     0.0104, 'ddot_loss':     0.0273, 'rew_loss':  1763.9923, 'lr':   8.17e-05, 'eps_e':     0.7001, 'lr_e':   8.17e-05})
Step:  138000, Reward:  -258.488 [ 375.292], Avg:  -341.939 (0.800) <0-04:11:07> ({'r_t': -4604.8193, 'eps':     0.8001, 'len': 10992.1600, 'dyn_loss':     0.0921, 'dot_loss':     0.0103, 'ddot_loss':     0.0265, 'rew_loss':  1633.7595, 'lr':   8.17e-05, 'eps_e':     0.8001, 'lr_e':   8.17e-05})
Step:  139000, Reward:  -163.354 [  79.701], Avg:  -340.664 (0.900) <0-04:12:19> ({'r_t': -5404.0992, 'eps':     0.9001, 'len': 11072.1600, 'dyn_loss':     0.0983, 'dot_loss':     0.0106, 'ddot_loss':     0.0275, 'rew_loss':  1655.1826, 'lr':   8.17e-05, 'eps_e':     0.9001, 'lr_e':   8.17e-05})
Step:  140000, Reward:  -273.473 [ 394.469], Avg:  -340.187 (0.000) <0-04:13:21> ({'r_t': -5916.3915, 'eps':     0.0001, 'len': 11152.1600, 'dyn_loss':     0.0965, 'dot_loss':     0.0105, 'ddot_loss':     0.0271, 'rew_loss':  1689.0066, 'lr':   8.17e-05, 'eps_e':     0.0001, 'lr_e':   8.17e-05})
Step:  141000, Reward:  -186.713 [  72.774], Avg:  -339.106 (0.100) <0-04:16:04> ({'r_t':  -903.7425, 'eps':     0.1001, 'len': 11232.1600, 'dyn_loss':     0.0916, 'dot_loss':     0.0103, 'ddot_loss':     0.0268, 'rew_loss':  1666.5891, 'lr':   8.17e-05, 'eps_e':     0.1001, 'lr_e':   8.17e-05})
Step:  142000, Reward:  -159.282 [  70.412], Avg:  -337.849 (0.200) <0-04:18:36> ({'r_t': -1141.4923, 'eps':     0.2001, 'len': 11312.1600, 'dyn_loss':     0.0969, 'dot_loss':     0.0104, 'ddot_loss':     0.0270, 'rew_loss':  1749.2018, 'lr':   8.17e-05, 'eps_e':     0.2001, 'lr_e':   8.17e-05})
Step:  143000, Reward:  -194.193 [ 120.690], Avg:  -336.851 (0.300) <0-04:20:56> ({'r_t': -1531.6850, 'eps':     0.3001, 'len': 11392.1600, 'dyn_loss':     0.0891, 'dot_loss':     0.0100, 'ddot_loss':     0.0260, 'rew_loss':  1711.6492, 'lr':   8.17e-05, 'eps_e':     0.3001, 'lr_e':   8.17e-05})
Step:  144000, Reward:  -210.815 [  80.395], Avg:  -335.982 (0.400) <0-04:23:06> ({'r_t': -2001.6747, 'eps':     0.4001, 'len': 11472.1600, 'dyn_loss':     0.0972, 'dot_loss':     0.0106, 'ddot_loss':     0.0276, 'rew_loss':  1672.9872, 'lr':   8.17e-05, 'eps_e':     0.4001, 'lr_e':   8.17e-05})
Step:  145000, Reward:  -292.863 [ 377.063], Avg:  -335.687 (0.500) <0-04:25:04> ({'r_t': -2642.0971, 'eps':     0.5001, 'len': 11552.1600, 'dyn_loss':     0.0931, 'dot_loss':     0.0104, 'ddot_loss':     0.0269, 'rew_loss':  1622.3677, 'lr':   8.17e-05, 'eps_e':     0.5001, 'lr_e':   8.17e-05})
Step:  146000, Reward:  -191.635 [ 108.812], Avg:  -334.707 (0.600) <0-04:26:50> ({'r_t': -3336.9444, 'eps':     0.6001, 'len': 11632.1600, 'dyn_loss':     0.0913, 'dot_loss':     0.0103, 'ddot_loss':     0.0268, 'rew_loss':  1627.2249, 'lr':   8.17e-05, 'eps_e':     0.6001, 'lr_e':   8.17e-05})
Step:  147000, Reward:  -201.640 [  74.694], Avg:  -333.807 (0.700) <0-04:28:24> ({'r_t': -3812.3477, 'eps':     0.7001, 'len': 11712.1600, 'dyn_loss':     0.0922, 'dot_loss':     0.0101, 'ddot_loss':     0.0265, 'rew_loss':  1617.3701, 'lr':   8.01e-05, 'eps_e':     0.7001, 'lr_e':   8.01e-05})
Step:  148000, Reward:  -194.906 [  79.014], Avg:  -332.875 (0.800) <0-04:29:47> ({'r_t': -4551.7144, 'eps':     0.8001, 'len': 11792.1600, 'dyn_loss':     0.0933, 'dot_loss':     0.0103, 'ddot_loss':     0.0271, 'rew_loss':  1659.4442, 'lr':   8.01e-05, 'eps_e':     0.8001, 'lr_e':   8.01e-05})
Step:  149000, Reward:  -162.956 [ 102.700], Avg:  -331.742 (0.900) <0-04:30:59> ({'r_t': -5271.2480, 'eps':     0.9001, 'len': 11872.1600, 'dyn_loss':     0.0945, 'dot_loss':     0.0103, 'ddot_loss':     0.0268, 'rew_loss':  1605.9543, 'lr':   8.01e-05, 'eps_e':     0.9001, 'lr_e':   8.01e-05})
Step:  150000, Reward:  -198.288 [  91.460], Avg:  -330.859 (0.000) <0-04:32:01> ({'r_t': -5915.0548, 'eps':     0.0001, 'len': 11952.1600, 'dyn_loss':     0.0879, 'dot_loss':     0.0098, 'ddot_loss':     0.0255, 'rew_loss':  1707.2158, 'lr':   8.01e-05, 'eps_e':     0.0001, 'lr_e':   8.01e-05})
Step:  151000, Reward:  -237.028 [ 108.651], Avg:  -330.241 (0.100) <0-04:34:44> ({'r_t':  -930.0412, 'eps':     0.1001, 'len': 12032.1600, 'dyn_loss':     0.0925, 'dot_loss':     0.0100, 'ddot_loss':     0.0265, 'rew_loss':  1627.0642, 'lr':   8.01e-05, 'eps_e':     0.1001, 'lr_e':   8.01e-05})
Step:  152000, Reward:  -210.587 [  92.979], Avg:  -329.459 (0.200) <0-04:37:16> ({'r_t': -1192.1220, 'eps':     0.2001, 'len': 12112.1600, 'dyn_loss':     0.0913, 'dot_loss':     0.0101, 'ddot_loss':     0.0265, 'rew_loss':  1642.0576, 'lr':   8.01e-05, 'eps_e':     0.2001, 'lr_e':   8.01e-05})
Step:  153000, Reward:  -264.176 [ 107.887], Avg:  -329.035 (0.300) <0-04:39:36> ({'r_t': -1475.8916, 'eps':     0.3001, 'len': 12192.1600, 'dyn_loss':     0.0903, 'dot_loss':     0.0102, 'ddot_loss':     0.0268, 'rew_loss':  1796.4733, 'lr':   8.01e-05, 'eps_e':     0.3001, 'lr_e':   8.01e-05})
Step:  154000, Reward:  -178.360 [  94.130], Avg:  -328.063 (0.400) <0-04:41:45> ({'r_t': -1924.0857, 'eps':     0.4001, 'len': 12272.1600, 'dyn_loss':     0.0918, 'dot_loss':     0.0103, 'ddot_loss':     0.0265, 'rew_loss':  1706.9064, 'lr':   8.01e-05, 'eps_e':     0.4001, 'lr_e':   8.01e-05})
Step:  155000, Reward:  -208.055 [  84.210], Avg:  -327.294 (0.500) <0-04:43:44> ({'r_t': -2667.5228, 'eps':     0.5001, 'len': 12352.1600, 'dyn_loss':     0.0887, 'dot_loss':     0.0101, 'ddot_loss':     0.0268, 'rew_loss':  1772.5149, 'lr':   8.01e-05, 'eps_e':     0.5001, 'lr_e':   8.01e-05})
Step:  156000, Reward:  -169.841 [  92.115], Avg:  -326.291 (0.600) <0-04:45:30> ({'r_t': -3396.5823, 'eps':     0.6001, 'len': 12432.1600, 'dyn_loss':     0.0930, 'dot_loss':     0.0104, 'ddot_loss':     0.0270, 'rew_loss':  1543.4785, 'lr':   8.01e-05, 'eps_e':     0.6001, 'lr_e':   8.01e-05})
Step:  157000, Reward:  -365.399 [ 533.528], Avg:  -326.539 (0.700) <0-04:47:04> ({'r_t': -3858.1496, 'eps':     0.7001, 'len': 12512.1600, 'dyn_loss':     0.0948, 'dot_loss':     0.0103, 'ddot_loss':     0.0269, 'rew_loss':  1693.7058, 'lr':   8.01e-05, 'eps_e':     0.7001, 'lr_e':   8.01e-05})
Step:  158000, Reward:  -194.894 [  99.331], Avg:  -325.711 (0.800) <0-04:48:27> ({'r_t': -4704.4480, 'eps':     0.8001, 'len': 12592.1600, 'dyn_loss':     0.0904, 'dot_loss':     0.0102, 'ddot_loss':     0.0263, 'rew_loss':  1575.0220, 'lr':   7.85e-05, 'eps_e':     0.8001, 'lr_e':   7.85e-05})
Step:  159000, Reward:  -251.442 [ 399.134], Avg:  -325.247 (0.900) <0-04:49:39> ({'r_t': -5386.3853, 'eps':     0.9001, 'len': 12672.1600, 'dyn_loss':     0.0943, 'dot_loss':     0.0102, 'ddot_loss':     0.0268, 'rew_loss':  1687.2540, 'lr':   7.85e-05, 'eps_e':     0.9001, 'lr_e':   7.85e-05})
Step:  160000, Reward:  -172.717 [  97.841], Avg:  -324.299 (0.000) <0-04:50:41> ({'r_t': -5925.2052, 'eps':     0.0001, 'len': 12752.1600, 'dyn_loss':     0.0883, 'dot_loss':     0.0100, 'ddot_loss':     0.0264, 'rew_loss':  1757.8101, 'lr':   7.85e-05, 'eps_e':     0.0001, 'lr_e':   7.85e-05})
Step:  161000, Reward:  -205.768 [  97.676], Avg:  -323.567 (0.100) <0-04:53:24> ({'r_t':  -902.0673, 'eps':     0.1001, 'len': 12832.1600, 'dyn_loss':     0.0903, 'dot_loss':     0.0099, 'ddot_loss':     0.0266, 'rew_loss':  1712.8328, 'lr':   7.85e-05, 'eps_e':     0.1001, 'lr_e':   7.85e-05})
Step:  162000, Reward:  -183.615 [  91.853], Avg:  -322.709 (0.200) <0-04:55:57> ({'r_t': -1464.8616, 'eps':     0.2001, 'len': 12912.1600, 'dyn_loss':     0.0913, 'dot_loss':     0.0101, 'ddot_loss':     0.0268, 'rew_loss':  1819.2638, 'lr':   7.85e-05, 'eps_e':     0.2001, 'lr_e':   7.85e-05})
Step:  163000, Reward:  -200.374 [ 127.326], Avg:  -321.963 (0.300) <0-04:58:17> ({'r_t': -1580.0697, 'eps':     0.3001, 'len': 12992.1600, 'dyn_loss':     0.0878, 'dot_loss':     0.0101, 'ddot_loss':     0.0266, 'rew_loss':  1593.6649, 'lr':   7.85e-05, 'eps_e':     0.3001, 'lr_e':   7.85e-05})
Step:  164000, Reward:  -185.847 [  88.180], Avg:  -321.138 (0.400) <0-05:00:26> ({'r_t': -1994.7037, 'eps':     0.4001, 'len': 13072.1600, 'dyn_loss':     0.0907, 'dot_loss':     0.0100, 'ddot_loss':     0.0263, 'rew_loss':  1651.6760, 'lr':   7.85e-05, 'eps_e':     0.4001, 'lr_e':   7.85e-05})
Step:  165000, Reward:  -232.605 [  90.968], Avg:  -320.605 (0.500) <0-05:02:24> ({'r_t': -2721.6896, 'eps':     0.5001, 'len': 13152.1600, 'dyn_loss':     0.0872, 'dot_loss':     0.0096, 'ddot_loss':     0.0256, 'rew_loss':  1583.4038, 'lr':   7.85e-05, 'eps_e':     0.5001, 'lr_e':   7.85e-05})
Step:  166000, Reward:  -246.151 [ 414.040], Avg:  -320.159 (0.600) <0-05:04:10> ({'r_t': -3245.0557, 'eps':     0.6001, 'len': 13232.1600, 'dyn_loss':     0.0902, 'dot_loss':     0.0101, 'ddot_loss':     0.0267, 'rew_loss':  1673.0251, 'lr':   7.85e-05, 'eps_e':     0.6001, 'lr_e':   7.85e-05})
Step:  167000, Reward:  -189.620 [ 103.169], Avg:  -319.382 (0.700) <0-05:05:45> ({'r_t': -3967.2698, 'eps':     0.7001, 'len': 13312.1600, 'dyn_loss':     0.0897, 'dot_loss':     0.0099, 'ddot_loss':     0.0261, 'rew_loss':  1642.0081, 'lr':   7.85e-05, 'eps_e':     0.7001, 'lr_e':   7.85e-05})
Step:  168000, Reward:  -166.893 [  78.039], Avg:  -318.479 (0.800) <0-05:07:08> ({'r_t': -4556.5778, 'eps':     0.8001, 'len': 13392.1600, 'dyn_loss':     0.0932, 'dot_loss':     0.0100, 'ddot_loss':     0.0263, 'rew_loss':  1695.4852, 'lr':   7.85e-05, 'eps_e':     0.8001, 'lr_e':   7.85e-05})
Step:  169000, Reward:  -240.603 [ 217.067], Avg:  -318.021 (0.900) <0-05:08:20> ({'r_t': -5313.1601, 'eps':     0.9001, 'len': 13472.1600, 'dyn_loss':     0.0883, 'dot_loss':     0.0100, 'ddot_loss':     0.0262, 'rew_loss':  1711.3158, 'lr':   7.69e-05, 'eps_e':     0.9001, 'lr_e':   7.69e-05})
Step:  170000, Reward:  -223.588 [ 108.577], Avg:  -317.469 (0.000) <0-05:09:22> ({'r_t': -6167.9927, 'eps':     0.0001, 'len': 13552.1600, 'dyn_loss':     0.0957, 'dot_loss':     0.0104, 'ddot_loss':     0.0273, 'rew_loss':  1641.8202, 'lr':   7.69e-05, 'eps_e':     0.0001, 'lr_e':   7.69e-05})
Step:  171000, Reward:  -201.024 [  72.660], Avg:  -316.792 (0.100) <0-05:12:05> ({'r_t':  -901.5374, 'eps':     0.1001, 'len': 13632.1600, 'dyn_loss':     0.0917, 'dot_loss':     0.0100, 'ddot_loss':     0.0264, 'rew_loss':  1662.8457, 'lr':   7.69e-05, 'eps_e':     0.1001, 'lr_e':   7.69e-05})
Step:  172000, Reward:  -273.459 [ 397.434], Avg:  -316.542 (0.200) <0-05:14:37> ({'r_t': -1194.0589, 'eps':     0.2001, 'len': 13712.1600, 'dyn_loss':     0.0893, 'dot_loss':     0.0098, 'ddot_loss':     0.0262, 'rew_loss':  1668.3691, 'lr':   7.69e-05, 'eps_e':     0.2001, 'lr_e':   7.69e-05})
Step:  173000, Reward:  -185.652 [  79.856], Avg:  -315.789 (0.300) <0-05:16:58> ({'r_t': -1754.1005, 'eps':     0.3001, 'len': 13792.1600, 'dyn_loss':     0.0890, 'dot_loss':     0.0098, 'ddot_loss':     0.0262, 'rew_loss':  1623.8575, 'lr':   7.69e-05, 'eps_e':     0.3001, 'lr_e':   7.69e-05})
Step:  174000, Reward:  -186.297 [ 111.844], Avg:  -315.049 (0.400) <0-05:19:07> ({'r_t': -2079.8125, 'eps':     0.4001, 'len': 13872.1600, 'dyn_loss':     0.0880, 'dot_loss':     0.0099, 'ddot_loss':     0.0265, 'rew_loss':  1682.3733, 'lr':   7.69e-05, 'eps_e':     0.4001, 'lr_e':   7.69e-05})
Step:  175000, Reward:  -177.655 [  72.899], Avg:  -314.269 (0.500) <0-05:21:04> ({'r_t': -2638.6453, 'eps':     0.5001, 'len': 13952.1600, 'dyn_loss':     0.0915, 'dot_loss':     0.0100, 'ddot_loss':     0.0266, 'rew_loss':  1705.4326, 'lr':   7.69e-05, 'eps_e':     0.5001, 'lr_e':   7.69e-05})
Step:  176000, Reward:  -192.665 [  90.025], Avg:  -313.582 (0.600) <0-05:22:50> ({'r_t': -3109.1250, 'eps':     0.6001, 'len': 14032.1600, 'dyn_loss':     0.0871, 'dot_loss':     0.0098, 'ddot_loss':     0.0259, 'rew_loss':  1649.3739, 'lr':   7.69e-05, 'eps_e':     0.6001, 'lr_e':   7.69e-05})
Step:  177000, Reward:  -202.850 [  94.220], Avg:  -312.960 (0.700) <0-05:24:25> ({'r_t': -4011.3396, 'eps':     0.7001, 'len': 14112.1600, 'dyn_loss':     0.0889, 'dot_loss':     0.0097, 'ddot_loss':     0.0254, 'rew_loss':  1703.5957, 'lr':   7.69e-05, 'eps_e':     0.7001, 'lr_e':   7.69e-05})
Step:  178000, Reward:  -212.140 [ 218.208], Avg:  -312.396 (0.800) <0-05:25:48> ({'r_t': -4762.9504, 'eps':     0.8001, 'len': 14192.1600, 'dyn_loss':     0.0913, 'dot_loss':     0.0099, 'ddot_loss':     0.0261, 'rew_loss':  1665.2085, 'lr':   7.69e-05, 'eps_e':     0.8001, 'lr_e':   7.69e-05})
Step:  179000, Reward:  -161.747 [  79.897], Avg:  -311.560 (0.900) <0-05:27:00> ({'r_t': -5313.6852, 'eps':     0.9001, 'len': 14272.1600, 'dyn_loss':     0.0918, 'dot_loss':     0.0103, 'ddot_loss':     0.0271, 'rew_loss':  1581.6543, 'lr':   7.69e-05, 'eps_e':     0.9001, 'lr_e':   7.69e-05})
Step:  180000, Reward:  -185.166 [  94.833], Avg:  -310.861 (0.000) <0-05:28:02> ({'r_t': -5986.7600, 'eps':     0.0001, 'len': 14352.1600, 'dyn_loss':     0.0880, 'dot_loss':     0.0098, 'ddot_loss':     0.0263, 'rew_loss':  1648.3009, 'lr':   7.54e-05, 'eps_e':     0.0001, 'lr_e':   7.54e-05})
Step:  181000, Reward:  -200.548 [  86.276], Avg:  -310.255 (0.100) <0-05:30:46> ({'r_t': -1002.3696, 'eps':     0.1001, 'len': 14432.1600, 'dyn_loss':     0.0900, 'dot_loss':     0.0099, 'ddot_loss':     0.0263, 'rew_loss':  1776.4586, 'lr':   7.54e-05, 'eps_e':     0.1001, 'lr_e':   7.54e-05})
Step:  182000, Reward:  -566.496 [ 692.450], Avg:  -311.655 (0.200) <0-05:33:18> ({'r_t': -1061.9231, 'eps':     0.2001, 'len': 14512.1600, 'dyn_loss':     0.0856, 'dot_loss':     0.0096, 'ddot_loss':     0.0256, 'rew_loss':  1734.0503, 'lr':   7.54e-05, 'eps_e':     0.2001, 'lr_e':   7.54e-05})
Step:  183000, Reward:  -199.858 [  86.435], Avg:  -311.048 (0.300) <0-05:35:38> ({'r_t': -2372.0847, 'eps':     0.3001, 'len': 14592.1600, 'dyn_loss':     0.0875, 'dot_loss':     0.0098, 'ddot_loss':     0.0261, 'rew_loss':  1742.0305, 'lr':   7.54e-05, 'eps_e':     0.3001, 'lr_e':   7.54e-05})
Step:  184000, Reward:  -261.953 [ 409.298], Avg:  -310.782 (0.400) <0-05:37:47> ({'r_t': -2237.5012, 'eps':     0.4001, 'len': 14672.1600, 'dyn_loss':     0.0898, 'dot_loss':     0.0100, 'ddot_loss':     0.0265, 'rew_loss':  1695.8569, 'lr':   7.54e-05, 'eps_e':     0.4001, 'lr_e':   7.54e-05})
Step:  185000, Reward:  -161.003 [  56.562], Avg:  -309.977 (0.500) <0-05:39:45> ({'r_t': -2727.7354, 'eps':     0.5001, 'len': 14752.1600, 'dyn_loss':     0.0894, 'dot_loss':     0.0100, 'ddot_loss':     0.0264, 'rew_loss':  1590.2684, 'lr':   7.54e-05, 'eps_e':     0.5001, 'lr_e':   7.54e-05})
Step:  186000, Reward:  -394.833 [ 531.714], Avg:  -310.431 (0.600) <0-05:41:31> ({'r_t': -3376.6559, 'eps':     0.6001, 'len': 14832.1600, 'dyn_loss':     0.0914, 'dot_loss':     0.0098, 'ddot_loss':     0.0257, 'rew_loss':  1569.4031, 'lr':   7.54e-05, 'eps_e':     0.6001, 'lr_e':   7.54e-05})
Step:  187000, Reward:  -206.212 [  79.922], Avg:  -309.876 (0.700) <0-05:43:06> ({'r_t': -3918.4333, 'eps':     0.7001, 'len': 14912.1600, 'dyn_loss':     0.0882, 'dot_loss':     0.0097, 'ddot_loss':     0.0259, 'rew_loss':  1690.9733, 'lr':   7.54e-05, 'eps_e':     0.7001, 'lr_e':   7.54e-05})
Step:  188000, Reward:  -201.529 [ 123.777], Avg:  -309.303 (0.800) <0-05:44:30> ({'r_t': -4487.5559, 'eps':     0.8001, 'len': 14992.1600, 'dyn_loss':     0.0911, 'dot_loss':     0.0099, 'ddot_loss':     0.0264, 'rew_loss':  1733.2336, 'lr':   7.54e-05, 'eps_e':     0.8001, 'lr_e':   7.54e-05})
Step:  189000, Reward:  -185.343 [  71.676], Avg:  -308.651 (0.900) <0-05:45:43> ({'r_t': -5243.2502, 'eps':     0.9001, 'len': 15072.1600, 'dyn_loss':     0.0854, 'dot_loss':     0.0097, 'ddot_loss':     0.0259, 'rew_loss':  1612.5272, 'lr':   7.54e-05, 'eps_e':     0.9001, 'lr_e':   7.54e-05})
Step:  190000, Reward:  -249.365 [ 146.346], Avg:  -308.340 (0.000) <0-05:46:45> ({'r_t': -5980.6898, 'eps':     0.0001, 'len': 15152.1600, 'dyn_loss':     0.0876, 'dot_loss':     0.0098, 'ddot_loss':     0.0258, 'rew_loss':  1625.9932, 'lr':   7.54e-05, 'eps_e':     0.0001, 'lr_e':   7.54e-05})
Step:  191000, Reward:  -135.114 [  75.352], Avg:  -307.438 (0.100) <0-05:49:30> ({'r_t':  -928.2351, 'eps':     0.1001, 'len': 15232.1600, 'dyn_loss':     0.0863, 'dot_loss':     0.0095, 'ddot_loss':     0.0257, 'rew_loss':  1721.4658, 'lr':   7.39e-05, 'eps_e':     0.1001, 'lr_e':   7.39e-05})
Step:  192000, Reward:  -212.193 [  91.826], Avg:  -306.945 (0.200) <0-05:52:03> ({'r_t': -1508.6886, 'eps':     0.2001, 'len': 15312.1600, 'dyn_loss':     0.0864, 'dot_loss':     0.0097, 'ddot_loss':     0.0262, 'rew_loss':  1680.1809, 'lr':   7.39e-05, 'eps_e':     0.2001, 'lr_e':   7.39e-05})
Step:  193000, Reward:  -159.557 [  57.088], Avg:  -306.185 (0.300) <0-05:54:25> ({'r_t': -1511.3017, 'eps':     0.3001, 'len': 15392.1600, 'dyn_loss':     0.0878, 'dot_loss':     0.0096, 'ddot_loss':     0.0255, 'rew_loss':  1638.1420, 'lr':   7.39e-05, 'eps_e':     0.3001, 'lr_e':   7.39e-05})
Step:  194000, Reward:  -164.957 [  69.814], Avg:  -305.461 (0.400) <0-05:56:35> ({'r_t': -2044.4230, 'eps':     0.4001, 'len': 15472.1600, 'dyn_loss':     0.0853, 'dot_loss':     0.0094, 'ddot_loss':     0.0258, 'rew_loss':  1780.1062, 'lr':   7.39e-05, 'eps_e':     0.4001, 'lr_e':   7.39e-05})
Step:  195000, Reward:  -174.106 [  86.785], Avg:  -304.791 (0.500) <0-05:58:34> ({'r_t': -2579.2981, 'eps':     0.5001, 'len': 15552.1600, 'dyn_loss':     0.0851, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1652.1550, 'lr':   7.39e-05, 'eps_e':     0.5001, 'lr_e':   7.39e-05})
Step:  196000, Reward:  -188.611 [  77.097], Avg:  -304.201 (0.600) <0-06:00:21> ({'r_t': -3347.9940, 'eps':     0.6001, 'len': 15632.1600, 'dyn_loss':     0.0886, 'dot_loss':     0.0099, 'ddot_loss':     0.0262, 'rew_loss':  1677.1952, 'lr':   7.39e-05, 'eps_e':     0.6001, 'lr_e':   7.39e-05})
Step:  197000, Reward:  -213.229 [  98.441], Avg:  -303.741 (0.700) <0-06:01:57> ({'r_t': -4131.3902, 'eps':     0.7001, 'len': 15712.1600, 'dyn_loss':     0.0839, 'dot_loss':     0.0094, 'ddot_loss':     0.0252, 'rew_loss':  1676.5143, 'lr':   7.39e-05, 'eps_e':     0.7001, 'lr_e':   7.39e-05})
Step:  198000, Reward:  -288.169 [ 401.283], Avg:  -303.663 (0.800) <0-06:03:21> ({'r_t': -4593.8522, 'eps':     0.8001, 'len': 15792.1600, 'dyn_loss':     0.0908, 'dot_loss':     0.0100, 'ddot_loss':     0.0267, 'rew_loss':  1656.0029, 'lr':   7.39e-05, 'eps_e':     0.8001, 'lr_e':   7.39e-05})
Step:  199000, Reward:  -220.739 [ 105.123], Avg:  -303.248 (0.900) <0-06:04:33> ({'r_t': -5331.7479, 'eps':     0.9001, 'len': 15872.1600, 'dyn_loss':     0.0852, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1695.9762, 'lr':   7.39e-05, 'eps_e':     0.9001, 'lr_e':   7.39e-05})
Step:  200000, Reward:  -192.098 [  84.859], Avg:  -302.695 (0.000) <0-06:05:36> ({'r_t': -6153.2703, 'eps':     0.0001, 'len': 15952.1600, 'dyn_loss':     0.0920, 'dot_loss':     0.0100, 'ddot_loss':     0.0264, 'rew_loss':  1617.2063, 'lr':   7.39e-05, 'eps_e':     0.0001, 'lr_e':   7.39e-05})
Step:  201000, Reward:  -211.703 [ 124.813], Avg:  -302.245 (0.100) <0-06:08:21> ({'r_t':  -895.8587, 'eps':     0.1001, 'len': 16032.1600, 'dyn_loss':     0.0854, 'dot_loss':     0.0095, 'ddot_loss':     0.0256, 'rew_loss':  1726.0264, 'lr':   7.39e-05, 'eps_e':     0.1001, 'lr_e':   7.39e-05})
Step:  202000, Reward:  -261.713 [ 115.321], Avg:  -302.045 (0.200) <0-06:10:55> ({'r_t': -1129.2164, 'eps':     0.2001, 'len': 16112.1600, 'dyn_loss':     0.0872, 'dot_loss':     0.0095, 'ddot_loss':     0.0250, 'rew_loss':  1676.1741, 'lr':   7.24e-05, 'eps_e':     0.2001, 'lr_e':   7.24e-05})
Step:  203000, Reward:  -175.417 [  75.550], Avg:  -301.425 (0.300) <0-06:13:17> ({'r_t': -1565.8106, 'eps':     0.3001, 'len': 16192.1600, 'dyn_loss':     0.0897, 'dot_loss':     0.0095, 'ddot_loss':     0.0254, 'rew_loss':  1548.1724, 'lr':   7.24e-05, 'eps_e':     0.3001, 'lr_e':   7.24e-05})
Step:  204000, Reward:  -204.127 [  72.881], Avg:  -300.950 (0.400) <0-06:15:27> ({'r_t': -2048.0731, 'eps':     0.4001, 'len': 16272.1600, 'dyn_loss':     0.0816, 'dot_loss':     0.0093, 'ddot_loss':     0.0250, 'rew_loss':  1638.9259, 'lr':   7.24e-05, 'eps_e':     0.4001, 'lr_e':   7.24e-05})
Step:  205000, Reward:  -203.377 [  76.815], Avg:  -300.476 (0.500) <0-06:17:26> ({'r_t': -2955.7939, 'eps':     0.5001, 'len': 16352.1600, 'dyn_loss':     0.0873, 'dot_loss':     0.0096, 'ddot_loss':     0.0257, 'rew_loss':  1639.1399, 'lr':   7.24e-05, 'eps_e':     0.5001, 'lr_e':   7.24e-05})
Step:  206000, Reward:  -198.531 [  82.205], Avg:  -299.984 (0.600) <0-06:19:13> ({'r_t': -3264.0308, 'eps':     0.6001, 'len': 16432.1600, 'dyn_loss':     0.0883, 'dot_loss':     0.0096, 'ddot_loss':     0.0257, 'rew_loss':  1664.4996, 'lr':   7.24e-05, 'eps_e':     0.6001, 'lr_e':   7.24e-05})
Step:  207000, Reward:  -166.027 [  70.272], Avg:  -299.340 (0.700) <0-06:20:49> ({'r_t': -3910.6001, 'eps':     0.7001, 'len': 16512.1600, 'dyn_loss':     0.0818, 'dot_loss':     0.0092, 'ddot_loss':     0.0249, 'rew_loss':  1666.7672, 'lr':   7.24e-05, 'eps_e':     0.7001, 'lr_e':   7.24e-05})
Step:  208000, Reward:  -208.058 [  90.726], Avg:  -298.903 (0.800) <0-06:22:13> ({'r_t': -4560.3147, 'eps':     0.8001, 'len': 16592.1600, 'dyn_loss':     0.0861, 'dot_loss':     0.0095, 'ddot_loss':     0.0250, 'rew_loss':  1631.7316, 'lr':   7.24e-05, 'eps_e':     0.8001, 'lr_e':   7.24e-05})
Step:  209000, Reward:  -253.610 [ 116.741], Avg:  -298.687 (0.900) <0-06:23:25> ({'r_t': -5283.1717, 'eps':     0.9001, 'len': 16672.1600, 'dyn_loss':     0.0890, 'dot_loss':     0.0100, 'ddot_loss':     0.0267, 'rew_loss':  1711.3309, 'lr':   7.24e-05, 'eps_e':     0.9001, 'lr_e':   7.24e-05})
Step:  210000, Reward:  -185.455 [  93.026], Avg:  -298.151 (0.000) <0-06:24:28> ({'r_t': -6088.9590, 'eps':     0.0001, 'len': 16752.1600, 'dyn_loss':     0.0878, 'dot_loss':     0.0097, 'ddot_loss':     0.0264, 'rew_loss':  1670.4121, 'lr':   7.24e-05, 'eps_e':     0.0001, 'lr_e':   7.24e-05})
Step:  211000, Reward:  -170.478 [  80.432], Avg:  -297.549 (0.100) <0-06:27:13> ({'r_t':  -919.1753, 'eps':     0.1001, 'len': 16832.1600, 'dyn_loss':     0.0882, 'dot_loss':     0.0097, 'ddot_loss':     0.0257, 'rew_loss':  1580.4502, 'lr':   7.24e-05, 'eps_e':     0.1001, 'lr_e':   7.24e-05})
Step:  212000, Reward:  -169.314 [  78.637], Avg:  -296.946 (0.200) <0-06:29:47> ({'r_t':  -992.7378, 'eps':     0.2001, 'len': 16912.1600, 'dyn_loss':     0.0916, 'dot_loss':     0.0099, 'ddot_loss':     0.0265, 'rew_loss':  1643.1736, 'lr':   7.24e-05, 'eps_e':     0.2001, 'lr_e':   7.24e-05})
Step:  213000, Reward:  -175.461 [ 102.766], Avg:  -296.379 (0.300) <0-06:32:08> ({'r_t': -1639.8316, 'eps':     0.3001, 'len': 16992.1600, 'dyn_loss':     0.0865, 'dot_loss':     0.0095, 'ddot_loss':     0.0260, 'rew_loss':  1777.2610, 'lr':   7.09e-05, 'eps_e':     0.3001, 'lr_e':   7.09e-05})
Step:  214000, Reward:  -171.487 [  69.916], Avg:  -295.798 (0.400) <0-06:34:19> ({'r_t': -2019.4483, 'eps':     0.4001, 'len': 17072.1600, 'dyn_loss':     0.0820, 'dot_loss':     0.0093, 'ddot_loss':     0.0253, 'rew_loss':  1776.2823, 'lr':   7.09e-05, 'eps_e':     0.4001, 'lr_e':   7.09e-05})
Step:  215000, Reward:  -193.591 [  71.682], Avg:  -295.325 (0.500) <0-06:36:18> ({'r_t': -2652.5310, 'eps':     0.5001, 'len': 17152.1600, 'dyn_loss':     0.0850, 'dot_loss':     0.0095, 'ddot_loss':     0.0258, 'rew_loss':  1611.5581, 'lr':   7.09e-05, 'eps_e':     0.5001, 'lr_e':   7.09e-05})
Step:  216000, Reward:  -159.818 [  81.250], Avg:  -294.700 (0.600) <0-06:38:05> ({'r_t': -3325.6080, 'eps':     0.6001, 'len': 17232.1600, 'dyn_loss':     0.0869, 'dot_loss':     0.0096, 'ddot_loss':     0.0255, 'rew_loss':  1546.1624, 'lr':   7.09e-05, 'eps_e':     0.6001, 'lr_e':   7.09e-05})
Step:  217000, Reward:  -207.644 [ 133.220], Avg:  -294.301 (0.700) <0-06:39:40> ({'r_t': -3874.4889, 'eps':     0.7001, 'len': 17312.1600, 'dyn_loss':     0.0863, 'dot_loss':     0.0095, 'ddot_loss':     0.0257, 'rew_loss':  1619.8672, 'lr':   7.09e-05, 'eps_e':     0.7001, 'lr_e':   7.09e-05})
Step:  218000, Reward:  -159.229 [  86.484], Avg:  -293.684 (0.800) <0-06:41:04> ({'r_t': -4594.1208, 'eps':     0.8001, 'len': 17392.1600, 'dyn_loss':     0.0825, 'dot_loss':     0.0094, 'ddot_loss':     0.0254, 'rew_loss':  1772.1217, 'lr':   7.09e-05, 'eps_e':     0.8001, 'lr_e':   7.09e-05})
Step:  219000, Reward:  -233.969 [ 134.274], Avg:  -293.413 (0.900) <0-06:42:16> ({'r_t': -5327.9600, 'eps':     0.9001, 'len': 17472.1600, 'dyn_loss':     0.0866, 'dot_loss':     0.0096, 'ddot_loss':     0.0261, 'rew_loss':  1763.5359, 'lr':   7.09e-05, 'eps_e':     0.9001, 'lr_e':   7.09e-05})
Step:  220000, Reward:  -344.289 [ 413.551], Avg:  -293.643 (0.000) <0-06:43:19> ({'r_t': -6012.7471, 'eps':     0.0001, 'len': 17552.1600, 'dyn_loss':     0.0833, 'dot_loss':     0.0093, 'ddot_loss':     0.0250, 'rew_loss':  1692.2944, 'lr':   7.09e-05, 'eps_e':     0.0001, 'lr_e':   7.09e-05})
Step:  221000, Reward:  -291.567 [ 393.345], Avg:  -293.634 (0.100) <0-06:46:04> ({'r_t':  -924.7291, 'eps':     0.1001, 'len': 17632.1600, 'dyn_loss':     0.0830, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1743.6580, 'lr':   7.09e-05, 'eps_e':     0.1001, 'lr_e':   7.09e-05})
Step:  222000, Reward:  -241.185 [  97.256], Avg:  -293.398 (0.200) <0-06:48:37> ({'r_t': -1308.8291, 'eps':     0.2001, 'len': 17712.1600, 'dyn_loss':     0.0836, 'dot_loss':     0.0095, 'ddot_loss':     0.0257, 'rew_loss':  1768.0236, 'lr':   7.09e-05, 'eps_e':     0.2001, 'lr_e':   7.09e-05})
Step:  223000, Reward:  -159.299 [  62.267], Avg:  -292.800 (0.300) <0-06:50:59> ({'r_t': -1644.0983, 'eps':     0.3001, 'len': 17792.1600, 'dyn_loss':     0.0862, 'dot_loss':     0.0095, 'ddot_loss':     0.0252, 'rew_loss':  1541.2396, 'lr':   7.09e-05, 'eps_e':     0.3001, 'lr_e':   7.09e-05})
Step:  224000, Reward:  -196.660 [ 119.301], Avg:  -292.372 (0.400) <0-06:53:09> ({'r_t': -2112.3817, 'eps':     0.4001, 'len': 17872.1600, 'dyn_loss':     0.0844, 'dot_loss':     0.0095, 'ddot_loss':     0.0256, 'rew_loss':  1710.1813, 'lr':   6.95e-05, 'eps_e':     0.4001, 'lr_e':   6.95e-05})
Step:  225000, Reward:  -162.402 [ 101.687], Avg:  -291.797 (0.500) <0-06:55:08> ({'r_t': -2651.2050, 'eps':     0.5001, 'len': 17952.1600, 'dyn_loss':     0.0837, 'dot_loss':     0.0093, 'ddot_loss':     0.0249, 'rew_loss':  1668.1682, 'lr':   6.95e-05, 'eps_e':     0.5001, 'lr_e':   6.95e-05})
Step:  226000, Reward:  -187.433 [  74.872], Avg:  -291.338 (0.600) <0-06:56:55> ({'r_t': -3300.4510, 'eps':     0.6001, 'len': 18032.1600, 'dyn_loss':     0.0830, 'dot_loss':     0.0097, 'ddot_loss':     0.0259, 'rew_loss':  1507.2784, 'lr':   6.95e-05, 'eps_e':     0.6001, 'lr_e':   6.95e-05})
Step:  227000, Reward:  -271.568 [ 107.003], Avg:  -291.251 (0.700) <0-06:58:31> ({'r_t': -3938.3480, 'eps':     0.7001, 'len': 18112.1600, 'dyn_loss':     0.0845, 'dot_loss':     0.0096, 'ddot_loss':     0.0263, 'rew_loss':  1542.4304, 'lr':   6.95e-05, 'eps_e':     0.7001, 'lr_e':   6.95e-05})
Step:  228000, Reward:  -161.986 [ 108.948], Avg:  -290.686 (0.800) <0-06:59:55> ({'r_t': -4600.7076, 'eps':     0.8001, 'len': 18192.1600, 'dyn_loss':     0.0846, 'dot_loss':     0.0096, 'ddot_loss':     0.0261, 'rew_loss':  1693.0962, 'lr':   6.95e-05, 'eps_e':     0.8001, 'lr_e':   6.95e-05})
Step:  229000, Reward:  -197.193 [  89.118], Avg:  -290.280 (0.900) <0-07:01:07> ({'r_t': -5327.7052, 'eps':     0.9001, 'len': 18272.1600, 'dyn_loss':     0.0862, 'dot_loss':     0.0096, 'ddot_loss':     0.0261, 'rew_loss':  1768.7017, 'lr':   6.95e-05, 'eps_e':     0.9001, 'lr_e':   6.95e-05})
Step:  230000, Reward:  -149.707 [  78.236], Avg:  -289.671 (0.000) <0-07:02:10> ({'r_t': -5980.6935, 'eps':     0.0001, 'len': 18352.1600, 'dyn_loss':     0.0848, 'dot_loss':     0.0095, 'ddot_loss':     0.0255, 'rew_loss':  1670.2798, 'lr':   6.95e-05, 'eps_e':     0.0001, 'lr_e':   6.95e-05})
Step:  231000, Reward:  -247.772 [ 108.296], Avg:  -289.491 (0.100) <0-07:04:55> ({'r_t':  -876.0752, 'eps':     0.1001, 'len': 18432.1600, 'dyn_loss':     0.0883, 'dot_loss':     0.0097, 'ddot_loss':     0.0260, 'rew_loss':  1716.5413, 'lr':   6.95e-05, 'eps_e':     0.1001, 'lr_e':   6.95e-05})
Step:  232000, Reward:  -271.568 [  94.845], Avg:  -289.414 (0.200) <0-07:07:28> ({'r_t': -1005.8502, 'eps':     0.2001, 'len': 18512.1600, 'dyn_loss':     0.0838, 'dot_loss':     0.0097, 'ddot_loss':     0.0262, 'rew_loss':  1736.1752, 'lr':   6.95e-05, 'eps_e':     0.2001, 'lr_e':   6.95e-05})
Step:  233000, Reward:  -293.011 [ 408.912], Avg:  -289.429 (0.300) <0-07:09:51> ({'r_t': -1624.0348, 'eps':     0.3001, 'len': 18592.1600, 'dyn_loss':     0.0851, 'dot_loss':     0.0096, 'ddot_loss':     0.0257, 'rew_loss':  1526.8529, 'lr':   6.95e-05, 'eps_e':     0.3001, 'lr_e':   6.95e-05})
Step:  234000, Reward:  -208.766 [ 100.397], Avg:  -289.086 (0.400) <0-07:12:01> ({'r_t': -2187.0857, 'eps':     0.4001, 'len': 18672.1600, 'dyn_loss':     0.0801, 'dot_loss':     0.0093, 'ddot_loss':     0.0250, 'rew_loss':  1652.9552, 'lr':   6.95e-05, 'eps_e':     0.4001, 'lr_e':   6.95e-05})
Step:  235000, Reward:  -202.816 [  86.359], Avg:  -288.720 (0.500) <0-07:14:00> ({'r_t': -3305.9606, 'eps':     0.5001, 'len': 18752.1600, 'dyn_loss':     0.0825, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1726.2610, 'lr':   6.81e-05, 'eps_e':     0.5001, 'lr_e':   6.81e-05})
Step:  236000, Reward:  -202.315 [ 122.573], Avg:  -288.356 (0.600) <0-07:15:48> ({'r_t': -3352.2894, 'eps':     0.6001, 'len': 18832.1600, 'dyn_loss':     0.0855, 'dot_loss':     0.0097, 'ddot_loss':     0.0262, 'rew_loss':  1663.5208, 'lr':   6.81e-05, 'eps_e':     0.6001, 'lr_e':   6.81e-05})
Step:  237000, Reward:  -204.437 [  73.962], Avg:  -288.003 (0.700) <0-07:17:23> ({'r_t': -3759.1069, 'eps':     0.7001, 'len': 18912.1600, 'dyn_loss':     0.0870, 'dot_loss':     0.0094, 'ddot_loss':     0.0257, 'rew_loss':  1708.9958, 'lr':   6.81e-05, 'eps_e':     0.7001, 'lr_e':   6.81e-05})
Step:  238000, Reward:  -281.437 [ 301.309], Avg:  -287.976 (0.800) <0-07:18:47> ({'r_t': -4423.4976, 'eps':     0.8001, 'len': 18992.1600, 'dyn_loss':     0.0859, 'dot_loss':     0.0095, 'ddot_loss':     0.0254, 'rew_loss':  1660.0972, 'lr':   6.81e-05, 'eps_e':     0.8001, 'lr_e':   6.81e-05})
Step:  239000, Reward:  -298.450 [ 408.025], Avg:  -288.019 (0.900) <0-07:20:00> ({'r_t': -5295.8629, 'eps':     0.9001, 'len': 19072.1600, 'dyn_loss':     0.0841, 'dot_loss':     0.0098, 'ddot_loss':     0.0264, 'rew_loss':  1805.7828, 'lr':   6.81e-05, 'eps_e':     0.9001, 'lr_e':   6.81e-05})
Step:  240000, Reward:  -262.547 [ 352.576], Avg:  -287.914 (0.000) <0-07:21:02> ({'r_t': -6020.7221, 'eps':     0.0001, 'len': 19152.1600, 'dyn_loss':     0.0849, 'dot_loss':     0.0097, 'ddot_loss':     0.0265, 'rew_loss':  1732.2350, 'lr':   6.81e-05, 'eps_e':     0.0001, 'lr_e':   6.81e-05})
Step:  241000, Reward:  -203.835 [  86.711], Avg:  -287.566 (0.100) <0-07:23:47> ({'r_t': -1180.7424, 'eps':     0.1001, 'len': 19232.1600, 'dyn_loss':     0.0833, 'dot_loss':     0.0095, 'ddot_loss':     0.0259, 'rew_loss':  1751.1453, 'lr':   6.81e-05, 'eps_e':     0.1001, 'lr_e':   6.81e-05})
Step:  242000, Reward:  -216.645 [  90.892], Avg:  -287.274 (0.200) <0-07:26:20> ({'r_t': -1444.6500, 'eps':     0.2001, 'len': 19312.1600, 'dyn_loss':     0.0784, 'dot_loss':     0.0090, 'ddot_loss':     0.0249, 'rew_loss':  1761.1180, 'lr':   6.81e-05, 'eps_e':     0.2001, 'lr_e':   6.81e-05})
Step:  243000, Reward:  -187.881 [  90.019], Avg:  -286.867 (0.300) <0-07:28:42> ({'r_t': -1879.6244, 'eps':     0.3001, 'len': 19392.1600, 'dyn_loss':     0.0798, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1772.9222, 'lr':   6.81e-05, 'eps_e':     0.3001, 'lr_e':   6.81e-05})
Step:  244000, Reward:  -221.535 [ 103.535], Avg:  -286.600 (0.400) <0-07:30:53> ({'r_t': -2292.9059, 'eps':     0.4001, 'len': 19472.1600, 'dyn_loss':     0.0822, 'dot_loss':     0.0095, 'ddot_loss':     0.0254, 'rew_loss':  1535.3284, 'lr':   6.81e-05, 'eps_e':     0.4001, 'lr_e':   6.81e-05})
Step:  245000, Reward:  -189.123 [  66.383], Avg:  -286.204 (0.500) <0-07:32:51> ({'r_t': -2587.7802, 'eps':     0.5001, 'len': 19552.1600, 'dyn_loss':     0.0842, 'dot_loss':     0.0094, 'ddot_loss':     0.0257, 'rew_loss':  1711.1818, 'lr':   6.81e-05, 'eps_e':     0.5001, 'lr_e':   6.81e-05})
Step:  246000, Reward:  -195.683 [ 123.009], Avg:  -285.838 (0.600) <0-07:34:38> ({'r_t': -3306.1922, 'eps':     0.6001, 'len': 19632.1600, 'dyn_loss':     0.0823, 'dot_loss':     0.0094, 'ddot_loss':     0.0257, 'rew_loss':  1702.4005, 'lr':   6.68e-05, 'eps_e':     0.6001, 'lr_e':   6.68e-05})
Step:  247000, Reward:  -192.121 [ 104.091], Avg:  -285.460 (0.700) <0-07:36:14> ({'r_t': -4112.5725, 'eps':     0.7001, 'len': 19712.1600, 'dyn_loss':     0.0805, 'dot_loss':     0.0095, 'ddot_loss':     0.0259, 'rew_loss':  1721.1216, 'lr':   6.68e-05, 'eps_e':     0.7001, 'lr_e':   6.68e-05})
Step:  248000, Reward:  -147.616 [  69.784], Avg:  -284.906 (0.800) <0-07:37:38> ({'r_t': -4683.7521, 'eps':     0.8001, 'len': 19792.1600, 'dyn_loss':     0.0811, 'dot_loss':     0.0094, 'ddot_loss':     0.0256, 'rew_loss':  1667.8567, 'lr':   6.68e-05, 'eps_e':     0.8001, 'lr_e':   6.68e-05})
Step:  249000, Reward:  -220.731 [ 117.196], Avg:  -284.650 (0.900) <0-07:38:50> ({'r_t': -5509.7406, 'eps':     0.9001, 'len': 19872.1600, 'dyn_loss':     0.0857, 'dot_loss':     0.0095, 'ddot_loss':     0.0258, 'rew_loss':  1704.5571, 'lr':   6.68e-05, 'eps_e':     0.9001, 'lr_e':   6.68e-05})
Step:  250000, Reward:  -185.128 [  84.277], Avg:  -284.253 (0.000) <0-07:39:53> ({'r_t': -5960.5138, 'eps':     0.0001, 'len': 19952.1600, 'dyn_loss':     0.0798, 'dot_loss':     0.0095, 'ddot_loss':     0.0257, 'rew_loss':  1621.0668, 'lr':   6.68e-05, 'eps_e':     0.0001, 'lr_e':   6.68e-05})
Step:  251000, Reward:  -178.208 [  86.791], Avg:  -283.832 (0.100) <0-07:42:39> ({'r_t':  -944.8455, 'eps':     0.1001, 'len': 20032.1600, 'dyn_loss':     0.0830, 'dot_loss':     0.0096, 'ddot_loss':     0.0261, 'rew_loss':  1729.4156, 'lr':   6.68e-05, 'eps_e':     0.1001, 'lr_e':   6.68e-05})
Step:  252000, Reward:  -178.475 [  58.963], Avg:  -283.416 (0.200) <0-07:45:12> ({'r_t': -1151.1978, 'eps':     0.2001, 'len': 20112.1600, 'dyn_loss':     0.0812, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1703.6213, 'lr':   6.68e-05, 'eps_e':     0.2001, 'lr_e':   6.68e-05})
Step:  253000, Reward:  -202.545 [ 115.360], Avg:  -283.097 (0.300) <0-07:47:34> ({'r_t': -1527.6081, 'eps':     0.3001, 'len': 20192.1600, 'dyn_loss':     0.0791, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1673.4365, 'lr':   6.68e-05, 'eps_e':     0.3001, 'lr_e':   6.68e-05})
Step:  254000, Reward:  -154.133 [  77.520], Avg:  -282.592 (0.400) <0-07:49:44> ({'r_t': -2066.3296, 'eps':     0.4001, 'len': 20272.1600, 'dyn_loss':     0.0837, 'dot_loss':     0.0098, 'ddot_loss':     0.0263, 'rew_loss':  1731.8496, 'lr':   6.68e-05, 'eps_e':     0.4001, 'lr_e':   6.68e-05})
Step:  255000, Reward:  -193.047 [ 102.883], Avg:  -282.242 (0.500) <0-07:51:43> ({'r_t': -2587.0280, 'eps':     0.5001, 'len': 20352.1600, 'dyn_loss':     0.0782, 'dot_loss':     0.0091, 'ddot_loss':     0.0248, 'rew_loss':  1592.7705, 'lr':   6.68e-05, 'eps_e':     0.5001, 'lr_e':   6.68e-05})
Step:  256000, Reward:  -208.726 [  82.903], Avg:  -281.956 (0.600) <0-07:53:30> ({'r_t': -3211.9170, 'eps':     0.6001, 'len': 20432.1600, 'dyn_loss':     0.0860, 'dot_loss':     0.0095, 'ddot_loss':     0.0259, 'rew_loss':  1794.8267, 'lr':   6.68e-05, 'eps_e':     0.6001, 'lr_e':   6.68e-05})
Step:  257000, Reward:  -173.468 [  78.762], Avg:  -281.535 (0.700) <0-07:55:06> ({'r_t': -3888.2004, 'eps':     0.7001, 'len': 20512.1600, 'dyn_loss':     0.0826, 'dot_loss':     0.0095, 'ddot_loss':     0.0259, 'rew_loss':  1727.3733, 'lr':   6.54e-05, 'eps_e':     0.7001, 'lr_e':   6.54e-05})
Step:  258000, Reward:  -169.975 [  86.404], Avg:  -281.105 (0.800) <0-07:56:30> ({'r_t': -4476.0702, 'eps':     0.8001, 'len': 20592.1600, 'dyn_loss':     0.0835, 'dot_loss':     0.0095, 'ddot_loss':     0.0258, 'rew_loss':  1784.4611, 'lr':   6.54e-05, 'eps_e':     0.8001, 'lr_e':   6.54e-05})
Step:  259000, Reward:  -192.864 [ 113.277], Avg:  -280.765 (0.900) <0-07:57:42> ({'r_t': -5402.6073, 'eps':     0.9001, 'len': 20672.1600, 'dyn_loss':     0.0793, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1691.0106, 'lr':   6.54e-05, 'eps_e':     0.9001, 'lr_e':   6.54e-05})
Step:  260000, Reward:  -190.914 [ 107.233], Avg:  -280.421 (0.000) <0-07:58:45> ({'r_t': -5962.8194, 'eps':     0.0001, 'len': 20752.1600, 'dyn_loss':     0.0785, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1643.2244, 'lr':   6.54e-05, 'eps_e':     0.0001, 'lr_e':   6.54e-05})
Step:  261000, Reward:  -220.061 [  94.889], Avg:  -280.191 (0.100) <0-08:01:31> ({'r_t':  -966.5767, 'eps':     0.1001, 'len': 20832.1600, 'dyn_loss':     0.0848, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1710.8665, 'lr':   6.54e-05, 'eps_e':     0.1001, 'lr_e':   6.54e-05})
Step:  262000, Reward:  -215.908 [ 104.496], Avg:  -279.946 (0.200) <0-08:04:04> ({'r_t': -1162.2469, 'eps':     0.2001, 'len': 20912.1600, 'dyn_loss':     0.0828, 'dot_loss':     0.0092, 'ddot_loss':     0.0250, 'rew_loss':  1770.9779, 'lr':   6.54e-05, 'eps_e':     0.2001, 'lr_e':   6.54e-05})
Step:  263000, Reward:  -200.761 [ 119.258], Avg:  -279.646 (0.300) <0-08:06:26> ({'r_t': -1695.2888, 'eps':     0.3001, 'len': 20992.1600, 'dyn_loss':     0.0794, 'dot_loss':     0.0091, 'ddot_loss':     0.0248, 'rew_loss':  1670.0347, 'lr':   6.54e-05, 'eps_e':     0.3001, 'lr_e':   6.54e-05})
Step:  264000, Reward:  -173.898 [ 108.246], Avg:  -279.247 (0.400) <0-08:08:37> ({'r_t': -2042.1283, 'eps':     0.4001, 'len': 21072.1600, 'dyn_loss':     0.0820, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1697.1505, 'lr':   6.54e-05, 'eps_e':     0.4001, 'lr_e':   6.54e-05})
Step:  265000, Reward:  -243.913 [  78.881], Avg:  -279.114 (0.500) <0-08:10:36> ({'r_t': -2653.2236, 'eps':     0.5001, 'len': 21152.1600, 'dyn_loss':     0.0772, 'dot_loss':     0.0091, 'ddot_loss':     0.0248, 'rew_loss':  1629.6879, 'lr':   6.54e-05, 'eps_e':     0.5001, 'lr_e':   6.54e-05})
Step:  266000, Reward:  -196.271 [  79.720], Avg:  -278.804 (0.600) <0-08:12:23> ({'r_t': -3308.2612, 'eps':     0.6001, 'len': 21232.1600, 'dyn_loss':     0.0798, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1668.8915, 'lr':   6.54e-05, 'eps_e':     0.6001, 'lr_e':   6.54e-05})
Step:  267000, Reward:  -184.402 [ 129.968], Avg:  -278.452 (0.700) <0-08:13:59> ({'r_t': -3772.9898, 'eps':     0.7001, 'len': 21312.1600, 'dyn_loss':     0.0781, 'dot_loss':     0.0092, 'ddot_loss':     0.0252, 'rew_loss':  1617.6545, 'lr':   6.54e-05, 'eps_e':     0.7001, 'lr_e':   6.54e-05})
Step:  268000, Reward:  -171.145 [  71.790], Avg:  -278.053 (0.800) <0-08:15:23> ({'r_t': -4415.6343, 'eps':     0.8001, 'len': 21392.1600, 'dyn_loss':     0.0794, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1601.7913, 'lr':   6.41e-05, 'eps_e':     0.8001, 'lr_e':   6.41e-05})
Step:  269000, Reward:  -172.093 [  79.781], Avg:  -277.660 (0.900) <0-08:16:36> ({'r_t': -5128.4987, 'eps':     0.9001, 'len': 21472.1600, 'dyn_loss':     0.0789, 'dot_loss':     0.0092, 'ddot_loss':     0.0250, 'rew_loss':  1679.8281, 'lr':   6.41e-05, 'eps_e':     0.9001, 'lr_e':   6.41e-05})
Step:  270000, Reward:  -266.815 [ 166.149], Avg:  -277.620 (0.000) <0-08:17:39> ({'r_t': -5945.0530, 'eps':     0.0001, 'len': 21552.1600, 'dyn_loss':     0.0843, 'dot_loss':     0.0094, 'ddot_loss':     0.0257, 'rew_loss':  1836.0542, 'lr':   6.41e-05, 'eps_e':     0.0001, 'lr_e':   6.41e-05})
Step:  271000, Reward:  -172.800 [  72.392], Avg:  -277.235 (0.100) <0-08:20:24> ({'r_t':  -912.9119, 'eps':     0.1001, 'len': 21632.1600, 'dyn_loss':     0.0835, 'dot_loss':     0.0094, 'ddot_loss':     0.0259, 'rew_loss':  1598.2780, 'lr':   6.41e-05, 'eps_e':     0.1001, 'lr_e':   6.41e-05})
Step:  272000, Reward:  -208.324 [  85.290], Avg:  -276.983 (0.200) <0-08:22:59> ({'r_t': -1214.7157, 'eps':     0.2001, 'len': 21712.1600, 'dyn_loss':     0.0817, 'dot_loss':     0.0092, 'ddot_loss':     0.0252, 'rew_loss':  1643.2269, 'lr':   6.41e-05, 'eps_e':     0.2001, 'lr_e':   6.41e-05})
Step:  273000, Reward:  -219.691 [  99.667], Avg:  -276.774 (0.300) <0-08:25:21> ({'r_t': -1536.8124, 'eps':     0.3001, 'len': 21792.1600, 'dyn_loss':     0.0823, 'dot_loss':     0.0094, 'ddot_loss':     0.0256, 'rew_loss':  1676.3136, 'lr':   6.41e-05, 'eps_e':     0.3001, 'lr_e':   6.41e-05})
Step:  274000, Reward:  -219.532 [ 122.674], Avg:  -276.565 (0.400) <0-08:27:32> ({'r_t': -2007.7387, 'eps':     0.4001, 'len': 21872.1600, 'dyn_loss':     0.0796, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1596.6208, 'lr':   6.41e-05, 'eps_e':     0.4001, 'lr_e':   6.41e-05})
Step:  275000, Reward:  -185.608 [  84.232], Avg:  -276.236 (0.500) <0-08:29:31> ({'r_t': -2568.1326, 'eps':     0.5001, 'len': 21952.1600, 'dyn_loss':     0.0808, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1629.5728, 'lr':   6.41e-05, 'eps_e':     0.5001, 'lr_e':   6.41e-05})
Step:  276000, Reward:  -222.594 [  96.256], Avg:  -276.042 (0.600) <0-08:31:19> ({'r_t': -3298.9373, 'eps':     0.6001, 'len': 22032.1600, 'dyn_loss':     0.0786, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1718.6958, 'lr':   6.41e-05, 'eps_e':     0.6001, 'lr_e':   6.41e-05})
Step:  277000, Reward:  -195.853 [  75.063], Avg:  -275.754 (0.700) <0-08:32:55> ({'r_t': -3799.6690, 'eps':     0.7001, 'len': 22112.1600, 'dyn_loss':     0.0805, 'dot_loss':     0.0095, 'ddot_loss':     0.0259, 'rew_loss':  1549.4391, 'lr':   6.41e-05, 'eps_e':     0.7001, 'lr_e':   6.41e-05})
Step:  278000, Reward:  -132.554 [  75.496], Avg:  -275.240 (0.800) <0-08:34:20> ({'r_t': -4532.3532, 'eps':     0.8001, 'len': 22192.1600, 'dyn_loss':     0.0806, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1679.9425, 'lr':   6.41e-05, 'eps_e':     0.8001, 'lr_e':   6.41e-05})
Step:  279000, Reward:  -183.699 [  84.955], Avg:  -274.914 (0.900) <0-08:35:32> ({'r_t': -5286.5303, 'eps':     0.9001, 'len': 22272.1600, 'dyn_loss':     0.0791, 'dot_loss':     0.0091, 'ddot_loss':     0.0251, 'rew_loss':  1700.2229, 'lr':   6.28e-05, 'eps_e':     0.9001, 'lr_e':   6.28e-05})
Step:  280000, Reward:  -175.275 [  72.047], Avg:  -274.559 (0.000) <0-08:36:36> ({'r_t': -5951.7640, 'eps':     0.0001, 'len': 22352.1600, 'dyn_loss':     0.0816, 'dot_loss':     0.0093, 'ddot_loss':     0.0254, 'rew_loss':  1816.6896, 'lr':   6.28e-05, 'eps_e':     0.0001, 'lr_e':   6.28e-05})
Step:  281000, Reward:  -185.960 [ 104.995], Avg:  -274.245 (0.100) <0-08:39:23> ({'r_t':  -933.2563, 'eps':     0.1001, 'len': 22432.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0089, 'ddot_loss':     0.0244, 'rew_loss':  1665.8625, 'lr':   6.28e-05, 'eps_e':     0.1001, 'lr_e':   6.28e-05})
Step:  282000, Reward:  -134.335 [  41.949], Avg:  -273.750 (0.200) <0-08:41:58> ({'r_t': -1059.3489, 'eps':     0.2001, 'len': 22512.1600, 'dyn_loss':     0.0781, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1693.4520, 'lr':   6.28e-05, 'eps_e':     0.2001, 'lr_e':   6.28e-05})
Step:  283000, Reward:  -160.240 [  81.790], Avg:  -273.351 (0.300) <0-08:44:21> ({'r_t': -1480.8539, 'eps':     0.3001, 'len': 22592.1600, 'dyn_loss':     0.0850, 'dot_loss':     0.0095, 'ddot_loss':     0.0255, 'rew_loss':  1600.7861, 'lr':   6.28e-05, 'eps_e':     0.3001, 'lr_e':   6.28e-05})
Step:  284000, Reward:  -206.303 [  80.152], Avg:  -273.115 (0.400) <0-08:46:32> ({'r_t': -2078.5300, 'eps':     0.4001, 'len': 22672.1600, 'dyn_loss':     0.0816, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1692.9386, 'lr':   6.28e-05, 'eps_e':     0.4001, 'lr_e':   6.28e-05})
Step:  285000, Reward:  -175.420 [  82.939], Avg:  -272.774 (0.500) <0-08:48:32> ({'r_t': -2618.8665, 'eps':     0.5001, 'len': 22752.1600, 'dyn_loss':     0.0838, 'dot_loss':     0.0096, 'ddot_loss':     0.0261, 'rew_loss':  1622.7045, 'lr':   6.28e-05, 'eps_e':     0.5001, 'lr_e':   6.28e-05})
Step:  286000, Reward:  -182.684 [  96.122], Avg:  -272.460 (0.600) <0-08:50:20> ({'r_t': -3178.6355, 'eps':     0.6001, 'len': 22832.1600, 'dyn_loss':     0.0809, 'dot_loss':     0.0094, 'ddot_loss':     0.0256, 'rew_loss':  1631.6920, 'lr':   6.28e-05, 'eps_e':     0.6001, 'lr_e':   6.28e-05})
Step:  287000, Reward:  -170.820 [  74.771], Avg:  -272.107 (0.700) <0-08:51:57> ({'r_t': -3893.6499, 'eps':     0.7001, 'len': 22912.1600, 'dyn_loss':     0.0784, 'dot_loss':     0.0091, 'ddot_loss':     0.0251, 'rew_loss':  1521.2306, 'lr':   6.28e-05, 'eps_e':     0.7001, 'lr_e':   6.28e-05})
Step:  288000, Reward:  -151.288 [  61.329], Avg:  -271.689 (0.800) <0-08:53:21> ({'r_t': -4519.3678, 'eps':     0.8001, 'len': 22992.1600, 'dyn_loss':     0.0775, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1701.4305, 'lr':   6.28e-05, 'eps_e':     0.8001, 'lr_e':   6.28e-05})
Step:  289000, Reward:  -167.033 [  56.142], Avg:  -271.328 (0.900) <0-08:54:34> ({'r_t': -5204.0921, 'eps':     0.9001, 'len': 23072.1600, 'dyn_loss':     0.0827, 'dot_loss':     0.0095, 'ddot_loss':     0.0257, 'rew_loss':  1684.4424, 'lr':   6.28e-05, 'eps_e':     0.9001, 'lr_e':   6.28e-05})
Step:  290000, Reward:  -195.110 [  69.294], Avg:  -271.066 (0.000) <0-08:55:38> ({'r_t': -5978.4030, 'eps':     0.0001, 'len': 23152.1600, 'dyn_loss':     0.0791, 'dot_loss':     0.0091, 'ddot_loss':     0.0251, 'rew_loss':  1705.2039, 'lr':   6.16e-05, 'eps_e':     0.0001, 'lr_e':   6.16e-05})
Step:  291000, Reward:  -198.614 [  93.550], Avg:  -270.818 (0.100) <0-08:58:23> ({'r_t':  -889.4856, 'eps':     0.1001, 'len': 23232.1600, 'dyn_loss':     0.0816, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1658.3202, 'lr':   6.16e-05, 'eps_e':     0.1001, 'lr_e':   6.16e-05})
Step:  292000, Reward:  -201.437 [  89.317], Avg:  -270.581 (0.200) <0-09:00:58> ({'r_t': -1160.3198, 'eps':     0.2001, 'len': 23312.1600, 'dyn_loss':     0.0772, 'dot_loss':     0.0091, 'ddot_loss':     0.0249, 'rew_loss':  1555.6160, 'lr':   6.16e-05, 'eps_e':     0.2001, 'lr_e':   6.16e-05})
Step:  293000, Reward:  -164.262 [ 106.893], Avg:  -270.220 (0.300) <0-09:03:20> ({'r_t': -1584.3407, 'eps':     0.3001, 'len': 23392.1600, 'dyn_loss':     0.0807, 'dot_loss':     0.0093, 'ddot_loss':     0.0253, 'rew_loss':  1695.4847, 'lr':   6.16e-05, 'eps_e':     0.3001, 'lr_e':   6.16e-05})
Step:  294000, Reward:  -194.142 [  78.579], Avg:  -269.962 (0.400) <0-09:05:32> ({'r_t': -2190.7420, 'eps':     0.4001, 'len': 23472.1600, 'dyn_loss':     0.0818, 'dot_loss':     0.0094, 'ddot_loss':     0.0255, 'rew_loss':  1577.4379, 'lr':   6.16e-05, 'eps_e':     0.4001, 'lr_e':   6.16e-05})
Step:  295000, Reward:  -217.946 [  93.599], Avg:  -269.786 (0.500) <0-09:07:31> ({'r_t': -2611.4180, 'eps':     0.5001, 'len': 23552.1600, 'dyn_loss':     0.0798, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1693.4551, 'lr':   6.16e-05, 'eps_e':     0.5001, 'lr_e':   6.16e-05})
Step:  296000, Reward:  -220.620 [  92.771], Avg:  -269.620 (0.600) <0-09:09:19> ({'r_t': -3176.2431, 'eps':     0.6001, 'len': 23632.1600, 'dyn_loss':     0.0789, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1768.0460, 'lr':   6.16e-05, 'eps_e':     0.6001, 'lr_e':   6.16e-05})
Step:  297000, Reward:  -204.700 [  83.299], Avg:  -269.403 (0.700) <0-09:10:56> ({'r_t': -3710.7494, 'eps':     0.7001, 'len': 23712.1600, 'dyn_loss':     0.0802, 'dot_loss':     0.0091, 'ddot_loss':     0.0246, 'rew_loss':  1476.0122, 'lr':   6.16e-05, 'eps_e':     0.7001, 'lr_e':   6.16e-05})
Step:  298000, Reward:  -170.039 [  99.596], Avg:  -269.070 (0.800) <0-09:12:20> ({'r_t': -4525.0710, 'eps':     0.8001, 'len': 23792.1600, 'dyn_loss':     0.0835, 'dot_loss':     0.0096, 'ddot_loss':     0.0259, 'rew_loss':  1659.5905, 'lr':   6.16e-05, 'eps_e':     0.8001, 'lr_e':   6.16e-05})
Step:  299000, Reward:  -167.701 [ 100.871], Avg:  -268.732 (0.900) <0-09:13:33> ({'r_t': -5316.5269, 'eps':     0.9001, 'len': 23872.1600, 'dyn_loss':     0.0819, 'dot_loss':     0.0093, 'ddot_loss':     0.0259, 'rew_loss':  1733.3119, 'lr':   6.16e-05, 'eps_e':     0.9001, 'lr_e':   6.16e-05})
Step:  300000, Reward:  -204.628 [ 132.909], Avg:  -268.519 (0.000) <0-09:14:36> ({'r_t': -6045.4158, 'eps':     0.0001, 'len': 23952.1600, 'dyn_loss':     0.0793, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1719.9620, 'lr':   6.16e-05, 'eps_e':     0.0001, 'lr_e':   6.16e-05})
Step:  301000, Reward:  -143.202 [  80.505], Avg:  -268.104 (0.100) <0-09:17:23> ({'r_t':  -891.5271, 'eps':     0.1001, 'len': 24032.1600, 'dyn_loss':     0.0806, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1747.3055, 'lr':   6.03e-05, 'eps_e':     0.1001, 'lr_e':   6.03e-05})
Step:  302000, Reward:  -160.797 [  84.734], Avg:  -267.750 (0.200) <0-09:20:01> ({'r_t': -1385.3490, 'eps':     0.2001, 'len': 24112.1600, 'dyn_loss':     0.0786, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1622.6545, 'lr':   6.03e-05, 'eps_e':     0.2001, 'lr_e':   6.03e-05})
Step:  303000, Reward:  -167.122 [  68.270], Avg:  -267.419 (0.300) <0-09:22:25> ({'r_t': -1642.3016, 'eps':     0.3001, 'len': 24192.1600, 'dyn_loss':     0.0769, 'dot_loss':     0.0091, 'ddot_loss':     0.0255, 'rew_loss':  1730.8536, 'lr':   6.03e-05, 'eps_e':     0.3001, 'lr_e':   6.03e-05})
Step:  304000, Reward:  -160.667 [  83.304], Avg:  -267.069 (0.400) <0-09:24:37> ({'r_t': -2044.5229, 'eps':     0.4001, 'len': 24272.1600, 'dyn_loss':     0.0773, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1589.2285, 'lr':   6.03e-05, 'eps_e':     0.4001, 'lr_e':   6.03e-05})
Step:  305000, Reward:  -169.498 [  57.421], Avg:  -266.750 (0.500) <0-09:26:36> ({'r_t': -2583.5643, 'eps':     0.5001, 'len': 24352.1600, 'dyn_loss':     0.0783, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1759.5793, 'lr':   6.03e-05, 'eps_e':     0.5001, 'lr_e':   6.03e-05})
Step:  306000, Reward:  -198.889 [  93.512], Avg:  -266.529 (0.600) <0-09:28:24> ({'r_t': -3164.9106, 'eps':     0.6001, 'len': 24432.1600, 'dyn_loss':     0.0790, 'dot_loss':     0.0090, 'ddot_loss':     0.0249, 'rew_loss':  1778.8733, 'lr':   6.03e-05, 'eps_e':     0.6001, 'lr_e':   6.03e-05})
Step:  307000, Reward:  -159.163 [  52.722], Avg:  -266.181 (0.700) <0-09:30:00> ({'r_t': -3872.7332, 'eps':     0.7001, 'len': 24512.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0093, 'ddot_loss':     0.0254, 'rew_loss':  1716.1619, 'lr':   6.03e-05, 'eps_e':     0.7001, 'lr_e':   6.03e-05})
Step:  308000, Reward:  -138.033 [  70.466], Avg:  -265.766 (0.800) <0-09:31:25> ({'r_t': -4519.0288, 'eps':     0.8001, 'len': 24592.1600, 'dyn_loss':     0.0785, 'dot_loss':     0.0092, 'ddot_loss':     0.0252, 'rew_loss':  1684.0531, 'lr':   6.03e-05, 'eps_e':     0.8001, 'lr_e':   6.03e-05})
Step:  309000, Reward:  -224.599 [ 219.451], Avg:  -265.633 (0.900) <0-09:32:39> ({'r_t': -5170.4100, 'eps':     0.9001, 'len': 24672.1600, 'dyn_loss':     0.0784, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1675.3829, 'lr':   6.03e-05, 'eps_e':     0.9001, 'lr_e':   6.03e-05})
Step:  310000, Reward:  -184.371 [  71.843], Avg:  -265.372 (0.000) <0-09:33:43> ({'r_t': -5882.9452, 'eps':     0.0001, 'len': 24752.1600, 'dyn_loss':     0.0819, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1747.7847, 'lr':   6.03e-05, 'eps_e':     0.0001, 'lr_e':   6.03e-05})
Step:  311000, Reward:  -171.920 [  77.800], Avg:  -265.072 (0.100) <0-09:36:30> ({'r_t':  -927.4021, 'eps':     0.1001, 'len': 24832.1600, 'dyn_loss':     0.0781, 'dot_loss':     0.0091, 'ddot_loss':     0.0249, 'rew_loss':  1772.9658, 'lr':   6.03e-05, 'eps_e':     0.1001, 'lr_e':   6.03e-05})
Step:  312000, Reward:  -185.045 [  74.307], Avg:  -264.817 (0.200) <0-09:39:05> ({'r_t': -1036.7971, 'eps':     0.2001, 'len': 24912.1600, 'dyn_loss':     0.0765, 'dot_loss':     0.0089, 'ddot_loss':     0.0246, 'rew_loss':  1747.6997, 'lr':   5.91e-05, 'eps_e':     0.2001, 'lr_e':   5.91e-05})
Step:  313000, Reward:  -211.660 [ 116.958], Avg:  -264.647 (0.300) <0-09:41:28> ({'r_t': -1635.7610, 'eps':     0.3001, 'len': 24992.1600, 'dyn_loss':     0.0784, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1648.8153, 'lr':   5.91e-05, 'eps_e':     0.3001, 'lr_e':   5.91e-05})
Step:  314000, Reward:  -181.212 [  71.225], Avg:  -264.383 (0.400) <0-09:43:40> ({'r_t': -2117.5923, 'eps':     0.4001, 'len': 25072.1600, 'dyn_loss':     0.0789, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1780.0612, 'lr':   5.91e-05, 'eps_e':     0.4001, 'lr_e':   5.91e-05})
Step:  315000, Reward:  -199.686 [  82.163], Avg:  -264.178 (0.500) <0-09:45:40> ({'r_t': -2689.2417, 'eps':     0.5001, 'len': 25152.1600, 'dyn_loss':     0.0758, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1623.2137, 'lr':   5.91e-05, 'eps_e':     0.5001, 'lr_e':   5.91e-05})
Step:  316000, Reward:  -190.453 [  80.658], Avg:  -263.945 (0.600) <0-09:47:31> ({'r_t': -3230.7676, 'eps':     0.6001, 'len': 25232.1600, 'dyn_loss':     0.0798, 'dot_loss':     0.0092, 'ddot_loss':     0.0250, 'rew_loss':  1677.1315, 'lr':   5.91e-05, 'eps_e':     0.6001, 'lr_e':   5.91e-05})
Step:  317000, Reward:  -166.083 [  79.049], Avg:  -263.638 (0.700) <0-09:49:09> ({'r_t': -3928.2190, 'eps':     0.7001, 'len': 25312.1600, 'dyn_loss':     0.0808, 'dot_loss':     0.0093, 'ddot_loss':     0.0254, 'rew_loss':  1707.1941, 'lr':   5.91e-05, 'eps_e':     0.7001, 'lr_e':   5.91e-05})
Step:  318000, Reward:  -188.634 [  86.016], Avg:  -263.402 (0.800) <0-09:50:35> ({'r_t': -4566.2651, 'eps':     0.8001, 'len': 25392.1600, 'dyn_loss':     0.0765, 'dot_loss':     0.0089, 'ddot_loss':     0.0246, 'rew_loss':  1574.8314, 'lr':   5.91e-05, 'eps_e':     0.8001, 'lr_e':   5.91e-05})
Step:  319000, Reward:  -194.018 [ 102.061], Avg:  -263.186 (0.900) <0-09:51:48> ({'r_t': -5187.4926, 'eps':     0.9001, 'len': 25472.1600, 'dyn_loss':     0.0814, 'dot_loss':     0.0097, 'ddot_loss':     0.0264, 'rew_loss':  1650.5055, 'lr':   5.91e-05, 'eps_e':     0.9001, 'lr_e':   5.91e-05})
Step:  320000, Reward:  -121.243 [  78.781], Avg:  -262.743 (0.000) <0-09:52:53> ({'r_t': -6112.9446, 'eps':     0.0001, 'len': 25552.1600, 'dyn_loss':     0.0786, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1708.9847, 'lr':   5.91e-05, 'eps_e':     0.0001, 'lr_e':   5.91e-05})
Step:  321000, Reward:  -219.986 [ 102.681], Avg:  -262.611 (0.100) <0-09:55:43> ({'r_t':  -973.3318, 'eps':     0.1001, 'len': 25632.1600, 'dyn_loss':     0.0792, 'dot_loss':     0.0093, 'ddot_loss':     0.0253, 'rew_loss':  1637.3335, 'lr':   5.91e-05, 'eps_e':     0.1001, 'lr_e':   5.91e-05})
Step:  322000, Reward:  -191.869 [  83.608], Avg:  -262.392 (0.200) <0-09:58:21> ({'r_t': -1056.1060, 'eps':     0.2001, 'len': 25712.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0092, 'ddot_loss':     0.0251, 'rew_loss':  1569.4337, 'lr':   5.91e-05, 'eps_e':     0.2001, 'lr_e':   5.91e-05})
Step:  323000, Reward:  -172.848 [  96.795], Avg:  -262.115 (0.300) <0-10:00:46> ({'r_t': -1514.3093, 'eps':     0.3001, 'len': 25792.1600, 'dyn_loss':     0.0799, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1574.1826, 'lr':   5.80e-05, 'eps_e':     0.3001, 'lr_e':   5.80e-05})
Step:  324000, Reward:  -187.246 [  90.712], Avg:  -261.885 (0.400) <0-10:02:59> ({'r_t': -2103.9801, 'eps':     0.4001, 'len': 25872.1600, 'dyn_loss':     0.0757, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1620.3690, 'lr':   5.80e-05, 'eps_e':     0.4001, 'lr_e':   5.80e-05})
Step:  325000, Reward:  -223.401 [ 118.779], Avg:  -261.767 (0.500) <0-10:05:02> ({'r_t': -2693.0429, 'eps':     0.5001, 'len': 25952.1600, 'dyn_loss':     0.0771, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1770.0173, 'lr':   5.80e-05, 'eps_e':     0.5001, 'lr_e':   5.80e-05})
Step:  326000, Reward:  -130.229 [  96.933], Avg:  -261.365 (0.600) <0-10:06:52> ({'r_t': -3171.2402, 'eps':     0.6001, 'len': 26032.1600, 'dyn_loss':     0.0821, 'dot_loss':     0.0095, 'ddot_loss':     0.0260, 'rew_loss':  1612.9518, 'lr':   5.80e-05, 'eps_e':     0.6001, 'lr_e':   5.80e-05})
Step:  327000, Reward:  -196.339 [ 109.952], Avg:  -261.166 (0.700) <0-10:08:30> ({'r_t': -3896.6854, 'eps':     0.7001, 'len': 26112.1600, 'dyn_loss':     0.0809, 'dot_loss':     0.0095, 'ddot_loss':     0.0262, 'rew_loss':  1807.8739, 'lr':   5.80e-05, 'eps_e':     0.7001, 'lr_e':   5.80e-05})
Step:  328000, Reward:  -189.088 [ 100.858], Avg:  -260.947 (0.800) <0-10:09:56> ({'r_t': -4614.5317, 'eps':     0.8001, 'len': 26192.1600, 'dyn_loss':     0.0776, 'dot_loss':     0.0092, 'ddot_loss':     0.0258, 'rew_loss':  1613.3866, 'lr':   5.80e-05, 'eps_e':     0.8001, 'lr_e':   5.80e-05})
Step:  329000, Reward:  -192.579 [ 107.301], Avg:  -260.740 (0.900) <0-10:11:11> ({'r_t': -5484.3118, 'eps':     0.9001, 'len': 26272.1600, 'dyn_loss':     0.0778, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1624.1741, 'lr':   5.80e-05, 'eps_e':     0.9001, 'lr_e':   5.80e-05})
Step:  330000, Reward:  -200.683 [  90.358], Avg:  -260.559 (0.000) <0-10:12:16> ({'r_t': -6095.3897, 'eps':     0.0001, 'len': 26352.1600, 'dyn_loss':     0.0770, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1727.5424, 'lr':   5.80e-05, 'eps_e':     0.0001, 'lr_e':   5.80e-05})
Step:  331000, Reward:  -183.289 [  85.814], Avg:  -260.326 (0.100) <0-10:15:04> ({'r_t':  -894.3134, 'eps':     0.1001, 'len': 26432.1600, 'dyn_loss':     0.0761, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1674.8064, 'lr':   5.80e-05, 'eps_e':     0.1001, 'lr_e':   5.80e-05})
Step:  332000, Reward:  -205.246 [ 105.501], Avg:  -260.160 (0.200) <0-10:17:40> ({'r_t': -1278.4183, 'eps':     0.2001, 'len': 26512.1600, 'dyn_loss':     0.0776, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1708.0642, 'lr':   5.80e-05, 'eps_e':     0.2001, 'lr_e':   5.80e-05})
Step:  333000, Reward:  -188.630 [  78.895], Avg:  -259.946 (0.300) <0-10:20:06> ({'r_t': -1566.0422, 'eps':     0.3001, 'len': 26592.1600, 'dyn_loss':     0.0769, 'dot_loss':     0.0088, 'ddot_loss':     0.0244, 'rew_loss':  1718.2915, 'lr':   5.80e-05, 'eps_e':     0.3001, 'lr_e':   5.80e-05})
Step:  334000, Reward:  -229.792 [  98.075], Avg:  -259.856 (0.400) <0-10:22:19> ({'r_t': -2118.5753, 'eps':     0.4001, 'len': 26672.1600, 'dyn_loss':     0.0781, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1820.1073, 'lr':   5.68e-05, 'eps_e':     0.4001, 'lr_e':   5.68e-05})
Step:  335000, Reward:  -214.654 [  72.083], Avg:  -259.722 (0.500) <0-10:24:21> ({'r_t': -2585.9020, 'eps':     0.5001, 'len': 26752.1600, 'dyn_loss':     0.0774, 'dot_loss':     0.0090, 'ddot_loss':     0.0247, 'rew_loss':  1671.4003, 'lr':   5.68e-05, 'eps_e':     0.5001, 'lr_e':   5.68e-05})
Step:  336000, Reward:  -195.255 [  88.810], Avg:  -259.530 (0.600) <0-10:26:11> ({'r_t': -3227.2166, 'eps':     0.6001, 'len': 26832.1600, 'dyn_loss':     0.0770, 'dot_loss':     0.0091, 'ddot_loss':     0.0251, 'rew_loss':  1650.6395, 'lr':   5.68e-05, 'eps_e':     0.6001, 'lr_e':   5.68e-05})
Step:  337000, Reward:  -184.627 [ 134.500], Avg:  -259.309 (0.700) <0-10:27:49> ({'r_t': -3759.9479, 'eps':     0.7001, 'len': 26912.1600, 'dyn_loss':     0.0741, 'dot_loss':     0.0088, 'ddot_loss':     0.0245, 'rew_loss':  1638.7861, 'lr':   5.68e-05, 'eps_e':     0.7001, 'lr_e':   5.68e-05})
Step:  338000, Reward:  -129.919 [  77.336], Avg:  -258.927 (0.800) <0-10:29:15> ({'r_t': -4525.9395, 'eps':     0.8001, 'len': 26992.1600, 'dyn_loss':     0.0811, 'dot_loss':     0.0094, 'ddot_loss':     0.0258, 'rew_loss':  1609.7501, 'lr':   5.68e-05, 'eps_e':     0.8001, 'lr_e':   5.68e-05})
Step:  339000, Reward:  -173.470 [  57.971], Avg:  -258.676 (0.900) <0-10:30:30> ({'r_t': -5324.0673, 'eps':     0.9001, 'len': 27072.1600, 'dyn_loss':     0.0785, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1564.4226, 'lr':   5.68e-05, 'eps_e':     0.9001, 'lr_e':   5.68e-05})
Step:  340000, Reward:  -183.487 [  98.805], Avg:  -258.455 (0.000) <0-10:31:34> ({'r_t': -5919.0037, 'eps':     0.0001, 'len': 27152.1600, 'dyn_loss':     0.0787, 'dot_loss':     0.0093, 'ddot_loss':     0.0258, 'rew_loss':  1707.4133, 'lr':   5.68e-05, 'eps_e':     0.0001, 'lr_e':   5.68e-05})
Step:  341000, Reward:  -168.766 [  98.373], Avg:  -258.193 (0.100) <0-10:34:23> ({'r_t':  -899.2854, 'eps':     0.1001, 'len': 27232.1600, 'dyn_loss':     0.0769, 'dot_loss':     0.0091, 'ddot_loss':     0.0248, 'rew_loss':  1615.8073, 'lr':   5.68e-05, 'eps_e':     0.1001, 'lr_e':   5.68e-05})
Step:  342000, Reward:  -204.584 [  72.486], Avg:  -258.037 (0.200) <0-10:37:03> ({'r_t': -1115.6362, 'eps':     0.2001, 'len': 27312.1600, 'dyn_loss':     0.0775, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1780.5634, 'lr':   5.68e-05, 'eps_e':     0.2001, 'lr_e':   5.68e-05})
Step:  343000, Reward:  -216.923 [ 109.046], Avg:  -257.917 (0.300) <0-10:39:29> ({'r_t': -1523.3115, 'eps':     0.3001, 'len': 27392.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0091, 'ddot_loss':     0.0249, 'rew_loss':  1672.3512, 'lr':   5.68e-05, 'eps_e':     0.3001, 'lr_e':   5.68e-05})
Step:  344000, Reward:  -206.204 [  98.059], Avg:  -257.767 (0.400) <0-10:41:44> ({'r_t': -2221.1638, 'eps':     0.4001, 'len': 27472.1600, 'dyn_loss':     0.0773, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1597.4869, 'lr':   5.68e-05, 'eps_e':     0.4001, 'lr_e':   5.68e-05})
Step:  345000, Reward:  -253.117 [ 108.066], Avg:  -257.754 (0.500) <0-10:43:48> ({'r_t': -2665.3805, 'eps':     0.5001, 'len': 27552.1600, 'dyn_loss':     0.0765, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1706.5017, 'lr':   5.57e-05, 'eps_e':     0.5001, 'lr_e':   5.57e-05})
Step:  346000, Reward:  -207.515 [  88.545], Avg:  -257.609 (0.600) <0-10:45:40> ({'r_t': -3271.5159, 'eps':     0.6001, 'len': 27632.1600, 'dyn_loss':     0.0746, 'dot_loss':     0.0090, 'ddot_loss':     0.0253, 'rew_loss':  1755.2125, 'lr':   5.57e-05, 'eps_e':     0.6001, 'lr_e':   5.57e-05})
Step:  347000, Reward:  -199.141 [  97.824], Avg:  -257.441 (0.700) <0-10:47:20> ({'r_t': -3921.1687, 'eps':     0.7001, 'len': 27712.1600, 'dyn_loss':     0.0740, 'dot_loss':     0.0089, 'ddot_loss':     0.0245, 'rew_loss':  1679.5066, 'lr':   5.57e-05, 'eps_e':     0.7001, 'lr_e':   5.57e-05})
Step:  348000, Reward:  -178.632 [  87.052], Avg:  -257.215 (0.800) <0-10:48:47> ({'r_t': -4570.4336, 'eps':     0.8001, 'len': 27792.1600, 'dyn_loss':     0.0789, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1637.4185, 'lr':   5.57e-05, 'eps_e':     0.8001, 'lr_e':   5.57e-05})
Step:  349000, Reward:  -216.013 [  98.788], Avg:  -257.098 (0.900) <0-10:50:03> ({'r_t': -5203.8560, 'eps':     0.9001, 'len': 27872.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1710.0375, 'lr':   5.57e-05, 'eps_e':     0.9001, 'lr_e':   5.57e-05})
Step:  350000, Reward:  -193.348 [  99.167], Avg:  -256.916 (0.000) <0-10:51:08> ({'r_t': -5957.6720, 'eps':     0.0001, 'len': 27952.1600, 'dyn_loss':     0.0768, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1688.1436, 'lr':   5.57e-05, 'eps_e':     0.0001, 'lr_e':   5.57e-05})
Step:  351000, Reward:  -188.560 [  80.630], Avg:  -256.722 (0.100) <0-10:54:00> ({'r_t':  -911.3946, 'eps':     0.1001, 'len': 28032.1600, 'dyn_loss':     0.0794, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1692.9890, 'lr':   5.57e-05, 'eps_e':     0.1001, 'lr_e':   5.57e-05})
Step:  352000, Reward:  -163.905 [  97.949], Avg:  -256.459 (0.200) <0-10:56:40> ({'r_t': -1122.9960, 'eps':     0.2001, 'len': 28112.1600, 'dyn_loss':     0.0778, 'dot_loss':     0.0091, 'ddot_loss':     0.0257, 'rew_loss':  1756.8680, 'lr':   5.57e-05, 'eps_e':     0.2001, 'lr_e':   5.57e-05})
Step:  353000, Reward:  -205.368 [ 106.971], Avg:  -256.315 (0.300) <0-10:59:11> ({'r_t': -1641.9629, 'eps':     0.3001, 'len': 28192.1600, 'dyn_loss':     0.0764, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1760.7592, 'lr':   5.57e-05, 'eps_e':     0.3001, 'lr_e':   5.57e-05})
Step:  354000, Reward:  -178.548 [  87.511], Avg:  -256.095 (0.400) <0-11:01:29> ({'r_t': -2032.5116, 'eps':     0.4001, 'len': 28272.1600, 'dyn_loss':     0.0817, 'dot_loss':     0.0096, 'ddot_loss':     0.0262, 'rew_loss':  1673.8857, 'lr':   5.57e-05, 'eps_e':     0.4001, 'lr_e':   5.57e-05})
Step:  355000, Reward:  -160.678 [  57.454], Avg:  -255.827 (0.500) <0-11:03:34> ({'r_t': -2650.3141, 'eps':     0.5001, 'len': 28352.1600, 'dyn_loss':     0.0795, 'dot_loss':     0.0093, 'ddot_loss':     0.0260, 'rew_loss':  1627.3833, 'lr':   5.57e-05, 'eps_e':     0.5001, 'lr_e':   5.57e-05})
Step:  356000, Reward:  -202.629 [  91.239], Avg:  -255.678 (0.600) <0-11:05:28> ({'r_t': -3197.9504, 'eps':     0.6001, 'len': 28432.1600, 'dyn_loss':     0.0760, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1647.6312, 'lr':   5.45e-05, 'eps_e':     0.6001, 'lr_e':   5.45e-05})
Step:  357000, Reward:  -214.114 [  95.172], Avg:  -255.562 (0.700) <0-11:07:07> ({'r_t': -3887.1488, 'eps':     0.7001, 'len': 28512.1600, 'dyn_loss':     0.0749, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1642.4379, 'lr':   5.45e-05, 'eps_e':     0.7001, 'lr_e':   5.45e-05})
Step:  358000, Reward:  -171.377 [  93.271], Avg:  -255.328 (0.800) <0-11:08:35> ({'r_t': -4555.9421, 'eps':     0.8001, 'len': 28592.1600, 'dyn_loss':     0.0772, 'dot_loss':     0.0089, 'ddot_loss':     0.0246, 'rew_loss':  1740.1821, 'lr':   5.45e-05, 'eps_e':     0.8001, 'lr_e':   5.45e-05})
Step:  359000, Reward:  -198.505 [  94.291], Avg:  -255.170 (0.900) <0-11:09:51> ({'r_t': -5229.4813, 'eps':     0.9001, 'len': 28672.1600, 'dyn_loss':     0.0773, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1729.3766, 'lr':   5.45e-05, 'eps_e':     0.9001, 'lr_e':   5.45e-05})
Step:  360000, Reward:  -195.497 [  97.895], Avg:  -255.005 (0.000) <0-11:10:57> ({'r_t': -5950.4652, 'eps':     0.0001, 'len': 28752.1600, 'dyn_loss':     0.0766, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1697.7003, 'lr':   5.45e-05, 'eps_e':     0.0001, 'lr_e':   5.45e-05})
Step:  361000, Reward:  -201.665 [  78.907], Avg:  -254.857 (0.100) <0-11:13:49> ({'r_t':  -934.8650, 'eps':     0.1001, 'len': 28832.1600, 'dyn_loss':     0.0761, 'dot_loss':     0.0089, 'ddot_loss':     0.0246, 'rew_loss':  1621.7535, 'lr':   5.45e-05, 'eps_e':     0.1001, 'lr_e':   5.45e-05})
Step:  362000, Reward:  -181.945 [  96.116], Avg:  -254.656 (0.200) <0-11:16:30> ({'r_t': -1154.3674, 'eps':     0.2001, 'len': 28912.1600, 'dyn_loss':     0.0733, 'dot_loss':     0.0088, 'ddot_loss':     0.0246, 'rew_loss':  1791.1843, 'lr':   5.45e-05, 'eps_e':     0.2001, 'lr_e':   5.45e-05})
Step:  363000, Reward:  -176.677 [  97.812], Avg:  -254.442 (0.300) <0-11:19:00> ({'r_t': -1567.4878, 'eps':     0.3001, 'len': 28992.1600, 'dyn_loss':     0.0741, 'dot_loss':     0.0090, 'ddot_loss':     0.0248, 'rew_loss':  1564.9800, 'lr':   5.45e-05, 'eps_e':     0.3001, 'lr_e':   5.45e-05})
Step:  364000, Reward:  -169.251 [ 107.978], Avg:  -254.209 (0.400) <0-11:21:17> ({'r_t': -2107.1278, 'eps':     0.4001, 'len': 29072.1600, 'dyn_loss':     0.0715, 'dot_loss':     0.0086, 'ddot_loss':     0.0245, 'rew_loss':  1783.8079, 'lr':   5.45e-05, 'eps_e':     0.4001, 'lr_e':   5.45e-05})
Step:  365000, Reward:  -163.589 [  95.633], Avg:  -253.961 (0.500) <0-11:23:23> ({'r_t': -2723.9354, 'eps':     0.5001, 'len': 29152.1600, 'dyn_loss':     0.0791, 'dot_loss':     0.0093, 'ddot_loss':     0.0254, 'rew_loss':  1619.3622, 'lr':   5.45e-05, 'eps_e':     0.5001, 'lr_e':   5.45e-05})
Step:  366000, Reward:  -208.625 [  87.116], Avg:  -253.838 (0.600) <0-11:25:15> ({'r_t': -3385.1400, 'eps':     0.6001, 'len': 29232.1600, 'dyn_loss':     0.0787, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1571.3063, 'lr':   5.45e-05, 'eps_e':     0.6001, 'lr_e':   5.45e-05})
Step:  367000, Reward:  -211.405 [ 119.747], Avg:  -253.722 (0.700) <0-11:27:01> ({'r_t': -3966.2675, 'eps':     0.7001, 'len': 29312.1600, 'dyn_loss':     0.0786, 'dot_loss':     0.0094, 'ddot_loss':     0.0259, 'rew_loss':  1658.3562, 'lr':   5.35e-05, 'eps_e':     0.7001, 'lr_e':   5.35e-05})
Step:  368000, Reward:  -171.238 [  82.871], Avg:  -253.499 (0.800) <0-11:28:33> ({'r_t': -4548.9606, 'eps':     0.8001, 'len': 29392.1600, 'dyn_loss':     0.0766, 'dot_loss':     0.0090, 'ddot_loss':     0.0251, 'rew_loss':  1590.2012, 'lr':   5.35e-05, 'eps_e':     0.8001, 'lr_e':   5.35e-05})
Step:  369000, Reward:  -194.278 [  91.967], Avg:  -253.339 (0.900) <0-11:29:56> ({'r_t': -5324.3726, 'eps':     0.9001, 'len': 29472.1600, 'dyn_loss':     0.0770, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1711.2522, 'lr':   5.35e-05, 'eps_e':     0.9001, 'lr_e':   5.35e-05})
Step:  370000, Reward:  -180.123 [  83.324], Avg:  -253.141 (0.000) <0-11:31:04> ({'r_t': -6001.6082, 'eps':     0.0001, 'len': 29552.1600, 'dyn_loss':     0.0778, 'dot_loss':     0.0093, 'ddot_loss':     0.0261, 'rew_loss':  1713.9471, 'lr':   5.35e-05, 'eps_e':     0.0001, 'lr_e':   5.35e-05})
Step:  371000, Reward:  -192.470 [ 101.310], Avg:  -252.978 (0.100) <0-11:34:11> ({'r_t':  -914.9601, 'eps':     0.1001, 'len': 29632.1600, 'dyn_loss':     0.0754, 'dot_loss':     0.0090, 'ddot_loss':     0.0249, 'rew_loss':  1579.9407, 'lr':   5.35e-05, 'eps_e':     0.1001, 'lr_e':   5.35e-05})
Step:  372000, Reward:  -208.243 [  80.254], Avg:  -252.858 (0.200) <0-11:37:07> ({'r_t': -1089.0176, 'eps':     0.2001, 'len': 29712.1600, 'dyn_loss':     0.0755, 'dot_loss':     0.0094, 'ddot_loss':     0.0266, 'rew_loss':  1585.8982, 'lr':   5.35e-05, 'eps_e':     0.2001, 'lr_e':   5.35e-05})
Step:  373000, Reward:  -192.618 [ 107.502], Avg:  -252.697 (0.300) <0-11:39:43> ({'r_t': -1653.8518, 'eps':     0.3001, 'len': 29792.1600, 'dyn_loss':     0.0784, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1567.4801, 'lr':   5.35e-05, 'eps_e':     0.3001, 'lr_e':   5.35e-05})
Step:  374000, Reward:  -154.279 [  82.462], Avg:  -252.435 (0.400) <0-11:42:09> ({'r_t': -2023.0200, 'eps':     0.4001, 'len': 29872.1600, 'dyn_loss':     0.0775, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1625.8182, 'lr':   5.35e-05, 'eps_e':     0.4001, 'lr_e':   5.35e-05})
Step:  375000, Reward:  -196.930 [ 101.787], Avg:  -252.287 (0.500) <0-11:44:27> ({'r_t': -2679.8119, 'eps':     0.5001, 'len': 29952.1600, 'dyn_loss':     0.0767, 'dot_loss':     0.0090, 'ddot_loss':     0.0248, 'rew_loss':  1630.1830, 'lr':   5.35e-05, 'eps_e':     0.5001, 'lr_e':   5.35e-05})
Step:  376000, Reward:  -184.098 [  68.840], Avg:  -252.106 (0.600) <0-11:46:24> ({'r_t': -3059.9664, 'eps':     0.6001, 'len': 30032.1600, 'dyn_loss':     0.0775, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1693.4832, 'lr':   5.35e-05, 'eps_e':     0.6001, 'lr_e':   5.35e-05})
Step:  377000, Reward:  -199.722 [  93.709], Avg:  -251.968 (0.700) <0-11:48:12> ({'r_t': -3801.5055, 'eps':     0.7001, 'len': 30112.1600, 'dyn_loss':     0.0764, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1467.8857, 'lr':   5.35e-05, 'eps_e':     0.7001, 'lr_e':   5.35e-05})
Step:  378000, Reward:  -234.696 [  96.202], Avg:  -251.922 (0.800) <0-11:49:57> ({'r_t': -4499.1606, 'eps':     0.8001, 'len': 30192.1600, 'dyn_loss':     0.0773, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1661.5797, 'lr':   5.24e-05, 'eps_e':     0.8001, 'lr_e':   5.24e-05})
Step:  379000, Reward:  -172.599 [ 103.481], Avg:  -251.714 (0.900) <0-11:51:36> ({'r_t': -5217.8557, 'eps':     0.9001, 'len': 30272.1600, 'dyn_loss':     0.0760, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1719.8472, 'lr':   5.24e-05, 'eps_e':     0.9001, 'lr_e':   5.24e-05})
Step:  380000, Reward:  -217.450 [  78.129], Avg:  -251.624 (0.000) <0-11:53:01> ({'r_t': -5770.6996, 'eps':     0.0001, 'len': 30352.1600, 'dyn_loss':     0.0759, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1705.9403, 'lr':   5.24e-05, 'eps_e':     0.0001, 'lr_e':   5.24e-05})
Step:  381000, Reward:  -173.352 [ 104.055], Avg:  -251.419 (0.100) <0-11:57:00> ({'r_t':  -952.1448, 'eps':     0.1001, 'len': 30432.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1616.8228, 'lr':   5.24e-05, 'eps_e':     0.1001, 'lr_e':   5.24e-05})
Step:  382000, Reward:  -206.027 [ 118.447], Avg:  -251.300 (0.200) <0-12:00:17> ({'r_t': -1179.6983, 'eps':     0.2001, 'len': 30512.1600, 'dyn_loss':     0.0766, 'dot_loss':     0.0090, 'ddot_loss':     0.0252, 'rew_loss':  1729.1422, 'lr':   5.24e-05, 'eps_e':     0.2001, 'lr_e':   5.24e-05})
Step:  383000, Reward:  -196.582 [ 103.131], Avg:  -251.158 (0.300) <0-12:03:27> ({'r_t': -1582.9129, 'eps':     0.3001, 'len': 30592.1600, 'dyn_loss':     0.0743, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1648.2297, 'lr':   5.24e-05, 'eps_e':     0.3001, 'lr_e':   5.24e-05})
Step:  384000, Reward:  -215.380 [ 122.497], Avg:  -251.065 (0.400) <0-12:06:22> ({'r_t': -2056.8724, 'eps':     0.4001, 'len': 30672.1600, 'dyn_loss':     0.0720, 'dot_loss':     0.0090, 'ddot_loss':     0.0249, 'rew_loss':  1584.8392, 'lr':   5.24e-05, 'eps_e':     0.4001, 'lr_e':   5.24e-05})
Step:  385000, Reward:  -233.013 [ 103.320], Avg:  -251.018 (0.500) <0-12:08:54> ({'r_t': -2601.7010, 'eps':     0.5001, 'len': 30752.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1624.0256, 'lr':   5.24e-05, 'eps_e':     0.5001, 'lr_e':   5.24e-05})
Step:  386000, Reward:  -189.698 [  98.609], Avg:  -250.860 (0.600) <0-12:11:05> ({'r_t': -3232.8963, 'eps':     0.6001, 'len': 30832.1600, 'dyn_loss':     0.0801, 'dot_loss':     0.0096, 'ddot_loss':     0.0266, 'rew_loss':  1792.1445, 'lr':   5.24e-05, 'eps_e':     0.6001, 'lr_e':   5.24e-05})
Step:  387000, Reward:  -177.097 [  86.597], Avg:  -250.669 (0.700) <0-12:13:14> ({'r_t': -3949.2314, 'eps':     0.7001, 'len': 30912.1600, 'dyn_loss':     0.0758, 'dot_loss':     0.0090, 'ddot_loss':     0.0251, 'rew_loss':  1619.8153, 'lr':   5.24e-05, 'eps_e':     0.7001, 'lr_e':   5.24e-05})
Step:  388000, Reward:  -170.864 [  81.520], Avg:  -250.464 (0.800) <0-12:14:48> ({'r_t': -4570.6894, 'eps':     0.8001, 'len': 30992.1600, 'dyn_loss':     0.0756, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1667.9324, 'lr':   5.24e-05, 'eps_e':     0.8001, 'lr_e':   5.24e-05})
Step:  389000, Reward:  -167.846 [  82.930], Avg:  -250.252 (0.900) <0-12:16:26> ({'r_t': -5338.0380, 'eps':     0.9001, 'len': 31072.1600, 'dyn_loss':     0.0700, 'dot_loss':     0.0087, 'ddot_loss':     0.0244, 'rew_loss':  1706.8424, 'lr':   5.13e-05, 'eps_e':     0.9001, 'lr_e':   5.13e-05})
Step:  390000, Reward:  -181.592 [  93.592], Avg:  -250.077 (0.000) <0-12:17:38> ({'r_t': -5987.1926, 'eps':     0.0001, 'len': 31152.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1645.8448, 'lr':   5.13e-05, 'eps_e':     0.0001, 'lr_e':   5.13e-05})
Step:  391000, Reward:  -211.398 [  79.911], Avg:  -249.978 (0.100) <0-12:21:03> ({'r_t':  -930.0963, 'eps':     0.1001, 'len': 31232.1600, 'dyn_loss':     0.0779, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1775.9288, 'lr':   5.13e-05, 'eps_e':     0.1001, 'lr_e':   5.13e-05})
Step:  392000, Reward:  -375.603 [ 532.460], Avg:  -250.298 (0.200) <0-12:24:32> ({'r_t': -1064.6340, 'eps':     0.2001, 'len': 31312.1600, 'dyn_loss':     0.0734, 'dot_loss':     0.0091, 'ddot_loss':     0.0251, 'rew_loss':  1705.2087, 'lr':   5.13e-05, 'eps_e':     0.2001, 'lr_e':   5.13e-05})
Step:  393000, Reward:  -224.907 [  95.194], Avg:  -250.233 (0.300) <0-12:27:22> ({'r_t': -1807.7558, 'eps':     0.3001, 'len': 31392.1600, 'dyn_loss':     0.0745, 'dot_loss':     0.0090, 'ddot_loss':     0.0248, 'rew_loss':  1600.7290, 'lr':   5.13e-05, 'eps_e':     0.3001, 'lr_e':   5.13e-05})
Step:  394000, Reward:  -154.478 [  80.686], Avg:  -249.991 (0.400) <0-12:30:03> ({'r_t': -2189.3616, 'eps':     0.4001, 'len': 31472.1600, 'dyn_loss':     0.0753, 'dot_loss':     0.0090, 'ddot_loss':     0.0248, 'rew_loss':  1808.5913, 'lr':   5.13e-05, 'eps_e':     0.4001, 'lr_e':   5.13e-05})
Step:  395000, Reward:  -184.917 [ 123.941], Avg:  -249.827 (0.500) <0-12:32:33> ({'r_t': -2930.0090, 'eps':     0.5001, 'len': 31552.1600, 'dyn_loss':     0.0740, 'dot_loss':     0.0090, 'ddot_loss':     0.0249, 'rew_loss':  1590.9641, 'lr':   5.13e-05, 'eps_e':     0.5001, 'lr_e':   5.13e-05})
Step:  396000, Reward:  -182.845 [  88.825], Avg:  -249.658 (0.600) <0-12:34:49> ({'r_t': -3368.3249, 'eps':     0.6001, 'len': 31632.1600, 'dyn_loss':     0.0776, 'dot_loss':     0.0093, 'ddot_loss':     0.0255, 'rew_loss':  1667.3960, 'lr':   5.13e-05, 'eps_e':     0.6001, 'lr_e':   5.13e-05})
Step:  397000, Reward:  -178.955 [  57.324], Avg:  -249.480 (0.700) <0-12:36:53> ({'r_t': -3829.4399, 'eps':     0.7001, 'len': 31712.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1566.9662, 'lr':   5.13e-05, 'eps_e':     0.7001, 'lr_e':   5.13e-05})
Step:  398000, Reward:  -166.070 [ 100.366], Avg:  -249.271 (0.800) <0-12:38:44> ({'r_t': -4523.0575, 'eps':     0.8001, 'len': 31792.1600, 'dyn_loss':     0.0748, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1679.7168, 'lr':   5.13e-05, 'eps_e':     0.8001, 'lr_e':   5.13e-05})
Step:  399000, Reward:  -138.726 [  70.165], Avg:  -248.995 (0.900) <0-12:40:17> ({'r_t': -5186.1151, 'eps':     0.9001, 'len': 31872.1600, 'dyn_loss':     0.0758, 'dot_loss':     0.0093, 'ddot_loss':     0.0258, 'rew_loss':  1844.0885, 'lr':   5.13e-05, 'eps_e':     0.9001, 'lr_e':   5.13e-05})
Step:  400000, Reward:  -185.197 [  99.460], Avg:  -248.836 (0.000) <0-12:41:36> ({'r_t': -5842.1807, 'eps':     0.0001, 'len': 31952.1600, 'dyn_loss':     0.0738, 'dot_loss':     0.0090, 'ddot_loss':     0.0248, 'rew_loss':  1725.2308, 'lr':   5.03e-05, 'eps_e':     0.0001, 'lr_e':   5.03e-05})
Step:  401000, Reward:  -182.518 [ 115.416], Avg:  -248.671 (0.100) <0-12:45:11> ({'r_t':  -949.6511, 'eps':     0.1001, 'len': 32032.1600, 'dyn_loss':     0.0772, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1651.1500, 'lr':   5.03e-05, 'eps_e':     0.1001, 'lr_e':   5.03e-05})
Step:  402000, Reward:  -169.316 [  83.340], Avg:  -248.474 (0.200) <0-12:48:33> ({'r_t': -1131.3313, 'eps':     0.2001, 'len': 32112.1600, 'dyn_loss':     0.0742, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1742.2151, 'lr':   5.03e-05, 'eps_e':     0.2001, 'lr_e':   5.03e-05})
Step:  403000, Reward:  -151.625 [  92.784], Avg:  -248.234 (0.300) <0-12:51:48> ({'r_t': -1699.2588, 'eps':     0.3001, 'len': 32192.1600, 'dyn_loss':     0.0780, 'dot_loss':     0.0093, 'ddot_loss':     0.0259, 'rew_loss':  1729.8496, 'lr':   5.03e-05, 'eps_e':     0.3001, 'lr_e':   5.03e-05})
Step:  404000, Reward:  -179.227 [  71.756], Avg:  -248.064 (0.400) <0-12:54:55> ({'r_t': -2188.8775, 'eps':     0.4001, 'len': 32272.1600, 'dyn_loss':     0.0767, 'dot_loss':     0.0092, 'ddot_loss':     0.0257, 'rew_loss':  1651.7847, 'lr':   5.03e-05, 'eps_e':     0.4001, 'lr_e':   5.03e-05})
Step:  405000, Reward:  -154.001 [  70.693], Avg:  -247.832 (0.500) <0-12:57:34> ({'r_t': -2791.9025, 'eps':     0.5001, 'len': 32352.1600, 'dyn_loss':     0.0750, 'dot_loss':     0.0090, 'ddot_loss':     0.0251, 'rew_loss':  1746.7935, 'lr':   5.03e-05, 'eps_e':     0.5001, 'lr_e':   5.03e-05})
Step:  406000, Reward:  -199.698 [  73.889], Avg:  -247.714 (0.600) <0-13:00:09> ({'r_t': -3172.5213, 'eps':     0.6001, 'len': 32432.1600, 'dyn_loss':     0.0739, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1668.9275, 'lr':   5.03e-05, 'eps_e':     0.6001, 'lr_e':   5.03e-05})
Step:  407000, Reward:  -182.172 [  60.749], Avg:  -247.553 (0.700) <0-13:02:34> ({'r_t': -3940.5484, 'eps':     0.7001, 'len': 32512.1600, 'dyn_loss':     0.0727, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1641.6003, 'lr':   5.03e-05, 'eps_e':     0.7001, 'lr_e':   5.03e-05})
Step:  408000, Reward:  -178.023 [  83.096], Avg:  -247.383 (0.800) <0-13:04:36> ({'r_t': -4654.0351, 'eps':     0.8001, 'len': 32592.1600, 'dyn_loss':     0.0743, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1552.3445, 'lr':   5.03e-05, 'eps_e':     0.8001, 'lr_e':   5.03e-05})
Step:  409000, Reward:  -167.388 [ 104.275], Avg:  -247.188 (0.900) <0-13:06:19> ({'r_t': -5185.2330, 'eps':     0.9001, 'len': 32672.1600, 'dyn_loss':     0.0767, 'dot_loss':     0.0093, 'ddot_loss':     0.0254, 'rew_loss':  1770.9365, 'lr':   5.03e-05, 'eps_e':     0.9001, 'lr_e':   5.03e-05})
Step:  410000, Reward:  -179.456 [  86.014], Avg:  -247.023 (0.000) <0-13:08:01> ({'r_t': -6052.5685, 'eps':     0.0001, 'len': 32752.1600, 'dyn_loss':     0.0751, 'dot_loss':     0.0091, 'ddot_loss':     0.0255, 'rew_loss':  1742.5554, 'lr':   5.03e-05, 'eps_e':     0.0001, 'lr_e':   5.03e-05})
Step:  411000, Reward:  -150.773 [  93.951], Avg:  -246.790 (0.100) <0-13:11:52> ({'r_t': -1029.3124, 'eps':     0.1001, 'len': 32832.1600, 'dyn_loss':     0.0741, 'dot_loss':     0.0091, 'ddot_loss':     0.0250, 'rew_loss':  1572.2684, 'lr':   4.93e-05, 'eps_e':     0.1001, 'lr_e':   4.93e-05})
Step:  412000, Reward:  -186.149 [  85.191], Avg:  -246.643 (0.200) <0-13:15:00> ({'r_t': -1187.5179, 'eps':     0.2001, 'len': 32912.1600, 'dyn_loss':     0.0756, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1582.2058, 'lr':   4.93e-05, 'eps_e':     0.2001, 'lr_e':   4.93e-05})
Step:  413000, Reward:  -205.612 [  86.436], Avg:  -246.544 (0.300) <0-13:17:54> ({'r_t': -1518.9518, 'eps':     0.3001, 'len': 32992.1600, 'dyn_loss':     0.0756, 'dot_loss':     0.0093, 'ddot_loss':     0.0256, 'rew_loss':  1652.2188, 'lr':   4.93e-05, 'eps_e':     0.3001, 'lr_e':   4.93e-05})
Step:  414000, Reward:  -216.672 [ 103.283], Avg:  -246.472 (0.400) <0-13:20:27> ({'r_t': -2053.6837, 'eps':     0.4001, 'len': 33072.1600, 'dyn_loss':     0.0751, 'dot_loss':     0.0093, 'ddot_loss':     0.0260, 'rew_loss':  1655.6104, 'lr':   4.93e-05, 'eps_e':     0.4001, 'lr_e':   4.93e-05})
Step:  415000, Reward:  -175.542 [  60.081], Avg:  -246.301 (0.500) <0-13:22:50> ({'r_t': -2612.7258, 'eps':     0.5001, 'len': 33152.1600, 'dyn_loss':     0.0737, 'dot_loss':     0.0090, 'ddot_loss':     0.0246, 'rew_loss':  1618.8688, 'lr':   4.93e-05, 'eps_e':     0.5001, 'lr_e':   4.93e-05})
Step:  416000, Reward:  -171.722 [  82.018], Avg:  -246.122 (0.600) <0-13:25:01> ({'r_t': -3156.5684, 'eps':     0.6001, 'len': 33232.1600, 'dyn_loss':     0.0729, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1588.6049, 'lr':   4.93e-05, 'eps_e':     0.6001, 'lr_e':   4.93e-05})
Step:  417000, Reward:  -244.535 [ 106.904], Avg:  -246.119 (0.700) <0-13:27:05> ({'r_t': -3874.1361, 'eps':     0.7001, 'len': 33312.1600, 'dyn_loss':     0.0758, 'dot_loss':     0.0093, 'ddot_loss':     0.0259, 'rew_loss':  1647.0997, 'lr':   4.93e-05, 'eps_e':     0.7001, 'lr_e':   4.93e-05})
Step:  418000, Reward:  -220.663 [  99.415], Avg:  -246.058 (0.800) <0-13:28:48> ({'r_t': -4466.5025, 'eps':     0.8001, 'len': 33392.1600, 'dyn_loss':     0.0711, 'dot_loss':     0.0088, 'ddot_loss':     0.0249, 'rew_loss':  1697.1693, 'lr':   4.93e-05, 'eps_e':     0.8001, 'lr_e':   4.93e-05})
Step:  419000, Reward:  -281.672 [ 382.010], Avg:  -246.143 (0.900) <0-13:30:30> ({'r_t': -5275.6786, 'eps':     0.9001, 'len': 33472.1600, 'dyn_loss':     0.0732, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1798.0925, 'lr':   4.93e-05, 'eps_e':     0.9001, 'lr_e':   4.93e-05})
Step:  420000, Reward:  -213.452 [ 171.789], Avg:  -246.065 (0.000) <0-13:31:53> ({'r_t': -6108.7260, 'eps':     0.0001, 'len': 33552.1600, 'dyn_loss':     0.0714, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1639.2365, 'lr':   4.93e-05, 'eps_e':     0.0001, 'lr_e':   4.93e-05})
Step:  421000, Reward:  -178.570 [  89.736], Avg:  -245.905 (0.100) <0-13:35:21> ({'r_t':  -983.3113, 'eps':     0.1001, 'len': 33632.1600, 'dyn_loss':     0.0816, 'dot_loss':     0.0094, 'ddot_loss':     0.0258, 'rew_loss':  1686.2312, 'lr':   4.93e-05, 'eps_e':     0.1001, 'lr_e':   4.93e-05})
Step:  422000, Reward:  -242.808 [ 129.258], Avg:  -245.898 (0.200) <0-13:38:36> ({'r_t': -1113.0023, 'eps':     0.2001, 'len': 33712.1600, 'dyn_loss':     0.0739, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1505.9474, 'lr':   4.83e-05, 'eps_e':     0.2001, 'lr_e':   4.83e-05})
Step:  423000, Reward:  -199.312 [  80.782], Avg:  -245.788 (0.300) <0-13:41:33> ({'r_t': -1622.2396, 'eps':     0.3001, 'len': 33792.1600, 'dyn_loss':     0.0775, 'dot_loss':     0.0090, 'ddot_loss':     0.0255, 'rew_loss':  1839.6469, 'lr':   4.83e-05, 'eps_e':     0.3001, 'lr_e':   4.83e-05})
Step:  424000, Reward:  -206.857 [  86.888], Avg:  -245.696 (0.400) <0-13:44:06> ({'r_t': -2237.4826, 'eps':     0.4001, 'len': 33872.1600, 'dyn_loss':     0.0723, 'dot_loss':     0.0088, 'ddot_loss':     0.0248, 'rew_loss':  1628.6788, 'lr':   4.83e-05, 'eps_e':     0.4001, 'lr_e':   4.83e-05})
Step:  425000, Reward:  -209.073 [  83.932], Avg:  -245.610 (0.500) <0-13:46:23> ({'r_t': -2683.0369, 'eps':     0.5001, 'len': 33952.1600, 'dyn_loss':     0.0748, 'dot_loss':     0.0091, 'ddot_loss':     0.0254, 'rew_loss':  1650.9948, 'lr':   4.83e-05, 'eps_e':     0.5001, 'lr_e':   4.83e-05})
Step:  426000, Reward:  -158.684 [  68.107], Avg:  -245.407 (0.600) <0-13:48:33> ({'r_t': -3195.5976, 'eps':     0.6001, 'len': 34032.1600, 'dyn_loss':     0.0757, 'dot_loss':     0.0091, 'ddot_loss':     0.0254, 'rew_loss':  1710.5112, 'lr':   4.83e-05, 'eps_e':     0.6001, 'lr_e':   4.83e-05})
Step:  427000, Reward:  -201.436 [ 119.017], Avg:  -245.304 (0.700) <0-13:50:27> ({'r_t': -3974.7323, 'eps':     0.7001, 'len': 34112.1600, 'dyn_loss':     0.0773, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1693.8529, 'lr':   4.83e-05, 'eps_e':     0.7001, 'lr_e':   4.83e-05})
Step:  428000, Reward:  -186.605 [  78.837], Avg:  -245.167 (0.800) <0-13:52:06> ({'r_t': -4602.9057, 'eps':     0.8001, 'len': 34192.1600, 'dyn_loss':     0.0727, 'dot_loss':     0.0088, 'ddot_loss':     0.0250, 'rew_loss':  1736.9146, 'lr':   4.83e-05, 'eps_e':     0.8001, 'lr_e':   4.83e-05})
Step:  429000, Reward:  -162.169 [  63.710], Avg:  -244.974 (0.900) <0-13:53:28> ({'r_t': -5420.4494, 'eps':     0.9001, 'len': 34272.1600, 'dyn_loss':     0.0724, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1533.8667, 'lr':   4.83e-05, 'eps_e':     0.9001, 'lr_e':   4.83e-05})
Step:  430000, Reward:  -145.420 [  63.175], Avg:  -244.743 (0.000) <0-13:54:47> ({'r_t': -5979.6403, 'eps':     0.0001, 'len': 34352.1600, 'dyn_loss':     0.0730, 'dot_loss':     0.0090, 'ddot_loss':     0.0251, 'rew_loss':  1614.3799, 'lr':   4.83e-05, 'eps_e':     0.0001, 'lr_e':   4.83e-05})
Step:  431000, Reward:  -181.307 [  76.753], Avg:  -244.596 (0.100) <0-13:58:17> ({'r_t':  -949.1048, 'eps':     0.1001, 'len': 34432.1600, 'dyn_loss':     0.0703, 'dot_loss':     0.0086, 'ddot_loss':     0.0241, 'rew_loss':  1748.0106, 'lr':   4.83e-05, 'eps_e':     0.1001, 'lr_e':   4.83e-05})
Step:  432000, Reward:  -191.300 [  97.785], Avg:  -244.473 (0.200) <0-14:01:12> ({'r_t': -1135.9850, 'eps':     0.2001, 'len': 34512.1600, 'dyn_loss':     0.0720, 'dot_loss':     0.0089, 'ddot_loss':     0.0252, 'rew_loss':  1675.5061, 'lr':   4.83e-05, 'eps_e':     0.2001, 'lr_e':   4.83e-05})
Step:  433000, Reward:  -183.952 [  98.370], Avg:  -244.334 (0.300) <0-14:04:22> ({'r_t': -1495.8547, 'eps':     0.3001, 'len': 34592.1600, 'dyn_loss':     0.0742, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1651.3611, 'lr':   4.74e-05, 'eps_e':     0.3001, 'lr_e':   4.74e-05})
Step:  434000, Reward:  -188.881 [ 102.432], Avg:  -244.206 (0.400) <0-14:07:10> ({'r_t': -2000.8269, 'eps':     0.4001, 'len': 34672.1600, 'dyn_loss':     0.0754, 'dot_loss':     0.0090, 'ddot_loss':     0.0252, 'rew_loss':  1610.1570, 'lr':   4.74e-05, 'eps_e':     0.4001, 'lr_e':   4.74e-05})
Step:  435000, Reward:  -202.817 [  77.645], Avg:  -244.111 (0.500) <0-14:09:41> ({'r_t': -2576.6366, 'eps':     0.5001, 'len': 34752.1600, 'dyn_loss':     0.0739, 'dot_loss':     0.0091, 'ddot_loss':     0.0254, 'rew_loss':  1613.9510, 'lr':   4.74e-05, 'eps_e':     0.5001, 'lr_e':   4.74e-05})
Step:  436000, Reward:  -174.087 [  85.442], Avg:  -243.951 (0.600) <0-14:12:00> ({'r_t': -3366.2656, 'eps':     0.6001, 'len': 34832.1600, 'dyn_loss':     0.0752, 'dot_loss':     0.0092, 'ddot_loss':     0.0253, 'rew_loss':  1736.5393, 'lr':   4.74e-05, 'eps_e':     0.6001, 'lr_e':   4.74e-05})
Step:  437000, Reward:  -160.192 [  97.474], Avg:  -243.760 (0.700) <0-14:14:00> ({'r_t': -3917.0162, 'eps':     0.7001, 'len': 34912.1600, 'dyn_loss':     0.0744, 'dot_loss':     0.0093, 'ddot_loss':     0.0261, 'rew_loss':  1754.3724, 'lr':   4.74e-05, 'eps_e':     0.7001, 'lr_e':   4.74e-05})
Step:  438000, Reward:  -268.370 [ 286.325], Avg:  -243.816 (0.800) <0-14:15:40> ({'r_t': -4660.8291, 'eps':     0.8001, 'len': 34992.1600, 'dyn_loss':     0.0761, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1644.4425, 'lr':   4.74e-05, 'eps_e':     0.8001, 'lr_e':   4.74e-05})
Step:  439000, Reward:  -173.786 [  81.945], Avg:  -243.657 (0.900) <0-14:17:26> ({'r_t': -5382.7756, 'eps':     0.9001, 'len': 35072.1600, 'dyn_loss':     0.0744, 'dot_loss':     0.0092, 'ddot_loss':     0.0256, 'rew_loss':  1562.3142, 'lr':   4.74e-05, 'eps_e':     0.9001, 'lr_e':   4.74e-05})
Step:  440000, Reward:  -133.594 [  78.928], Avg:  -243.407 (0.000) <0-14:18:45> ({'r_t': -5984.9562, 'eps':     0.0001, 'len': 35152.1600, 'dyn_loss':     0.0750, 'dot_loss':     0.0092, 'ddot_loss':     0.0257, 'rew_loss':  1741.0851, 'lr':   4.74e-05, 'eps_e':     0.0001, 'lr_e':   4.74e-05})
Step:  441000, Reward:  -240.787 [ 196.091], Avg:  -243.401 (0.100) <0-14:22:09> ({'r_t':  -893.2640, 'eps':     0.1001, 'len': 35232.1600, 'dyn_loss':     0.0752, 'dot_loss':     0.0091, 'ddot_loss':     0.0256, 'rew_loss':  1619.4409, 'lr':   4.74e-05, 'eps_e':     0.1001, 'lr_e':   4.74e-05})
Step:  442000, Reward:  -198.084 [  83.111], Avg:  -243.299 (0.200) <0-14:25:23> ({'r_t': -1284.3397, 'eps':     0.2001, 'len': 35312.1600, 'dyn_loss':     0.0729, 'dot_loss':     0.0092, 'ddot_loss':     0.0259, 'rew_loss':  1702.6230, 'lr':   4.74e-05, 'eps_e':     0.2001, 'lr_e':   4.74e-05})
Step:  443000, Reward:  -182.644 [ 104.697], Avg:  -243.162 (0.300) <0-14:28:04> ({'r_t': -1524.4623, 'eps':     0.3001, 'len': 35392.1600, 'dyn_loss':     0.0708, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1711.5649, 'lr':   4.74e-05, 'eps_e':     0.3001, 'lr_e':   4.74e-05})
Step:  444000, Reward:  -246.485 [  97.036], Avg:  -243.170 (0.400) <0-14:30:44> ({'r_t': -2106.8607, 'eps':     0.4001, 'len': 35472.1600, 'dyn_loss':     0.0731, 'dot_loss':     0.0091, 'ddot_loss':     0.0254, 'rew_loss':  1651.6189, 'lr':   4.64e-05, 'eps_e':     0.4001, 'lr_e':   4.64e-05})
Step:  445000, Reward:  -170.613 [ 115.158], Avg:  -243.007 (0.500) <0-14:33:15> ({'r_t': -2638.5312, 'eps':     0.5001, 'len': 35552.1600, 'dyn_loss':     0.0717, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1591.4054, 'lr':   4.64e-05, 'eps_e':     0.5001, 'lr_e':   4.64e-05})
Step:  446000, Reward:  -181.787 [  72.969], Avg:  -242.870 (0.600) <0-14:35:20> ({'r_t': -3311.1541, 'eps':     0.6001, 'len': 35632.1600, 'dyn_loss':     0.0719, 'dot_loss':     0.0090, 'ddot_loss':     0.0252, 'rew_loss':  1567.0872, 'lr':   4.64e-05, 'eps_e':     0.6001, 'lr_e':   4.64e-05})
Step:  447000, Reward:  -189.251 [  61.744], Avg:  -242.751 (0.700) <0-14:37:03> ({'r_t': -3891.7589, 'eps':     0.7001, 'len': 35712.1600, 'dyn_loss':     0.0703, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1646.3270, 'lr':   4.64e-05, 'eps_e':     0.7001, 'lr_e':   4.64e-05})
Step:  448000, Reward:  -132.860 [ 105.706], Avg:  -242.506 (0.800) <0-14:38:31> ({'r_t': -4522.0333, 'eps':     0.8001, 'len': 35792.1600, 'dyn_loss':     0.0742, 'dot_loss':     0.0091, 'ddot_loss':     0.0258, 'rew_loss':  1625.4929, 'lr':   4.64e-05, 'eps_e':     0.8001, 'lr_e':   4.64e-05})
Step:  449000, Reward:  -202.785 [ 119.094], Avg:  -242.418 (0.900) <0-14:39:56> ({'r_t': -5261.5724, 'eps':     0.9001, 'len': 35872.1600, 'dyn_loss':     0.0708, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1663.3850, 'lr':   4.64e-05, 'eps_e':     0.9001, 'lr_e':   4.64e-05})
Step:  450000, Reward:  -174.640 [ 133.129], Avg:  -242.267 (0.000) <0-14:41:10> ({'r_t': -5835.1326, 'eps':     0.0001, 'len': 35952.1600, 'dyn_loss':     0.0728, 'dot_loss':     0.0090, 'ddot_loss':     0.0247, 'rew_loss':  1452.1078, 'lr':   4.64e-05, 'eps_e':     0.0001, 'lr_e':   4.64e-05})
Step:  451000, Reward:  -215.772 [  94.872], Avg:  -242.209 (0.100) <0-14:44:32> ({'r_t':  -851.7857, 'eps':     0.1001, 'len': 36032.1600, 'dyn_loss':     0.0753, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1657.3148, 'lr':   4.64e-05, 'eps_e':     0.1001, 'lr_e':   4.64e-05})
Step:  452000, Reward:  -177.599 [  55.467], Avg:  -242.066 (0.200) <0-14:47:23> ({'r_t': -1080.1979, 'eps':     0.2001, 'len': 36112.1600, 'dyn_loss':     0.0725, 'dot_loss':     0.0088, 'ddot_loss':     0.0251, 'rew_loss':  1581.8910, 'lr':   4.64e-05, 'eps_e':     0.2001, 'lr_e':   4.64e-05})
Step:  453000, Reward:  -185.145 [  72.206], Avg:  -241.941 (0.300) <0-14:49:55> ({'r_t': -1553.4093, 'eps':     0.3001, 'len': 36192.1600, 'dyn_loss':     0.0723, 'dot_loss':     0.0089, 'ddot_loss':     0.0251, 'rew_loss':  1775.2887, 'lr':   4.64e-05, 'eps_e':     0.3001, 'lr_e':   4.64e-05})
Step:  454000, Reward:  -179.304 [  63.644], Avg:  -241.803 (0.400) <0-14:52:21> ({'r_t': -2068.5196, 'eps':     0.4001, 'len': 36272.1600, 'dyn_loss':     0.0743, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1621.8795, 'lr':   4.64e-05, 'eps_e':     0.4001, 'lr_e':   4.64e-05})
Step:  455000, Reward:  -188.856 [ 111.367], Avg:  -241.687 (0.500) <0-14:54:40> ({'r_t': -2541.8457, 'eps':     0.5001, 'len': 36352.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0091, 'ddot_loss':     0.0256, 'rew_loss':  1819.7689, 'lr':   4.55e-05, 'eps_e':     0.5001, 'lr_e':   4.55e-05})
Step:  456000, Reward:  -201.913 [  82.069], Avg:  -241.600 (0.600) <0-14:56:48> ({'r_t': -3289.1722, 'eps':     0.6001, 'len': 36432.1600, 'dyn_loss':     0.0721, 'dot_loss':     0.0091, 'ddot_loss':     0.0257, 'rew_loss':  1780.0271, 'lr':   4.55e-05, 'eps_e':     0.6001, 'lr_e':   4.55e-05})
Step:  457000, Reward:  -179.579 [  91.099], Avg:  -241.464 (0.700) <0-14:58:38> ({'r_t': -3915.7738, 'eps':     0.7001, 'len': 36512.1600, 'dyn_loss':     0.0729, 'dot_loss':     0.0087, 'ddot_loss':     0.0245, 'rew_loss':  1562.6804, 'lr':   4.55e-05, 'eps_e':     0.7001, 'lr_e':   4.55e-05})
Step:  458000, Reward:  -146.035 [  80.778], Avg:  -241.256 (0.800) <0-15:00:19> ({'r_t': -4480.0978, 'eps':     0.8001, 'len': 36592.1600, 'dyn_loss':     0.0720, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1713.7606, 'lr':   4.55e-05, 'eps_e':     0.8001, 'lr_e':   4.55e-05})
Step:  459000, Reward:  -150.869 [ 100.144], Avg:  -241.060 (0.900) <0-15:01:46> ({'r_t': -5209.4610, 'eps':     0.9001, 'len': 36672.1600, 'dyn_loss':     0.0719, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1670.3601, 'lr':   4.55e-05, 'eps_e':     0.9001, 'lr_e':   4.55e-05})
Step:  460000, Reward:  -180.747 [  71.643], Avg:  -240.929 (0.000) <0-15:03:03> ({'r_t': -5972.4122, 'eps':     0.0001, 'len': 36752.1600, 'dyn_loss':     0.0768, 'dot_loss':     0.0091, 'ddot_loss':     0.0252, 'rew_loss':  1732.2159, 'lr':   4.55e-05, 'eps_e':     0.0001, 'lr_e':   4.55e-05})
Step:  461000, Reward:  -194.488 [ 106.169], Avg:  -240.829 (0.100) <0-15:06:11> ({'r_t': -1007.0607, 'eps':     0.1001, 'len': 36832.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0090, 'ddot_loss':     0.0253, 'rew_loss':  1748.5272, 'lr':   4.55e-05, 'eps_e':     0.1001, 'lr_e':   4.55e-05})
Step:  462000, Reward:  -241.741 [  90.444], Avg:  -240.831 (0.200) <0-15:09:07> ({'r_t': -1180.2674, 'eps':     0.2001, 'len': 36912.1600, 'dyn_loss':     0.0739, 'dot_loss':     0.0090, 'ddot_loss':     0.0254, 'rew_loss':  1672.2295, 'lr':   4.55e-05, 'eps_e':     0.2001, 'lr_e':   4.55e-05})
Step:  463000, Reward:  -213.398 [  99.081], Avg:  -240.771 (0.300) <0-15:11:37> ({'r_t': -1481.2117, 'eps':     0.3001, 'len': 36992.1600, 'dyn_loss':     0.0701, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1740.3733, 'lr':   4.55e-05, 'eps_e':     0.3001, 'lr_e':   4.55e-05})
Step:  464000, Reward:  -165.467 [  79.276], Avg:  -240.610 (0.400) <0-15:13:54> ({'r_t': -2123.0280, 'eps':     0.4001, 'len': 37072.1600, 'dyn_loss':     0.0736, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1637.5267, 'lr':   4.55e-05, 'eps_e':     0.4001, 'lr_e':   4.55e-05})
Step:  465000, Reward:  -178.519 [  97.586], Avg:  -240.476 (0.500) <0-15:16:10> ({'r_t': -2526.1174, 'eps':     0.5001, 'len': 37152.1600, 'dyn_loss':     0.0728, 'dot_loss':     0.0092, 'ddot_loss':     0.0258, 'rew_loss':  1587.1288, 'lr':   4.55e-05, 'eps_e':     0.5001, 'lr_e':   4.55e-05})
Step:  466000, Reward:  -188.669 [  74.926], Avg:  -240.365 (0.600) <0-15:18:20> ({'r_t': -3258.5303, 'eps':     0.6001, 'len': 37232.1600, 'dyn_loss':     0.0719, 'dot_loss':     0.0091, 'ddot_loss':     0.0256, 'rew_loss':  1716.5892, 'lr':   4.46e-05, 'eps_e':     0.6001, 'lr_e':   4.46e-05})
Step:  467000, Reward:  -197.066 [  97.289], Avg:  -240.273 (0.700) <0-15:20:10> ({'r_t': -3972.6814, 'eps':     0.7001, 'len': 37312.1600, 'dyn_loss':     0.0745, 'dot_loss':     0.0093, 'ddot_loss':     0.0258, 'rew_loss':  1678.0625, 'lr':   4.46e-05, 'eps_e':     0.7001, 'lr_e':   4.46e-05})
Step:  468000, Reward:  -232.567 [  95.558], Avg:  -240.256 (0.800) <0-15:21:39> ({'r_t': -4533.5887, 'eps':     0.8001, 'len': 37392.1600, 'dyn_loss':     0.0707, 'dot_loss':     0.0089, 'ddot_loss':     0.0245, 'rew_loss':  1620.5900, 'lr':   4.46e-05, 'eps_e':     0.8001, 'lr_e':   4.46e-05})
Step:  469000, Reward:  -193.288 [  72.854], Avg:  -240.156 (0.900) <0-15:22:59> ({'r_t': -5305.2106, 'eps':     0.9001, 'len': 37472.1600, 'dyn_loss':     0.0706, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1658.8250, 'lr':   4.46e-05, 'eps_e':     0.9001, 'lr_e':   4.46e-05})
Step:  470000, Reward:  -189.458 [ 123.939], Avg:  -240.049 (0.000) <0-15:24:18> ({'r_t': -5936.1343, 'eps':     0.0001, 'len': 37552.1600, 'dyn_loss':     0.0713, 'dot_loss':     0.0090, 'ddot_loss':     0.0254, 'rew_loss':  1603.0414, 'lr':   4.46e-05, 'eps_e':     0.0001, 'lr_e':   4.46e-05})
Step:  471000, Reward:  -177.004 [  91.432], Avg:  -239.915 (0.100) <0-15:27:22> ({'r_t': -1020.6918, 'eps':     0.1001, 'len': 37632.1600, 'dyn_loss':     0.0736, 'dot_loss':     0.0088, 'ddot_loss':     0.0246, 'rew_loss':  1581.1405, 'lr':   4.46e-05, 'eps_e':     0.1001, 'lr_e':   4.46e-05})
Step:  472000, Reward:  -170.110 [  67.870], Avg:  -239.768 (0.200) <0-15:30:32> ({'r_t': -1107.9588, 'eps':     0.2001, 'len': 37712.1600, 'dyn_loss':     0.0728, 'dot_loss':     0.0091, 'ddot_loss':     0.0256, 'rew_loss':  1590.3400, 'lr':   4.46e-05, 'eps_e':     0.2001, 'lr_e':   4.46e-05})
Step:  473000, Reward:  -210.077 [ 100.135], Avg:  -239.705 (0.300) <0-15:33:23> ({'r_t': -1370.7814, 'eps':     0.3001, 'len': 37792.1600, 'dyn_loss':     0.0712, 'dot_loss':     0.0090, 'ddot_loss':     0.0252, 'rew_loss':  1808.5835, 'lr':   4.46e-05, 'eps_e':     0.3001, 'lr_e':   4.46e-05})
Step:  474000, Reward:  -176.341 [  85.684], Avg:  -239.572 (0.400) <0-15:36:10> ({'r_t': -2080.3273, 'eps':     0.4001, 'len': 37872.1600, 'dyn_loss':     0.0716, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1499.0514, 'lr':   4.46e-05, 'eps_e':     0.4001, 'lr_e':   4.46e-05})
Step:  475000, Reward:  -253.936 [ 269.945], Avg:  -239.602 (0.500) <0-15:38:25> ({'r_t': -2570.1885, 'eps':     0.5001, 'len': 37952.1600, 'dyn_loss':     0.0759, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1653.7401, 'lr':   4.46e-05, 'eps_e':     0.5001, 'lr_e':   4.46e-05})
Step:  476000, Reward:  -194.701 [  91.795], Avg:  -239.508 (0.600) <0-15:40:27> ({'r_t': -3318.1666, 'eps':     0.6001, 'len': 38032.1600, 'dyn_loss':     0.0698, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1655.5740, 'lr':   4.46e-05, 'eps_e':     0.6001, 'lr_e':   4.46e-05})
Step:  477000, Reward:  -157.273 [ 110.877], Avg:  -239.336 (0.700) <0-15:42:23> ({'r_t': -4068.1086, 'eps':     0.7001, 'len': 38112.1600, 'dyn_loss':     0.0687, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1697.3593, 'lr':   4.37e-05, 'eps_e':     0.7001, 'lr_e':   4.37e-05})
Step:  478000, Reward:  -173.308 [  97.966], Avg:  -239.198 (0.800) <0-15:44:08> ({'r_t': -4625.1632, 'eps':     0.8001, 'len': 38192.1600, 'dyn_loss':     0.0732, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1769.8292, 'lr':   4.37e-05, 'eps_e':     0.8001, 'lr_e':   4.37e-05})
Step:  479000, Reward:  -210.064 [ 103.346], Avg:  -239.137 (0.900) <0-15:45:40> ({'r_t': -5381.7545, 'eps':     0.9001, 'len': 38272.1600, 'dyn_loss':     0.0736, 'dot_loss':     0.0092, 'ddot_loss':     0.0255, 'rew_loss':  1613.8864, 'lr':   4.37e-05, 'eps_e':     0.9001, 'lr_e':   4.37e-05})
Step:  480000, Reward:  -181.140 [  85.027], Avg:  -239.017 (0.000) <0-15:46:55> ({'r_t': -5994.7808, 'eps':     0.0001, 'len': 38352.1600, 'dyn_loss':     0.0734, 'dot_loss':     0.0092, 'ddot_loss':     0.0257, 'rew_loss':  1658.6469, 'lr':   4.37e-05, 'eps_e':     0.0001, 'lr_e':   4.37e-05})
Step:  481000, Reward:  -211.098 [  96.675], Avg:  -238.959 (0.100) <0-15:50:02> ({'r_t':  -855.6834, 'eps':     0.1001, 'len': 38432.1600, 'dyn_loss':     0.0750, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1792.1881, 'lr':   4.37e-05, 'eps_e':     0.1001, 'lr_e':   4.37e-05})
Step:  482000, Reward:  -175.884 [  88.563], Avg:  -238.828 (0.200) <0-15:53:03> ({'r_t':  -973.2557, 'eps':     0.2001, 'len': 38512.1600, 'dyn_loss':     0.0724, 'dot_loss':     0.0090, 'ddot_loss':     0.0253, 'rew_loss':  1639.2118, 'lr':   4.37e-05, 'eps_e':     0.2001, 'lr_e':   4.37e-05})
Step:  483000, Reward:  -205.363 [ 128.213], Avg:  -238.759 (0.300) <0-15:55:51> ({'r_t': -1512.0213, 'eps':     0.3001, 'len': 38592.1600, 'dyn_loss':     0.0760, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1712.7738, 'lr':   4.37e-05, 'eps_e':     0.3001, 'lr_e':   4.37e-05})
Step:  484000, Reward:  -245.668 [ 148.943], Avg:  -238.773 (0.400) <0-15:58:23> ({'r_t': -2042.1253, 'eps':     0.4001, 'len': 38672.1600, 'dyn_loss':     0.0702, 'dot_loss':     0.0089, 'ddot_loss':     0.0250, 'rew_loss':  1771.2561, 'lr':   4.37e-05, 'eps_e':     0.4001, 'lr_e':   4.37e-05})
Step:  485000, Reward:  -202.869 [ 112.918], Avg:  -238.699 (0.500) <0-16:00:51> ({'r_t': -2626.9276, 'eps':     0.5001, 'len': 38752.1600, 'dyn_loss':     0.0718, 'dot_loss':     0.0089, 'ddot_loss':     0.0249, 'rew_loss':  1731.1488, 'lr':   4.37e-05, 'eps_e':     0.5001, 'lr_e':   4.37e-05})
Step:  486000, Reward:  -189.969 [  74.921], Avg:  -238.599 (0.600) <0-16:03:01> ({'r_t': -3241.3317, 'eps':     0.6001, 'len': 38832.1600, 'dyn_loss':     0.0750, 'dot_loss':     0.0093, 'ddot_loss':     0.0261, 'rew_loss':  1735.6584, 'lr':   4.37e-05, 'eps_e':     0.6001, 'lr_e':   4.37e-05})
Step:  487000, Reward:  -188.673 [  94.767], Avg:  -238.497 (0.700) <0-16:04:51> ({'r_t': -3734.4041, 'eps':     0.7001, 'len': 38912.1600, 'dyn_loss':     0.0711, 'dot_loss':     0.0090, 'ddot_loss':     0.0251, 'rew_loss':  1742.2952, 'lr':   4.37e-05, 'eps_e':     0.7001, 'lr_e':   4.37e-05})
Step:  488000, Reward:  -146.559 [ 114.958], Avg:  -238.309 (0.800) <0-16:06:28> ({'r_t': -4652.5834, 'eps':     0.8001, 'len': 38992.1600, 'dyn_loss':     0.0702, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1583.6456, 'lr':   4.28e-05, 'eps_e':     0.8001, 'lr_e':   4.28e-05})
Step:  489000, Reward:  -147.390 [  85.831], Avg:  -238.123 (0.900) <0-16:07:53> ({'r_t': -5275.2335, 'eps':     0.9001, 'len': 39072.1600, 'dyn_loss':     0.0731, 'dot_loss':     0.0090, 'ddot_loss':     0.0253, 'rew_loss':  1754.1632, 'lr':   4.28e-05, 'eps_e':     0.9001, 'lr_e':   4.28e-05})
Step:  490000, Reward:  -203.607 [ 107.474], Avg:  -238.053 (0.000) <0-16:09:04> ({'r_t': -6072.7098, 'eps':     0.0001, 'len': 39152.1600, 'dyn_loss':     0.0720, 'dot_loss':     0.0090, 'ddot_loss':     0.0250, 'rew_loss':  1628.9899, 'lr':   4.28e-05, 'eps_e':     0.0001, 'lr_e':   4.28e-05})
Step:  491000, Reward:  -189.621 [  83.805], Avg:  -237.955 (0.100) <0-16:12:09> ({'r_t':  -882.0869, 'eps':     0.1001, 'len': 39232.1600, 'dyn_loss':     0.0746, 'dot_loss':     0.0091, 'ddot_loss':     0.0253, 'rew_loss':  1700.0148, 'lr':   4.28e-05, 'eps_e':     0.1001, 'lr_e':   4.28e-05})
Step:  492000, Reward:  -206.814 [ 116.406], Avg:  -237.891 (0.200) <0-16:14:54> ({'r_t': -1011.0824, 'eps':     0.2001, 'len': 39312.1600, 'dyn_loss':     0.0759, 'dot_loss':     0.0090, 'ddot_loss':     0.0252, 'rew_loss':  1622.2203, 'lr':   4.28e-05, 'eps_e':     0.2001, 'lr_e':   4.28e-05})
Step:  493000, Reward:  -181.116 [  78.383], Avg:  -237.776 (0.300) <0-16:17:36> ({'r_t': -1428.7822, 'eps':     0.3001, 'len': 39392.1600, 'dyn_loss':     0.0692, 'dot_loss':     0.0088, 'ddot_loss':     0.0248, 'rew_loss':  1692.0365, 'lr':   4.28e-05, 'eps_e':     0.3001, 'lr_e':   4.28e-05})
Step:  494000, Reward:  -177.048 [ 120.241], Avg:  -237.654 (0.400) <0-16:19:56> ({'r_t': -1968.4671, 'eps':     0.4001, 'len': 39472.1600, 'dyn_loss':     0.0745, 'dot_loss':     0.0092, 'ddot_loss':     0.0258, 'rew_loss':  1620.2120, 'lr':   4.28e-05, 'eps_e':     0.4001, 'lr_e':   4.28e-05})
Step:  495000, Reward:  -191.549 [  97.041], Avg:  -237.561 (0.500) <0-16:22:07> ({'r_t': -2586.9156, 'eps':     0.5001, 'len': 39552.1600, 'dyn_loss':     0.0693, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1704.6637, 'lr':   4.28e-05, 'eps_e':     0.5001, 'lr_e':   4.28e-05})
Step:  496000, Reward:  -188.267 [  96.073], Avg:  -237.462 (0.600) <0-16:24:07> ({'r_t': -3252.8639, 'eps':     0.6001, 'len': 39632.1600, 'dyn_loss':     0.0735, 'dot_loss':     0.0091, 'ddot_loss':     0.0254, 'rew_loss':  1697.3199, 'lr':   4.28e-05, 'eps_e':     0.6001, 'lr_e':   4.28e-05})
Step:  497000, Reward:  -195.514 [  96.681], Avg:  -237.377 (0.700) <0-16:25:52> ({'r_t': -3722.2636, 'eps':     0.7001, 'len': 39712.1600, 'dyn_loss':     0.0733, 'dot_loss':     0.0089, 'ddot_loss':     0.0247, 'rew_loss':  1605.8184, 'lr':   4.28e-05, 'eps_e':     0.7001, 'lr_e':   4.28e-05})
Step:  498000, Reward:  -200.473 [  95.138], Avg:  -237.303 (0.800) <0-16:27:27> ({'r_t': -4590.6040, 'eps':     0.8001, 'len': 39792.1600, 'dyn_loss':     0.0707, 'dot_loss':     0.0089, 'ddot_loss':     0.0248, 'rew_loss':  1662.8335, 'lr':   4.28e-05, 'eps_e':     0.8001, 'lr_e':   4.28e-05})
Step:  499000, Reward:  -201.281 [  89.037], Avg:  -237.231 (0.900) <0-16:28:50> ({'r_t': -5391.6134, 'eps':     0.9001, 'len': 39872.1600, 'dyn_loss':     0.0749, 'dot_loss':     0.0092, 'ddot_loss':     0.0254, 'rew_loss':  1633.9980, 'lr':   4.19e-05, 'eps_e':     0.9001, 'lr_e':   4.19e-05})
Step:  500000, Reward:  -178.333 [ 190.874], Avg:  -237.114 (0.000) <0-16:30:00> ({'r_t': -5924.9990, 'eps':     0.0001, 'len': 39952.1600, 'dyn_loss':     0.0710, 'dot_loss':     0.0087, 'ddot_loss':     0.0245, 'rew_loss':  1669.7545, 'lr':   4.19e-05, 'eps_e':     0.0001, 'lr_e':   4.19e-05})
