Model: <class 'src.models.pytorch.mpc.mppi.MPPIAgent'>, Env: CartPole-v0, Date: 08/06/2020 02:13:47
CPU: 20 Core, 0.0GHz, 377.59 GB, Linux-4.14.175-llgrid-10ms-x86_64-with-debian-buster-sid
GPU 0: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
Git URL: https://github.com/shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: dfadcfaa5da451b9a2ea3569848592f6da9848be
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 1000
   TARGET_UPDATE_RATE = 0.0004
   TRAIN_EVERY = 1000
   BATCH_SIZE = 250
   EPS_CYCLE = 10000
   ENV_MODEL = dfrntl
   MPC = 
      NSAMPLES = 1000
      HORIZON = 20
      LAMBDA = 0.1
      COV = 1
   dynamics_size = 4
   state_size = (4,)
   action_size = [2]
   env_name = CartPole-v0
   rank = 0
   size = 17
   split = 17
   model = mppi
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False
   DYN = 
      REG_LAMBDA = 1e-06
      FACTOR = 0.98
      PATIENCE = 10
      LEARN_RATE = 0.0001
      TRANSITION_HIDDEN = 512
      REWARD_HIDDEN = 256
      BETA_DYN = 1
      BETA_DOT = 0
      BETA_DDOT = 0,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f9b3dc01f60> 
	env = <GymEnv<TimeLimit<CartPoleEnv<CartPole-v0>>>> 
		env = <TimeLimit<CartPoleEnv<CartPole-v0>>> 
			env = <CartPoleEnv<CartPole-v0>> 
				gravity = 9.8
				masscart = 1.0
				masspole = 0.1
				total_mass = 1.1
				length = 0.5
				polemass_length = 0.05
				force_mag = 10.0
				tau = 0.02
				kinematics_integrator = euler
				theta_threshold_radians = 0.20943951023931953
				x_threshold = 2.4
				action_space = Discrete(2) 
					n = 2
					shape = ()
					dtype = int64
					np_random = RandomState(MT19937)
				observation_space = Box(4,) 
					dtype = float32
					shape = (4,)
					low = [-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38]
					high = [ 4.800e+00  3.403e+38  4.189e-01  3.403e+38]
					bounded_below = [ True  True  True  True]
					bounded_above = [ True  True  True  True]
					np_random = RandomState(MT19937)
				np_random = RandomState(MT19937)
				viewer = None
				state = None
				steps_beyond_done = None
				spec = EnvSpec(CartPole-v0) 
					id = CartPole-v0
					entry_point = gym.envs.classic_control:CartPoleEnv
					reward_threshold = 195.0
					nondeterministic = False
					max_episode_steps = 200
				verbose = 0
			action_space = Discrete(2) 
				n = 2
				shape = ()
				dtype = int64
				np_random = RandomState(MT19937)
			observation_space = Box(4,) 
				dtype = float32
				shape = (4,)
				low = [-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38]
				high = [ 4.800e+00  3.403e+38  4.189e-01  3.403e+38]
				bounded_below = [ True  True  True  True]
				bounded_above = [ True  True  True  True]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		action_space = Discrete(2) 
			n = 2
			shape = ()
			dtype = int64
			np_random = RandomState(MT19937)
		observation_space = Box(4,) 
			dtype = float32
			shape = (4,)
			low = [-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38]
			high = [ 4.800e+00  3.403e+38  4.189e-01  3.403e+38]
			bounded_below = [ True  True  True  True]
			bounded_above = [ True  True  True  True]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 50}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f9b3dc17b70> 
			observation_space = Box(4,) 
				dtype = float32
				shape = (4,)
				low = [-4.800e+00 -3.403e+38 -4.189e-01 -3.403e+38]
				high = [ 4.800e+00  3.403e+38  4.189e-01  3.403e+38]
				bounded_below = [ True  True  True  True]
				bounded_above = [ True  True  True  True]
				np_random = RandomState(MT19937)
	state_size = (4,)
	action_size = [2]
	action_space = Discrete(2) 
		n = 2
		shape = ()
		dtype = int64
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.MPIConnection object at 0x7f9b3db60240> 
		root = 0
		rank = 0
		cluster = <list len=16>
	num_envs = 16
	max_steps = 200,
agent: <src.models.wrappers.ParallelAgent object at 0x7f9b3db60278> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f9b3db699b0> 
		state_size = (4,)
	agent = <src.models.pytorch.mpc.mppi.MPPIAgent object at 0x7f9b3db7add8> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f9b3db7ae10> 
			size = [2]
			dt = 0.2
			action = [-1.000 -1.000]
			daction_dt = [ 0.981  0.121]
		discrete = True
		action_size = [2]
		state_size = (4,)
		config = <src.utils.config.Config object at 0x7f9b3def6c18> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 1000
			TARGET_UPDATE_RATE = 0.0004
			TRAIN_EVERY = 1000
			BATCH_SIZE = 250
			EPS_CYCLE = 10000
			ENV_MODEL = dfrntl
			MPC = <src.utils.config.Config object at 0x7f9b63d70160> 
				NSAMPLES = 1000
				HORIZON = 20
				LAMBDA = 0.1
				COV = 1
			dynamics_size = 4
			state_size = (4,)
			action_size = [2]
			env_name = CartPole-v0
			rank = 0
			size = 17
			split = 17
			model = mppi
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
			DYN = <src.utils.config.Config object at 0x7f9b622b6a58> 
				REG_LAMBDA = 1e-06
				FACTOR = 0.98
				PATIENCE = 10
				LEARN_RATE = 0.0001
				TRANSITION_HIDDEN = 512
				REWARD_HIDDEN = 256
				BETA_DYN = 1
				BETA_DOT = 0
				BETA_DDOT = 0
		stats = <src.utils.logger.Stats object at 0x7f9b3db7ae48> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = MPPIController() 
			training = True
			tau = 0.0004
			name = mppi
			stats = <src.utils.logger.Stats object at 0x7f9b3db7aeb8> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f9b3def6c18> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 1000
				TARGET_UPDATE_RATE = 0.0004
				TRAIN_EVERY = 1000
				BATCH_SIZE = 250
				EPS_CYCLE = 10000
				ENV_MODEL = dfrntl
				MPC = <src.utils.config.Config object at 0x7f9b63d70160> 
					NSAMPLES = 1000
					HORIZON = 20
					LAMBDA = 0.1
					COV = 1
				dynamics_size = 4
				state_size = (4,)
				action_size = [2]
				env_name = CartPole-v0
				rank = 0
				size = 17
				split = 17
				model = mppi
				framework = pt
				train_prop = 1.0
				tcp_ports = []
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
				DYN = <src.utils.config.Config object at 0x7f9b622b6a58> 
					REG_LAMBDA = 1e-06
					FACTOR = 0.98
					PATIENCE = 10
					LEARN_RATE = 0.0001
					TRANSITION_HIDDEN = 512
					REWARD_HIDDEN = 256
					BETA_DYN = 1
					BETA_DOT = 0
					BETA_DDOT = 0
			device = cuda
			envmodel = <src.models.pytorch.mpc.EnvModel object at 0x7f9b3db7aef0> 
				network = DifferentialEnv(
					  (reward): RewardModel(
					    (linear1): Linear(in_features=10, out_features=256, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=256, out_features=256, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (linear3): Linear(in_features=256, out_features=256, bias=True)
					    (linear4): Linear(in_features=256, out_features=1, bias=True)
					  )
					  (dynamics): TransitionModel(
					    (gru): GRUCell(10, 512)
					    (linear1): Linear(in_features=512, out_features=512, bias=True)
					    (drop1): Dropout(p=0.5, inplace=False)
					    (linear2): Linear(in_features=512, out_features=512, bias=True)
					    (drop2): Dropout(p=0.5, inplace=False)
					    (state_ddot): Linear(in_features=512, out_features=4, bias=True)
					  )
					) 
					training = True
					tau = 0.0004
					name = dfrntl
					stats = <src.utils.logger.Stats object at 0x7f9b3db7af60> 
						mean_dict = {}
						sum_dict = {}
					config = <src.utils.config.Config object at 0x7f9b3def6c18> 
						TRIAL_AT = 1000
						SAVE_AT = 1
						SEED = 0
						REG_LAMBDA = 1e-06
						LEARN_RATE = 0.0001
						DISCOUNT_RATE = 0.99
						ADVANTAGE_DECAY = 0.95
						INPUT_LAYER = 512
						ACTOR_HIDDEN = 256
						CRITIC_HIDDEN = 1024
						EPS_MAX = 1.0
						EPS_MIN = 0.1
						EPS_DECAY = 0.998
						NUM_STEPS = 500
						MAX_BUFFER_SIZE = 1000000
						REPLAY_BATCH_SIZE = 1000
						TARGET_UPDATE_RATE = 0.0004
						TRAIN_EVERY = 1000
						BATCH_SIZE = 250
						EPS_CYCLE = 10000
						ENV_MODEL = dfrntl
						MPC = <src.utils.config.Config object at 0x7f9b63d70160> 
							NSAMPLES = 1000
							HORIZON = 20
							LAMBDA = 0.1
							COV = 1
						dynamics_size = 4
						state_size = (4,)
						action_size = [2]
						env_name = CartPole-v0
						rank = 0
						size = 17
						split = 17
						model = mppi
						framework = pt
						train_prop = 1.0
						tcp_ports = []
						tcp_rank = 0
						num_envs = 1
						nsteps = 500000
						render = False
						trial = False
						icm = False
						rs = False
						DYN = <src.utils.config.Config object at 0x7f9b622b6a58> 
							REG_LAMBDA = 1e-06
							FACTOR = 0.98
							PATIENCE = 10
							LEARN_RATE = 0.0001
							TRANSITION_HIDDEN = 512
							REWARD_HIDDEN = 256
							BETA_DYN = 1
							BETA_DOT = 0
							BETA_DDOT = 0
					device = cuda
					state_size = (4,)
					action_size = [2]
					discrete = True
					dyn_index = 4
					optimizer = Adam (
					Parameter Group 0
					    amsgrad: False
					    betas: (0.9, 0.999)
					    eps: 1e-08
					    lr: 0.0001
					    weight_decay: 1e-06
					)
					scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f9b3db8a320>
				state_size = (4,)
				action_size = [2]
			mu = [ 0.000  0.000]
			cov = [[ 1.000  0.000]
			 [ 0.000  1.000]]
			icov = [[ 1.000  0.000]
			 [ 0.000  1.000]]
			lamda = 0.1
			horizon = 20
			nsamples = 1000
			action_size = [2]
			control = [[[ 0.097  0.585]
			  [-0.117 -0.952]
			  [-0.730 -0.900]
			  [-0.587 -0.929]
			  [ 0.715 -0.647]
			  [ 0.750  0.032]
			  [ 0.944  0.283]
			  [-0.901 -0.916]
			  [ 0.144 -0.089]
			  [ 0.221 -0.021]
			  [-0.839  0.344]
			  [-0.166 -0.802]
			  [ 0.984  0.834]
			  [-0.969  0.031]
			  [ 0.392  0.805]
			  [ 0.571  0.482]
			  [ 0.782 -0.466]
			  [ 0.643 -0.588]
			  [-0.557 -0.647]
			  [ 0.119 -0.912]]]
			noise = [[[[ 1.009  0.756]
			   [ 0.907 -0.208]
			   [ 0.171 -1.116]
			   ...
			   [-0.486  0.405]
			   [ 1.804 -0.738]
			   [-1.971 -0.875]]
			
			  [[ 0.528 -0.531]
			   [-1.123 -0.763]
			   [ 0.343  0.402]
			   ...
			   [ 0.649 -0.484]
			   [-0.007  0.913]
			   [ 0.702 -1.494]]
			
			  [[ 0.420 -1.292]
			   [-1.204 -1.348]
			   [ 0.160  0.373]
			   ...
			   [-0.942  1.464]
			   [-1.012 -0.973]
			   [-1.065 -0.652]]
			
			  ...
			
			  [[ 1.132 -0.655]
			   [ 0.452  0.271]
			   [ 1.942 -1.837]
			   ...
			   [-1.235 -0.485]
			   [ 0.465 -0.767]
			   [ 1.803 -1.225]]
			
			  [[ 0.676  0.740]
			   [-0.735 -0.076]
			   [-0.796  0.173]
			   ...
			   [-0.141  0.557]
			   [-1.156 -1.199]
			   [ 1.387 -0.010]]
			
			  [[ 0.729  0.553]
			   [ 0.049 -1.401]
			   [ 0.978 -0.349]
			   ...
			   [ 0.772 -0.150]
			   [-1.295  0.025]
			   [ 0.838 -0.555]]]]
			init_cost = [[-3.469e-02  1.769e+00  5.581e+00 -4.477e+00  1.646e-02  3.455e+00 -8.336e+00  6.969e+00 -6.554e+00 -9.847e+00  6.334e+00  9.962e-01 -2.655e+00  6.316e+00  6.073e-01 -1.728e+00  7.068e+00 -8.419e-01 -1.011e+00 -1.731e+00 -2.830e+00  1.446e+00 -3.935e-01 -6.478e+00 -2.988e+00 -1.135e+01 -3.337e+00  3.208e+00 -2.488e+00  1.181e+00  6.369e+00 -1.464e+00  1.013e+00  4.492e+00  1.592e+00 -1.974e+00 -1.004e+00 -1.704e+00  1.322e+00 -2.692e+00 -1.790e+00  4.309e-01  6.891e-01  3.978e+00  5.803e-01 -9.086e+00  1.990e-01 -1.675e+00  2.306e+00  2.309e+00  3.265e+00 -4.006e+00  3.284e+00 -4.269e+00  6.557e+00  3.652e+00  6.858e+00  2.104e+00  3.366e+00 -3.075e+00  3.522e+00 -6.191e+00  3.643e+00  3.812e+00 -6.186e-01  1.707e+00 -2.162e+00  4.262e+00 -1.791e+00 -2.330e+00  4.057e+00 -1.285e+00 -4.712e+00  4.135e-01 -3.718e+00 -4.669e-01 -1.055e-01  8.540e-01 -7.637e-01  2.195e+00  8.625e+00 -1.829e+00 -2.587e+00 -2.816e+00 -2.005e+00 -3.888e+00 -3.323e+00  5.053e-01  2.178e+00  2.542e-01 -1.311e-01 -4.640e+00 -6.651e-01 -8.123e-01  2.391e+00  1.901e+00  3.702e+00  4.753e+00 -3.988e+00  2.972e+00  1.075e-02  7.316e+00  1.202e+00 -4.658e+00 -3.151e+00 -3.120e+00 -2.587e+00  4.866e+00  5.322e+00  6.851e-02 -4.142e+00 -3.555e-01 -4.054e+00  1.987e-02  3.478e+00 -1.326e+00 -2.644e-01 -3.168e-01  2.155e+00  3.903e+00 -2.086e+00  3.316e+00 -4.312e+00 -1.672e+00  1.191e+00  1.519e+00 -2.427e-01  2.389e+00  4.582e+00 -3.636e+00  6.614e-01 -4.800e-01 -6.478e+00  5.851e+00  6.666e-01 -4.627e+00 -2.994e+00 -5.458e-01 -6.378e+00  1.792e+00 -2.120e+00  1.031e+00 -5.391e+00 -6.581e+00  4.917e+00 -5.443e+00 -6.917e+00 -8.688e+00  3.183e+00  5.824e+00 -5.591e+00  1.668e+00  8.594e+00 -1.041e-01  1.601e+00 -3.673e+00  2.545e+00  1.518e+00 -4.941e+00 -2.579e+00  4.852e+00  6.349e-01  3.266e+00  2.537e+00  9.333e-01 -2.488e+00  5.528e+00  2.623e+00 -6.503e+00  5.395e+00 -5.955e+00 -9.464e-02  3.239e+00  1.229e+00  1.057e+01 -5.655e+00  7.147e-01  1.905e+00  3.154e-01  3.015e+00  1.093e+01
			   8.926e-01  7.158e+00 -5.230e+00  5.307e+00  1.598e+00  5.337e+00 -2.815e+00  2.526e+00  4.382e-01  1.468e-02  1.503e-01  1.774e+00 -1.186e+00 -2.155e+00 -4.586e+00  2.202e+00  2.594e+00 -6.005e+00 -1.063e+00  6.357e+00  3.149e-01  1.798e+00 -4.148e+00 -1.718e+00  2.042e+00 -1.313e+00 -3.796e-01  2.240e+00 -3.443e+00  2.650e+00 -1.859e+00  8.706e+00  8.500e-01 -7.601e-02 -8.968e-01 -1.969e+00 -6.587e-01  1.753e-01 -4.285e+00  2.577e-01 -2.485e-01 -8.413e+00 -5.227e+00 -8.867e-01 -5.764e-03  2.020e+00 -4.112e+00  1.843e+00  5.655e-01  3.058e-01 -3.624e+00 -5.897e+00 -1.664e+00 -1.658e+00  2.570e+00  4.769e+00  3.301e+00  3.264e+00  5.832e+00 -9.885e-01 -2.076e+00  1.863e+00  2.956e+00 -4.356e+00 -5.110e+00  3.872e+00  6.555e+00  4.135e-01 -2.154e+00 -1.124e+00  1.556e+00  2.942e-01 -4.471e+00  6.380e-01 -1.374e+00  7.054e+00  9.282e-01  7.446e+00 -5.644e+00 -2.426e+00  7.959e-01  4.353e+00 -1.270e+00  3.908e+00 -2.062e+00  1.447e+00  3.643e+00  2.059e+00 -2.595e+00 -1.089e+00  8.425e+00  3.844e+00 -5.319e+00  1.668e+00 -3.063e+00  2.504e+00 -5.928e-02 -5.576e+00  1.784e+00  1.893e+00 -3.347e+00  3.158e+00 -1.192e+00 -3.567e+00  3.311e+00  3.947e+00 -4.028e+00  9.780e+00 -6.536e+00  1.494e+00  9.773e-01 -2.371e+00 -5.398e+00  3.224e+00 -8.167e-01  4.052e+00  2.692e+00 -3.474e-01  6.282e+00 -4.255e+00 -2.456e+00 -8.701e-01  2.055e+00 -1.989e+00 -2.463e+00  6.383e+00 -6.559e-01 -2.044e+00 -1.676e-01 -3.148e+00 -2.447e+00  6.706e-01  1.744e+00 -3.256e+00  6.063e-01  2.795e+00 -1.078e+01 -3.481e-01  1.951e+00  2.762e+00 -3.769e-01 -2.042e+00  3.388e+00  2.783e+00  1.170e+00 -2.566e-02  2.748e-01  1.396e-01 -2.438e+00  6.300e+00 -7.363e+00 -5.560e+00  1.262e+00 -3.277e+00 -2.387e+00  4.142e+00  3.482e+00 -8.353e-01  9.506e+00  5.286e+00  2.322e+00  2.767e-01 -4.143e+00 -3.906e-01  5.791e+00  1.048e+00 -9.892e-01 -4.971e-01  2.063e+00 -3.046e-02 -5.625e+00 -4.120e+00 -3.313e+00  4.877e+00 -7.625e+00  3.054e+00  2.655e+00 -6.953e+00 -3.604e+00  1.263e-02 -2.249e-01
			   6.302e+00  4.458e+00  1.202e+00  3.432e+00 -4.853e+00 -5.031e+00  2.966e+00 -2.472e+00  1.044e+01  3.242e-01  2.315e+00  3.702e+00 -8.795e-01 -3.876e-01 -1.873e+00  9.052e-01  2.026e+00  1.122e+00 -3.043e+00 -7.785e-01 -3.031e+00  1.401e+00 -4.145e+00  2.558e+00  5.083e-01 -6.213e+00  7.757e-01  5.713e+00  2.587e-01  5.365e+00  1.107e+00 -6.103e+00 -4.056e+00  1.162e+00  2.465e+00 -2.968e+00 -4.913e-01  5.260e+00  1.149e-01  2.487e+00  5.959e+00  5.019e-02  2.146e+00  2.763e+00 -9.074e-02 -2.053e+00  4.789e+00 -1.687e+00  3.052e+00 -6.584e+00 -5.646e+00 -2.076e+00  1.575e+00 -5.233e+00  2.907e-02  3.178e+00  2.298e+00  4.853e+00  6.892e-01 -2.273e+00 -2.891e+00  2.609e+00 -1.068e+01  5.190e-01 -2.813e+00  2.885e+00  7.365e+00  4.886e+00  2.201e+00  4.561e-01 -6.970e+00 -3.250e-01  1.782e+00  1.130e+00 -8.155e+00 -4.195e+00  2.673e+00 -2.484e+00  2.701e+00  6.274e-01 -4.193e+00 -8.637e-01 -1.417e+00 -3.033e+00 -9.119e-01 -6.608e-01  3.832e-01  5.274e+00 -2.616e+00  1.867e+00 -7.279e+00  7.323e-01 -6.453e-01  8.271e+00 -2.221e+00  1.330e+00  2.289e+00 -5.059e+00  2.292e+00  2.970e+00  4.372e+00  4.884e+00 -4.199e+00  3.924e+00 -5.266e+00 -8.004e+00 -9.887e-01 -8.915e-01  9.581e-01 -9.104e-01  1.011e+00 -8.197e+00  3.438e+00  2.537e-01  3.425e+00 -3.396e+00 -3.996e+00 -3.183e+00  4.734e-01 -8.040e-01 -3.957e+00 -4.614e+00  3.216e+00 -5.212e-01  1.883e+00 -3.648e+00 -3.473e+00  5.335e+00 -9.324e-01  4.668e+00 -3.717e+00  4.653e-01 -4.630e-01  5.299e-01 -8.812e-01  6.381e+00 -1.249e+00 -6.447e+00  2.770e+00 -1.498e-01 -2.452e+00 -2.803e+00 -2.995e-02 -2.605e+00  1.008e-01 -1.137e+00 -5.926e+00 -5.650e-01 -8.848e+00 -5.126e-01 -4.267e-01  2.530e+00  5.743e+00 -1.992e-01  4.717e+00 -1.057e+00  2.238e+00  8.297e+00  4.382e-01  1.068e+01  1.840e+00 -9.378e-01 -8.070e-01  1.090e+00 -3.531e+00  2.312e+00 -3.842e+00 -5.356e+00  7.124e+00  1.298e+00 -6.999e+00  1.158e+00  5.126e+00  4.370e+00 -1.692e+00  1.852e+00  6.814e+00  3.618e+00 -6.448e+00  1.425e+00  8.577e+00
			   5.525e-01  7.214e-01  3.738e+00 -2.784e-01  3.396e+00  2.433e+00  9.275e-01 -6.129e+00  5.860e+00 -2.040e+00  4.984e+00 -9.218e-01  2.718e+00  4.494e+00  3.353e+00 -7.987e-01 -1.844e+00  1.059e+01 -8.650e-01 -1.087e+01  3.912e+00 -5.069e-01  3.381e+00 -1.820e+00 -2.594e+00 -1.307e+00 -5.551e-01 -5.278e+00 -2.360e+00  7.189e+00  8.096e+00  1.090e+00  1.593e+00 -1.816e+00  4.714e+00 -7.297e+00  8.999e-01 -4.539e+00 -2.390e+00 -1.013e+01  3.609e+00  1.060e+00 -3.684e+00  6.106e+00  1.080e+00  1.578e+00  2.938e+00  1.917e+00  1.776e+00  3.252e+00  4.040e+00 -1.695e+00 -5.711e+00  4.145e+00 -1.156e+00  2.777e-01  4.121e+00 -5.096e+00  2.720e+00 -2.629e+00  6.607e+00 -4.669e+00 -6.524e+00 -6.720e+00  1.550e+00  3.723e+00  1.115e+01 -4.495e+00 -7.729e-01 -4.700e+00 -1.485e+00 -1.138e+00 -7.488e+00 -8.565e-01 -1.243e+00 -2.210e+00 -1.043e+00  5.456e+00  5.096e+00  4.613e+00  1.915e+00  1.988e+00 -3.847e+00  2.766e+00 -3.370e+00  3.639e+00 -1.567e+00 -1.280e+00 -1.170e+00 -3.987e+00  5.511e+00  6.048e+00  9.070e-01 -4.093e+00  1.268e+00 -2.251e+00  5.991e+00 -2.974e-01 -7.883e+00 -3.916e+00  5.254e+00  2.708e+00 -3.208e+00  5.549e-01 -9.780e-01  3.062e+00 -2.820e+00 -8.880e+00  1.679e+00  4.432e+00 -2.841e-01  1.397e+00  1.851e+00  1.700e+00 -5.885e-01 -2.420e-01 -1.049e+00  2.985e+00 -7.756e+00 -1.822e+00  3.007e+00 -1.841e-01  2.980e+00 -5.587e+00 -2.842e+00 -7.345e+00 -6.138e+00  2.771e+00  4.864e+00  1.176e+00  1.047e+01  1.497e+00  2.624e+00  1.306e+00 -2.579e+00 -2.733e+00 -1.738e+00  3.004e+00  6.358e-01 -2.820e+00  3.550e+00  1.044e+00 -1.425e+00  5.842e+00 -4.796e+00 -3.441e-01  4.509e+00  2.472e+00  1.008e-01 -5.076e+00 -1.979e+00 -4.612e-01  4.762e+00  3.373e+00 -6.661e+00 -9.393e-01 -4.063e+00  5.709e+00 -2.043e+00 -2.513e+00  8.346e-01 -1.313e+00  4.519e+00  1.830e+00 -3.618e+00  1.713e-02  5.312e+00 -4.019e+00 -1.131e+00  1.411e+00 -2.005e+00  9.386e-01  8.561e+00  3.150e+00  8.001e+00 -4.055e+00 -7.255e+00  2.075e-01 -5.566e+00 -2.690e+00 -6.175e+00
			   3.339e+00  5.892e+00  1.910e+00 -7.085e+00  4.394e+00 -4.606e+00 -5.173e+00  2.769e-02 -1.718e+00 -8.132e-01 -5.141e+00  3.489e+00 -4.574e+00  2.276e+00  9.292e-01  6.302e+00  7.343e+00  5.012e-01 -5.033e+00  2.008e+00 -4.342e+00 -2.639e+00  1.294e+00  1.249e+00 -6.115e+00 -1.169e+00 -3.791e+00  9.663e+00  2.901e+00  5.146e-01  2.949e+00  5.865e+00  4.508e+00 -1.273e+00  5.347e+00 -6.395e+00 -1.850e+00  1.893e+00 -1.587e-01  3.016e+00  5.364e-01 -2.738e+00  7.641e+00 -7.631e+00  6.140e+00  3.767e+00 -5.392e+00  2.681e+00 -5.996e+00 -5.248e+00  3.523e-02  1.151e-01 -2.441e-01  5.238e-01 -2.473e+00 -3.103e+00 -1.314e+00  3.651e+00 -6.256e+00  3.254e+00 -2.319e-01  2.194e+00  4.427e+00  6.177e-01  2.245e+00 -1.238e+00  3.001e+00  8.604e+00 -8.006e-01  8.034e+00  4.680e+00  1.164e+00  4.629e+00  8.847e-01  1.348e+00  8.114e+00 -5.438e+00 -2.573e+00  5.521e+00 -4.555e+00 -4.548e+00 -6.923e+00  3.355e+00  4.648e+00 -5.905e+00 -3.463e+00 -1.748e+00 -8.889e+00 -2.650e+00  7.851e-01 -4.000e+00  6.872e+00 -3.041e+00 -1.705e-01  2.907e+00  2.299e-01  1.829e+00  2.112e+00 -2.174e+00 -4.679e+00 -3.518e+00  7.902e+00  6.116e-01 -7.532e+00 -2.346e+00 -3.887e+00  6.074e+00 -1.102e+00 -3.316e+00  8.647e-01 -1.883e+00  7.967e+00 -2.092e+00  6.877e-01  1.126e+00 -5.385e+00  2.484e+00 -6.485e+00  9.483e+00 -1.761e+00 -4.163e+00  1.193e+00  1.033e+01  3.176e+00 -4.016e+00  2.770e+00  6.052e-01 -3.223e+00  3.783e+00 -2.890e+00  2.377e+00  4.126e+00  6.151e+00 -3.041e+00  2.429e+00  3.222e+00 -7.282e+00  1.758e+00 -4.719e+00  1.039e+00  1.803e+00  1.303e+01  1.543e+00  3.467e+00  5.010e-01 -7.311e-01 -7.114e-01 -4.777e-01  5.725e+00 -8.663e+00 -2.152e+00 -5.938e+00 -4.755e+00 -4.784e+00  5.840e+00 -3.734e+00 -3.731e+00 -2.047e+00 -1.088e+00  5.387e+00 -6.160e+00  2.963e+00 -4.084e+00  1.219e+00 -3.128e+00 -5.538e+00 -5.735e-01 -6.851e+00  1.238e+00 -1.059e+00  4.320e+00  4.724e-02 -3.616e+00  8.077e+00  7.083e+00 -2.124e+00  2.097e+00  6.123e+00  5.389e+00 -3.561e+00 -9.860e+00
			   6.057e+00 -6.570e-01 -4.860e-01  4.440e+00  7.986e+00 -1.649e+00 -2.615e+00 -2.623e+00  1.209e+00  7.352e-01  2.427e+00 -4.163e-01  1.596e+00  1.343e+00  4.951e+00  5.092e+00 -2.243e+00 -2.868e+00  6.587e+00 -2.517e+00 -2.756e+00 -2.101e+00  1.353e+00 -3.013e+00 -3.072e+00 -3.490e+00  5.115e+00 -1.407e+00  6.103e+00 -2.175e+00 -7.704e-01  9.518e+00  2.926e-01  3.126e+00  2.943e+00  3.766e+00 -3.036e+00  3.063e+00  3.441e-01 -4.952e+00 -1.621e+00 -6.887e-01  2.913e-01  1.444e+00  9.797e-01 -4.613e+00  1.691e+00 -2.411e+00  3.278e+00 -9.426e-01  5.352e+00  3.902e+00 -4.130e+00  6.678e+00 -1.347e+00 -5.055e+00 -4.283e+00  7.979e-03  7.001e-01  4.818e+00  3.286e+00  2.026e+00 -5.426e+00  1.222e-01  9.710e+00  2.667e+00  8.138e+00  4.003e+00 -3.302e+00 -1.754e+00  1.657e+00 -3.612e+00  3.379e+00 -1.753e+00  4.377e+00  5.462e+00 -2.436e+00 -3.654e+00  2.129e+00  9.713e-01  5.043e+00  6.092e+00  1.347e+00  1.906e+00  7.370e-01 -1.683e+00  3.921e+00 -5.619e+00  7.827e-01 -3.651e+00 -7.325e-02  1.102e+01 -6.817e+00 -4.306e+00  4.540e-01]]
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f9b3db8a358> 
			buffer = deque([], maxlen=1000000)
		buffer = []
		dataset = <class 'src.data.loaders.OnlineDataset'>
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f9b3db8a438> 
		size = [2]
		dt = 0.2
		action = [ 0.969 -0.924]
		daction_dt = [ 1.333  0.243]
	discrete = True
	action_size = [2]
	state_size = (4,)
	config = <src.utils.config.Config object at 0x7f9b3def6c18> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 1000
		TARGET_UPDATE_RATE = 0.0004
		TRAIN_EVERY = 1000
		BATCH_SIZE = 250
		EPS_CYCLE = 10000
		ENV_MODEL = dfrntl
		MPC = <src.utils.config.Config object at 0x7f9b63d70160> 
			NSAMPLES = 1000
			HORIZON = 20
			LAMBDA = 0.1
			COV = 1
		dynamics_size = 4
		state_size = (4,)
		action_size = [2]
		env_name = CartPole-v0
		rank = 0
		size = 17
		split = 17
		model = mppi
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
		DYN = <src.utils.config.Config object at 0x7f9b622b6a58> 
			REG_LAMBDA = 1e-06
			FACTOR = 0.98
			PATIENCE = 10
			LEARN_RATE = 0.0001
			TRANSITION_HIDDEN = 512
			REWARD_HIDDEN = 256
			BETA_DYN = 1
			BETA_DOT = 0
			BETA_DDOT = 0
	stats = <src.utils.logger.Stats object at 0x7f9b3db8a470> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import tqdm
import torch
import random
import numpy as np
import scipy as sp
from scipy.stats import multivariate_normal
from src.utils.rand import RandomAgent, ReplayBuffer
from src.utils.misc import load_module
from ..agents.base import PTNetwork, PTAgent, Conv, one_hot_from_indices
from . import EnvModel

class MPPIController(PTNetwork):
	def __init__(self, state_size, action_size, config, load="", gpu=True, name="mppi"):
		super().__init__(config, gpu=gpu, name=name)
		self.envmodel = EnvModel(state_size, action_size, config, load=load, gpu=gpu)
		self.mu = np.zeros(action_size)
		self.cov = np.diag(np.ones(action_size))*config.MPC.COV
		self.icov = np.linalg.inv(self.cov)
		self.lamda = config.MPC.LAMBDA
		self.horizon = config.MPC.HORIZON
		self.nsamples = config.MPC.NSAMPLES
		self.action_size = action_size
		self.config = config
		self.init_control()

	def get_action(self, state, eps=None, sample=True):
		batch = state.shape[:-1]
		horizon = max(int((1-eps)*self.horizon),1) if eps else self.horizon
		if len(batch) and self.control.shape[0] != batch[0]: self.init_control(batch[0])
		x = torch.Tensor(state).view(*batch, 1,-1).repeat_interleave(self.nsamples, -2)
		noise = self.noise[...,:horizon,:] * max(eps if eps else 0, 0.1)
		controls = np.clip(self.control[:,None,:horizon,:] + noise, -1, 1)
		self.states, rewards = self.envmodel.rollout(controls, x, numpy=True)
		costs = -np.sum(rewards, -1)# + self.lamda * np.copy(self.init_cost)
		beta = np.min(costs, -1, keepdims=True)
		costs_norm = -(costs - beta)/self.lamda
		weights = sp.special.softmax(costs_norm, axis=-1)
		self.control[...,:horizon,:] += np.sum(weights[:,:,None,None]*noise, len(batch))
		action = self.control[...,0,:]
		self.control = np.roll(self.control, -1, axis=-2)
		self.control[...,-1,:] = 0
		return action

	def init_control(self, batch_size=1):
		self.control = np.random.uniform(-1, 1, size=[batch_size, self.horizon, *self.action_size])
		self.noise = np.random.multivariate_normal(self.mu, self.cov, size=[batch_size, self.nsamples, self.horizon])
		self.init_cost = np.sum(self.control[:,None,:,None,:] @ self.icov[None,None,None,:,:] @ self.noise[:,:,:,:,None], axis=(2,3,4))

	def optimize(self, states, actions, next_states, rewards, dones):
		return self.envmodel.optimize(states, actions, next_states, rewards, dones)

	def save_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.save_model(dirname, name, net)
		
	def load_model(self, dirname="pytorch", name="checkpoint", net=None):
		return self.envmodel.load_model(dirname, name, net)

	def get_stats(self):
		return {**super().get_stats(), **self.envmodel.get_stats()}

class MPPIAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, MPPIController, gpu=gpu, load=load)
		self.dataset = load_module("src.data.loaders:OnlineDataset")

	def get_action(self, state, eps=None, sample=True):
		action_random = super().get_action(state)
		if eps is None and not hasattr(self, "losses"): return action_random
		eps = self.eps if eps is None else eps
		action_greedy = self.network.get_action(np.array(state), eps)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action

	def train(self, state, action, next_state, reward, done):
		self.time = getattr(self, "time", 0) + 1
		if not hasattr(self, "buffers"): self.buffers = [[] for _ in done]
		for buffer, s, a, ns, r, d in zip(self.buffers, state, action, next_state, reward, done):
			buffer.append((s, a, s if d else ns, r, d))
			if not d: continue
			states, actions, next_states, rewards, dones = map(lambda x: self.to_tensor(x)[None], zip(*buffer))
			buffer.clear()
			values = self.network.envmodel.network.reward(actions, states, next_states)[0]
			rewards = self.compute_gae(0*values[-1], rewards.transpose(0,1), dones.transpose(0,1), values)[0].transpose(0,1)
			states, actions, next_states, rewards, dones = map(lambda x: x.cpu().numpy(), [states, actions, next_states, rewards, dones])
			self.replay_buffer.extend(list(zip(states, actions, next_states, rewards, dones)), shuffle=False)
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE and self.time % self.config.TRAIN_EVERY == 0:
			self.losses = []
			samples = list(self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=None)[0])
			dataset = self.dataset(self.config, samples, seq_len=self.config.MPC.HORIZON)
			loader = torch.utils.data.DataLoader(dataset, batch_size=self.config.BATCH_SIZE, shuffle=True)
			pbar = tqdm.tqdm(loader)
			for states, actions, next_states, rewards, dones in pbar:
				self.losses.append(self.network.optimize(states, actions, next_states, rewards, dones))
				pbar.set_postfix_str(f"Loss: {self.losses[-1]:.4f}")
			self.network.envmodel.network.schedule(np.mean(self.losses))
		self.eps = (self.time%self.config.EPS_CYCLE)/self.config.EPS_CYCLE if hasattr(self, "losses") else 1
		self.stats.mean(len=len(self.replay_buffer))


Step:       0, Reward:    13.500 [   3.674], Avg:    13.500 (1.000) <0-00:00:00> ({'r_t':     1.0000, 'eps':     1.0000, 'len':   0.00e+00, 'lr':     0.0001, 'eps_e':     1.0000, 'lr_e':     0.0001})
Step:    1000, Reward:    14.812 [   6.839], Avg:    14.156 (0.100) <0-00:00:08> ({'r_t':  1000.0000, 'eps':     0.1001, 'len':   584.2270, 'dyn_loss':    10.8802, 'dot_loss':     1.1243, 'ddot_loss':     0.3655, 'rew_loss':    44.4403, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:    2000, Reward:     9.125 [   0.696], Avg:    12.479 (0.200) <0-00:01:58> ({'r_t':  1000.0000, 'eps':     0.2001, 'len':  1985.0550, 'dyn_loss':     2.5287, 'dot_loss':     0.3814, 'ddot_loss':     0.2417, 'rew_loss':    25.8842, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:    3000, Reward:     9.438 [   0.788], Avg:    11.719 (0.300) <0-00:03:36> ({'r_t':  1000.0000, 'eps':     0.3001, 'len':  3658.8510, 'dyn_loss':     1.7224, 'dot_loss':     0.3300, 'ddot_loss':     0.2247, 'rew_loss':    12.8528, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:    4000, Reward:    11.250 [   4.380], Avg:    11.625 (0.400) <0-00:05:03> ({'r_t':  1000.0000, 'eps':     0.4001, 'len':  5336.5790, 'dyn_loss':     1.5145, 'dot_loss':     0.3146, 'ddot_loss':     0.2169, 'rew_loss':    13.3685, 'lr':     0.0001, 'eps_e':     0.4001, 'lr_e':     0.0001})
Step:    5000, Reward:     9.562 [   0.788], Avg:    11.281 (0.500) <0-00:06:16> ({'r_t':  1000.0000, 'eps':     0.5001, 'len':  6960.7190, 'dyn_loss':     1.3228, 'dot_loss':     0.2932, 'ddot_loss':     0.2044, 'rew_loss':    14.4140, 'lr':     0.0001, 'eps_e':     0.5001, 'lr_e':     0.0001})
Step:    6000, Reward:     9.375 [   0.781], Avg:    11.009 (0.600) <0-00:07:18> ({'r_t':  1000.0000, 'eps':     0.6001, 'len':  8469.0760, 'dyn_loss':     1.1984, 'dot_loss':     0.2782, 'ddot_loss':     0.2073, 'rew_loss':    13.8979, 'lr':     0.0001, 'eps_e':     0.6001, 'lr_e':     0.0001})
Step:    7000, Reward:     9.250 [   0.750], Avg:    10.789 (0.700) <0-00:08:07> ({'r_t':  1000.0000, 'eps':     0.7001, 'len':  9886.0980, 'dyn_loss':     1.1055, 'dot_loss':     0.2708, 'ddot_loss':     0.2057, 'rew_loss':    16.0386, 'lr':     0.0001, 'eps_e':     0.7001, 'lr_e':     0.0001})
Step:    8000, Reward:    23.812 [   5.138], Avg:    12.236 (0.800) <0-00:08:47> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 11209.5710, 'dyn_loss':     1.0003, 'dot_loss':     0.2593, 'ddot_loss':     0.2010, 'rew_loss':    15.8928, 'lr':     0.0001, 'eps_e':     0.8001, 'lr_e':     0.0001})
Step:    9000, Reward:    18.062 [   8.257], Avg:    12.819 (0.900) <0-00:09:15> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 12402.7460, 'dyn_loss':     0.9504, 'dot_loss':     0.2465, 'ddot_loss':     0.2063, 'rew_loss':    16.7082, 'lr':     0.0001, 'eps_e':     0.9001, 'lr_e':     0.0001})
Step:   10000, Reward:    18.188 [  14.170], Avg:    13.307 (0.000) <0-00:09:38> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 13581.4550, 'dyn_loss':     0.8973, 'dot_loss':     0.2329, 'ddot_loss':     0.1943, 'rew_loss':    15.6210, 'lr':     0.0001, 'eps_e':     0.0001, 'lr_e':     0.0001})
Step:   11000, Reward:    20.188 [   3.925], Avg:    13.880 (0.100) <0-00:11:41> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 14635.6760, 'dyn_loss':     0.8241, 'dot_loss':     0.2314, 'ddot_loss':     0.2259, 'rew_loss':    14.0675, 'lr':     0.0001, 'eps_e':     0.1001, 'lr_e':     0.0001})
Step:   12000, Reward:    29.750 [  13.108], Avg:    15.101 (0.200) <0-00:13:37> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 15479.8300, 'dyn_loss':     0.7672, 'dot_loss':     0.2235, 'ddot_loss':     0.2374, 'rew_loss':    17.1484, 'lr':     0.0001, 'eps_e':     0.2001, 'lr_e':     0.0001})
Step:   13000, Reward:    27.188 [   8.626], Avg:    15.964 (0.300) <0-00:15:18> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 16188.5880, 'dyn_loss':     0.6907, 'dot_loss':     0.2153, 'ddot_loss':     0.2486, 'rew_loss':    18.3273, 'lr':     0.0001, 'eps_e':     0.3001, 'lr_e':     0.0001})
Step:   14000, Reward:    36.375 [  15.194], Avg:    17.325 (0.400) <0-00:16:50> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 16821.5770, 'dyn_loss':     0.6751, 'dot_loss':     0.2091, 'ddot_loss':     0.2556, 'rew_loss':    28.5616, 'lr':   9.80e-05, 'eps_e':     0.4001, 'lr_e':   9.80e-05})
Step:   15000, Reward:    32.875 [  16.393], Avg:    18.297 (0.500) <0-00:18:10> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 17412.7050, 'dyn_loss':     0.5944, 'dot_loss':     0.1952, 'ddot_loss':     0.2497, 'rew_loss':    28.0021, 'lr':   9.80e-05, 'eps_e':     0.5001, 'lr_e':   9.80e-05})
Step:   16000, Reward:    38.062 [  17.569], Avg:    19.460 (0.600) <0-00:19:19> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 18040.5240, 'dyn_loss':     0.5579, 'dot_loss':     0.1839, 'ddot_loss':     0.2348, 'rew_loss':    25.9860, 'lr':   9.80e-05, 'eps_e':     0.6001, 'lr_e':   9.80e-05})
Step:   17000, Reward:    33.375 [  13.504], Avg:    20.233 (0.700) <0-00:20:13> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 18727.3930, 'dyn_loss':     0.5314, 'dot_loss':     0.1765, 'ddot_loss':     0.2354, 'rew_loss':    29.1891, 'lr':   9.80e-05, 'eps_e':     0.7001, 'lr_e':   9.80e-05})
Step:   18000, Reward:    48.375 [  20.784], Avg:    21.714 (0.800) <0-00:21:01> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 19528.5770, 'dyn_loss':     0.5056, 'dot_loss':     0.1705, 'ddot_loss':     0.2291, 'rew_loss':    28.1774, 'lr':   9.80e-05, 'eps_e':     0.8001, 'lr_e':   9.80e-05})
Step:   19000, Reward:    38.688 [  12.231], Avg:    22.562 (0.900) <0-00:21:33> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 20495.8260, 'dyn_loss':     0.4914, 'dot_loss':     0.1634, 'ddot_loss':     0.2229, 'rew_loss':    26.2548, 'lr':   9.80e-05, 'eps_e':     0.9001, 'lr_e':   9.80e-05})
Step:   20000, Reward:    47.188 [  12.724], Avg:    23.735 (0.000) <0-00:21:55> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 21560.7150, 'dyn_loss':     0.4593, 'dot_loss':     0.1549, 'ddot_loss':     0.2146, 'rew_loss':    31.9836, 'lr':   9.80e-05, 'eps_e':     0.0001, 'lr_e':   9.80e-05})
Step:   21000, Reward:    55.750 [  26.684], Avg:    25.190 (0.100) <0-00:24:10> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 22276.9970, 'dyn_loss':     0.4227, 'dot_loss':     0.1491, 'ddot_loss':     0.2189, 'rew_loss':    35.7967, 'lr':   9.80e-05, 'eps_e':     0.1001, 'lr_e':   9.80e-05})
Step:   22000, Reward:    40.438 [  18.811], Avg:    25.853 (0.200) <0-00:26:07> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 22634.5810, 'dyn_loss':     0.4025, 'dot_loss':     0.1395, 'ddot_loss':     0.2034, 'rew_loss':    38.0965, 'lr':   9.80e-05, 'eps_e':     0.2001, 'lr_e':   9.80e-05})
Step:   23000, Reward:    42.000 [  14.573], Avg:    26.526 (0.300) <0-00:27:52> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 22997.3760, 'dyn_loss':     0.3981, 'dot_loss':     0.1337, 'ddot_loss':     0.1962, 'rew_loss':    39.4063, 'lr':   9.80e-05, 'eps_e':     0.3001, 'lr_e':   9.80e-05})
Step:   24000, Reward:    46.375 [  21.351], Avg:    27.320 (0.400) <0-00:29:28> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 23373.8680, 'dyn_loss':     0.3829, 'dot_loss':     0.1292, 'ddot_loss':     0.1980, 'rew_loss':    44.6756, 'lr':   9.80e-05, 'eps_e':     0.4001, 'lr_e':   9.80e-05})
Step:   25000, Reward:    48.688 [  21.097], Avg:    28.142 (0.500) <0-00:30:51> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 23785.6260, 'dyn_loss':     0.3472, 'dot_loss':     0.1199, 'ddot_loss':     0.1816, 'rew_loss':    44.3263, 'lr':   9.60e-05, 'eps_e':     0.5001, 'lr_e':   9.60e-05})
Step:   26000, Reward:    39.250 [  21.271], Avg:    28.553 (0.600) <0-00:32:02> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 24256.0270, 'dyn_loss':     0.3341, 'dot_loss':     0.1169, 'ddot_loss':     0.1842, 'rew_loss':    45.0741, 'lr':   9.60e-05, 'eps_e':     0.6001, 'lr_e':   9.60e-05})
Step:   27000, Reward:    49.250 [  23.732], Avg:    29.292 (0.700) <0-00:33:02> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 24874.6260, 'dyn_loss':     0.3284, 'dot_loss':     0.1139, 'ddot_loss':     0.1827, 'rew_loss':    45.0939, 'lr':   9.60e-05, 'eps_e':     0.7001, 'lr_e':   9.60e-05})
Step:   28000, Reward:    51.312 [  15.414], Avg:    30.052 (0.800) <0-00:33:50> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 25629.2450, 'dyn_loss':     0.3039, 'dot_loss':     0.1095, 'ddot_loss':     0.1801, 'rew_loss':    42.3816, 'lr':   9.60e-05, 'eps_e':     0.8001, 'lr_e':   9.60e-05})
Step:   29000, Reward:    40.312 [  20.463], Avg:    30.394 (0.900) <0-00:34:24> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 26527.2290, 'dyn_loss':     0.2936, 'dot_loss':     0.1072, 'ddot_loss':     0.1793, 'rew_loss':    41.5809, 'lr':   9.60e-05, 'eps_e':     0.9001, 'lr_e':   9.60e-05})
Step:   30000, Reward:    55.875 [  26.865], Avg:    31.216 (0.000) <0-00:34:53> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 27574.0170, 'dyn_loss':     0.2760, 'dot_loss':     0.1012, 'ddot_loss':     0.1716, 'rew_loss':    41.5555, 'lr':   9.60e-05, 'eps_e':     0.0001, 'lr_e':   9.60e-05})
Step:   31000, Reward:    59.125 [  20.230], Avg:    32.088 (0.100) <0-00:37:06> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 28263.9550, 'dyn_loss':     0.2706, 'dot_loss':     0.0990, 'ddot_loss':     0.1700, 'rew_loss':    43.1912, 'lr':   9.60e-05, 'eps_e':     0.1001, 'lr_e':   9.60e-05})
Step:   32000, Reward:    49.688 [  17.705], Avg:    32.621 (0.200) <0-00:39:04> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 28540.4120, 'dyn_loss':     0.2586, 'dot_loss':     0.0963, 'ddot_loss':     0.1672, 'rew_loss':    45.1412, 'lr':   9.60e-05, 'eps_e':     0.2001, 'lr_e':   9.60e-05})
Step:   33000, Reward:    71.625 [  37.749], Avg:    33.768 (0.300) <0-00:40:58> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 28788.3960, 'dyn_loss':     0.2650, 'dot_loss':     0.0972, 'ddot_loss':     0.1718, 'rew_loss':    46.2793, 'lr':   9.60e-05, 'eps_e':     0.3001, 'lr_e':   9.60e-05})
Step:   34000, Reward:    78.125 [  43.380], Avg:    35.036 (0.400) <0-00:42:45> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 29015.5740, 'dyn_loss':     0.2412, 'dot_loss':     0.0917, 'ddot_loss':     0.1644, 'rew_loss':    44.9285, 'lr':   9.60e-05, 'eps_e':     0.4001, 'lr_e':   9.60e-05})
Step:   35000, Reward:    64.500 [  44.965], Avg:    35.854 (0.500) <0-00:44:21> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 29301.1050, 'dyn_loss':     0.2405, 'dot_loss':     0.0912, 'ddot_loss':     0.1648, 'rew_loss':    44.2048, 'lr':   9.60e-05, 'eps_e':     0.5001, 'lr_e':   9.60e-05})
Step:   36000, Reward:    81.125 [  60.006], Avg:    37.078 (0.600) <0-00:45:44> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 29674.5460, 'dyn_loss':     0.2363, 'dot_loss':     0.0882, 'ddot_loss':     0.1584, 'rew_loss':    51.1671, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:   37000, Reward:   105.000 [  50.318], Avg:    38.865 (0.700) <0-00:46:55> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 30196.9640, 'dyn_loss':     0.2293, 'dot_loss':     0.0869, 'ddot_loss':     0.1576, 'rew_loss':    48.6371, 'lr':   9.41e-05, 'eps_e':     0.7001, 'lr_e':   9.41e-05})
Step:   38000, Reward:   135.562 [  42.448], Avg:    41.345 (0.800) <0-00:47:55> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 30890.5200, 'dyn_loss':     0.2241, 'dot_loss':     0.0845, 'ddot_loss':     0.1548, 'rew_loss':    48.3273, 'lr':   9.41e-05, 'eps_e':     0.8001, 'lr_e':   9.41e-05})
Step:   39000, Reward:    93.375 [  51.304], Avg:    42.645 (0.900) <0-00:48:42> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 31768.1380, 'dyn_loss':     0.2231, 'dot_loss':     0.0851, 'ddot_loss':     0.1573, 'rew_loss':    46.3596, 'lr':   9.41e-05, 'eps_e':     0.9001, 'lr_e':   9.41e-05})
Step:   40000, Reward:   133.688 [  44.442], Avg:    44.866 (0.000) <0-00:49:20> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 32773.7190, 'dyn_loss':     0.2101, 'dot_loss':     0.0815, 'ddot_loss':     0.1530, 'rew_loss':    45.6062, 'lr':   9.41e-05, 'eps_e':     0.0001, 'lr_e':   9.41e-05})
Step:   41000, Reward:   137.188 [  42.801], Avg:    47.064 (0.100) <0-00:51:43> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 33378.7770, 'dyn_loss':     0.2051, 'dot_loss':     0.0793, 'ddot_loss':     0.1479, 'rew_loss':    49.5668, 'lr':   9.41e-05, 'eps_e':     0.1001, 'lr_e':   9.41e-05})
Step:   42000, Reward:   184.000 [  26.292], Avg:    50.249 (0.200) <0-00:53:54> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 33484.4120, 'dyn_loss':     0.2063, 'dot_loss':     0.0796, 'ddot_loss':     0.1495, 'rew_loss':    52.4084, 'lr':   9.41e-05, 'eps_e':     0.2001, 'lr_e':   9.41e-05})
Step:   43000, Reward:   130.188 [  61.912], Avg:    52.065 (0.300) <0-00:55:53> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 33599.3430, 'dyn_loss':     0.2125, 'dot_loss':     0.0787, 'ddot_loss':     0.1441, 'rew_loss':    54.4374, 'lr':   9.41e-05, 'eps_e':     0.3001, 'lr_e':   9.41e-05})
Step:   44000, Reward:   160.000 [  42.034], Avg:    54.464 (0.400) <0-00:57:40> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 33726.8300, 'dyn_loss':     0.2129, 'dot_loss':     0.0807, 'ddot_loss':     0.1490, 'rew_loss':    55.0108, 'lr':   9.41e-05, 'eps_e':     0.4001, 'lr_e':   9.41e-05})
Step:   45000, Reward:   104.312 [  46.373], Avg:    55.548 (0.500) <0-00:59:13> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 33936.3440, 'dyn_loss':     0.2038, 'dot_loss':     0.0786, 'ddot_loss':     0.1469, 'rew_loss':    59.1512, 'lr':   9.41e-05, 'eps_e':     0.5001, 'lr_e':   9.41e-05})
Step:   46000, Reward:   144.250 [  50.089], Avg:    57.435 (0.600) <0-01:00:36> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 34268.2110, 'dyn_loss':     0.2032, 'dot_loss':     0.0791, 'ddot_loss':     0.1485, 'rew_loss':    62.8536, 'lr':   9.41e-05, 'eps_e':     0.6001, 'lr_e':   9.41e-05})
Step:   47000, Reward:   123.688 [  68.220], Avg:    58.815 (0.700) <0-01:01:48> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 34748.5280, 'dyn_loss':     0.1973, 'dot_loss':     0.0774, 'ddot_loss':     0.1477, 'rew_loss':    56.9104, 'lr':   9.22e-05, 'eps_e':     0.7001, 'lr_e':   9.22e-05})
Step:   48000, Reward:   192.125 [  15.078], Avg:    61.536 (0.800) <0-01:02:47> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 35410.5510, 'dyn_loss':     0.1908, 'dot_loss':     0.0750, 'ddot_loss':     0.1430, 'rew_loss':    62.4995, 'lr':   9.22e-05, 'eps_e':     0.8001, 'lr_e':   9.22e-05})
Step:   49000, Reward:   165.500 [  51.309], Avg:    63.615 (0.900) <0-01:03:35> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 36283.7910, 'dyn_loss':     0.1843, 'dot_loss':     0.0731, 'ddot_loss':     0.1428, 'rew_loss':    57.3066, 'lr':   9.22e-05, 'eps_e':     0.9001, 'lr_e':   9.22e-05})
Step:   50000, Reward:   148.812 [  48.970], Avg:    65.286 (0.000) <0-01:04:13> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 37322.3910, 'dyn_loss':     0.1811, 'dot_loss':     0.0714, 'ddot_loss':     0.1389, 'rew_loss':    59.7802, 'lr':   9.22e-05, 'eps_e':     0.0001, 'lr_e':   9.22e-05})
Step:   51000, Reward:   189.500 [  13.879], Avg:    67.674 (0.100) <0-01:06:36> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 37915.1350, 'dyn_loss':     0.1784, 'dot_loss':     0.0701, 'ddot_loss':     0.1366, 'rew_loss':    61.6111, 'lr':   9.22e-05, 'eps_e':     0.1001, 'lr_e':   9.22e-05})
Step:   52000, Reward:   163.438 [  46.344], Avg:    69.481 (0.200) <0-01:08:48> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 38003.3990, 'dyn_loss':     0.1763, 'dot_loss':     0.0696, 'ddot_loss':     0.1358, 'rew_loss':    61.3151, 'lr':   9.22e-05, 'eps_e':     0.2001, 'lr_e':   9.22e-05})
Step:   53000, Reward:   159.750 [  44.499], Avg:    71.153 (0.300) <0-01:10:47> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 38103.7050, 'dyn_loss':     0.1720, 'dot_loss':     0.0680, 'ddot_loss':     0.1329, 'rew_loss':    61.1213, 'lr':   9.22e-05, 'eps_e':     0.3001, 'lr_e':   9.22e-05})
Step:   54000, Reward:   172.312 [  46.021], Avg:    72.992 (0.400) <0-01:12:34> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 38231.2630, 'dyn_loss':     0.1699, 'dot_loss':     0.0676, 'ddot_loss':     0.1348, 'rew_loss':    60.1191, 'lr':   9.22e-05, 'eps_e':     0.4001, 'lr_e':   9.22e-05})
Step:   55000, Reward:   174.188 [  44.708], Avg:    74.799 (0.500) <0-01:14:10> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 38435.0230, 'dyn_loss':     0.1671, 'dot_loss':     0.0661, 'ddot_loss':     0.1298, 'rew_loss':    63.8757, 'lr':   9.22e-05, 'eps_e':     0.5001, 'lr_e':   9.22e-05})
Step:   56000, Reward:   132.812 [  64.364], Avg:    75.817 (0.600) <0-01:15:34> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 38738.3710, 'dyn_loss':     0.1646, 'dot_loss':     0.0658, 'ddot_loss':     0.1298, 'rew_loss':    66.7762, 'lr':   9.22e-05, 'eps_e':     0.6001, 'lr_e':   9.22e-05})
Step:   57000, Reward:   179.688 [  25.879], Avg:    77.608 (0.700) <0-01:16:45> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 39203.2650, 'dyn_loss':     0.1648, 'dot_loss':     0.0654, 'ddot_loss':     0.1291, 'rew_loss':    68.0935, 'lr':   9.22e-05, 'eps_e':     0.7001, 'lr_e':   9.22e-05})
Step:   58000, Reward:   156.000 [  64.442], Avg:    78.936 (0.800) <0-01:17:45> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 39855.1930, 'dyn_loss':     0.1616, 'dot_loss':     0.0636, 'ddot_loss':     0.1260, 'rew_loss':    64.4047, 'lr':   9.04e-05, 'eps_e':     0.8001, 'lr_e':   9.04e-05})
Step:   59000, Reward:   182.312 [  27.565], Avg:    80.659 (0.900) <0-01:18:33> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 40740.2070, 'dyn_loss':     0.1595, 'dot_loss':     0.0629, 'ddot_loss':     0.1254, 'rew_loss':    62.5099, 'lr':   9.04e-05, 'eps_e':     0.9001, 'lr_e':   9.04e-05})
Step:   60000, Reward:   162.375 [  41.252], Avg:    81.999 (0.000) <0-01:19:11> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 41793.5160, 'dyn_loss':     0.1582, 'dot_loss':     0.0630, 'ddot_loss':     0.1258, 'rew_loss':    70.1946, 'lr':   9.04e-05, 'eps_e':     0.0001, 'lr_e':   9.04e-05})
Step:   61000, Reward:   159.188 [  50.703], Avg:    83.244 (0.100) <0-01:21:35> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 42390.3670, 'dyn_loss':     0.1540, 'dot_loss':     0.0606, 'ddot_loss':     0.1211, 'rew_loss':    67.0403, 'lr':   9.04e-05, 'eps_e':     0.1001, 'lr_e':   9.04e-05})
Step:   62000, Reward:   180.812 [  31.353], Avg:    84.793 (0.200) <0-01:23:46> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 42481.9090, 'dyn_loss':     0.1543, 'dot_loss':     0.0610, 'ddot_loss':     0.1212, 'rew_loss':    72.2543, 'lr':   9.04e-05, 'eps_e':     0.2001, 'lr_e':   9.04e-05})
Step:   63000, Reward:   142.062 [  59.686], Avg:    85.688 (0.300) <0-01:25:46> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 42585.4670, 'dyn_loss':     0.1532, 'dot_loss':     0.0616, 'ddot_loss':     0.1230, 'rew_loss':    69.4601, 'lr':   9.04e-05, 'eps_e':     0.3001, 'lr_e':   9.04e-05})
Step:   64000, Reward:   162.188 [  61.799], Avg:    86.864 (0.400) <0-01:27:34> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 42726.2080, 'dyn_loss':     0.1509, 'dot_loss':     0.0597, 'ddot_loss':     0.1194, 'rew_loss':    67.2050, 'lr':   9.04e-05, 'eps_e':     0.4001, 'lr_e':   9.04e-05})
Step:   65000, Reward:   171.625 [  33.606], Avg:    88.149 (0.500) <0-01:29:09> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 42935.2380, 'dyn_loss':     0.1458, 'dot_loss':     0.0575, 'ddot_loss':     0.1145, 'rew_loss':    68.6145, 'lr':   9.04e-05, 'eps_e':     0.5001, 'lr_e':   9.04e-05})
Step:   66000, Reward:   129.562 [  67.823], Avg:    88.767 (0.600) <0-01:30:33> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 43244.7620, 'dyn_loss':     0.1436, 'dot_loss':     0.0557, 'ddot_loss':     0.1119, 'rew_loss':    69.1801, 'lr':   9.04e-05, 'eps_e':     0.6001, 'lr_e':   9.04e-05})
Step:   67000, Reward:   170.812 [  48.981], Avg:    89.973 (0.700) <0-01:31:45> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 43732.2250, 'dyn_loss':     0.1447, 'dot_loss':     0.0565, 'ddot_loss':     0.1134, 'rew_loss':    71.8449, 'lr':   9.04e-05, 'eps_e':     0.7001, 'lr_e':   9.04e-05})
Step:   68000, Reward:   173.938 [  44.289], Avg:    91.190 (0.800) <0-01:32:45> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 44408.5780, 'dyn_loss':     0.1418, 'dot_loss':     0.0548, 'ddot_loss':     0.1098, 'rew_loss':    70.2399, 'lr':   9.04e-05, 'eps_e':     0.8001, 'lr_e':   9.04e-05})
Step:   69000, Reward:   161.562 [  50.233], Avg:    92.196 (0.900) <0-01:33:32> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 45286.9350, 'dyn_loss':     0.1397, 'dot_loss':     0.0534, 'ddot_loss':     0.1073, 'rew_loss':    67.0681, 'lr':   8.86e-05, 'eps_e':     0.9001, 'lr_e':   8.86e-05})
Step:   70000, Reward:   169.875 [  52.483], Avg:    93.290 (0.000) <0-01:34:11> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 46340.3650, 'dyn_loss':     0.1386, 'dot_loss':     0.0528, 'ddot_loss':     0.1064, 'rew_loss':    63.6050, 'lr':   8.86e-05, 'eps_e':     0.0001, 'lr_e':   8.86e-05})
Step:   71000, Reward:   144.250 [  64.058], Avg:    93.997 (0.100) <0-01:36:34> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 46935.4130, 'dyn_loss':     0.1374, 'dot_loss':     0.0516, 'ddot_loss':     0.1028, 'rew_loss':    71.5909, 'lr':   8.86e-05, 'eps_e':     0.1001, 'lr_e':   8.86e-05})
Step:   72000, Reward:   153.312 [  58.633], Avg:    94.810 (0.200) <0-01:38:46> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 47026.4220, 'dyn_loss':     0.1344, 'dot_loss':     0.0515, 'ddot_loss':     0.1026, 'rew_loss':    72.4441, 'lr':   8.86e-05, 'eps_e':     0.2001, 'lr_e':   8.86e-05})
Step:   73000, Reward:   147.625 [  54.197], Avg:    95.524 (0.300) <0-01:40:46> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 47134.5060, 'dyn_loss':     0.1352, 'dot_loss':     0.0509, 'ddot_loss':     0.1019, 'rew_loss':    75.9736, 'lr':   8.86e-05, 'eps_e':     0.3001, 'lr_e':   8.86e-05})
Step:   74000, Reward:   142.438 [  59.236], Avg:    96.149 (0.400) <0-01:42:34> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 47271.6290, 'dyn_loss':     0.1335, 'dot_loss':     0.0492, 'ddot_loss':     0.0983, 'rew_loss':    71.5512, 'lr':   8.86e-05, 'eps_e':     0.4001, 'lr_e':   8.86e-05})
Step:   75000, Reward:   130.938 [  70.725], Avg:    96.607 (0.500) <0-01:44:09> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 47466.5400, 'dyn_loss':     0.1341, 'dot_loss':     0.0487, 'ddot_loss':     0.0976, 'rew_loss':    73.0347, 'lr':   8.86e-05, 'eps_e':     0.5001, 'lr_e':   8.86e-05})
Step:   76000, Reward:   150.938 [  64.108], Avg:    97.312 (0.600) <0-01:45:33> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 47761.3440, 'dyn_loss':     0.1324, 'dot_loss':     0.0476, 'ddot_loss':     0.0944, 'rew_loss':    72.0185, 'lr':   8.86e-05, 'eps_e':     0.6001, 'lr_e':   8.86e-05})
Step:   77000, Reward:   167.438 [  45.867], Avg:    98.212 (0.700) <0-01:46:45> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 48196.3750, 'dyn_loss':     0.1303, 'dot_loss':     0.0470, 'ddot_loss':     0.0931, 'rew_loss':    76.0662, 'lr':   8.86e-05, 'eps_e':     0.7001, 'lr_e':   8.86e-05})
Step:   78000, Reward:   161.312 [  64.355], Avg:    99.010 (0.800) <0-01:47:45> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 48887.7730, 'dyn_loss':     0.1260, 'dot_loss':     0.0451, 'ddot_loss':     0.0888, 'rew_loss':    74.1360, 'lr':   8.86e-05, 'eps_e':     0.8001, 'lr_e':   8.86e-05})
Step:   79000, Reward:   159.625 [  55.096], Avg:    99.768 (0.900) <0-01:48:33> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 49747.5820, 'dyn_loss':     0.1274, 'dot_loss':     0.0448, 'ddot_loss':     0.0883, 'rew_loss':    73.0092, 'lr':   8.86e-05, 'eps_e':     0.9001, 'lr_e':   8.86e-05})
Step:   80000, Reward:   158.125 [  43.743], Avg:   100.488 (0.000) <0-01:49:12> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 50786.8100, 'dyn_loss':     0.1275, 'dot_loss':     0.0437, 'ddot_loss':     0.0856, 'rew_loss':    76.8331, 'lr':   8.68e-05, 'eps_e':     0.0001, 'lr_e':   8.68e-05})
Step:   81000, Reward:   144.688 [  75.945], Avg:   101.027 (0.100) <0-01:51:35> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 51379.2730, 'dyn_loss':     0.1252, 'dot_loss':     0.0428, 'ddot_loss':     0.0832, 'rew_loss':    71.5542, 'lr':   8.68e-05, 'eps_e':     0.1001, 'lr_e':   8.68e-05})
Step:   82000, Reward:   170.125 [  38.298], Avg:   101.860 (0.200) <0-01:53:47> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 51473.9090, 'dyn_loss':     0.1250, 'dot_loss':     0.0426, 'ddot_loss':     0.0821, 'rew_loss':    74.9845, 'lr':   8.68e-05, 'eps_e':     0.2001, 'lr_e':   8.68e-05})
Step:   83000, Reward:   168.875 [  40.123], Avg:   102.658 (0.300) <0-01:55:47> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 51590.3570, 'dyn_loss':     0.1227, 'dot_loss':     0.0411, 'ddot_loss':     0.0789, 'rew_loss':    77.4721, 'lr':   8.68e-05, 'eps_e':     0.3001, 'lr_e':   8.68e-05})
Step:   84000, Reward:   148.562 [  62.979], Avg:   103.198 (0.400) <0-01:57:35> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 51734.1050, 'dyn_loss':     0.1208, 'dot_loss':     0.0409, 'ddot_loss':     0.0782, 'rew_loss':    79.7603, 'lr':   8.68e-05, 'eps_e':     0.4001, 'lr_e':   8.68e-05})
Step:   85000, Reward:   138.938 [  55.038], Avg:   103.613 (0.500) <0-01:59:10> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 51931.4150, 'dyn_loss':     0.1233, 'dot_loss':     0.0395, 'ddot_loss':     0.0751, 'rew_loss':    75.0622, 'lr':   8.68e-05, 'eps_e':     0.5001, 'lr_e':   8.68e-05})
Step:   86000, Reward:    94.875 [  75.848], Avg:   103.513 (0.600) <0-02:00:34> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 52245.5740, 'dyn_loss':     0.1191, 'dot_loss':     0.0391, 'ddot_loss':     0.0743, 'rew_loss':    76.9282, 'lr':   8.68e-05, 'eps_e':     0.6001, 'lr_e':   8.68e-05})
Step:   87000, Reward:   141.625 [  56.793], Avg:   103.946 (0.700) <0-02:01:46> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 52733.4790, 'dyn_loss':     0.1158, 'dot_loss':     0.0389, 'ddot_loss':     0.0735, 'rew_loss':    77.2811, 'lr':   8.68e-05, 'eps_e':     0.7001, 'lr_e':   8.68e-05})
Step:   88000, Reward:   138.312 [  65.955], Avg:   104.332 (0.800) <0-02:02:46> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 53409.4410, 'dyn_loss':     0.1215, 'dot_loss':     0.0385, 'ddot_loss':     0.0724, 'rew_loss':    75.5555, 'lr':   8.68e-05, 'eps_e':     0.8001, 'lr_e':   8.68e-05})
Step:   89000, Reward:   152.750 [  63.371], Avg:   104.870 (0.900) <0-02:03:34> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 54280.8470, 'dyn_loss':     0.1172, 'dot_loss':     0.0373, 'ddot_loss':     0.0699, 'rew_loss':    80.4485, 'lr':   8.68e-05, 'eps_e':     0.9001, 'lr_e':   8.68e-05})
Step:   90000, Reward:   159.125 [  52.321], Avg:   105.466 (0.000) <0-02:04:13> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 55289.0350, 'dyn_loss':     0.1141, 'dot_loss':     0.0377, 'ddot_loss':     0.0706, 'rew_loss':    78.3242, 'lr':   8.68e-05, 'eps_e':     0.0001, 'lr_e':   8.68e-05})
Step:   91000, Reward:   156.688 [  61.665], Avg:   106.023 (0.100) <0-02:06:37> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 55871.9040, 'dyn_loss':     0.1184, 'dot_loss':     0.0373, 'ddot_loss':     0.0699, 'rew_loss':    80.5463, 'lr':   8.51e-05, 'eps_e':     0.1001, 'lr_e':   8.51e-05})
Step:   92000, Reward:   179.250 [  39.220], Avg:   106.810 (0.200) <0-02:08:49> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 55965.5320, 'dyn_loss':     0.1163, 'dot_loss':     0.0367, 'ddot_loss':     0.0688, 'rew_loss':    79.0626, 'lr':   8.51e-05, 'eps_e':     0.2001, 'lr_e':   8.51e-05})
Step:   93000, Reward:   187.438 [  45.406], Avg:   107.668 (0.300) <0-02:10:49> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 56072.3740, 'dyn_loss':     0.1156, 'dot_loss':     0.0364, 'ddot_loss':     0.0683, 'rew_loss':    78.9504, 'lr':   8.51e-05, 'eps_e':     0.3001, 'lr_e':   8.51e-05})
Step:   94000, Reward:   161.750 [  46.871], Avg:   108.237 (0.400) <0-02:12:37> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 56199.1110, 'dyn_loss':     0.1113, 'dot_loss':     0.0360, 'ddot_loss':     0.0672, 'rew_loss':    72.0517, 'lr':   8.51e-05, 'eps_e':     0.4001, 'lr_e':   8.51e-05})
Step:   95000, Reward:   160.938 [  39.810], Avg:   108.786 (0.500) <0-02:14:13> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 56408.0480, 'dyn_loss':     0.1114, 'dot_loss':     0.0364, 'ddot_loss':     0.0683, 'rew_loss':    81.4231, 'lr':   8.51e-05, 'eps_e':     0.5001, 'lr_e':   8.51e-05})
Step:   96000, Reward:   146.438 [  68.412], Avg:   109.175 (0.600) <0-02:15:37> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 56711.2400, 'dyn_loss':     0.1120, 'dot_loss':     0.0359, 'ddot_loss':     0.0670, 'rew_loss':    80.9087, 'lr':   8.51e-05, 'eps_e':     0.6001, 'lr_e':   8.51e-05})
Step:   97000, Reward:   158.375 [  54.689], Avg:   109.677 (0.700) <0-02:16:49> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 57197.1820, 'dyn_loss':     0.1092, 'dot_loss':     0.0356, 'ddot_loss':     0.0664, 'rew_loss':    79.9194, 'lr':   8.51e-05, 'eps_e':     0.7001, 'lr_e':   8.51e-05})
Step:   98000, Reward:   183.375 [  35.128], Avg:   110.421 (0.800) <0-02:17:49> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 57896.7260, 'dyn_loss':     0.1116, 'dot_loss':     0.0348, 'ddot_loss':     0.0647, 'rew_loss':    76.4345, 'lr':   8.51e-05, 'eps_e':     0.8001, 'lr_e':   8.51e-05})
Step:   99000, Reward:   159.812 [  54.268], Avg:   110.915 (0.900) <0-02:18:37> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 58786.0540, 'dyn_loss':     0.1108, 'dot_loss':     0.0352, 'ddot_loss':     0.0657, 'rew_loss':    76.1669, 'lr':   8.51e-05, 'eps_e':     0.9001, 'lr_e':   8.51e-05})
Step:  100000, Reward:   125.125 [  55.593], Avg:   111.056 (0.000) <0-02:19:16> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 59835.5080, 'dyn_loss':     0.1097, 'dot_loss':     0.0345, 'ddot_loss':     0.0643, 'rew_loss':    79.4310, 'lr':   8.51e-05, 'eps_e':     0.0001, 'lr_e':   8.51e-05})
Step:  101000, Reward:   156.688 [  48.588], Avg:   111.503 (0.100) <0-02:21:40> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 60444.7310, 'dyn_loss':     0.1067, 'dot_loss':     0.0340, 'ddot_loss':     0.0630, 'rew_loss':    81.0839, 'lr':   8.51e-05, 'eps_e':     0.1001, 'lr_e':   8.51e-05})
Step:  102000, Reward:   131.500 [  53.760], Avg:   111.697 (0.200) <0-02:23:52> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 60540.2120, 'dyn_loss':     0.1098, 'dot_loss':     0.0344, 'ddot_loss':     0.0642, 'rew_loss':    85.8734, 'lr':   8.34e-05, 'eps_e':     0.2001, 'lr_e':   8.34e-05})
Step:  103000, Reward:   142.438 [  55.410], Avg:   111.993 (0.300) <0-02:25:52> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 60658.1400, 'dyn_loss':     0.1056, 'dot_loss':     0.0339, 'ddot_loss':     0.0629, 'rew_loss':    77.9409, 'lr':   8.34e-05, 'eps_e':     0.3001, 'lr_e':   8.34e-05})
Step:  104000, Reward:   144.125 [  55.706], Avg:   112.299 (0.400) <0-02:27:40> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 60816.9880, 'dyn_loss':     0.1050, 'dot_loss':     0.0334, 'ddot_loss':     0.0619, 'rew_loss':    81.1471, 'lr':   8.34e-05, 'eps_e':     0.4001, 'lr_e':   8.34e-05})
Step:  105000, Reward:   156.438 [  63.143], Avg:   112.715 (0.500) <0-02:29:15> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 61022.0790, 'dyn_loss':     0.1071, 'dot_loss':     0.0331, 'ddot_loss':     0.0613, 'rew_loss':    85.4693, 'lr':   8.34e-05, 'eps_e':     0.5001, 'lr_e':   8.34e-05})
Step:  106000, Reward:   124.625 [  71.174], Avg:   112.827 (0.600) <0-02:30:39> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 61349.7790, 'dyn_loss':     0.1062, 'dot_loss':     0.0331, 'ddot_loss':     0.0614, 'rew_loss':    84.3744, 'lr':   8.34e-05, 'eps_e':     0.6001, 'lr_e':   8.34e-05})
Step:  107000, Reward:   166.625 [  67.788], Avg:   113.325 (0.700) <0-02:31:52> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 61831.6580, 'dyn_loss':     0.1048, 'dot_loss':     0.0330, 'ddot_loss':     0.0612, 'rew_loss':    87.1125, 'lr':   8.34e-05, 'eps_e':     0.7001, 'lr_e':   8.34e-05})
Step:  108000, Reward:   149.812 [  61.375], Avg:   113.659 (0.800) <0-02:32:52> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 62515.9900, 'dyn_loss':     0.1043, 'dot_loss':     0.0333, 'ddot_loss':     0.0620, 'rew_loss':    83.2034, 'lr':   8.34e-05, 'eps_e':     0.8001, 'lr_e':   8.34e-05})
Step:  109000, Reward:   188.938 [  25.823], Avg:   114.344 (0.900) <0-02:33:40> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 63376.2010, 'dyn_loss':     0.1074, 'dot_loss':     0.0324, 'ddot_loss':     0.0597, 'rew_loss':    82.5655, 'lr':   8.34e-05, 'eps_e':     0.9001, 'lr_e':   8.34e-05})
Step:  110000, Reward:   138.000 [  69.337], Avg:   114.557 (0.000) <0-02:34:19> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 64398.8560, 'dyn_loss':     0.1037, 'dot_loss':     0.0322, 'ddot_loss':     0.0595, 'rew_loss':    82.1836, 'lr':   8.34e-05, 'eps_e':     0.0001, 'lr_e':   8.34e-05})
Step:  111000, Reward:   137.688 [  63.367], Avg:   114.763 (0.100) <0-02:36:43> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 64974.9990, 'dyn_loss':     0.1041, 'dot_loss':     0.0321, 'ddot_loss':     0.0595, 'rew_loss':    82.7864, 'lr':   8.34e-05, 'eps_e':     0.1001, 'lr_e':   8.34e-05})
Step:  112000, Reward:   163.562 [  47.147], Avg:   115.195 (0.200) <0-02:38:54> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 65073.7000, 'dyn_loss':     0.1052, 'dot_loss':     0.0315, 'ddot_loss':     0.0579, 'rew_loss':    88.1513, 'lr':   8.34e-05, 'eps_e':     0.2001, 'lr_e':   8.34e-05})
Step:  113000, Reward:   148.625 [  68.916], Avg:   115.488 (0.300) <0-02:40:54> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 65192.7480, 'dyn_loss':     0.1041, 'dot_loss':     0.0313, 'ddot_loss':     0.0577, 'rew_loss':    80.8404, 'lr':   8.17e-05, 'eps_e':     0.3001, 'lr_e':   8.17e-05})
Step:  114000, Reward:   165.438 [  59.347], Avg:   115.923 (0.400) <0-02:42:42> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 65343.3980, 'dyn_loss':     0.1008, 'dot_loss':     0.0313, 'ddot_loss':     0.0579, 'rew_loss':    87.8656, 'lr':   8.17e-05, 'eps_e':     0.4001, 'lr_e':   8.17e-05})
Step:  115000, Reward:   165.062 [  63.104], Avg:   116.346 (0.500) <0-02:44:18> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 65541.2670, 'dyn_loss':     0.1011, 'dot_loss':     0.0306, 'ddot_loss':     0.0562, 'rew_loss':    84.6511, 'lr':   8.17e-05, 'eps_e':     0.5001, 'lr_e':   8.17e-05})
Step:  116000, Reward:   138.500 [  67.297], Avg:   116.536 (0.600) <0-02:45:42> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 65852.7680, 'dyn_loss':     0.0984, 'dot_loss':     0.0307, 'ddot_loss':     0.0564, 'rew_loss':    84.8913, 'lr':   8.17e-05, 'eps_e':     0.6001, 'lr_e':   8.17e-05})
Step:  117000, Reward:   150.625 [  72.206], Avg:   116.825 (0.700) <0-02:46:54> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 66330.5950, 'dyn_loss':     0.1059, 'dot_loss':     0.0305, 'ddot_loss':     0.0559, 'rew_loss':    87.4585, 'lr':   8.17e-05, 'eps_e':     0.7001, 'lr_e':   8.17e-05})
Step:  118000, Reward:   165.500 [  49.409], Avg:   117.234 (0.800) <0-02:47:54> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 67019.4050, 'dyn_loss':     0.1000, 'dot_loss':     0.0303, 'ddot_loss':     0.0556, 'rew_loss':    83.3261, 'lr':   8.17e-05, 'eps_e':     0.8001, 'lr_e':   8.17e-05})
Step:  119000, Reward:   140.750 [  55.613], Avg:   117.430 (0.900) <0-02:48:43> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 67930.4370, 'dyn_loss':     0.1001, 'dot_loss':     0.0304, 'ddot_loss':     0.0557, 'rew_loss':    85.5920, 'lr':   8.17e-05, 'eps_e':     0.9001, 'lr_e':   8.17e-05})
Step:  120000, Reward:   131.438 [  67.900], Avg:   117.545 (0.000) <0-02:49:21> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 68974.5660, 'dyn_loss':     0.0980, 'dot_loss':     0.0300, 'ddot_loss':     0.0549, 'rew_loss':    82.8683, 'lr':   8.17e-05, 'eps_e':     0.0001, 'lr_e':   8.17e-05})
Step:  121000, Reward:   133.562 [  60.806], Avg:   117.677 (0.100) <0-02:51:45> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 69581.6120, 'dyn_loss':     0.1006, 'dot_loss':     0.0297, 'ddot_loss':     0.0541, 'rew_loss':    86.8298, 'lr':   8.17e-05, 'eps_e':     0.1001, 'lr_e':   8.17e-05})
Step:  122000, Reward:   137.562 [  57.774], Avg:   117.838 (0.200) <0-02:53:57> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 69680.8930, 'dyn_loss':     0.0989, 'dot_loss':     0.0294, 'ddot_loss':     0.0535, 'rew_loss':    84.6306, 'lr':   8.17e-05, 'eps_e':     0.2001, 'lr_e':   8.17e-05})
Step:  123000, Reward:   165.375 [  51.953], Avg:   118.222 (0.300) <0-02:55:57> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 69807.9600, 'dyn_loss':     0.0977, 'dot_loss':     0.0296, 'ddot_loss':     0.0540, 'rew_loss':    83.1181, 'lr':   8.17e-05, 'eps_e':     0.3001, 'lr_e':   8.17e-05})
Step:  124000, Reward:   170.625 [  52.505], Avg:   118.641 (0.400) <0-02:57:45> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 69970.5310, 'dyn_loss':     0.0957, 'dot_loss':     0.0294, 'ddot_loss':     0.0538, 'rew_loss':    82.0068, 'lr':   8.01e-05, 'eps_e':     0.4001, 'lr_e':   8.01e-05})
Step:  125000, Reward:   164.938 [  64.271], Avg:   119.008 (0.500) <0-02:59:21> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 70179.9190, 'dyn_loss':     0.0983, 'dot_loss':     0.0293, 'ddot_loss':     0.0534, 'rew_loss':    90.2893, 'lr':   8.01e-05, 'eps_e':     0.5001, 'lr_e':   8.01e-05})
Step:  126000, Reward:   159.375 [  59.438], Avg:   119.326 (0.600) <0-03:00:45> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 70494.4190, 'dyn_loss':     0.0993, 'dot_loss':     0.0289, 'ddot_loss':     0.0523, 'rew_loss':    86.3852, 'lr':   8.01e-05, 'eps_e':     0.6001, 'lr_e':   8.01e-05})
Step:  127000, Reward:   143.938 [  55.899], Avg:   119.519 (0.700) <0-03:01:58> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 70987.7280, 'dyn_loss':     0.0953, 'dot_loss':     0.0290, 'ddot_loss':     0.0528, 'rew_loss':    90.5271, 'lr':   8.01e-05, 'eps_e':     0.7001, 'lr_e':   8.01e-05})
Step:  128000, Reward:   142.938 [  70.266], Avg:   119.700 (0.800) <0-03:02:58> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 71681.5430, 'dyn_loss':     0.0974, 'dot_loss':     0.0284, 'ddot_loss':     0.0512, 'rew_loss':    86.6159, 'lr':   8.01e-05, 'eps_e':     0.8001, 'lr_e':   8.01e-05})
Step:  129000, Reward:   141.688 [  69.440], Avg:   119.869 (0.900) <0-03:03:46> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 72581.5210, 'dyn_loss':     0.0944, 'dot_loss':     0.0286, 'ddot_loss':     0.0520, 'rew_loss':    88.2965, 'lr':   8.01e-05, 'eps_e':     0.9001, 'lr_e':   8.01e-05})
Step:  130000, Reward:   134.000 [  75.255], Avg:   119.977 (0.000) <0-03:04:26> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 73644.6800, 'dyn_loss':     0.0977, 'dot_loss':     0.0284, 'ddot_loss':     0.0513, 'rew_loss':    86.0521, 'lr':   8.01e-05, 'eps_e':     0.0001, 'lr_e':   8.01e-05})
Step:  131000, Reward:   156.500 [  66.599], Avg:   120.254 (0.100) <0-03:06:50> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 74232.0990, 'dyn_loss':     0.0934, 'dot_loss':     0.0283, 'ddot_loss':     0.0517, 'rew_loss':    88.6833, 'lr':   8.01e-05, 'eps_e':     0.1001, 'lr_e':   8.01e-05})
Step:  132000, Reward:   150.562 [  57.661], Avg:   120.482 (0.200) <0-03:09:02> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 74339.1930, 'dyn_loss':     0.0978, 'dot_loss':     0.0278, 'ddot_loss':     0.0501, 'rew_loss':    87.2943, 'lr':   8.01e-05, 'eps_e':     0.2001, 'lr_e':   8.01e-05})
Step:  133000, Reward:   167.562 [  51.548], Avg:   120.833 (0.300) <0-03:11:02> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 74464.5470, 'dyn_loss':     0.0941, 'dot_loss':     0.0278, 'ddot_loss':     0.0504, 'rew_loss':    89.3322, 'lr':   8.01e-05, 'eps_e':     0.3001, 'lr_e':   8.01e-05})
Step:  134000, Reward:   166.250 [  53.244], Avg:   121.169 (0.400) <0-03:12:50> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 74621.1070, 'dyn_loss':     0.0919, 'dot_loss':     0.0276, 'ddot_loss':     0.0497, 'rew_loss':    85.8291, 'lr':   8.01e-05, 'eps_e':     0.4001, 'lr_e':   8.01e-05})
Step:  135000, Reward:   151.000 [  78.996], Avg:   121.389 (0.500) <0-03:14:26> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 74835.4690, 'dyn_loss':     0.0974, 'dot_loss':     0.0278, 'ddot_loss':     0.0500, 'rew_loss':    92.3734, 'lr':   7.85e-05, 'eps_e':     0.5001, 'lr_e':   7.85e-05})
Step:  136000, Reward:   122.438 [  66.659], Avg:   121.396 (0.600) <0-03:15:51> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 75157.8860, 'dyn_loss':     0.0956, 'dot_loss':     0.0275, 'ddot_loss':     0.0494, 'rew_loss':    88.3879, 'lr':   7.85e-05, 'eps_e':     0.6001, 'lr_e':   7.85e-05})
Step:  137000, Reward:   143.250 [  65.237], Avg:   121.555 (0.700) <0-03:17:03> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 75630.4870, 'dyn_loss':     0.0969, 'dot_loss':     0.0274, 'ddot_loss':     0.0492, 'rew_loss':    90.6638, 'lr':   7.85e-05, 'eps_e':     0.7001, 'lr_e':   7.85e-05})
Step:  138000, Reward:   164.125 [  62.923], Avg:   121.861 (0.800) <0-03:18:03> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 76325.2620, 'dyn_loss':     0.0952, 'dot_loss':     0.0271, 'ddot_loss':     0.0485, 'rew_loss':    88.7926, 'lr':   7.85e-05, 'eps_e':     0.8001, 'lr_e':   7.85e-05})
Step:  139000, Reward:   160.125 [  55.136], Avg:   122.134 (0.900) <0-03:18:51> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 77204.8580, 'dyn_loss':     0.0956, 'dot_loss':     0.0270, 'ddot_loss':     0.0483, 'rew_loss':    88.8625, 'lr':   7.85e-05, 'eps_e':     0.9001, 'lr_e':   7.85e-05})
Step:  140000, Reward:   136.750 [  72.714], Avg:   122.238 (0.000) <0-03:19:30> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 78255.0020, 'dyn_loss':     0.0974, 'dot_loss':     0.0266, 'ddot_loss':     0.0473, 'rew_loss':    85.5207, 'lr':   7.85e-05, 'eps_e':     0.0001, 'lr_e':   7.85e-05})
Step:  141000, Reward:   130.812 [  67.927], Avg:   122.298 (0.100) <0-03:21:54> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 78847.6410, 'dyn_loss':     0.0957, 'dot_loss':     0.0268, 'ddot_loss':     0.0480, 'rew_loss':    87.2859, 'lr':   7.85e-05, 'eps_e':     0.1001, 'lr_e':   7.85e-05})
Step:  142000, Reward:   132.250 [  52.714], Avg:   122.368 (0.200) <0-03:24:06> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 78953.4360, 'dyn_loss':     0.0900, 'dot_loss':     0.0264, 'ddot_loss':     0.0473, 'rew_loss':    91.0242, 'lr':   7.85e-05, 'eps_e':     0.2001, 'lr_e':   7.85e-05})
Step:  143000, Reward:   145.812 [  68.249], Avg:   122.531 (0.300) <0-03:26:06> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 79092.1760, 'dyn_loss':     0.0883, 'dot_loss':     0.0267, 'ddot_loss':     0.0482, 'rew_loss':    85.7095, 'lr':   7.85e-05, 'eps_e':     0.3001, 'lr_e':   7.85e-05})
Step:  144000, Reward:   126.312 [  64.462], Avg:   122.557 (0.400) <0-03:27:54> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 79256.6030, 'dyn_loss':     0.0943, 'dot_loss':     0.0268, 'ddot_loss':     0.0481, 'rew_loss':    90.5288, 'lr':   7.85e-05, 'eps_e':     0.4001, 'lr_e':   7.85e-05})
Step:  145000, Reward:   192.875 [  18.970], Avg:   123.039 (0.500) <0-03:29:30> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 79469.9500, 'dyn_loss':     0.0935, 'dot_loss':     0.0261, 'ddot_loss':     0.0465, 'rew_loss':    89.6388, 'lr':   7.85e-05, 'eps_e':     0.5001, 'lr_e':   7.85e-05})
Step:  146000, Reward:   123.375 [  72.167], Avg:   123.041 (0.600) <0-03:30:55> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 79805.7120, 'dyn_loss':     0.0932, 'dot_loss':     0.0263, 'ddot_loss':     0.0472, 'rew_loss':    90.3596, 'lr':   7.69e-05, 'eps_e':     0.6001, 'lr_e':   7.69e-05})
Step:  147000, Reward:   142.500 [  64.781], Avg:   123.172 (0.700) <0-03:32:07> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 80284.1950, 'dyn_loss':     0.0956, 'dot_loss':     0.0259, 'ddot_loss':     0.0459, 'rew_loss':    92.8190, 'lr':   7.69e-05, 'eps_e':     0.7001, 'lr_e':   7.69e-05})
Step:  148000, Reward:   167.688 [  61.963], Avg:   123.471 (0.800) <0-03:33:07> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 80978.5490, 'dyn_loss':     0.0925, 'dot_loss':     0.0258, 'ddot_loss':     0.0459, 'rew_loss':    94.4305, 'lr':   7.69e-05, 'eps_e':     0.8001, 'lr_e':   7.69e-05})
Step:  149000, Reward:   138.438 [  66.782], Avg:   123.571 (0.900) <0-03:33:55> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 81860.1300, 'dyn_loss':     0.0915, 'dot_loss':     0.0258, 'ddot_loss':     0.0459, 'rew_loss':    89.6436, 'lr':   7.69e-05, 'eps_e':     0.9001, 'lr_e':   7.69e-05})
Step:  150000, Reward:   135.062 [  63.067], Avg:   123.647 (0.000) <0-03:34:34> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 82887.4180, 'dyn_loss':     0.0929, 'dot_loss':     0.0258, 'ddot_loss':     0.0457, 'rew_loss':    97.5406, 'lr':   7.69e-05, 'eps_e':     0.0001, 'lr_e':   7.69e-05})
Step:  151000, Reward:   138.062 [  67.251], Avg:   123.742 (0.100) <0-03:36:58> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 83487.3660, 'dyn_loss':     0.0910, 'dot_loss':     0.0253, 'ddot_loss':     0.0449, 'rew_loss':    91.1033, 'lr':   7.69e-05, 'eps_e':     0.1001, 'lr_e':   7.69e-05})
Step:  152000, Reward:   155.625 [  50.319], Avg:   123.950 (0.200) <0-03:39:10> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 83584.9260, 'dyn_loss':     0.0945, 'dot_loss':     0.0256, 'ddot_loss':     0.0452, 'rew_loss':    88.1515, 'lr':   7.69e-05, 'eps_e':     0.2001, 'lr_e':   7.69e-05})
Step:  153000, Reward:   141.938 [  47.787], Avg:   124.067 (0.300) <0-03:41:10> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 83705.9570, 'dyn_loss':     0.0907, 'dot_loss':     0.0255, 'ddot_loss':     0.0454, 'rew_loss':    90.3976, 'lr':   7.69e-05, 'eps_e':     0.3001, 'lr_e':   7.69e-05})
Step:  154000, Reward:   148.625 [  71.825], Avg:   124.225 (0.400) <0-03:42:58> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 83879.1190, 'dyn_loss':     0.0914, 'dot_loss':     0.0255, 'ddot_loss':     0.0451, 'rew_loss':    91.1791, 'lr':   7.69e-05, 'eps_e':     0.4001, 'lr_e':   7.69e-05})
Step:  155000, Reward:   142.062 [  63.873], Avg:   124.340 (0.500) <0-03:44:34> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 84115.1480, 'dyn_loss':     0.0881, 'dot_loss':     0.0255, 'ddot_loss':     0.0456, 'rew_loss':    90.0166, 'lr':   7.69e-05, 'eps_e':     0.5001, 'lr_e':   7.69e-05})
Step:  156000, Reward:   153.812 [  67.867], Avg:   124.527 (0.600) <0-03:45:58> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 84441.3000, 'dyn_loss':     0.0916, 'dot_loss':     0.0254, 'ddot_loss':     0.0453, 'rew_loss':    90.5469, 'lr':   7.69e-05, 'eps_e':     0.6001, 'lr_e':   7.69e-05})
Step:  157000, Reward:   147.750 [  64.412], Avg:   124.674 (0.700) <0-03:47:11> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 84918.3480, 'dyn_loss':     0.0871, 'dot_loss':     0.0252, 'ddot_loss':     0.0451, 'rew_loss':    91.9999, 'lr':   7.54e-05, 'eps_e':     0.7001, 'lr_e':   7.54e-05})
Step:  158000, Reward:   173.062 [  53.936], Avg:   124.979 (0.800) <0-03:48:10> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 85593.0520, 'dyn_loss':     0.0895, 'dot_loss':     0.0250, 'ddot_loss':     0.0442, 'rew_loss':    85.7169, 'lr':   7.54e-05, 'eps_e':     0.8001, 'lr_e':   7.54e-05})
Step:  159000, Reward:   139.500 [  79.313], Avg:   125.070 (0.900) <0-03:49:00> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 86475.1940, 'dyn_loss':     0.0880, 'dot_loss':     0.0249, 'ddot_loss':     0.0443, 'rew_loss':    91.0004, 'lr':   7.54e-05, 'eps_e':     0.9001, 'lr_e':   7.54e-05})
Step:  160000, Reward:   131.375 [  74.129], Avg:   125.109 (0.000) <0-03:49:40> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 87543.1460, 'dyn_loss':     0.0937, 'dot_loss':     0.0254, 'ddot_loss':     0.0447, 'rew_loss':    90.3689, 'lr':   7.54e-05, 'eps_e':     0.0001, 'lr_e':   7.54e-05})
Step:  161000, Reward:   156.688 [  54.044], Avg:   125.304 (0.100) <0-03:52:03> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 88138.4130, 'dyn_loss':     0.0906, 'dot_loss':     0.0252, 'ddot_loss':     0.0445, 'rew_loss':    92.8683, 'lr':   7.54e-05, 'eps_e':     0.1001, 'lr_e':   7.54e-05})
Step:  162000, Reward:   139.250 [  69.641], Avg:   125.389 (0.200) <0-03:54:15> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 88239.0810, 'dyn_loss':     0.0938, 'dot_loss':     0.0248, 'ddot_loss':     0.0435, 'rew_loss':    90.7441, 'lr':   7.54e-05, 'eps_e':     0.2001, 'lr_e':   7.54e-05})
Step:  163000, Reward:   128.188 [  72.169], Avg:   125.406 (0.300) <0-03:56:15> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 88366.6370, 'dyn_loss':     0.0860, 'dot_loss':     0.0248, 'ddot_loss':     0.0444, 'rew_loss':    88.1171, 'lr':   7.54e-05, 'eps_e':     0.3001, 'lr_e':   7.54e-05})
Step:  164000, Reward:   149.188 [  67.040], Avg:   125.550 (0.400) <0-03:58:03> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 88528.9770, 'dyn_loss':     0.0910, 'dot_loss':     0.0245, 'ddot_loss':     0.0431, 'rew_loss':    95.7860, 'lr':   7.54e-05, 'eps_e':     0.4001, 'lr_e':   7.54e-05})
Step:  165000, Reward:   156.062 [  59.663], Avg:   125.734 (0.500) <0-03:59:39> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 88750.5100, 'dyn_loss':     0.0915, 'dot_loss':     0.0246, 'ddot_loss':     0.0432, 'rew_loss':    94.2020, 'lr':   7.54e-05, 'eps_e':     0.5001, 'lr_e':   7.54e-05})
Step:  166000, Reward:   145.188 [  51.521], Avg:   125.851 (0.600) <0-04:01:02> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 89080.2600, 'dyn_loss':     0.0893, 'dot_loss':     0.0244, 'ddot_loss':     0.0432, 'rew_loss':    90.2220, 'lr':   7.54e-05, 'eps_e':     0.6001, 'lr_e':   7.54e-05})
Step:  167000, Reward:   139.688 [  75.588], Avg:   125.933 (0.700) <0-04:02:14> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 89579.7770, 'dyn_loss':     0.0906, 'dot_loss':     0.0241, 'ddot_loss':     0.0423, 'rew_loss':    92.3678, 'lr':   7.54e-05, 'eps_e':     0.7001, 'lr_e':   7.54e-05})
Step:  168000, Reward:   152.938 [  53.936], Avg:   126.093 (0.800) <0-04:03:15> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 90278.7770, 'dyn_loss':     0.0897, 'dot_loss':     0.0243, 'ddot_loss':     0.0427, 'rew_loss':    93.9348, 'lr':   7.39e-05, 'eps_e':     0.8001, 'lr_e':   7.39e-05})
Step:  169000, Reward:   145.688 [  62.723], Avg:   126.208 (0.900) <0-04:04:03> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 91182.1460, 'dyn_loss':     0.0901, 'dot_loss':     0.0241, 'ddot_loss':     0.0425, 'rew_loss':    93.0713, 'lr':   7.39e-05, 'eps_e':     0.9001, 'lr_e':   7.39e-05})
Step:  170000, Reward:   134.312 [  62.494], Avg:   126.255 (0.000) <0-04:04:42> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 92245.7700, 'dyn_loss':     0.0887, 'dot_loss':     0.0241, 'ddot_loss':     0.0426, 'rew_loss':    93.5794, 'lr':   7.39e-05, 'eps_e':     0.0001, 'lr_e':   7.39e-05})
Step:  171000, Reward:   134.000 [  77.011], Avg:   126.301 (0.100) <0-04:07:06> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 92832.2600, 'dyn_loss':     0.0902, 'dot_loss':     0.0241, 'ddot_loss':     0.0426, 'rew_loss':    93.6426, 'lr':   7.39e-05, 'eps_e':     0.1001, 'lr_e':   7.39e-05})
Step:  172000, Reward:   164.438 [  60.795], Avg:   126.521 (0.200) <0-04:09:17> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 92935.8880, 'dyn_loss':     0.0873, 'dot_loss':     0.0250, 'ddot_loss':     0.0453, 'rew_loss':    89.9060, 'lr':   7.39e-05, 'eps_e':     0.2001, 'lr_e':   7.39e-05})
Step:  173000, Reward:   184.625 [  28.579], Avg:   126.855 (0.300) <0-04:11:17> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 93062.5750, 'dyn_loss':     0.0885, 'dot_loss':     0.0243, 'ddot_loss':     0.0433, 'rew_loss':    94.8813, 'lr':   7.39e-05, 'eps_e':     0.3001, 'lr_e':   7.39e-05})
Step:  174000, Reward:   154.312 [  57.095], Avg:   127.012 (0.400) <0-04:13:06> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 93231.0620, 'dyn_loss':     0.0847, 'dot_loss':     0.0244, 'ddot_loss':     0.0435, 'rew_loss':    95.9910, 'lr':   7.39e-05, 'eps_e':     0.4001, 'lr_e':   7.39e-05})
Step:  175000, Reward:    91.625 [  80.680], Avg:   126.811 (0.500) <0-04:14:42> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 93464.2830, 'dyn_loss':     0.0888, 'dot_loss':     0.0240, 'ddot_loss':     0.0424, 'rew_loss':    93.1271, 'lr':   7.39e-05, 'eps_e':     0.5001, 'lr_e':   7.39e-05})
Step:  176000, Reward:   179.688 [  38.876], Avg:   127.109 (0.600) <0-04:16:06> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 93829.3610, 'dyn_loss':     0.0893, 'dot_loss':     0.0237, 'ddot_loss':     0.0415, 'rew_loss':    93.6854, 'lr':   7.39e-05, 'eps_e':     0.6001, 'lr_e':   7.39e-05})
Step:  177000, Reward:   176.688 [  43.236], Avg:   127.388 (0.700) <0-04:17:18> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 94359.7670, 'dyn_loss':     0.0874, 'dot_loss':     0.0240, 'ddot_loss':     0.0424, 'rew_loss':    96.0132, 'lr':   7.39e-05, 'eps_e':     0.7001, 'lr_e':   7.39e-05})
Step:  178000, Reward:   159.250 [  55.625], Avg:   127.566 (0.800) <0-04:18:18> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 95062.5720, 'dyn_loss':     0.0876, 'dot_loss':     0.0236, 'ddot_loss':     0.0416, 'rew_loss':    96.4647, 'lr':   7.39e-05, 'eps_e':     0.8001, 'lr_e':   7.39e-05})
Step:  179000, Reward:   136.562 [  67.025], Avg:   127.616 (0.900) <0-04:19:07> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 95922.1840, 'dyn_loss':     0.0837, 'dot_loss':     0.0238, 'ddot_loss':     0.0425, 'rew_loss':    92.8301, 'lr':   7.24e-05, 'eps_e':     0.9001, 'lr_e':   7.24e-05})
Step:  180000, Reward:   159.875 [  64.735], Avg:   127.794 (0.000) <0-04:19:46> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 96970.6450, 'dyn_loss':     0.0861, 'dot_loss':     0.0239, 'ddot_loss':     0.0426, 'rew_loss':    89.7147, 'lr':   7.24e-05, 'eps_e':     0.0001, 'lr_e':   7.24e-05})
Step:  181000, Reward:   156.562 [  51.045], Avg:   127.952 (0.100) <0-04:22:11> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 97586.5580, 'dyn_loss':     0.0859, 'dot_loss':     0.0237, 'ddot_loss':     0.0418, 'rew_loss':    91.0517, 'lr':   7.24e-05, 'eps_e':     0.1001, 'lr_e':   7.24e-05})
Step:  182000, Reward:   165.688 [  50.876], Avg:   128.158 (0.200) <0-04:24:22> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 97683.1560, 'dyn_loss':     0.0884, 'dot_loss':     0.0236, 'ddot_loss':     0.0413, 'rew_loss':    98.0188, 'lr':   7.24e-05, 'eps_e':     0.2001, 'lr_e':   7.24e-05})
Step:  183000, Reward:   134.625 [  69.526], Avg:   128.194 (0.300) <0-04:26:23> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 97809.6310, 'dyn_loss':     0.0854, 'dot_loss':     0.0234, 'ddot_loss':     0.0413, 'rew_loss':    94.3214, 'lr':   7.24e-05, 'eps_e':     0.3001, 'lr_e':   7.24e-05})
Step:  184000, Reward:   155.375 [  66.415], Avg:   128.341 (0.400) <0-04:28:10> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 97973.5100, 'dyn_loss':     0.0843, 'dot_loss':     0.0236, 'ddot_loss':     0.0419, 'rew_loss':    94.3299, 'lr':   7.24e-05, 'eps_e':     0.4001, 'lr_e':   7.24e-05})
Step:  185000, Reward:   153.812 [  72.234], Avg:   128.477 (0.500) <0-04:29:46> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 98198.8490, 'dyn_loss':     0.0872, 'dot_loss':     0.0236, 'ddot_loss':     0.0417, 'rew_loss':    95.1247, 'lr':   7.24e-05, 'eps_e':     0.5001, 'lr_e':   7.24e-05})
Step:  186000, Reward:   148.688 [  66.033], Avg:   128.586 (0.600) <0-04:31:10> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 98554.5530, 'dyn_loss':     0.0860, 'dot_loss':     0.0234, 'ddot_loss':     0.0414, 'rew_loss':   100.4198, 'lr':   7.24e-05, 'eps_e':     0.6001, 'lr_e':   7.24e-05})
Step:  187000, Reward:   126.812 [  82.032], Avg:   128.576 (0.700) <0-04:32:23> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 99075.4610, 'dyn_loss':     0.0841, 'dot_loss':     0.0237, 'ddot_loss':     0.0420, 'rew_loss':    92.3408, 'lr':   7.24e-05, 'eps_e':     0.7001, 'lr_e':   7.24e-05})
Step:  188000, Reward:   167.250 [  59.528], Avg:   128.781 (0.800) <0-04:33:23> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 99799.2280, 'dyn_loss':     0.0843, 'dot_loss':     0.0233, 'ddot_loss':     0.0414, 'rew_loss':    91.0403, 'lr':   7.24e-05, 'eps_e':     0.8001, 'lr_e':   7.24e-05})
Step:  189000, Reward:   138.188 [  78.182], Avg:   128.830 (0.900) <0-04:34:11> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 100695.6460, 'dyn_loss':     0.0908, 'dot_loss':     0.0236, 'ddot_loss':     0.0412, 'rew_loss':    94.9198, 'lr':   7.24e-05, 'eps_e':     0.9001, 'lr_e':   7.24e-05})
Step:  190000, Reward:   174.125 [  49.209], Avg:   129.067 (0.000) <0-04:34:50> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 101754.7370, 'dyn_loss':     0.0848, 'dot_loss':     0.0233, 'ddot_loss':     0.0412, 'rew_loss':    97.6096, 'lr':   7.09e-05, 'eps_e':     0.0001, 'lr_e':   7.09e-05})
Step:  191000, Reward:   132.500 [  59.067], Avg:   129.085 (0.100) <0-04:37:14> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 102347.9610, 'dyn_loss':     0.0835, 'dot_loss':     0.0233, 'ddot_loss':     0.0413, 'rew_loss':    89.3607, 'lr':   7.09e-05, 'eps_e':     0.1001, 'lr_e':   7.09e-05})
Step:  192000, Reward:   160.688 [  34.862], Avg:   129.249 (0.200) <0-04:39:26> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 102446.7270, 'dyn_loss':     0.0860, 'dot_loss':     0.0233, 'ddot_loss':     0.0413, 'rew_loss':    94.8285, 'lr':   7.09e-05, 'eps_e':     0.2001, 'lr_e':   7.09e-05})
Step:  193000, Reward:   144.438 [  69.579], Avg:   129.327 (0.300) <0-04:41:26> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 102580.8520, 'dyn_loss':     0.0819, 'dot_loss':     0.0230, 'ddot_loss':     0.0408, 'rew_loss':    90.1683, 'lr':   7.09e-05, 'eps_e':     0.3001, 'lr_e':   7.09e-05})
Step:  194000, Reward:   127.062 [  76.805], Avg:   129.316 (0.400) <0-04:43:14> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 102750.2970, 'dyn_loss':     0.0823, 'dot_loss':     0.0232, 'ddot_loss':     0.0414, 'rew_loss':    96.4026, 'lr':   7.09e-05, 'eps_e':     0.4001, 'lr_e':   7.09e-05})
Step:  195000, Reward:   117.375 [  68.049], Avg:   129.255 (0.500) <0-04:44:50> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 102974.6080, 'dyn_loss':     0.0854, 'dot_loss':     0.0232, 'ddot_loss':     0.0410, 'rew_loss':    97.7941, 'lr':   7.09e-05, 'eps_e':     0.5001, 'lr_e':   7.09e-05})
Step:  196000, Reward:   138.438 [  70.425], Avg:   129.301 (0.600) <0-04:46:14> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 103328.4350, 'dyn_loss':     0.0845, 'dot_loss':     0.0232, 'ddot_loss':     0.0412, 'rew_loss':    95.9932, 'lr':   7.09e-05, 'eps_e':     0.6001, 'lr_e':   7.09e-05})
Step:  197000, Reward:   161.688 [  50.902], Avg:   129.465 (0.700) <0-04:47:27> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 103857.9190, 'dyn_loss':     0.0866, 'dot_loss':     0.0232, 'ddot_loss':     0.0410, 'rew_loss':    97.5899, 'lr':   7.09e-05, 'eps_e':     0.7001, 'lr_e':   7.09e-05})
Step:  198000, Reward:   149.438 [  66.090], Avg:   129.565 (0.800) <0-04:48:27> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 104594.8380, 'dyn_loss':     0.0883, 'dot_loss':     0.0229, 'ddot_loss':     0.0400, 'rew_loss':    94.4408, 'lr':   7.09e-05, 'eps_e':     0.8001, 'lr_e':   7.09e-05})
Step:  199000, Reward:   143.375 [  68.672], Avg:   129.634 (0.900) <0-04:49:15> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 105512.4460, 'dyn_loss':     0.0882, 'dot_loss':     0.0229, 'ddot_loss':     0.0400, 'rew_loss':    95.2322, 'lr':   7.09e-05, 'eps_e':     0.9001, 'lr_e':   7.09e-05})
Step:  200000, Reward:   128.938 [  72.371], Avg:   129.631 (0.000) <0-04:49:54> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 106561.0110, 'dyn_loss':     0.0854, 'dot_loss':     0.0227, 'ddot_loss':     0.0398, 'rew_loss':    96.2071, 'lr':   7.09e-05, 'eps_e':     0.0001, 'lr_e':   7.09e-05})
Step:  201000, Reward:   117.250 [  54.308], Avg:   129.570 (0.100) <0-04:52:18> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 107156.4840, 'dyn_loss':     0.0839, 'dot_loss':     0.0231, 'ddot_loss':     0.0407, 'rew_loss':    95.0134, 'lr':   6.95e-05, 'eps_e':     0.1001, 'lr_e':   6.95e-05})
Step:  202000, Reward:   157.562 [  53.478], Avg:   129.708 (0.200) <0-04:54:32> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 107265.5340, 'dyn_loss':     0.0823, 'dot_loss':     0.0230, 'ddot_loss':     0.0410, 'rew_loss':    96.5815, 'lr':   6.95e-05, 'eps_e':     0.2001, 'lr_e':   6.95e-05})
Step:  203000, Reward:   127.000 [  51.210], Avg:   129.694 (0.300) <0-04:56:34> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 107405.8150, 'dyn_loss':     0.0829, 'dot_loss':     0.0228, 'ddot_loss':     0.0405, 'rew_loss':    95.5340, 'lr':   6.95e-05, 'eps_e':     0.3001, 'lr_e':   6.95e-05})
Step:  204000, Reward:   130.938 [  63.330], Avg:   129.700 (0.400) <0-04:58:23> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 107573.0770, 'dyn_loss':     0.0804, 'dot_loss':     0.0228, 'ddot_loss':     0.0407, 'rew_loss':    90.7083, 'lr':   6.95e-05, 'eps_e':     0.4001, 'lr_e':   6.95e-05})
Step:  205000, Reward:   129.250 [  73.796], Avg:   129.698 (0.500) <0-04:59:59> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 107811.1400, 'dyn_loss':     0.0842, 'dot_loss':     0.0229, 'ddot_loss':     0.0408, 'rew_loss':    96.7729, 'lr':   6.95e-05, 'eps_e':     0.5001, 'lr_e':   6.95e-05})
Step:  206000, Reward:   137.562 [  63.203], Avg:   129.736 (0.600) <0-05:01:23> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 108155.3480, 'dyn_loss':     0.0841, 'dot_loss':     0.0227, 'ddot_loss':     0.0400, 'rew_loss':    94.6746, 'lr':   6.95e-05, 'eps_e':     0.6001, 'lr_e':   6.95e-05})
Step:  207000, Reward:   124.000 [  63.342], Avg:   129.709 (0.700) <0-05:02:35> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 108645.2710, 'dyn_loss':     0.0854, 'dot_loss':     0.0227, 'ddot_loss':     0.0401, 'rew_loss':    96.8608, 'lr':   6.95e-05, 'eps_e':     0.7001, 'lr_e':   6.95e-05})
Step:  208000, Reward:   128.750 [  67.278], Avg:   129.704 (0.800) <0-05:03:36> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 109358.9010, 'dyn_loss':     0.0834, 'dot_loss':     0.0228, 'ddot_loss':     0.0405, 'rew_loss':    98.3279, 'lr':   6.95e-05, 'eps_e':     0.8001, 'lr_e':   6.95e-05})
Step:  209000, Reward:   126.000 [  64.104], Avg:   129.686 (0.900) <0-05:04:24> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 110279.8170, 'dyn_loss':     0.0824, 'dot_loss':     0.0224, 'ddot_loss':     0.0395, 'rew_loss':    93.0808, 'lr':   6.95e-05, 'eps_e':     0.9001, 'lr_e':   6.95e-05})
Step:  210000, Reward:   154.500 [  59.234], Avg:   129.804 (0.000) <0-05:05:03> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 111330.7110, 'dyn_loss':     0.0839, 'dot_loss':     0.0225, 'ddot_loss':     0.0394, 'rew_loss':    94.7623, 'lr':   6.95e-05, 'eps_e':     0.0001, 'lr_e':   6.95e-05})
Step:  211000, Reward:   135.250 [  65.508], Avg:   129.830 (0.100) <0-05:07:27> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 111926.4420, 'dyn_loss':     0.0852, 'dot_loss':     0.0226, 'ddot_loss':     0.0398, 'rew_loss':    96.0256, 'lr':   6.95e-05, 'eps_e':     0.1001, 'lr_e':   6.95e-05})
Step:  212000, Reward:   122.438 [  59.103], Avg:   129.795 (0.200) <0-05:09:39> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 112033.2700, 'dyn_loss':     0.0807, 'dot_loss':     0.0227, 'ddot_loss':     0.0408, 'rew_loss':    97.3743, 'lr':   6.81e-05, 'eps_e':     0.2001, 'lr_e':   6.81e-05})
Step:  213000, Reward:   159.562 [  49.564], Avg:   129.934 (0.300) <0-05:11:39> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 112168.9830, 'dyn_loss':     0.0839, 'dot_loss':     0.0225, 'ddot_loss':     0.0398, 'rew_loss':    95.7594, 'lr':   6.81e-05, 'eps_e':     0.3001, 'lr_e':   6.81e-05})
Step:  214000, Reward:   130.250 [  72.695], Avg:   129.935 (0.400) <0-05:13:27> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 112342.8820, 'dyn_loss':     0.0820, 'dot_loss':     0.0228, 'ddot_loss':     0.0405, 'rew_loss':    99.9491, 'lr':   6.81e-05, 'eps_e':     0.4001, 'lr_e':   6.81e-05})
Step:  215000, Reward:   146.062 [  55.171], Avg:   130.010 (0.500) <0-05:15:03> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 112584.7330, 'dyn_loss':     0.0833, 'dot_loss':     0.0223, 'ddot_loss':     0.0390, 'rew_loss':    97.1905, 'lr':   6.81e-05, 'eps_e':     0.5001, 'lr_e':   6.81e-05})
Step:  216000, Reward:   155.000 [  61.506], Avg:   130.125 (0.600) <0-05:16:27> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 112940.9960, 'dyn_loss':     0.0858, 'dot_loss':     0.0223, 'ddot_loss':     0.0389, 'rew_loss':    95.8312, 'lr':   6.81e-05, 'eps_e':     0.6001, 'lr_e':   6.81e-05})
Step:  217000, Reward:   157.562 [  62.813], Avg:   130.251 (0.700) <0-05:17:40> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 113464.0450, 'dyn_loss':     0.0839, 'dot_loss':     0.0221, 'ddot_loss':     0.0387, 'rew_loss':    95.4698, 'lr':   6.81e-05, 'eps_e':     0.7001, 'lr_e':   6.81e-05})
Step:  218000, Reward:   161.875 [  50.163], Avg:   130.396 (0.800) <0-05:18:40> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 114199.0330, 'dyn_loss':     0.0804, 'dot_loss':     0.0225, 'ddot_loss':     0.0400, 'rew_loss':    94.1297, 'lr':   6.81e-05, 'eps_e':     0.8001, 'lr_e':   6.81e-05})
Step:  219000, Reward:   120.000 [  79.059], Avg:   130.348 (0.900) <0-05:19:28> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 115111.6030, 'dyn_loss':     0.0825, 'dot_loss':     0.0223, 'ddot_loss':     0.0396, 'rew_loss':   100.1564, 'lr':   6.81e-05, 'eps_e':     0.9001, 'lr_e':   6.81e-05})
Step:  220000, Reward:   144.438 [  54.117], Avg:   130.412 (0.000) <0-05:20:07> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 116149.1420, 'dyn_loss':     0.0850, 'dot_loss':     0.0221, 'ddot_loss':     0.0386, 'rew_loss':    97.1735, 'lr':   6.81e-05, 'eps_e':     0.0001, 'lr_e':   6.81e-05})
Step:  221000, Reward:   153.062 [  58.573], Avg:   130.514 (0.100) <0-05:22:32> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 116742.6750, 'dyn_loss':     0.0778, 'dot_loss':     0.0223, 'ddot_loss':     0.0401, 'rew_loss':    95.0842, 'lr':   6.81e-05, 'eps_e':     0.1001, 'lr_e':   6.81e-05})
Step:  222000, Reward:   143.000 [  57.139], Avg:   130.570 (0.200) <0-05:24:44> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 116847.8440, 'dyn_loss':     0.0867, 'dot_loss':     0.0227, 'ddot_loss':     0.0400, 'rew_loss':    99.6918, 'lr':   6.81e-05, 'eps_e':     0.2001, 'lr_e':   6.81e-05})
Step:  223000, Reward:   133.438 [  63.826], Avg:   130.583 (0.300) <0-05:26:44> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 116979.6330, 'dyn_loss':     0.0833, 'dot_loss':     0.0224, 'ddot_loss':     0.0394, 'rew_loss':    96.9505, 'lr':   6.68e-05, 'eps_e':     0.3001, 'lr_e':   6.68e-05})
Step:  224000, Reward:   144.625 [  59.723], Avg:   130.645 (0.400) <0-05:28:33> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 117156.8160, 'dyn_loss':     0.0813, 'dot_loss':     0.0222, 'ddot_loss':     0.0394, 'rew_loss':    92.7430, 'lr':   6.68e-05, 'eps_e':     0.4001, 'lr_e':   6.68e-05})
Step:  225000, Reward:   147.812 [  62.310], Avg:   130.721 (0.500) <0-05:30:09> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 117415.9180, 'dyn_loss':     0.0846, 'dot_loss':     0.0222, 'ddot_loss':     0.0390, 'rew_loss':    99.2992, 'lr':   6.68e-05, 'eps_e':     0.5001, 'lr_e':   6.68e-05})
Step:  226000, Reward:   132.125 [  76.426], Avg:   130.727 (0.600) <0-05:31:34> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 117773.1610, 'dyn_loss':     0.0809, 'dot_loss':     0.0223, 'ddot_loss':     0.0396, 'rew_loss':    96.4127, 'lr':   6.68e-05, 'eps_e':     0.6001, 'lr_e':   6.68e-05})
Step:  227000, Reward:   154.000 [  51.670], Avg:   130.829 (0.700) <0-05:32:46> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 118301.2300, 'dyn_loss':     0.0835, 'dot_loss':     0.0220, 'ddot_loss':     0.0385, 'rew_loss':   103.2554, 'lr':   6.68e-05, 'eps_e':     0.7001, 'lr_e':   6.68e-05})
Step:  228000, Reward:   140.438 [  59.922], Avg:   130.871 (0.800) <0-05:33:47> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 119039.2880, 'dyn_loss':     0.0790, 'dot_loss':     0.0217, 'ddot_loss':     0.0385, 'rew_loss':   100.4828, 'lr':   6.68e-05, 'eps_e':     0.8001, 'lr_e':   6.68e-05})
Step:  229000, Reward:   124.625 [  64.928], Avg:   130.844 (0.900) <0-05:34:35> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 119926.6370, 'dyn_loss':     0.0825, 'dot_loss':     0.0220, 'ddot_loss':     0.0386, 'rew_loss':    96.4068, 'lr':   6.68e-05, 'eps_e':     0.9001, 'lr_e':   6.68e-05})
Step:  230000, Reward:   136.438 [  51.148], Avg:   130.869 (0.000) <0-05:35:15> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 120971.0560, 'dyn_loss':     0.0852, 'dot_loss':     0.0223, 'ddot_loss':     0.0392, 'rew_loss':    95.3978, 'lr':   6.68e-05, 'eps_e':     0.0001, 'lr_e':   6.68e-05})
Step:  231000, Reward:   134.000 [  72.667], Avg:   130.882 (0.100) <0-05:37:40> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 121572.7290, 'dyn_loss':     0.0804, 'dot_loss':     0.0220, 'ddot_loss':     0.0389, 'rew_loss':    94.9803, 'lr':   6.68e-05, 'eps_e':     0.1001, 'lr_e':   6.68e-05})
Step:  232000, Reward:   156.812 [  41.343], Avg:   130.993 (0.200) <0-05:39:52> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 121680.7110, 'dyn_loss':     0.0828, 'dot_loss':     0.0220, 'ddot_loss':     0.0389, 'rew_loss':    95.9861, 'lr':   6.68e-05, 'eps_e':     0.2001, 'lr_e':   6.68e-05})
Step:  233000, Reward:   127.938 [  60.784], Avg:   130.980 (0.300) <0-05:41:52> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 121821.5550, 'dyn_loss':     0.0828, 'dot_loss':     0.0220, 'ddot_loss':     0.0386, 'rew_loss':   100.3261, 'lr':   6.68e-05, 'eps_e':     0.3001, 'lr_e':   6.68e-05})
Step:  234000, Reward:   135.688 [  69.403], Avg:   131.000 (0.400) <0-05:43:40> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 122002.7720, 'dyn_loss':     0.0852, 'dot_loss':     0.0221, 'ddot_loss':     0.0386, 'rew_loss':   100.8291, 'lr':   6.54e-05, 'eps_e':     0.4001, 'lr_e':   6.54e-05})
Step:  235000, Reward:   115.250 [  64.807], Avg:   130.934 (0.500) <0-05:45:17> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 122230.3290, 'dyn_loss':     0.0847, 'dot_loss':     0.0218, 'ddot_loss':     0.0380, 'rew_loss':    95.6623, 'lr':   6.54e-05, 'eps_e':     0.5001, 'lr_e':   6.54e-05})
Step:  236000, Reward:   128.125 [  83.917], Avg:   130.922 (0.600) <0-05:46:41> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 122591.3470, 'dyn_loss':     0.0848, 'dot_loss':     0.0218, 'ddot_loss':     0.0380, 'rew_loss':   102.1685, 'lr':   6.54e-05, 'eps_e':     0.6001, 'lr_e':   6.54e-05})
Step:  237000, Reward:   117.438 [  77.407], Avg:   130.865 (0.700) <0-05:47:53> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 123139.4090, 'dyn_loss':     0.0818, 'dot_loss':     0.0219, 'ddot_loss':     0.0385, 'rew_loss':    93.3646, 'lr':   6.54e-05, 'eps_e':     0.7001, 'lr_e':   6.54e-05})
Step:  238000, Reward:   138.812 [  72.175], Avg:   130.898 (0.800) <0-05:48:54> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 123835.3370, 'dyn_loss':     0.0812, 'dot_loss':     0.0218, 'ddot_loss':     0.0383, 'rew_loss':    99.6964, 'lr':   6.54e-05, 'eps_e':     0.8001, 'lr_e':   6.54e-05})
Step:  239000, Reward:   161.688 [  55.364], Avg:   131.027 (0.900) <0-05:49:42> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 124731.7890, 'dyn_loss':     0.0825, 'dot_loss':     0.0221, 'ddot_loss':     0.0390, 'rew_loss':    97.4505, 'lr':   6.54e-05, 'eps_e':     0.9001, 'lr_e':   6.54e-05})
Step:  240000, Reward:   158.000 [  54.386], Avg:   131.138 (0.000) <0-05:50:22> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 125783.0860, 'dyn_loss':     0.0854, 'dot_loss':     0.0216, 'ddot_loss':     0.0379, 'rew_loss':   104.0330, 'lr':   6.54e-05, 'eps_e':     0.0001, 'lr_e':   6.54e-05})
Step:  241000, Reward:   144.875 [  54.340], Avg:   131.195 (0.100) <0-05:52:46> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 126385.2870, 'dyn_loss':     0.0804, 'dot_loss':     0.0220, 'ddot_loss':     0.0390, 'rew_loss':    90.3970, 'lr':   6.54e-05, 'eps_e':     0.1001, 'lr_e':   6.54e-05})
Step:  242000, Reward:   152.812 [  48.304], Avg:   131.284 (0.200) <0-05:54:58> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 126485.6810, 'dyn_loss':     0.0808, 'dot_loss':     0.0219, 'ddot_loss':     0.0391, 'rew_loss':    95.3372, 'lr':   6.54e-05, 'eps_e':     0.2001, 'lr_e':   6.54e-05})
Step:  243000, Reward:   149.625 [  71.185], Avg:   131.359 (0.300) <0-05:56:58> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 126620.8710, 'dyn_loss':     0.0826, 'dot_loss':     0.0220, 'ddot_loss':     0.0388, 'rew_loss':    99.5802, 'lr':   6.54e-05, 'eps_e':     0.3001, 'lr_e':   6.54e-05})
Step:  244000, Reward:   129.938 [  54.192], Avg:   131.354 (0.400) <0-05:58:46> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 126805.6780, 'dyn_loss':     0.0810, 'dot_loss':     0.0216, 'ddot_loss':     0.0380, 'rew_loss':    91.5591, 'lr':   6.54e-05, 'eps_e':     0.4001, 'lr_e':   6.54e-05})
Step:  245000, Reward:   129.500 [  77.448], Avg:   131.346 (0.500) <0-06:00:23> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 127052.1970, 'dyn_loss':     0.0850, 'dot_loss':     0.0219, 'ddot_loss':     0.0382, 'rew_loss':    97.7298, 'lr':   6.41e-05, 'eps_e':     0.5001, 'lr_e':   6.41e-05})
Step:  246000, Reward:   126.562 [  61.039], Avg:   131.327 (0.600) <0-06:01:47> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 127410.6590, 'dyn_loss':     0.0840, 'dot_loss':     0.0219, 'ddot_loss':     0.0383, 'rew_loss':    97.6295, 'lr':   6.41e-05, 'eps_e':     0.6001, 'lr_e':   6.41e-05})
Step:  247000, Reward:   141.812 [  58.140], Avg:   131.369 (0.700) <0-06:02:59> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 127949.4730, 'dyn_loss':     0.0851, 'dot_loss':     0.0216, 'ddot_loss':     0.0377, 'rew_loss':    95.5513, 'lr':   6.41e-05, 'eps_e':     0.7001, 'lr_e':   6.41e-05})
Step:  248000, Reward:   164.438 [  40.321], Avg:   131.502 (0.800) <0-06:04:00> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 128686.2430, 'dyn_loss':     0.0819, 'dot_loss':     0.0217, 'ddot_loss':     0.0381, 'rew_loss':   100.3295, 'lr':   6.41e-05, 'eps_e':     0.8001, 'lr_e':   6.41e-05})
Step:  249000, Reward:   138.000 [  49.042], Avg:   131.528 (0.900) <0-06:04:48> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 129596.1420, 'dyn_loss':     0.0845, 'dot_loss':     0.0215, 'ddot_loss':     0.0376, 'rew_loss':    95.3908, 'lr':   6.41e-05, 'eps_e':     0.9001, 'lr_e':   6.41e-05})
Step:  250000, Reward:   149.938 [  58.053], Avg:   131.601 (0.000) <0-06:05:27> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 130630.4170, 'dyn_loss':     0.0860, 'dot_loss':     0.0215, 'ddot_loss':     0.0371, 'rew_loss':    98.8564, 'lr':   6.41e-05, 'eps_e':     0.0001, 'lr_e':   6.41e-05})
Step:  251000, Reward:   151.500 [  48.666], Avg:   131.680 (0.100) <0-06:07:51> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 131210.3340, 'dyn_loss':     0.0826, 'dot_loss':     0.0216, 'ddot_loss':     0.0377, 'rew_loss':    99.7612, 'lr':   6.41e-05, 'eps_e':     0.1001, 'lr_e':   6.41e-05})
Step:  252000, Reward:   161.312 [  51.047], Avg:   131.797 (0.200) <0-06:10:03> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 131316.5140, 'dyn_loss':     0.0830, 'dot_loss':     0.0218, 'ddot_loss':     0.0381, 'rew_loss':   101.7471, 'lr':   6.41e-05, 'eps_e':     0.2001, 'lr_e':   6.41e-05})
Step:  253000, Reward:   131.875 [  58.529], Avg:   131.797 (0.300) <0-06:12:03> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 131453.4830, 'dyn_loss':     0.0795, 'dot_loss':     0.0216, 'ddot_loss':     0.0382, 'rew_loss':    94.2722, 'lr':   6.41e-05, 'eps_e':     0.3001, 'lr_e':   6.41e-05})
Step:  254000, Reward:   165.250 [  57.509], Avg:   131.929 (0.400) <0-06:13:52> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 131634.9520, 'dyn_loss':     0.0787, 'dot_loss':     0.0214, 'ddot_loss':     0.0379, 'rew_loss':    98.7020, 'lr':   6.41e-05, 'eps_e':     0.4001, 'lr_e':   6.41e-05})
Step:  255000, Reward:   163.438 [  55.824], Avg:   132.052 (0.500) <0-06:15:28> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 131901.3110, 'dyn_loss':     0.0834, 'dot_loss':     0.0218, 'ddot_loss':     0.0382, 'rew_loss':   101.6205, 'lr':   6.41e-05, 'eps_e':     0.5001, 'lr_e':   6.41e-05})
Step:  256000, Reward:   176.125 [  48.653], Avg:   132.223 (0.600) <0-06:16:53> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 132265.1170, 'dyn_loss':     0.0837, 'dot_loss':     0.0217, 'ddot_loss':     0.0378, 'rew_loss':    99.8416, 'lr':   6.28e-05, 'eps_e':     0.6001, 'lr_e':   6.28e-05})
Step:  257000, Reward:   127.500 [  69.449], Avg:   132.205 (0.700) <0-06:18:06> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 132808.5590, 'dyn_loss':     0.0805, 'dot_loss':     0.0217, 'ddot_loss':     0.0382, 'rew_loss':   102.7284, 'lr':   6.28e-05, 'eps_e':     0.7001, 'lr_e':   6.28e-05})
Step:  258000, Reward:   142.750 [  61.243], Avg:   132.246 (0.800) <0-06:19:06> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 133546.3960, 'dyn_loss':     0.0843, 'dot_loss':     0.0216, 'ddot_loss':     0.0375, 'rew_loss':    99.2534, 'lr':   6.28e-05, 'eps_e':     0.8001, 'lr_e':   6.28e-05})
Step:  259000, Reward:   133.312 [  65.393], Avg:   132.250 (0.900) <0-06:19:54> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 134446.9220, 'dyn_loss':     0.0818, 'dot_loss':     0.0214, 'ddot_loss':     0.0375, 'rew_loss':    99.6565, 'lr':   6.28e-05, 'eps_e':     0.9001, 'lr_e':   6.28e-05})
Step:  260000, Reward:   141.438 [  51.992], Avg:   132.285 (0.000) <0-06:20:33> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 135483.0330, 'dyn_loss':     0.0833, 'dot_loss':     0.0215, 'ddot_loss':     0.0374, 'rew_loss':   101.2961, 'lr':   6.28e-05, 'eps_e':     0.0001, 'lr_e':   6.28e-05})
Step:  261000, Reward:   139.375 [  58.528], Avg:   132.312 (0.100) <0-06:22:58> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 136079.8510, 'dyn_loss':     0.0811, 'dot_loss':     0.0215, 'ddot_loss':     0.0375, 'rew_loss':    99.6172, 'lr':   6.28e-05, 'eps_e':     0.1001, 'lr_e':   6.28e-05})
Step:  262000, Reward:   174.438 [  42.022], Avg:   132.472 (0.200) <0-06:25:09> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 136185.6140, 'dyn_loss':     0.0811, 'dot_loss':     0.0215, 'ddot_loss':     0.0374, 'rew_loss':    98.1685, 'lr':   6.28e-05, 'eps_e':     0.2001, 'lr_e':   6.28e-05})
Step:  263000, Reward:   125.062 [  57.484], Avg:   132.444 (0.300) <0-06:27:10> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 136317.2500, 'dyn_loss':     0.0832, 'dot_loss':     0.0213, 'ddot_loss':     0.0369, 'rew_loss':   103.7006, 'lr':   6.28e-05, 'eps_e':     0.3001, 'lr_e':   6.28e-05})
Step:  264000, Reward:   152.000 [  60.158], Avg:   132.518 (0.400) <0-06:28:58> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 136484.0930, 'dyn_loss':     0.0825, 'dot_loss':     0.0213, 'ddot_loss':     0.0368, 'rew_loss':    97.1349, 'lr':   6.28e-05, 'eps_e':     0.4001, 'lr_e':   6.28e-05})
Step:  265000, Reward:   185.875 [  31.951], Avg:   132.719 (0.500) <0-06:30:35> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 136729.6770, 'dyn_loss':     0.0792, 'dot_loss':     0.0217, 'ddot_loss':     0.0383, 'rew_loss':    92.2134, 'lr':   6.28e-05, 'eps_e':     0.5001, 'lr_e':   6.28e-05})
Step:  266000, Reward:   116.125 [  60.959], Avg:   132.656 (0.600) <0-06:31:59> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 137079.3840, 'dyn_loss':     0.0808, 'dot_loss':     0.0217, 'ddot_loss':     0.0384, 'rew_loss':    96.5462, 'lr':   6.28e-05, 'eps_e':     0.6001, 'lr_e':   6.28e-05})
Step:  267000, Reward:   167.062 [  51.673], Avg:   132.785 (0.700) <0-06:33:11> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 137603.3150, 'dyn_loss':     0.0830, 'dot_loss':     0.0214, 'ddot_loss':     0.0371, 'rew_loss':    96.9108, 'lr':   6.16e-05, 'eps_e':     0.7001, 'lr_e':   6.16e-05})
Step:  268000, Reward:   135.375 [  77.786], Avg:   132.794 (0.800) <0-06:34:12> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 138343.6620, 'dyn_loss':     0.0792, 'dot_loss':     0.0215, 'ddot_loss':     0.0381, 'rew_loss':    96.4714, 'lr':   6.16e-05, 'eps_e':     0.8001, 'lr_e':   6.16e-05})
Step:  269000, Reward:   162.375 [  64.451], Avg:   132.904 (0.900) <0-06:35:02> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 139281.9250, 'dyn_loss':     0.0808, 'dot_loss':     0.0215, 'ddot_loss':     0.0379, 'rew_loss':   100.6403, 'lr':   6.16e-05, 'eps_e':     0.9001, 'lr_e':   6.16e-05})
Step:  270000, Reward:   154.812 [  46.814], Avg:   132.985 (0.000) <0-06:35:41> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 140360.1750, 'dyn_loss':     0.0827, 'dot_loss':     0.0215, 'ddot_loss':     0.0375, 'rew_loss':   100.3606, 'lr':   6.16e-05, 'eps_e':     0.0001, 'lr_e':   6.16e-05})
Step:  271000, Reward:   139.562 [  58.725], Avg:   133.009 (0.100) <0-06:38:05> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 140970.0950, 'dyn_loss':     0.0812, 'dot_loss':     0.0217, 'ddot_loss':     0.0381, 'rew_loss':    97.2024, 'lr':   6.16e-05, 'eps_e':     0.1001, 'lr_e':   6.16e-05})
Step:  272000, Reward:   129.812 [  54.289], Avg:   132.997 (0.200) <0-06:40:16> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 141073.2010, 'dyn_loss':     0.0845, 'dot_loss':     0.0213, 'ddot_loss':     0.0368, 'rew_loss':    99.2536, 'lr':   6.16e-05, 'eps_e':     0.2001, 'lr_e':   6.16e-05})
Step:  273000, Reward:   147.062 [  49.603], Avg:   133.049 (0.300) <0-06:42:16> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 141202.5100, 'dyn_loss':     0.0886, 'dot_loss':     0.0212, 'ddot_loss':     0.0362, 'rew_loss':   103.0871, 'lr':   6.16e-05, 'eps_e':     0.3001, 'lr_e':   6.16e-05})
Step:  274000, Reward:   125.875 [  67.363], Avg:   133.023 (0.400) <0-06:44:04> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 141367.3750, 'dyn_loss':     0.0834, 'dot_loss':     0.0212, 'ddot_loss':     0.0365, 'rew_loss':    99.2548, 'lr':   6.16e-05, 'eps_e':     0.4001, 'lr_e':   6.16e-05})
Step:  275000, Reward:   150.875 [  62.341], Avg:   133.087 (0.500) <0-06:45:40> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 141601.8730, 'dyn_loss':     0.0825, 'dot_loss':     0.0215, 'ddot_loss':     0.0374, 'rew_loss':    98.2426, 'lr':   6.16e-05, 'eps_e':     0.5001, 'lr_e':   6.16e-05})
Step:  276000, Reward:   151.125 [  45.633], Avg:   133.152 (0.600) <0-06:47:05> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 141960.3680, 'dyn_loss':     0.0799, 'dot_loss':     0.0215, 'ddot_loss':     0.0377, 'rew_loss':   100.0090, 'lr':   6.16e-05, 'eps_e':     0.6001, 'lr_e':   6.16e-05})
Step:  277000, Reward:   142.062 [  65.069], Avg:   133.184 (0.700) <0-06:48:17> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 142477.2980, 'dyn_loss':     0.0794, 'dot_loss':     0.0212, 'ddot_loss':     0.0375, 'rew_loss':   100.9233, 'lr':   6.16e-05, 'eps_e':     0.7001, 'lr_e':   6.16e-05})
Step:  278000, Reward:   126.250 [  69.770], Avg:   133.159 (0.800) <0-06:49:18> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 143182.3510, 'dyn_loss':     0.0816, 'dot_loss':     0.0215, 'ddot_loss':     0.0376, 'rew_loss':    97.2256, 'lr':   6.03e-05, 'eps_e':     0.8001, 'lr_e':   6.03e-05})
Step:  279000, Reward:   144.562 [  63.017], Avg:   133.200 (0.900) <0-06:50:06> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 144102.3980, 'dyn_loss':     0.0837, 'dot_loss':     0.0214, 'ddot_loss':     0.0371, 'rew_loss':    97.6790, 'lr':   6.03e-05, 'eps_e':     0.9001, 'lr_e':   6.03e-05})
Step:  280000, Reward:   145.438 [  72.791], Avg:   133.244 (0.000) <0-06:50:45> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 145168.1370, 'dyn_loss':     0.0796, 'dot_loss':     0.0214, 'ddot_loss':     0.0375, 'rew_loss':    91.7832, 'lr':   6.03e-05, 'eps_e':     0.0001, 'lr_e':   6.03e-05})
Step:  281000, Reward:   145.312 [  62.334], Avg:   133.287 (0.100) <0-06:53:09> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 145785.0990, 'dyn_loss':     0.0822, 'dot_loss':     0.0214, 'ddot_loss':     0.0371, 'rew_loss':   101.9441, 'lr':   6.03e-05, 'eps_e':     0.1001, 'lr_e':   6.03e-05})
Step:  282000, Reward:   150.625 [  53.977], Avg:   133.348 (0.200) <0-06:55:21> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 145883.7280, 'dyn_loss':     0.0808, 'dot_loss':     0.0215, 'ddot_loss':     0.0376, 'rew_loss':    98.2497, 'lr':   6.03e-05, 'eps_e':     0.2001, 'lr_e':   6.03e-05})
Step:  283000, Reward:   114.812 [  64.498], Avg:   133.283 (0.300) <0-06:57:21> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 146011.6820, 'dyn_loss':     0.0836, 'dot_loss':     0.0214, 'ddot_loss':     0.0371, 'rew_loss':   101.0768, 'lr':   6.03e-05, 'eps_e':     0.3001, 'lr_e':   6.03e-05})
Step:  284000, Reward:   129.688 [  56.107], Avg:   133.270 (0.400) <0-06:59:09> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 146182.8410, 'dyn_loss':     0.0865, 'dot_loss':     0.0211, 'ddot_loss':     0.0362, 'rew_loss':   102.9945, 'lr':   6.03e-05, 'eps_e':     0.4001, 'lr_e':   6.03e-05})
Step:  285000, Reward:   153.938 [  60.709], Avg:   133.342 (0.500) <0-07:00:45> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 146422.4850, 'dyn_loss':     0.0823, 'dot_loss':     0.0210, 'ddot_loss':     0.0361, 'rew_loss':    99.2242, 'lr':   6.03e-05, 'eps_e':     0.5001, 'lr_e':   6.03e-05})
Step:  286000, Reward:   139.438 [  68.378], Avg:   133.363 (0.600) <0-07:02:10> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 146775.1980, 'dyn_loss':     0.0791, 'dot_loss':     0.0214, 'ddot_loss':     0.0376, 'rew_loss':    97.7429, 'lr':   6.03e-05, 'eps_e':     0.6001, 'lr_e':   6.03e-05})
Step:  287000, Reward:   121.125 [  55.937], Avg:   133.321 (0.700) <0-07:03:22> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 147299.2020, 'dyn_loss':     0.0808, 'dot_loss':     0.0210, 'ddot_loss':     0.0367, 'rew_loss':   100.5138, 'lr':   6.03e-05, 'eps_e':     0.7001, 'lr_e':   6.03e-05})
Step:  288000, Reward:   147.750 [  56.101], Avg:   133.371 (0.800) <0-07:04:22> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 148019.7140, 'dyn_loss':     0.0815, 'dot_loss':     0.0212, 'ddot_loss':     0.0370, 'rew_loss':   101.7284, 'lr':   6.03e-05, 'eps_e':     0.8001, 'lr_e':   6.03e-05})
Step:  289000, Reward:   136.000 [  71.031], Avg:   133.380 (0.900) <0-07:05:10> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 148918.9870, 'dyn_loss':     0.0850, 'dot_loss':     0.0214, 'ddot_loss':     0.0370, 'rew_loss':   101.8434, 'lr':   5.91e-05, 'eps_e':     0.9001, 'lr_e':   5.91e-05})
Step:  290000, Reward:   124.312 [  74.959], Avg:   133.349 (0.000) <0-07:05:49> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 149938.0570, 'dyn_loss':     0.0814, 'dot_loss':     0.0215, 'ddot_loss':     0.0375, 'rew_loss':    98.1464, 'lr':   5.91e-05, 'eps_e':     0.0001, 'lr_e':   5.91e-05})
Step:  291000, Reward:   151.188 [  67.784], Avg:   133.410 (0.100) <0-07:08:14> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 150534.3050, 'dyn_loss':     0.0804, 'dot_loss':     0.0211, 'ddot_loss':     0.0369, 'rew_loss':    95.7127, 'lr':   5.91e-05, 'eps_e':     0.1001, 'lr_e':   5.91e-05})
Step:  292000, Reward:   170.812 [  45.163], Avg:   133.538 (0.200) <0-07:10:26> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 150640.5530, 'dyn_loss':     0.0801, 'dot_loss':     0.0211, 'ddot_loss':     0.0368, 'rew_loss':    97.5993, 'lr':   5.91e-05, 'eps_e':     0.2001, 'lr_e':   5.91e-05})
Step:  293000, Reward:   162.062 [  51.538], Avg:   133.635 (0.300) <0-07:12:27> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 150779.0890, 'dyn_loss':     0.0772, 'dot_loss':     0.0214, 'ddot_loss':     0.0382, 'rew_loss':    99.6296, 'lr':   5.91e-05, 'eps_e':     0.3001, 'lr_e':   5.91e-05})
Step:  294000, Reward:   139.062 [  58.507], Avg:   133.653 (0.400) <0-07:14:15> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 150947.3070, 'dyn_loss':     0.0781, 'dot_loss':     0.0213, 'ddot_loss':     0.0377, 'rew_loss':    96.3842, 'lr':   5.91e-05, 'eps_e':     0.4001, 'lr_e':   5.91e-05})
Step:  295000, Reward:   136.750 [  67.483], Avg:   133.663 (0.500) <0-07:15:51> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 151194.1550, 'dyn_loss':     0.0865, 'dot_loss':     0.0215, 'ddot_loss':     0.0371, 'rew_loss':   101.0340, 'lr':   5.91e-05, 'eps_e':     0.5001, 'lr_e':   5.91e-05})
Step:  296000, Reward:   108.500 [  65.454], Avg:   133.579 (0.600) <0-07:17:15> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 151567.1780, 'dyn_loss':     0.0823, 'dot_loss':     0.0213, 'ddot_loss':     0.0370, 'rew_loss':    98.8664, 'lr':   5.91e-05, 'eps_e':     0.6001, 'lr_e':   5.91e-05})
Step:  297000, Reward:   122.312 [  64.481], Avg:   133.541 (0.700) <0-07:18:27> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 152107.8240, 'dyn_loss':     0.0838, 'dot_loss':     0.0211, 'ddot_loss':     0.0362, 'rew_loss':   100.7122, 'lr':   5.91e-05, 'eps_e':     0.7001, 'lr_e':   5.91e-05})
Step:  298000, Reward:   168.000 [  43.281], Avg:   133.656 (0.800) <0-07:19:28> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 152848.3710, 'dyn_loss':     0.0822, 'dot_loss':     0.0210, 'ddot_loss':     0.0362, 'rew_loss':   100.1945, 'lr':   5.91e-05, 'eps_e':     0.8001, 'lr_e':   5.91e-05})
Step:  299000, Reward:   149.375 [  65.481], Avg:   133.709 (0.900) <0-07:20:16> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 153763.0830, 'dyn_loss':     0.0811, 'dot_loss':     0.0213, 'ddot_loss':     0.0372, 'rew_loss':   103.0148, 'lr':   5.91e-05, 'eps_e':     0.9001, 'lr_e':   5.91e-05})
Step:  300000, Reward:   136.938 [  66.592], Avg:   133.719 (0.000) <0-07:20:55> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 154809.2990, 'dyn_loss':     0.0790, 'dot_loss':     0.0212, 'ddot_loss':     0.0372, 'rew_loss':    97.1886, 'lr':   5.80e-05, 'eps_e':     0.0001, 'lr_e':   5.80e-05})
Step:  301000, Reward:   125.062 [  55.543], Avg:   133.691 (0.100) <0-07:23:24> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 155425.9030, 'dyn_loss':     0.0786, 'dot_loss':     0.0213, 'ddot_loss':     0.0375, 'rew_loss':    98.3009, 'lr':   5.80e-05, 'eps_e':     0.1001, 'lr_e':   5.80e-05})
Step:  302000, Reward:   146.500 [  58.821], Avg:   133.733 (0.200) <0-07:25:35> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 155530.1600, 'dyn_loss':     0.0830, 'dot_loss':     0.0212, 'ddot_loss':     0.0368, 'rew_loss':   102.5291, 'lr':   5.80e-05, 'eps_e':     0.2001, 'lr_e':   5.80e-05})
Step:  303000, Reward:   156.312 [  51.460], Avg:   133.807 (0.300) <0-07:27:36> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 155661.1210, 'dyn_loss':     0.0816, 'dot_loss':     0.0213, 'ddot_loss':     0.0371, 'rew_loss':    97.2876, 'lr':   5.80e-05, 'eps_e':     0.3001, 'lr_e':   5.80e-05})
Step:  304000, Reward:   135.625 [  62.989], Avg:   133.813 (0.400) <0-07:29:24> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 155826.1390, 'dyn_loss':     0.0826, 'dot_loss':     0.0212, 'ddot_loss':     0.0365, 'rew_loss':   100.5458, 'lr':   5.80e-05, 'eps_e':     0.4001, 'lr_e':   5.80e-05})
Step:  305000, Reward:   174.500 [  37.458], Avg:   133.946 (0.500) <0-07:31:00> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 156065.5380, 'dyn_loss':     0.0789, 'dot_loss':     0.0214, 'ddot_loss':     0.0374, 'rew_loss':   100.9296, 'lr':   5.80e-05, 'eps_e':     0.5001, 'lr_e':   5.80e-05})
Step:  306000, Reward:   151.188 [  63.226], Avg:   134.002 (0.600) <0-07:32:24> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 156413.1100, 'dyn_loss':     0.0807, 'dot_loss':     0.0212, 'ddot_loss':     0.0371, 'rew_loss':   101.6033, 'lr':   5.80e-05, 'eps_e':     0.6001, 'lr_e':   5.80e-05})
Step:  307000, Reward:   150.938 [  49.754], Avg:   134.057 (0.700) <0-07:33:37> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 156925.0630, 'dyn_loss':     0.0772, 'dot_loss':     0.0212, 'ddot_loss':     0.0377, 'rew_loss':    93.9580, 'lr':   5.80e-05, 'eps_e':     0.7001, 'lr_e':   5.80e-05})
Step:  308000, Reward:   141.812 [  59.632], Avg:   134.082 (0.800) <0-07:34:37> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 157671.8590, 'dyn_loss':     0.0809, 'dot_loss':     0.0209, 'ddot_loss':     0.0364, 'rew_loss':   102.6653, 'lr':   5.80e-05, 'eps_e':     0.8001, 'lr_e':   5.80e-05})
Step:  309000, Reward:   155.562 [  58.618], Avg:   134.152 (0.900) <0-07:35:26> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 158578.9200, 'dyn_loss':     0.0805, 'dot_loss':     0.0211, 'ddot_loss':     0.0368, 'rew_loss':    99.3293, 'lr':   5.80e-05, 'eps_e':     0.9001, 'lr_e':   5.80e-05})
Step:  310000, Reward:   153.062 [  55.640], Avg:   134.212 (0.000) <0-07:36:05> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 159607.7280, 'dyn_loss':     0.0826, 'dot_loss':     0.0212, 'ddot_loss':     0.0366, 'rew_loss':   101.1570, 'lr':   5.80e-05, 'eps_e':     0.0001, 'lr_e':   5.80e-05})
Step:  311000, Reward:   146.375 [  54.773], Avg:   134.251 (0.100) <0-07:38:29> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 160199.2590, 'dyn_loss':     0.0823, 'dot_loss':     0.0214, 'ddot_loss':     0.0370, 'rew_loss':   100.6277, 'lr':   5.68e-05, 'eps_e':     0.1001, 'lr_e':   5.68e-05})
Step:  312000, Reward:   147.125 [  54.207], Avg:   134.293 (0.200) <0-07:40:41> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 160301.7510, 'dyn_loss':     0.0821, 'dot_loss':     0.0210, 'ddot_loss':     0.0361, 'rew_loss':    99.3796, 'lr':   5.68e-05, 'eps_e':     0.2001, 'lr_e':   5.68e-05})
Step:  313000, Reward:   132.875 [  54.634], Avg:   134.288 (0.300) <0-07:42:41> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 160426.6780, 'dyn_loss':     0.0821, 'dot_loss':     0.0211, 'ddot_loss':     0.0366, 'rew_loss':    99.6873, 'lr':   5.68e-05, 'eps_e':     0.3001, 'lr_e':   5.68e-05})
Step:  314000, Reward:   154.438 [  52.854], Avg:   134.352 (0.400) <0-07:44:29> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 160612.7040, 'dyn_loss':     0.0825, 'dot_loss':     0.0214, 'ddot_loss':     0.0372, 'rew_loss':   100.7118, 'lr':   5.68e-05, 'eps_e':     0.4001, 'lr_e':   5.68e-05})
Step:  315000, Reward:   129.062 [  51.422], Avg:   134.335 (0.500) <0-07:46:04> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 160854.6440, 'dyn_loss':     0.0847, 'dot_loss':     0.0210, 'ddot_loss':     0.0360, 'rew_loss':   103.1480, 'lr':   5.68e-05, 'eps_e':     0.5001, 'lr_e':   5.68e-05})
Step:  316000, Reward:   121.688 [  71.581], Avg:   134.295 (0.600) <0-07:47:28> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 161208.8930, 'dyn_loss':     0.0821, 'dot_loss':     0.0210, 'ddot_loss':     0.0364, 'rew_loss':    98.4530, 'lr':   5.68e-05, 'eps_e':     0.6001, 'lr_e':   5.68e-05})
Step:  317000, Reward:   136.500 [  58.410], Avg:   134.302 (0.700) <0-07:48:41> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 161719.6870, 'dyn_loss':     0.0802, 'dot_loss':     0.0211, 'ddot_loss':     0.0367, 'rew_loss':    99.9854, 'lr':   5.68e-05, 'eps_e':     0.7001, 'lr_e':   5.68e-05})
Step:  318000, Reward:   123.438 [  62.276], Avg:   134.268 (0.800) <0-07:49:40> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 162447.8240, 'dyn_loss':     0.0810, 'dot_loss':     0.0210, 'ddot_loss':     0.0363, 'rew_loss':    99.2780, 'lr':   5.68e-05, 'eps_e':     0.8001, 'lr_e':   5.68e-05})
Step:  319000, Reward:   152.062 [  55.414], Avg:   134.324 (0.900) <0-07:50:29> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 163373.1790, 'dyn_loss':     0.0787, 'dot_loss':     0.0211, 'ddot_loss':     0.0371, 'rew_loss':   100.1344, 'lr':   5.68e-05, 'eps_e':     0.9001, 'lr_e':   5.68e-05})
Step:  320000, Reward:   147.875 [  49.408], Avg:   134.366 (0.000) <0-07:51:08> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 164432.5820, 'dyn_loss':     0.0817, 'dot_loss':     0.0215, 'ddot_loss':     0.0376, 'rew_loss':   100.7562, 'lr':   5.68e-05, 'eps_e':     0.0001, 'lr_e':   5.68e-05})
Step:  321000, Reward:   122.000 [  50.993], Avg:   134.328 (0.100) <0-07:53:32> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 165025.2980, 'dyn_loss':     0.0828, 'dot_loss':     0.0208, 'ddot_loss':     0.0360, 'rew_loss':   103.2857, 'lr':   5.68e-05, 'eps_e':     0.1001, 'lr_e':   5.68e-05})
Step:  322000, Reward:   155.938 [  61.657], Avg:   134.395 (0.200) <0-07:55:44> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 165127.5510, 'dyn_loss':     0.0820, 'dot_loss':     0.0213, 'ddot_loss':     0.0369, 'rew_loss':   100.1396, 'lr':   5.57e-05, 'eps_e':     0.2001, 'lr_e':   5.57e-05})
Step:  323000, Reward:   133.938 [  70.565], Avg:   134.393 (0.300) <0-07:57:44> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 165263.5790, 'dyn_loss':     0.0800, 'dot_loss':     0.0210, 'ddot_loss':     0.0365, 'rew_loss':    96.7754, 'lr':   5.57e-05, 'eps_e':     0.3001, 'lr_e':   5.57e-05})
Step:  324000, Reward:   142.625 [  51.005], Avg:   134.418 (0.400) <0-07:59:32> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 165434.0580, 'dyn_loss':     0.0825, 'dot_loss':     0.0210, 'ddot_loss':     0.0364, 'rew_loss':   100.0243, 'lr':   5.57e-05, 'eps_e':     0.4001, 'lr_e':   5.57e-05})
Step:  325000, Reward:   129.875 [  78.572], Avg:   134.405 (0.500) <0-08:01:08> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 165664.2420, 'dyn_loss':     0.0806, 'dot_loss':     0.0211, 'ddot_loss':     0.0366, 'rew_loss':   100.4017, 'lr':   5.57e-05, 'eps_e':     0.5001, 'lr_e':   5.57e-05})
Step:  326000, Reward:   146.000 [  67.923], Avg:   134.440 (0.600) <0-08:02:32> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 166010.2770, 'dyn_loss':     0.0831, 'dot_loss':     0.0207, 'ddot_loss':     0.0356, 'rew_loss':   101.6517, 'lr':   5.57e-05, 'eps_e':     0.6001, 'lr_e':   5.57e-05})
Step:  327000, Reward:   136.000 [  61.451], Avg:   134.445 (0.700) <0-08:03:44> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 166548.5470, 'dyn_loss':     0.0819, 'dot_loss':     0.0210, 'ddot_loss':     0.0362, 'rew_loss':   100.5579, 'lr':   5.57e-05, 'eps_e':     0.7001, 'lr_e':   5.57e-05})
Step:  328000, Reward:   133.938 [  58.723], Avg:   134.443 (0.800) <0-08:04:45> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 167280.7910, 'dyn_loss':     0.0816, 'dot_loss':     0.0211, 'ddot_loss':     0.0367, 'rew_loss':   101.8706, 'lr':   5.57e-05, 'eps_e':     0.8001, 'lr_e':   5.57e-05})
Step:  329000, Reward:   122.312 [  61.705], Avg:   134.406 (0.900) <0-08:05:33> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 168193.8330, 'dyn_loss':     0.0798, 'dot_loss':     0.0211, 'ddot_loss':     0.0369, 'rew_loss':    99.4451, 'lr':   5.57e-05, 'eps_e':     0.9001, 'lr_e':   5.57e-05})
Step:  330000, Reward:   132.938 [  66.889], Avg:   134.402 (0.000) <0-08:06:13> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 169240.3810, 'dyn_loss':     0.0784, 'dot_loss':     0.0211, 'ddot_loss':     0.0372, 'rew_loss':   101.0415, 'lr':   5.57e-05, 'eps_e':     0.0001, 'lr_e':   5.57e-05})
Step:  331000, Reward:   165.438 [  59.902], Avg:   134.495 (0.100) <0-08:08:37> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 169849.9200, 'dyn_loss':     0.0799, 'dot_loss':     0.0212, 'ddot_loss':     0.0373, 'rew_loss':   102.3353, 'lr':   5.57e-05, 'eps_e':     0.1001, 'lr_e':   5.57e-05})
Step:  332000, Reward:   158.312 [  49.719], Avg:   134.567 (0.200) <0-08:10:49> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 169946.3570, 'dyn_loss':     0.0831, 'dot_loss':     0.0211, 'ddot_loss':     0.0366, 'rew_loss':    99.0419, 'lr':   5.57e-05, 'eps_e':     0.2001, 'lr_e':   5.57e-05})
Step:  333000, Reward:   109.562 [  60.892], Avg:   134.492 (0.300) <0-08:12:48> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 170072.9340, 'dyn_loss':     0.0800, 'dot_loss':     0.0211, 'ddot_loss':     0.0369, 'rew_loss':    97.7721, 'lr':   5.45e-05, 'eps_e':     0.3001, 'lr_e':   5.45e-05})
Step:  334000, Reward:   140.688 [  64.808], Avg:   134.511 (0.400) <0-08:14:37> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 170228.9990, 'dyn_loss':     0.0822, 'dot_loss':     0.0213, 'ddot_loss':     0.0371, 'rew_loss':   104.7450, 'lr':   5.45e-05, 'eps_e':     0.4001, 'lr_e':   5.45e-05})
Step:  335000, Reward:   126.500 [  58.169], Avg:   134.487 (0.500) <0-08:16:13> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 170448.2040, 'dyn_loss':     0.0754, 'dot_loss':     0.0210, 'ddot_loss':     0.0371, 'rew_loss':    98.7926, 'lr':   5.45e-05, 'eps_e':     0.5001, 'lr_e':   5.45e-05})
Step:  336000, Reward:   184.188 [  30.297], Avg:   134.634 (0.600) <0-08:17:37> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 170799.9280, 'dyn_loss':     0.0810, 'dot_loss':     0.0212, 'ddot_loss':     0.0373, 'rew_loss':    98.5945, 'lr':   5.45e-05, 'eps_e':     0.6001, 'lr_e':   5.45e-05})
Step:  337000, Reward:   125.625 [  78.687], Avg:   134.608 (0.700) <0-08:18:49> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 171314.3270, 'dyn_loss':     0.0816, 'dot_loss':     0.0210, 'ddot_loss':     0.0364, 'rew_loss':    98.3354, 'lr':   5.45e-05, 'eps_e':     0.7001, 'lr_e':   5.45e-05})
Step:  338000, Reward:   145.062 [  54.910], Avg:   134.638 (0.800) <0-08:19:49> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 172028.6900, 'dyn_loss':     0.0806, 'dot_loss':     0.0209, 'ddot_loss':     0.0366, 'rew_loss':   101.2886, 'lr':   5.45e-05, 'eps_e':     0.8001, 'lr_e':   5.45e-05})
Step:  339000, Reward:   142.312 [  62.888], Avg:   134.661 (0.900) <0-08:20:38> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 172907.1230, 'dyn_loss':     0.0829, 'dot_loss':     0.0209, 'ddot_loss':     0.0362, 'rew_loss':    98.5023, 'lr':   5.45e-05, 'eps_e':     0.9001, 'lr_e':   5.45e-05})
Step:  340000, Reward:   139.250 [  58.600], Avg:   134.674 (0.000) <0-08:21:17> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 173950.2210, 'dyn_loss':     0.0824, 'dot_loss':     0.0212, 'ddot_loss':     0.0368, 'rew_loss':   100.4430, 'lr':   5.45e-05, 'eps_e':     0.0001, 'lr_e':   5.45e-05})
Step:  341000, Reward:   161.438 [  45.064], Avg:   134.753 (0.100) <0-08:23:41> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 174563.4610, 'dyn_loss':     0.0798, 'dot_loss':     0.0207, 'ddot_loss':     0.0361, 'rew_loss':   101.3365, 'lr':   5.45e-05, 'eps_e':     0.1001, 'lr_e':   5.45e-05})
Step:  342000, Reward:   132.000 [  68.560], Avg:   134.745 (0.200) <0-08:25:54> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 174662.4430, 'dyn_loss':     0.0818, 'dot_loss':     0.0211, 'ddot_loss':     0.0364, 'rew_loss':   103.4793, 'lr':   5.45e-05, 'eps_e':     0.2001, 'lr_e':   5.45e-05})
Step:  343000, Reward:   168.875 [  35.640], Avg:   134.844 (0.300) <0-08:27:54> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 174793.9290, 'dyn_loss':     0.0808, 'dot_loss':     0.0209, 'ddot_loss':     0.0364, 'rew_loss':   101.9595, 'lr':   5.45e-05, 'eps_e':     0.3001, 'lr_e':   5.45e-05})
Step:  344000, Reward:   133.625 [  68.494], Avg:   134.840 (0.400) <0-08:29:42> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 174962.4370, 'dyn_loss':     0.0814, 'dot_loss':     0.0210, 'ddot_loss':     0.0364, 'rew_loss':   100.4891, 'lr':   5.35e-05, 'eps_e':     0.4001, 'lr_e':   5.35e-05})
Step:  345000, Reward:   149.188 [  60.202], Avg:   134.882 (0.500) <0-08:31:18> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 175200.3200, 'dyn_loss':     0.0837, 'dot_loss':     0.0208, 'ddot_loss':     0.0357, 'rew_loss':    98.8653, 'lr':   5.35e-05, 'eps_e':     0.5001, 'lr_e':   5.35e-05})
Step:  346000, Reward:   178.000 [  38.221], Avg:   135.006 (0.600) <0-08:32:42> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 175565.0680, 'dyn_loss':     0.0771, 'dot_loss':     0.0212, 'ddot_loss':     0.0374, 'rew_loss':    95.8772, 'lr':   5.35e-05, 'eps_e':     0.6001, 'lr_e':   5.35e-05})
Step:  347000, Reward:   156.438 [  47.449], Avg:   135.068 (0.700) <0-08:33:55> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 176069.3160, 'dyn_loss':     0.0811, 'dot_loss':     0.0209, 'ddot_loss':     0.0362, 'rew_loss':   101.1071, 'lr':   5.35e-05, 'eps_e':     0.7001, 'lr_e':   5.35e-05})
Step:  348000, Reward:   143.062 [  52.891], Avg:   135.091 (0.800) <0-08:34:56> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 176790.3190, 'dyn_loss':     0.0791, 'dot_loss':     0.0208, 'ddot_loss':     0.0363, 'rew_loss':   101.7100, 'lr':   5.35e-05, 'eps_e':     0.8001, 'lr_e':   5.35e-05})
Step:  349000, Reward:   153.562 [  55.113], Avg:   135.143 (0.900) <0-08:35:44> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 177702.5160, 'dyn_loss':     0.0833, 'dot_loss':     0.0210, 'ddot_loss':     0.0362, 'rew_loss':    99.2196, 'lr':   5.35e-05, 'eps_e':     0.9001, 'lr_e':   5.35e-05})
Step:  350000, Reward:   116.438 [  54.320], Avg:   135.090 (0.000) <0-08:36:23> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 178724.2330, 'dyn_loss':     0.0784, 'dot_loss':     0.0211, 'ddot_loss':     0.0369, 'rew_loss':    98.9549, 'lr':   5.35e-05, 'eps_e':     0.0001, 'lr_e':   5.35e-05})
Step:  351000, Reward:   153.312 [  55.682], Avg:   135.142 (0.100) <0-08:38:48> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 179308.0930, 'dyn_loss':     0.0821, 'dot_loss':     0.0207, 'ddot_loss':     0.0360, 'rew_loss':   103.2766, 'lr':   5.35e-05, 'eps_e':     0.1001, 'lr_e':   5.35e-05})
Step:  352000, Reward:   162.875 [  36.326], Avg:   135.220 (0.200) <0-08:41:00> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 179410.8550, 'dyn_loss':     0.0789, 'dot_loss':     0.0209, 'ddot_loss':     0.0368, 'rew_loss':   101.8176, 'lr':   5.35e-05, 'eps_e':     0.2001, 'lr_e':   5.35e-05})
Step:  353000, Reward:   156.750 [  61.949], Avg:   135.281 (0.300) <0-08:43:01> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 179538.4160, 'dyn_loss':     0.0796, 'dot_loss':     0.0212, 'ddot_loss':     0.0371, 'rew_loss':   100.4923, 'lr':   5.35e-05, 'eps_e':     0.3001, 'lr_e':   5.35e-05})
Step:  354000, Reward:   139.500 [  70.234], Avg:   135.293 (0.400) <0-08:44:49> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 179701.0490, 'dyn_loss':     0.0811, 'dot_loss':     0.0208, 'ddot_loss':     0.0360, 'rew_loss':   102.8693, 'lr':   5.35e-05, 'eps_e':     0.4001, 'lr_e':   5.35e-05})
Step:  355000, Reward:   143.750 [  51.518], Avg:   135.317 (0.500) <0-08:46:26> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 179923.5690, 'dyn_loss':     0.0792, 'dot_loss':     0.0205, 'ddot_loss':     0.0359, 'rew_loss':    99.8619, 'lr':   5.24e-05, 'eps_e':     0.5001, 'lr_e':   5.24e-05})
Step:  356000, Reward:   141.562 [  59.186], Avg:   135.334 (0.600) <0-08:47:51> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 180284.2680, 'dyn_loss':     0.0826, 'dot_loss':     0.0210, 'ddot_loss':     0.0365, 'rew_loss':   100.8160, 'lr':   5.24e-05, 'eps_e':     0.6001, 'lr_e':   5.24e-05})
Step:  357000, Reward:   140.562 [  65.620], Avg:   135.349 (0.700) <0-08:49:04> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 180804.2980, 'dyn_loss':     0.0785, 'dot_loss':     0.0208, 'ddot_loss':     0.0366, 'rew_loss':    99.3323, 'lr':   5.24e-05, 'eps_e':     0.7001, 'lr_e':   5.24e-05})
Step:  358000, Reward:   130.438 [  57.131], Avg:   135.335 (0.800) <0-08:50:04> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 181526.3980, 'dyn_loss':     0.0823, 'dot_loss':     0.0207, 'ddot_loss':     0.0357, 'rew_loss':   103.0414, 'lr':   5.24e-05, 'eps_e':     0.8001, 'lr_e':   5.24e-05})
Step:  359000, Reward:   164.938 [  47.838], Avg:   135.418 (0.900) <0-08:50:54> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 182462.9520, 'dyn_loss':     0.0809, 'dot_loss':     0.0209, 'ddot_loss':     0.0362, 'rew_loss':    97.6491, 'lr':   5.24e-05, 'eps_e':     0.9001, 'lr_e':   5.24e-05})
Step:  360000, Reward:   137.438 [  44.282], Avg:   135.423 (0.000) <0-08:51:34> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 183562.0020, 'dyn_loss':     0.0788, 'dot_loss':     0.0209, 'ddot_loss':     0.0365, 'rew_loss':    99.1675, 'lr':   5.24e-05, 'eps_e':     0.0001, 'lr_e':   5.24e-05})
Step:  361000, Reward:   146.625 [  48.049], Avg:   135.454 (0.100) <0-08:53:58> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 184165.6960, 'dyn_loss':     0.0799, 'dot_loss':     0.0210, 'ddot_loss':     0.0364, 'rew_loss':    99.3490, 'lr':   5.24e-05, 'eps_e':     0.1001, 'lr_e':   5.24e-05})
Step:  362000, Reward:   141.625 [  64.062], Avg:   135.471 (0.200) <0-08:56:12> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 184274.7990, 'dyn_loss':     0.0833, 'dot_loss':     0.0208, 'ddot_loss':     0.0355, 'rew_loss':   100.4532, 'lr':   5.24e-05, 'eps_e':     0.2001, 'lr_e':   5.24e-05})
Step:  363000, Reward:   160.312 [  33.863], Avg:   135.539 (0.300) <0-08:58:12> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 184401.3290, 'dyn_loss':     0.0823, 'dot_loss':     0.0209, 'ddot_loss':     0.0360, 'rew_loss':    98.4110, 'lr':   5.24e-05, 'eps_e':     0.3001, 'lr_e':   5.24e-05})
Step:  364000, Reward:   146.812 [  62.705], Avg:   135.570 (0.400) <0-09:00:01> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 184553.1500, 'dyn_loss':     0.0808, 'dot_loss':     0.0211, 'ddot_loss':     0.0368, 'rew_loss':    97.6425, 'lr':   5.24e-05, 'eps_e':     0.4001, 'lr_e':   5.24e-05})
Step:  365000, Reward:   129.312 [  60.736], Avg:   135.553 (0.500) <0-09:01:37> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 184782.3250, 'dyn_loss':     0.0816, 'dot_loss':     0.0211, 'ddot_loss':     0.0367, 'rew_loss':   103.0996, 'lr':   5.24e-05, 'eps_e':     0.5001, 'lr_e':   5.24e-05})
Step:  366000, Reward:   146.188 [  48.060], Avg:   135.582 (0.600) <0-09:03:03> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 185135.2900, 'dyn_loss':     0.0802, 'dot_loss':     0.0211, 'ddot_loss':     0.0365, 'rew_loss':    98.8754, 'lr':   5.13e-05, 'eps_e':     0.6001, 'lr_e':   5.13e-05})
Step:  367000, Reward:   154.000 [  49.256], Avg:   135.632 (0.700) <0-09:04:15> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 185675.5730, 'dyn_loss':     0.0797, 'dot_loss':     0.0208, 'ddot_loss':     0.0364, 'rew_loss':   100.5732, 'lr':   5.13e-05, 'eps_e':     0.7001, 'lr_e':   5.13e-05})
Step:  368000, Reward:   157.312 [  45.322], Avg:   135.691 (0.800) <0-09:05:16> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 186420.0100, 'dyn_loss':     0.0771, 'dot_loss':     0.0207, 'ddot_loss':     0.0365, 'rew_loss':   101.2525, 'lr':   5.13e-05, 'eps_e':     0.8001, 'lr_e':   5.13e-05})
Step:  369000, Reward:   162.125 [  63.970], Avg:   135.762 (0.900) <0-09:06:05> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 187338.6610, 'dyn_loss':     0.0806, 'dot_loss':     0.0207, 'ddot_loss':     0.0361, 'rew_loss':    98.1210, 'lr':   5.13e-05, 'eps_e':     0.9001, 'lr_e':   5.13e-05})
Step:  370000, Reward:   147.250 [  63.130], Avg:   135.793 (0.000) <0-09:06:44> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 188404.1310, 'dyn_loss':     0.0798, 'dot_loss':     0.0208, 'ddot_loss':     0.0361, 'rew_loss':    99.7503, 'lr':   5.13e-05, 'eps_e':     0.0001, 'lr_e':   5.13e-05})
Step:  371000, Reward:   163.062 [  44.289], Avg:   135.867 (0.100) <0-09:09:09> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 189008.2670, 'dyn_loss':     0.0793, 'dot_loss':     0.0210, 'ddot_loss':     0.0366, 'rew_loss':    99.7902, 'lr':   5.13e-05, 'eps_e':     0.1001, 'lr_e':   5.13e-05})
Step:  372000, Reward:   122.312 [  54.327], Avg:   135.830 (0.200) <0-09:11:22> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 189110.1150, 'dyn_loss':     0.0789, 'dot_loss':     0.0209, 'ddot_loss':     0.0365, 'rew_loss':   100.0301, 'lr':   5.13e-05, 'eps_e':     0.2001, 'lr_e':   5.13e-05})
Step:  373000, Reward:   146.438 [  65.988], Avg:   135.859 (0.300) <0-09:13:23> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 189240.9890, 'dyn_loss':     0.0798, 'dot_loss':     0.0206, 'ddot_loss':     0.0358, 'rew_loss':    96.2053, 'lr':   5.13e-05, 'eps_e':     0.3001, 'lr_e':   5.13e-05})
Step:  374000, Reward:   168.688 [  40.968], Avg:   135.946 (0.400) <0-09:15:12> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 189402.1590, 'dyn_loss':     0.0789, 'dot_loss':     0.0210, 'ddot_loss':     0.0370, 'rew_loss':    98.8675, 'lr':   5.13e-05, 'eps_e':     0.4001, 'lr_e':   5.13e-05})
Step:  375000, Reward:   155.562 [  59.665], Avg:   135.998 (0.500) <0-09:16:49> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 189640.1500, 'dyn_loss':     0.0788, 'dot_loss':     0.0210, 'ddot_loss':     0.0368, 'rew_loss':    98.7115, 'lr':   5.13e-05, 'eps_e':     0.5001, 'lr_e':   5.13e-05})
Step:  376000, Reward:   151.750 [  67.822], Avg:   136.040 (0.600) <0-09:18:13> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 189982.2920, 'dyn_loss':     0.0823, 'dot_loss':     0.0208, 'ddot_loss':     0.0361, 'rew_loss':   103.6681, 'lr':   5.13e-05, 'eps_e':     0.6001, 'lr_e':   5.13e-05})
Step:  377000, Reward:   179.688 [  32.836], Avg:   136.156 (0.700) <0-09:19:28> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 190493.1760, 'dyn_loss':     0.0791, 'dot_loss':     0.0207, 'ddot_loss':     0.0360, 'rew_loss':   100.4250, 'lr':   5.03e-05, 'eps_e':     0.7001, 'lr_e':   5.03e-05})
Step:  378000, Reward:   155.250 [  54.906], Avg:   136.206 (0.800) <0-09:20:31> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 191219.5060, 'dyn_loss':     0.0819, 'dot_loss':     0.0211, 'ddot_loss':     0.0366, 'rew_loss':   105.0341, 'lr':   5.03e-05, 'eps_e':     0.8001, 'lr_e':   5.03e-05})
Step:  379000, Reward:   156.188 [  68.381], Avg:   136.259 (0.900) <0-09:21:20> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 192137.4590, 'dyn_loss':     0.0798, 'dot_loss':     0.0210, 'ddot_loss':     0.0367, 'rew_loss':    98.2901, 'lr':   5.03e-05, 'eps_e':     0.9001, 'lr_e':   5.03e-05})
Step:  380000, Reward:   139.875 [  56.943], Avg:   136.268 (0.000) <0-09:22:00> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 193220.2110, 'dyn_loss':     0.0757, 'dot_loss':     0.0207, 'ddot_loss':     0.0369, 'rew_loss':    97.3005, 'lr':   5.03e-05, 'eps_e':     0.0001, 'lr_e':   5.03e-05})
Step:  381000, Reward:    99.375 [  61.731], Avg:   136.171 (0.100) <0-09:24:24> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 193822.3310, 'dyn_loss':     0.0790, 'dot_loss':     0.0208, 'ddot_loss':     0.0362, 'rew_loss':    98.3751, 'lr':   5.03e-05, 'eps_e':     0.1001, 'lr_e':   5.03e-05})
Step:  382000, Reward:   167.938 [  53.067], Avg:   136.254 (0.200) <0-09:26:37> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 193930.4830, 'dyn_loss':     0.0802, 'dot_loss':     0.0208, 'ddot_loss':     0.0361, 'rew_loss':   101.6179, 'lr':   5.03e-05, 'eps_e':     0.2001, 'lr_e':   5.03e-05})
Step:  383000, Reward:   170.562 [  43.126], Avg:   136.344 (0.300) <0-09:28:38> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 194053.9990, 'dyn_loss':     0.0819, 'dot_loss':     0.0205, 'ddot_loss':     0.0354, 'rew_loss':   104.0648, 'lr':   5.03e-05, 'eps_e':     0.3001, 'lr_e':   5.03e-05})
Step:  384000, Reward:   163.438 [  55.042], Avg:   136.414 (0.400) <0-09:30:27> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 194208.5880, 'dyn_loss':     0.0802, 'dot_loss':     0.0208, 'ddot_loss':     0.0360, 'rew_loss':   102.9681, 'lr':   5.03e-05, 'eps_e':     0.4001, 'lr_e':   5.03e-05})
Step:  385000, Reward:   144.438 [  65.367], Avg:   136.435 (0.500) <0-09:32:04> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 194447.5620, 'dyn_loss':     0.0811, 'dot_loss':     0.0208, 'ddot_loss':     0.0361, 'rew_loss':   100.6129, 'lr':   5.03e-05, 'eps_e':     0.5001, 'lr_e':   5.03e-05})
Step:  386000, Reward:   148.125 [  47.229], Avg:   136.465 (0.600) <0-09:33:29> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 194807.0160, 'dyn_loss':     0.0813, 'dot_loss':     0.0207, 'ddot_loss':     0.0357, 'rew_loss':   102.9913, 'lr':   5.03e-05, 'eps_e':     0.6001, 'lr_e':   5.03e-05})
Step:  387000, Reward:   164.625 [  43.141], Avg:   136.538 (0.700) <0-09:34:42> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 195320.3510, 'dyn_loss':     0.0811, 'dot_loss':     0.0210, 'ddot_loss':     0.0368, 'rew_loss':   101.6461, 'lr':   5.03e-05, 'eps_e':     0.7001, 'lr_e':   5.03e-05})
Step:  388000, Reward:   160.250 [  50.317], Avg:   136.599 (0.800) <0-09:35:43> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 196028.0390, 'dyn_loss':     0.0755, 'dot_loss':     0.0207, 'ddot_loss':     0.0369, 'rew_loss':   100.6270, 'lr':   4.93e-05, 'eps_e':     0.8001, 'lr_e':   4.93e-05})
Step:  389000, Reward:   117.938 [  63.881], Avg:   136.551 (0.900) <0-09:36:32> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 196945.8860, 'dyn_loss':     0.0795, 'dot_loss':     0.0208, 'ddot_loss':     0.0365, 'rew_loss':   101.6827, 'lr':   4.93e-05, 'eps_e':     0.9001, 'lr_e':   4.93e-05})
Step:  390000, Reward:   162.812 [  46.736], Avg:   136.618 (0.000) <0-09:37:11> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 197978.4020, 'dyn_loss':     0.0805, 'dot_loss':     0.0206, 'ddot_loss':     0.0357, 'rew_loss':    99.7428, 'lr':   4.93e-05, 'eps_e':     0.0001, 'lr_e':   4.93e-05})
Step:  391000, Reward:   127.875 [  66.484], Avg:   136.596 (0.100) <0-09:39:37> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 198564.6500, 'dyn_loss':     0.0818, 'dot_loss':     0.0205, 'ddot_loss':     0.0353, 'rew_loss':    99.8290, 'lr':   4.93e-05, 'eps_e':     0.1001, 'lr_e':   4.93e-05})
Step:  392000, Reward:   158.438 [  53.963], Avg:   136.651 (0.200) <0-09:41:50> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 198662.6930, 'dyn_loss':     0.0801, 'dot_loss':     0.0208, 'ddot_loss':     0.0363, 'rew_loss':    98.7802, 'lr':   4.93e-05, 'eps_e':     0.2001, 'lr_e':   4.93e-05})
Step:  393000, Reward:   158.812 [  53.571], Avg:   136.707 (0.300) <0-09:43:51> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 198796.6630, 'dyn_loss':     0.0811, 'dot_loss':     0.0207, 'ddot_loss':     0.0358, 'rew_loss':    99.0318, 'lr':   4.93e-05, 'eps_e':     0.3001, 'lr_e':   4.93e-05})
Step:  394000, Reward:   160.312 [  53.427], Avg:   136.767 (0.400) <0-09:45:41> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 198980.6170, 'dyn_loss':     0.0784, 'dot_loss':     0.0206, 'ddot_loss':     0.0362, 'rew_loss':   104.3633, 'lr':   4.93e-05, 'eps_e':     0.4001, 'lr_e':   4.93e-05})
Step:  395000, Reward:   147.688 [  66.317], Avg:   136.795 (0.500) <0-09:47:18> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 199225.8230, 'dyn_loss':     0.0810, 'dot_loss':     0.0207, 'ddot_loss':     0.0357, 'rew_loss':    99.6464, 'lr':   4.93e-05, 'eps_e':     0.5001, 'lr_e':   4.93e-05})
Step:  396000, Reward:   139.938 [  61.289], Avg:   136.803 (0.600) <0-09:48:44> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 199565.3870, 'dyn_loss':     0.0825, 'dot_loss':     0.0205, 'ddot_loss':     0.0355, 'rew_loss':   103.4221, 'lr':   4.93e-05, 'eps_e':     0.6001, 'lr_e':   4.93e-05})
Step:  397000, Reward:    93.000 [  63.460], Avg:   136.693 (0.700) <0-09:49:57> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 200077.5360, 'dyn_loss':     0.0765, 'dot_loss':     0.0207, 'ddot_loss':     0.0365, 'rew_loss':   100.4536, 'lr':   4.93e-05, 'eps_e':     0.7001, 'lr_e':   4.93e-05})
Step:  398000, Reward:   168.125 [  41.369], Avg:   136.771 (0.800) <0-09:50:58> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 200793.3320, 'dyn_loss':     0.0830, 'dot_loss':     0.0208, 'ddot_loss':     0.0361, 'rew_loss':    98.9369, 'lr':   4.93e-05, 'eps_e':     0.8001, 'lr_e':   4.93e-05})
Step:  399000, Reward:   156.000 [  37.074], Avg:   136.820 (0.900) <0-09:51:49> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 201690.2100, 'dyn_loss':     0.0782, 'dot_loss':     0.0204, 'ddot_loss':     0.0356, 'rew_loss':    99.6672, 'lr':   4.83e-05, 'eps_e':     0.9001, 'lr_e':   4.83e-05})
Step:  400000, Reward:   138.375 [  62.958], Avg:   136.823 (0.000) <0-09:52:28> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 202746.4370, 'dyn_loss':     0.0800, 'dot_loss':     0.0204, 'ddot_loss':     0.0354, 'rew_loss':    97.6472, 'lr':   4.83e-05, 'eps_e':     0.0001, 'lr_e':   4.83e-05})
Step:  401000, Reward:   152.188 [  51.902], Avg:   136.862 (0.100) <0-09:54:55> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 203331.1560, 'dyn_loss':     0.0814, 'dot_loss':     0.0207, 'ddot_loss':     0.0360, 'rew_loss':    97.4385, 'lr':   4.83e-05, 'eps_e':     0.1001, 'lr_e':   4.83e-05})
Step:  402000, Reward:   136.062 [  51.399], Avg:   136.860 (0.200) <0-09:57:09> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 203435.0430, 'dyn_loss':     0.0815, 'dot_loss':     0.0207, 'ddot_loss':     0.0357, 'rew_loss':   102.2102, 'lr':   4.83e-05, 'eps_e':     0.2001, 'lr_e':   4.83e-05})
Step:  403000, Reward:   156.812 [  62.655], Avg:   136.909 (0.300) <0-09:59:12> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 203567.2640, 'dyn_loss':     0.0773, 'dot_loss':     0.0206, 'ddot_loss':     0.0362, 'rew_loss':   100.4723, 'lr':   4.83e-05, 'eps_e':     0.3001, 'lr_e':   4.83e-05})
Step:  404000, Reward:   157.000 [  61.155], Avg:   136.959 (0.400) <0-10:01:01> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 203725.1390, 'dyn_loss':     0.0833, 'dot_loss':     0.0207, 'ddot_loss':     0.0357, 'rew_loss':   100.7726, 'lr':   4.83e-05, 'eps_e':     0.4001, 'lr_e':   4.83e-05})
Step:  405000, Reward:   145.188 [  51.898], Avg:   136.979 (0.500) <0-10:02:40> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 203947.6270, 'dyn_loss':     0.0794, 'dot_loss':     0.0207, 'ddot_loss':     0.0360, 'rew_loss':    98.2795, 'lr':   4.83e-05, 'eps_e':     0.5001, 'lr_e':   4.83e-05})
Step:  406000, Reward:   153.312 [  70.118], Avg:   137.019 (0.600) <0-10:04:07> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 204293.3250, 'dyn_loss':     0.0791, 'dot_loss':     0.0206, 'ddot_loss':     0.0361, 'rew_loss':   101.7716, 'lr':   4.83e-05, 'eps_e':     0.6001, 'lr_e':   4.83e-05})
Step:  407000, Reward:   145.500 [  61.715], Avg:   137.040 (0.700) <0-10:05:20> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 204822.1140, 'dyn_loss':     0.0818, 'dot_loss':     0.0206, 'ddot_loss':     0.0360, 'rew_loss':   101.1978, 'lr':   4.83e-05, 'eps_e':     0.7001, 'lr_e':   4.83e-05})
Step:  408000, Reward:   128.125 [  68.386], Avg:   137.018 (0.800) <0-10:06:22> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 205542.0680, 'dyn_loss':     0.0799, 'dot_loss':     0.0208, 'ddot_loss':     0.0362, 'rew_loss':    96.7218, 'lr':   4.83e-05, 'eps_e':     0.8001, 'lr_e':   4.83e-05})
Step:  409000, Reward:   176.625 [  39.354], Avg:   137.115 (0.900) <0-10:07:12> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 206435.2550, 'dyn_loss':     0.0784, 'dot_loss':     0.0205, 'ddot_loss':     0.0359, 'rew_loss':   101.6080, 'lr':   4.83e-05, 'eps_e':     0.9001, 'lr_e':   4.83e-05})
Step:  410000, Reward:   146.188 [  62.093], Avg:   137.137 (0.000) <0-10:07:52> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 207464.3810, 'dyn_loss':     0.0795, 'dot_loss':     0.0206, 'ddot_loss':     0.0361, 'rew_loss':   100.0686, 'lr':   4.74e-05, 'eps_e':     0.0001, 'lr_e':   4.74e-05})
Step:  411000, Reward:   179.938 [  33.911], Avg:   137.241 (0.100) <0-10:10:18> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 208053.0900, 'dyn_loss':     0.0803, 'dot_loss':     0.0206, 'ddot_loss':     0.0359, 'rew_loss':    99.9582, 'lr':   4.74e-05, 'eps_e':     0.1001, 'lr_e':   4.74e-05})
Step:  412000, Reward:   154.188 [  53.574], Avg:   137.282 (0.200) <0-10:12:33> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 208158.3780, 'dyn_loss':     0.0787, 'dot_loss':     0.0210, 'ddot_loss':     0.0368, 'rew_loss':   100.4446, 'lr':   4.74e-05, 'eps_e':     0.2001, 'lr_e':   4.74e-05})
Step:  413000, Reward:   149.188 [  51.247], Avg:   137.310 (0.300) <0-10:14:35> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 208288.9620, 'dyn_loss':     0.0815, 'dot_loss':     0.0207, 'ddot_loss':     0.0359, 'rew_loss':   103.4396, 'lr':   4.74e-05, 'eps_e':     0.3001, 'lr_e':   4.74e-05})
Step:  414000, Reward:   142.938 [  54.873], Avg:   137.324 (0.400) <0-10:16:26> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 208452.0120, 'dyn_loss':     0.0788, 'dot_loss':     0.0207, 'ddot_loss':     0.0362, 'rew_loss':    99.0969, 'lr':   4.74e-05, 'eps_e':     0.4001, 'lr_e':   4.74e-05})
Step:  415000, Reward:   156.500 [  53.593], Avg:   137.370 (0.500) <0-10:18:04> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 208674.8800, 'dyn_loss':     0.0804, 'dot_loss':     0.0206, 'ddot_loss':     0.0360, 'rew_loss':    99.6343, 'lr':   4.74e-05, 'eps_e':     0.5001, 'lr_e':   4.74e-05})
Step:  416000, Reward:   151.062 [  58.437], Avg:   137.403 (0.600) <0-10:19:30> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 209025.0340, 'dyn_loss':     0.0814, 'dot_loss':     0.0206, 'ddot_loss':     0.0358, 'rew_loss':   102.1679, 'lr':   4.74e-05, 'eps_e':     0.6001, 'lr_e':   4.74e-05})
Step:  417000, Reward:   142.188 [  55.181], Avg:   137.414 (0.700) <0-10:20:44> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 209542.5160, 'dyn_loss':     0.0780, 'dot_loss':     0.0206, 'ddot_loss':     0.0360, 'rew_loss':    99.2213, 'lr':   4.74e-05, 'eps_e':     0.7001, 'lr_e':   4.74e-05})
Step:  418000, Reward:   164.625 [  49.846], Avg:   137.479 (0.800) <0-10:21:47> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 210277.1700, 'dyn_loss':     0.0812, 'dot_loss':     0.0207, 'ddot_loss':     0.0358, 'rew_loss':   103.4869, 'lr':   4.74e-05, 'eps_e':     0.8001, 'lr_e':   4.74e-05})
Step:  419000, Reward:   140.812 [  72.250], Avg:   137.487 (0.900) <0-10:22:36> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 211192.6060, 'dyn_loss':     0.0783, 'dot_loss':     0.0206, 'ddot_loss':     0.0360, 'rew_loss':    96.6546, 'lr':   4.74e-05, 'eps_e':     0.9001, 'lr_e':   4.74e-05})
Step:  420000, Reward:   143.500 [  52.753], Avg:   137.501 (0.000) <0-10:23:15> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 212268.7710, 'dyn_loss':     0.0794, 'dot_loss':     0.0204, 'ddot_loss':     0.0356, 'rew_loss':   102.6871, 'lr':   4.74e-05, 'eps_e':     0.0001, 'lr_e':   4.74e-05})
Step:  421000, Reward:   168.750 [  48.457], Avg:   137.576 (0.100) <0-10:25:43> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 212865.6330, 'dyn_loss':     0.0793, 'dot_loss':     0.0205, 'ddot_loss':     0.0359, 'rew_loss':   104.5066, 'lr':   4.64e-05, 'eps_e':     0.1001, 'lr_e':   4.64e-05})
Step:  422000, Reward:   150.438 [  46.760], Avg:   137.606 (0.200) <0-10:27:57> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 212962.7660, 'dyn_loss':     0.0818, 'dot_loss':     0.0206, 'ddot_loss':     0.0357, 'rew_loss':   101.7524, 'lr':   4.64e-05, 'eps_e':     0.2001, 'lr_e':   4.64e-05})
Step:  423000, Reward:   178.312 [  48.778], Avg:   137.702 (0.300) <0-10:30:00> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 213088.3190, 'dyn_loss':     0.0812, 'dot_loss':     0.0205, 'ddot_loss':     0.0355, 'rew_loss':   103.3484, 'lr':   4.64e-05, 'eps_e':     0.3001, 'lr_e':   4.64e-05})
Step:  424000, Reward:   179.875 [  33.397], Avg:   137.801 (0.400) <0-10:31:52> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 213248.9060, 'dyn_loss':     0.0778, 'dot_loss':     0.0208, 'ddot_loss':     0.0366, 'rew_loss':    96.8333, 'lr':   4.64e-05, 'eps_e':     0.4001, 'lr_e':   4.64e-05})
Step:  425000, Reward:   137.000 [  73.946], Avg:   137.799 (0.500) <0-10:33:30> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 213484.8600, 'dyn_loss':     0.0780, 'dot_loss':     0.0205, 'ddot_loss':     0.0362, 'rew_loss':    99.7926, 'lr':   4.64e-05, 'eps_e':     0.5001, 'lr_e':   4.64e-05})
Step:  426000, Reward:   127.250 [  63.503], Avg:   137.775 (0.600) <0-10:34:56> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 213837.8790, 'dyn_loss':     0.0804, 'dot_loss':     0.0204, 'ddot_loss':     0.0356, 'rew_loss':    99.7699, 'lr':   4.64e-05, 'eps_e':     0.6001, 'lr_e':   4.64e-05})
Step:  427000, Reward:   117.875 [  46.610], Avg:   137.728 (0.700) <0-10:36:11> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 214354.4850, 'dyn_loss':     0.0774, 'dot_loss':     0.0206, 'ddot_loss':     0.0363, 'rew_loss':    95.7586, 'lr':   4.64e-05, 'eps_e':     0.7001, 'lr_e':   4.64e-05})
Step:  428000, Reward:   136.500 [  50.310], Avg:   137.725 (0.800) <0-10:37:12> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 215067.1150, 'dyn_loss':     0.0806, 'dot_loss':     0.0207, 'ddot_loss':     0.0360, 'rew_loss':    99.4198, 'lr':   4.64e-05, 'eps_e':     0.8001, 'lr_e':   4.64e-05})
Step:  429000, Reward:   119.438 [  64.985], Avg:   137.683 (0.900) <0-10:38:02> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 215986.2560, 'dyn_loss':     0.0795, 'dot_loss':     0.0206, 'ddot_loss':     0.0355, 'rew_loss':    99.3458, 'lr':   4.64e-05, 'eps_e':     0.9001, 'lr_e':   4.64e-05})
Step:  430000, Reward:   130.938 [  63.651], Avg:   137.667 (0.000) <0-10:38:43> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 217041.4830, 'dyn_loss':     0.0798, 'dot_loss':     0.0205, 'ddot_loss':     0.0356, 'rew_loss':   102.3070, 'lr':   4.64e-05, 'eps_e':     0.0001, 'lr_e':   4.64e-05})
Step:  431000, Reward:   143.875 [  53.712], Avg:   137.681 (0.100) <0-10:41:13> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 217631.1290, 'dyn_loss':     0.0770, 'dot_loss':     0.0207, 'ddot_loss':     0.0366, 'rew_loss':    97.6010, 'lr':   4.64e-05, 'eps_e':     0.1001, 'lr_e':   4.64e-05})
Step:  432000, Reward:   142.000 [  59.740], Avg:   137.691 (0.200) <0-10:43:28> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 217743.0610, 'dyn_loss':     0.0787, 'dot_loss':     0.0205, 'ddot_loss':     0.0361, 'rew_loss':    99.2530, 'lr':   4.55e-05, 'eps_e':     0.2001, 'lr_e':   4.55e-05})
Step:  433000, Reward:   150.312 [  59.882], Avg:   137.720 (0.300) <0-10:45:32> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 217876.5080, 'dyn_loss':     0.0802, 'dot_loss':     0.0205, 'ddot_loss':     0.0355, 'rew_loss':   102.0955, 'lr':   4.55e-05, 'eps_e':     0.3001, 'lr_e':   4.55e-05})
Step:  434000, Reward:   149.125 [  54.907], Avg:   137.747 (0.400) <0-10:47:23> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 218031.8910, 'dyn_loss':     0.0791, 'dot_loss':     0.0204, 'ddot_loss':     0.0358, 'rew_loss':    98.4843, 'lr':   4.55e-05, 'eps_e':     0.4001, 'lr_e':   4.55e-05})
Step:  435000, Reward:   154.438 [  47.270], Avg:   137.785 (0.500) <0-10:49:03> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 218271.5720, 'dyn_loss':     0.0792, 'dot_loss':     0.0206, 'ddot_loss':     0.0360, 'rew_loss':   102.3580, 'lr':   4.55e-05, 'eps_e':     0.5001, 'lr_e':   4.55e-05})
Step:  436000, Reward:   126.188 [  64.355], Avg:   137.758 (0.600) <0-10:50:30> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 218627.2010, 'dyn_loss':     0.0784, 'dot_loss':     0.0203, 'ddot_loss':     0.0353, 'rew_loss':   103.0098, 'lr':   4.55e-05, 'eps_e':     0.6001, 'lr_e':   4.55e-05})
Step:  437000, Reward:   152.000 [  51.120], Avg:   137.791 (0.700) <0-10:51:44> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 219140.6200, 'dyn_loss':     0.0816, 'dot_loss':     0.0206, 'ddot_loss':     0.0356, 'rew_loss':   102.9305, 'lr':   4.55e-05, 'eps_e':     0.7001, 'lr_e':   4.55e-05})
Step:  438000, Reward:   118.312 [  56.107], Avg:   137.747 (0.800) <0-10:52:47> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 219856.1970, 'dyn_loss':     0.0812, 'dot_loss':     0.0205, 'ddot_loss':     0.0355, 'rew_loss':   101.6032, 'lr':   4.55e-05, 'eps_e':     0.8001, 'lr_e':   4.55e-05})
Step:  439000, Reward:   119.125 [  72.813], Avg:   137.704 (0.900) <0-10:53:37> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 220771.1080, 'dyn_loss':     0.0757, 'dot_loss':     0.0205, 'ddot_loss':     0.0362, 'rew_loss':    96.2139, 'lr':   4.55e-05, 'eps_e':     0.9001, 'lr_e':   4.55e-05})
Step:  440000, Reward:   124.438 [  65.776], Avg:   137.674 (0.000) <0-10:54:17> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 221830.3200, 'dyn_loss':     0.0811, 'dot_loss':     0.0204, 'ddot_loss':     0.0355, 'rew_loss':   100.3301, 'lr':   4.55e-05, 'eps_e':     0.0001, 'lr_e':   4.55e-05})
Step:  441000, Reward:   138.125 [  54.531], Avg:   137.675 (0.100) <0-10:56:48> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 222429.8800, 'dyn_loss':     0.0797, 'dot_loss':     0.0207, 'ddot_loss':     0.0361, 'rew_loss':    98.9847, 'lr':   4.55e-05, 'eps_e':     0.1001, 'lr_e':   4.55e-05})
Step:  442000, Reward:   140.438 [  59.784], Avg:   137.681 (0.200) <0-10:59:05> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 222541.3230, 'dyn_loss':     0.0825, 'dot_loss':     0.0206, 'ddot_loss':     0.0357, 'rew_loss':    97.7182, 'lr':   4.55e-05, 'eps_e':     0.2001, 'lr_e':   4.55e-05})
Step:  443000, Reward:   169.250 [  35.190], Avg:   137.753 (0.300) <0-11:01:09> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 222672.1760, 'dyn_loss':     0.0786, 'dot_loss':     0.0207, 'ddot_loss':     0.0366, 'rew_loss':    95.0382, 'lr':   4.46e-05, 'eps_e':     0.3001, 'lr_e':   4.46e-05})
Step:  444000, Reward:   152.438 [  55.263], Avg:   137.786 (0.400) <0-11:03:01> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 222824.8450, 'dyn_loss':     0.0809, 'dot_loss':     0.0206, 'ddot_loss':     0.0357, 'rew_loss':    97.9199, 'lr':   4.46e-05, 'eps_e':     0.4001, 'lr_e':   4.46e-05})
Step:  445000, Reward:   156.438 [  54.886], Avg:   137.827 (0.500) <0-11:04:41> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 223053.6390, 'dyn_loss':     0.0802, 'dot_loss':     0.0204, 'ddot_loss':     0.0354, 'rew_loss':   101.2964, 'lr':   4.46e-05, 'eps_e':     0.5001, 'lr_e':   4.46e-05})
Step:  446000, Reward:   132.188 [  56.000], Avg:   137.815 (0.600) <0-11:06:09> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 223399.3890, 'dyn_loss':     0.0763, 'dot_loss':     0.0204, 'ddot_loss':     0.0360, 'rew_loss':    99.6532, 'lr':   4.46e-05, 'eps_e':     0.6001, 'lr_e':   4.46e-05})
Step:  447000, Reward:   134.688 [  59.280], Avg:   137.808 (0.700) <0-11:07:24> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 223922.2930, 'dyn_loss':     0.0764, 'dot_loss':     0.0206, 'ddot_loss':     0.0364, 'rew_loss':   100.8395, 'lr':   4.46e-05, 'eps_e':     0.7001, 'lr_e':   4.46e-05})
Step:  448000, Reward:   117.875 [  69.968], Avg:   137.763 (0.800) <0-11:08:26> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 224644.7710, 'dyn_loss':     0.0795, 'dot_loss':     0.0207, 'ddot_loss':     0.0361, 'rew_loss':    95.9861, 'lr':   4.46e-05, 'eps_e':     0.8001, 'lr_e':   4.46e-05})
Step:  449000, Reward:   119.500 [  42.833], Avg:   137.723 (0.900) <0-11:09:17> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 225599.7490, 'dyn_loss':     0.0762, 'dot_loss':     0.0206, 'ddot_loss':     0.0366, 'rew_loss':    98.1377, 'lr':   4.46e-05, 'eps_e':     0.9001, 'lr_e':   4.46e-05})
Step:  450000, Reward:   152.688 [  57.076], Avg:   137.756 (0.000) <0-11:09:57> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 226635.0310, 'dyn_loss':     0.0807, 'dot_loss':     0.0203, 'ddot_loss':     0.0354, 'rew_loss':   100.6496, 'lr':   4.46e-05, 'eps_e':     0.0001, 'lr_e':   4.46e-05})
Step:  451000, Reward:   150.062 [  48.529], Avg:   137.783 (0.100) <0-11:12:28> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 227214.8020, 'dyn_loss':     0.0794, 'dot_loss':     0.0204, 'ddot_loss':     0.0354, 'rew_loss':   101.3971, 'lr':   4.46e-05, 'eps_e':     0.1001, 'lr_e':   4.46e-05})
Step:  452000, Reward:   149.688 [  54.255], Avg:   137.809 (0.200) <0-11:14:43> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 227319.2320, 'dyn_loss':     0.0790, 'dot_loss':     0.0205, 'ddot_loss':     0.0358, 'rew_loss':    99.2202, 'lr':   4.46e-05, 'eps_e':     0.2001, 'lr_e':   4.46e-05})
Step:  453000, Reward:   152.250 [  43.651], Avg:   137.841 (0.300) <0-11:16:47> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 227446.9760, 'dyn_loss':     0.0767, 'dot_loss':     0.0202, 'ddot_loss':     0.0355, 'rew_loss':   101.1807, 'lr':   4.46e-05, 'eps_e':     0.3001, 'lr_e':   4.46e-05})
Step:  454000, Reward:   119.312 [  63.320], Avg:   137.801 (0.400) <0-11:18:39> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 227610.0740, 'dyn_loss':     0.0783, 'dot_loss':     0.0202, 'ddot_loss':     0.0353, 'rew_loss':    98.6258, 'lr':   4.37e-05, 'eps_e':     0.4001, 'lr_e':   4.37e-05})
Step:  455000, Reward:   140.625 [  57.057], Avg:   137.807 (0.500) <0-11:20:20> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 227829.4740, 'dyn_loss':     0.0804, 'dot_loss':     0.0207, 'ddot_loss':     0.0362, 'rew_loss':   100.7664, 'lr':   4.37e-05, 'eps_e':     0.5001, 'lr_e':   4.37e-05})
Step:  456000, Reward:   128.750 [  61.722], Avg:   137.787 (0.600) <0-11:21:49> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 228152.1050, 'dyn_loss':     0.0782, 'dot_loss':     0.0204, 'ddot_loss':     0.0358, 'rew_loss':   101.0117, 'lr':   4.37e-05, 'eps_e':     0.6001, 'lr_e':   4.37e-05})
Step:  457000, Reward:   132.438 [  68.994], Avg:   137.775 (0.700) <0-11:23:03> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 228677.8290, 'dyn_loss':     0.0778, 'dot_loss':     0.0204, 'ddot_loss':     0.0357, 'rew_loss':   101.1874, 'lr':   4.37e-05, 'eps_e':     0.7001, 'lr_e':   4.37e-05})
Step:  458000, Reward:   139.062 [  66.803], Avg:   137.778 (0.800) <0-11:24:07> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 229393.6360, 'dyn_loss':     0.0787, 'dot_loss':     0.0205, 'ddot_loss':     0.0360, 'rew_loss':    96.9928, 'lr':   4.37e-05, 'eps_e':     0.8001, 'lr_e':   4.37e-05})
Step:  459000, Reward:   137.062 [  73.270], Avg:   137.776 (0.900) <0-11:24:58> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 230304.7520, 'dyn_loss':     0.0751, 'dot_loss':     0.0205, 'ddot_loss':     0.0368, 'rew_loss':    97.1480, 'lr':   4.37e-05, 'eps_e':     0.9001, 'lr_e':   4.37e-05})
Step:  460000, Reward:   128.625 [  70.568], Avg:   137.757 (0.000) <0-11:25:38> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 231370.4820, 'dyn_loss':     0.0784, 'dot_loss':     0.0204, 'ddot_loss':     0.0359, 'rew_loss':   103.8558, 'lr':   4.37e-05, 'eps_e':     0.0001, 'lr_e':   4.37e-05})
Step:  461000, Reward:   148.000 [  63.993], Avg:   137.779 (0.100) <0-11:28:10> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 231972.8400, 'dyn_loss':     0.0798, 'dot_loss':     0.0203, 'ddot_loss':     0.0353, 'rew_loss':   102.6113, 'lr':   4.37e-05, 'eps_e':     0.1001, 'lr_e':   4.37e-05})
Step:  462000, Reward:   148.688 [  62.353], Avg:   137.802 (0.200) <0-11:30:36> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 232075.2820, 'dyn_loss':     0.0805, 'dot_loss':     0.0205, 'ddot_loss':     0.0353, 'rew_loss':    96.1051, 'lr':   4.37e-05, 'eps_e':     0.2001, 'lr_e':   4.37e-05})
Step:  463000, Reward:   136.125 [  62.684], Avg:   137.799 (0.300) <0-11:32:45> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 232199.8830, 'dyn_loss':     0.0807, 'dot_loss':     0.0206, 'ddot_loss':     0.0357, 'rew_loss':   102.2308, 'lr':   4.37e-05, 'eps_e':     0.3001, 'lr_e':   4.37e-05})
Step:  464000, Reward:   162.875 [  50.811], Avg:   137.853 (0.400) <0-11:34:41> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 232362.4990, 'dyn_loss':     0.0789, 'dot_loss':     0.0204, 'ddot_loss':     0.0354, 'rew_loss':    97.8954, 'lr':   4.37e-05, 'eps_e':     0.4001, 'lr_e':   4.37e-05})
Step:  465000, Reward:   147.750 [  53.302], Avg:   137.874 (0.500) <0-11:36:24> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 232593.9150, 'dyn_loss':     0.0828, 'dot_loss':     0.0202, 'ddot_loss':     0.0349, 'rew_loss':   101.2859, 'lr':   4.28e-05, 'eps_e':     0.5001, 'lr_e':   4.28e-05})
Step:  466000, Reward:   139.750 [  59.374], Avg:   137.878 (0.600) <0-11:37:52> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 232941.5560, 'dyn_loss':     0.0835, 'dot_loss':     0.0203, 'ddot_loss':     0.0347, 'rew_loss':    96.4040, 'lr':   4.28e-05, 'eps_e':     0.6001, 'lr_e':   4.28e-05})
Step:  467000, Reward:   141.250 [  57.694], Avg:   137.885 (0.700) <0-11:39:09> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 233493.6630, 'dyn_loss':     0.0811, 'dot_loss':     0.0204, 'ddot_loss':     0.0352, 'rew_loss':   102.1643, 'lr':   4.28e-05, 'eps_e':     0.7001, 'lr_e':   4.28e-05})
Step:  468000, Reward:   144.750 [  46.394], Avg:   137.900 (0.800) <0-11:40:13> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 234259.9590, 'dyn_loss':     0.0817, 'dot_loss':     0.0205, 'ddot_loss':     0.0355, 'rew_loss':    98.7718, 'lr':   4.28e-05, 'eps_e':     0.8001, 'lr_e':   4.28e-05})
Step:  469000, Reward:   144.312 [  44.204], Avg:   137.913 (0.900) <0-11:41:04> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 235186.0370, 'dyn_loss':     0.0769, 'dot_loss':     0.0203, 'ddot_loss':     0.0356, 'rew_loss':   103.6441, 'lr':   4.28e-05, 'eps_e':     0.9001, 'lr_e':   4.28e-05})
Step:  470000, Reward:   162.000 [  67.328], Avg:   137.965 (0.000) <0-11:41:44> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 236264.6210, 'dyn_loss':     0.0771, 'dot_loss':     0.0203, 'ddot_loss':     0.0357, 'rew_loss':   100.3335, 'lr':   4.28e-05, 'eps_e':     0.0001, 'lr_e':   4.28e-05})
Step:  471000, Reward:   165.875 [  44.564], Avg:   138.024 (0.100) <0-11:44:17> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 236862.0520, 'dyn_loss':     0.0780, 'dot_loss':     0.0205, 'ddot_loss':     0.0363, 'rew_loss':    98.2823, 'lr':   4.28e-05, 'eps_e':     0.1001, 'lr_e':   4.28e-05})
Step:  472000, Reward:   117.125 [  64.774], Avg:   137.980 (0.200) <0-11:46:39> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 236962.2200, 'dyn_loss':     0.0794, 'dot_loss':     0.0205, 'ddot_loss':     0.0358, 'rew_loss':   100.8424, 'lr':   4.28e-05, 'eps_e':     0.2001, 'lr_e':   4.28e-05})
Step:  473000, Reward:   164.625 [  52.018], Avg:   138.036 (0.300) <0-11:48:47> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 237084.6490, 'dyn_loss':     0.0766, 'dot_loss':     0.0205, 'ddot_loss':     0.0361, 'rew_loss':    99.8078, 'lr':   4.28e-05, 'eps_e':     0.3001, 'lr_e':   4.28e-05})
Step:  474000, Reward:   166.562 [  35.338], Avg:   138.096 (0.400) <0-11:50:41> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 237239.5240, 'dyn_loss':     0.0795, 'dot_loss':     0.0205, 'ddot_loss':     0.0356, 'rew_loss':   103.8117, 'lr':   4.28e-05, 'eps_e':     0.4001, 'lr_e':   4.28e-05})
Step:  475000, Reward:   131.250 [  47.288], Avg:   138.081 (0.500) <0-11:52:23> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 237466.0730, 'dyn_loss':     0.0810, 'dot_loss':     0.0205, 'ddot_loss':     0.0356, 'rew_loss':    99.6571, 'lr':   4.28e-05, 'eps_e':     0.5001, 'lr_e':   4.28e-05})
Step:  476000, Reward:   147.375 [  68.975], Avg:   138.101 (0.600) <0-11:53:54> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 237822.9250, 'dyn_loss':     0.0796, 'dot_loss':     0.0203, 'ddot_loss':     0.0354, 'rew_loss':   101.4092, 'lr':   4.19e-05, 'eps_e':     0.6001, 'lr_e':   4.19e-05})
Step:  477000, Reward:   136.062 [  69.384], Avg:   138.097 (0.700) <0-11:55:11> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 238341.3820, 'dyn_loss':     0.0798, 'dot_loss':     0.0205, 'ddot_loss':     0.0357, 'rew_loss':    99.2214, 'lr':   4.19e-05, 'eps_e':     0.7001, 'lr_e':   4.19e-05})
Step:  478000, Reward:   156.750 [  53.765], Avg:   138.136 (0.800) <0-11:56:15> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 239027.4790, 'dyn_loss':     0.0786, 'dot_loss':     0.0208, 'ddot_loss':     0.0363, 'rew_loss':    98.3074, 'lr':   4.19e-05, 'eps_e':     0.8001, 'lr_e':   4.19e-05})
Step:  479000, Reward:   128.188 [  64.591], Avg:   138.115 (0.900) <0-11:57:07> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 239939.1990, 'dyn_loss':     0.0786, 'dot_loss':     0.0204, 'ddot_loss':     0.0358, 'rew_loss':   100.4920, 'lr':   4.19e-05, 'eps_e':     0.9001, 'lr_e':   4.19e-05})
Step:  480000, Reward:   124.000 [  56.481], Avg:   138.085 (0.000) <0-11:57:49> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 240997.9790, 'dyn_loss':     0.0785, 'dot_loss':     0.0206, 'ddot_loss':     0.0362, 'rew_loss':   100.9215, 'lr':   4.19e-05, 'eps_e':     0.0001, 'lr_e':   4.19e-05})
Step:  481000, Reward:   145.688 [  62.181], Avg:   138.101 (0.100) <0-12:00:20> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 241609.2530, 'dyn_loss':     0.0825, 'dot_loss':     0.0206, 'ddot_loss':     0.0355, 'rew_loss':   100.4837, 'lr':   4.19e-05, 'eps_e':     0.1001, 'lr_e':   4.19e-05})
Step:  482000, Reward:   156.750 [  47.484], Avg:   138.140 (0.200) <0-12:02:42> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 241718.7940, 'dyn_loss':     0.0776, 'dot_loss':     0.0204, 'ddot_loss':     0.0357, 'rew_loss':   102.1681, 'lr':   4.19e-05, 'eps_e':     0.2001, 'lr_e':   4.19e-05})
Step:  483000, Reward:   149.875 [  52.808], Avg:   138.164 (0.300) <0-12:04:46> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 241843.1620, 'dyn_loss':     0.0799, 'dot_loss':     0.0206, 'ddot_loss':     0.0361, 'rew_loss':    99.3066, 'lr':   4.19e-05, 'eps_e':     0.3001, 'lr_e':   4.19e-05})
Step:  484000, Reward:   104.562 [  56.438], Avg:   138.095 (0.400) <0-12:06:40> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 241998.5820, 'dyn_loss':     0.0749, 'dot_loss':     0.0204, 'ddot_loss':     0.0364, 'rew_loss':    99.6883, 'lr':   4.19e-05, 'eps_e':     0.4001, 'lr_e':   4.19e-05})
Step:  485000, Reward:   157.625 [  44.055], Avg:   138.135 (0.500) <0-12:08:21> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 242221.2450, 'dyn_loss':     0.0782, 'dot_loss':     0.0202, 'ddot_loss':     0.0354, 'rew_loss':   102.3902, 'lr':   4.19e-05, 'eps_e':     0.5001, 'lr_e':   4.19e-05})
Step:  486000, Reward:   164.938 [  38.811], Avg:   138.190 (0.600) <0-12:09:49> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 242568.8080, 'dyn_loss':     0.0769, 'dot_loss':     0.0204, 'ddot_loss':     0.0360, 'rew_loss':   101.6717, 'lr':   4.19e-05, 'eps_e':     0.6001, 'lr_e':   4.19e-05})
Step:  487000, Reward:   108.375 [  62.050], Avg:   138.129 (0.700) <0-12:11:04> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 243093.6860, 'dyn_loss':     0.0780, 'dot_loss':     0.0200, 'ddot_loss':     0.0353, 'rew_loss':    98.5902, 'lr':   4.11e-05, 'eps_e':     0.7001, 'lr_e':   4.11e-05})
Step:  488000, Reward:   160.375 [  48.218], Avg:   138.174 (0.800) <0-12:12:10> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 243818.9930, 'dyn_loss':     0.0777, 'dot_loss':     0.0204, 'ddot_loss':     0.0360, 'rew_loss':   100.2724, 'lr':   4.11e-05, 'eps_e':     0.8001, 'lr_e':   4.11e-05})
Step:  489000, Reward:   131.438 [  41.781], Avg:   138.161 (0.900) <0-12:13:02> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 244751.5300, 'dyn_loss':     0.0778, 'dot_loss':     0.0205, 'ddot_loss':     0.0362, 'rew_loss':    98.3224, 'lr':   4.11e-05, 'eps_e':     0.9001, 'lr_e':   4.11e-05})
Step:  490000, Reward:   141.062 [  55.515], Avg:   138.167 (0.000) <0-12:13:42> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 245818.3560, 'dyn_loss':     0.0770, 'dot_loss':     0.0203, 'ddot_loss':     0.0357, 'rew_loss':    98.3492, 'lr':   4.11e-05, 'eps_e':     0.0001, 'lr_e':   4.11e-05})
Step:  491000, Reward:   149.938 [  39.828], Avg:   138.191 (0.100) <0-12:16:13> ({'r_t':  1000.0000, 'eps':     0.1001, 'len': 246410.1410, 'dyn_loss':     0.0786, 'dot_loss':     0.0207, 'ddot_loss':     0.0363, 'rew_loss':    99.6394, 'lr':   4.11e-05, 'eps_e':     0.1001, 'lr_e':   4.11e-05})
Step:  492000, Reward:   156.312 [  44.321], Avg:   138.227 (0.200) <0-12:18:31> ({'r_t':  1000.0000, 'eps':     0.2001, 'len': 246523.1920, 'dyn_loss':     0.0774, 'dot_loss':     0.0202, 'ddot_loss':     0.0354, 'rew_loss':   104.0649, 'lr':   4.11e-05, 'eps_e':     0.2001, 'lr_e':   4.11e-05})
Step:  493000, Reward:   142.438 [  51.883], Avg:   138.236 (0.300) <0-12:20:38> ({'r_t':  1000.0000, 'eps':     0.3001, 'len': 246656.8400, 'dyn_loss':     0.0817, 'dot_loss':     0.0202, 'ddot_loss':     0.0350, 'rew_loss':   102.8905, 'lr':   4.11e-05, 'eps_e':     0.3001, 'lr_e':   4.11e-05})
Step:  494000, Reward:   143.875 [  60.987], Avg:   138.247 (0.400) <0-12:22:32> ({'r_t':  1000.0000, 'eps':     0.4001, 'len': 246821.7200, 'dyn_loss':     0.0767, 'dot_loss':     0.0203, 'ddot_loss':     0.0358, 'rew_loss':    97.9092, 'lr':   4.11e-05, 'eps_e':     0.4001, 'lr_e':   4.11e-05})
Step:  495000, Reward:   154.625 [  52.740], Avg:   138.280 (0.500) <0-12:24:11> ({'r_t':  1000.0000, 'eps':     0.5001, 'len': 247085.9440, 'dyn_loss':     0.0760, 'dot_loss':     0.0204, 'ddot_loss':     0.0362, 'rew_loss':    97.8233, 'lr':   4.11e-05, 'eps_e':     0.5001, 'lr_e':   4.11e-05})
Step:  496000, Reward:   135.500 [  53.746], Avg:   138.275 (0.600) <0-12:25:39> ({'r_t':  1000.0000, 'eps':     0.6001, 'len': 247447.4980, 'dyn_loss':     0.0785, 'dot_loss':     0.0205, 'ddot_loss':     0.0362, 'rew_loss':   101.8687, 'lr':   4.11e-05, 'eps_e':     0.6001, 'lr_e':   4.11e-05})
Step:  497000, Reward:   154.688 [  58.622], Avg:   138.308 (0.700) <0-12:26:56> ({'r_t':  1000.0000, 'eps':     0.7001, 'len': 247976.4630, 'dyn_loss':     0.0778, 'dot_loss':     0.0201, 'ddot_loss':     0.0354, 'rew_loss':   102.8503, 'lr':   4.11e-05, 'eps_e':     0.7001, 'lr_e':   4.11e-05})
Step:  498000, Reward:   141.438 [  59.109], Avg:   138.314 (0.800) <0-12:27:58> ({'r_t':  1000.0000, 'eps':     0.8001, 'len': 248699.7590, 'dyn_loss':     0.0778, 'dot_loss':     0.0202, 'ddot_loss':     0.0356, 'rew_loss':    95.4151, 'lr':   4.03e-05, 'eps_e':     0.8001, 'lr_e':   4.03e-05})
Step:  499000, Reward:   135.688 [  57.072], Avg:   138.309 (0.900) <0-12:28:49> ({'r_t':  1000.0000, 'eps':     0.9001, 'len': 249615.7150, 'dyn_loss':     0.0789, 'dot_loss':     0.0205, 'ddot_loss':     0.0360, 'rew_loss':    99.1395, 'lr':   4.03e-05, 'eps_e':     0.9001, 'lr_e':   4.03e-05})
Step:  500000, Reward:   107.875 [  57.259], Avg:   138.248 (0.000) <0-12:29:32> ({'r_t':  1000.0000, 'eps':     0.0001, 'len': 250687.0510, 'dyn_loss':     0.0809, 'dot_loss':     0.0205, 'ddot_loss':     0.0360, 'rew_loss':   100.7925, 'lr':   4.03e-05, 'eps_e':     0.0001, 'lr_e':   4.03e-05})
