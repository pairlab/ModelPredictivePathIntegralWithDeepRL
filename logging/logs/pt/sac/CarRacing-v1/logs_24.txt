Model: <class 'src.models.pytorch.agents.sac.SACAgent'>, Env: CarRacing-v1, Date: 21/05/2020 22:37:12
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 7da1397dc51b746721fd67dd4d44ed68d7643ced
Branch: master

config: 
   TRIAL_AT = 5000
   SAVE_AT = 1
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = sac
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f348108cfd0> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f348108cb10>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f3481044ef0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			pos_scale = 1
			vtarget = 25
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f348104ae50> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f348104a890> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				cost_map = [[ 214.381  214.299  214.217 ...  112.184  112.264  112.344]
				 [ 214.324  214.242  214.160 ...  112.124  112.204  112.284]
				 [ 214.267  214.185  214.103 ...  112.064  112.144  112.224]
				 ...
				 [  96.764   96.690   96.616 ...  242.661  242.689  242.717]
				 [  96.831   96.757   96.683 ...  242.757  242.785  242.813]
				 [  96.898   96.824   96.750 ...  242.852  242.881  242.909]]
				res = 0.1
				min_point = [-215.266 -178.250    0.000]
				max_point = [ 210.234  262.950    0.000]
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 
					def get_reward(self, state, prevstate=None):
						prevstate = state if prevstate is None else prevstate
						px, pz, py = prevstate[:3]*self.pos_scale
						x, z, y = state[:3]*self.pos_scale
						_, _, vy = state[3:6]
						idle = state[29]
						cost = self.cost_model.get_cost((x,y), transform=True)
						progress = self.cost_model.track.get_progress([px,py,pz], [x,y,z])
						reward = min(progress,0)*np.exp(cost) + max(progress,0)*np.exp(-cost)
						return reward
				
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state = self.observation(next_state)
						reward = self.get_reward(next_state, self.state) - (1-self.time/self.max_time)*int(done)
						self.state = next_state
			
			max_time = 500
			time = 0
			idle_timeout = 10
			state = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  1.000e+00  9.095e-13 -1.164e-10 -4.547e-12  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  2.000e-02 -1.617e-09  3.908e-03  7.273e-09  8.070e-02  4.592e-03  2.580e-01  1.513e-01  5.392e-03  5.773e-01  2.373e-01  6.680e-03  9.128e-01  3.132e-01  8.130e-03  1.261e+00  3.895e-01  1.002e-02  1.642e+00  5.043e-01  1.191e-02  2.129e+00  6.238e-01  3.193e-02  2.720e+00  7.631e-01  1.057e-01  3.366e+00  9.149e-01  1.247e-01  4.101e+00]
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f34ffcd8440>
					get_reward = <function CarRacing.get_reward at 0x7f34ffcd83b0>
					step = <function CarRacing.step at 0x7f34ffce64d0>
					render = <function CarRacing.render at 0x7f34ffce6560>
					observation = <function CarRacing.observation at 0x7f34ffce65f0>
					close = <function CarRacing.close at 0x7f34ffce6680>
					id = 1
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(60,) 
			dtype = float32
			shape = (60,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f348104aa50> 
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (60,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f3480ffe390> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=202, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56390), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=203, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 34932), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=204, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54984), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=205, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 43672), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=206, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 55752), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=207, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59724), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=208, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 60984), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=209, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51572), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=210, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47698), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=211, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51278), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=212, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48760), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=213, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56160), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=214, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33338), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=215, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51100), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=216, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33244), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=217, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47402), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 5000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f3480ffe690> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f3480ffe650> 
		state_size = (60,)
	agent = <src.models.pytorch.agents.sac.SACAgent object at 0x7f3480ffe710> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f348139f990> 
			size = (3,)
			dt = 0.2
			action = [-0.749 -0.157  0.143]
			daction_dt = [-0.876 -0.216 -0.486]
		discrete = False
		action_size = (3,)
		state_size = (60,)
		config = <src.utils.config.Config object at 0x7f3481546450> 
			TRIAL_AT = 5000
			SAVE_AT = 1
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = sac
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f3480ffe750> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = SACNetwork(
			  (actor_local): SACActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): SACActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): SACCritic(
			    (net_state): Linear(in_features=60, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): SACCritic(
			    (net_state): Linear(in_features=60, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = sac
			stats = <src.utils.logger.Stats object at 0x7f3480ffec90> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f3481546450> 
				TRIAL_AT = 5000
				SAVE_AT = 1
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = sac
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class SACActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config, use_discrete=False):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = use_discrete and type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\t\tself.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)\n\t\t\n\tdef forward(self, state, action=None, sample=True):\n\t\tstate = self.layer1(state).relu()\n\t\tstate = self.layer2(state).relu()\n\t\tstate = self.layer3(state).relu()\n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).clamp(-5,0).exp()\n\t\tdist = torch.distributions.Normal(action_mu, action_sig)\n\t\taction = dist.rsample() if sample else action_mu\n\t\taction_out = gsoftmax(action_mu, hard=False) if self.discrete else action.tanh()\n\t\tlog_prob = torch.log(action_out+1e-6) if self.discrete else dist.log_prob(action)-torch.log(1-action_out.pow(2)+1e-6)\n\t\treturn action_out, log_prob\n', 'class SACCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			alpha_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 0
			)
			target_entropy = -3
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f3480ffe810> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f3480ffed10> 
		size = (3,)
		dt = 0.2
		action = [-0.205 -1.000  0.719]
		daction_dt = [-0.874 -0.883 -1.440]
	discrete = False
	action_size = (3,)
	state_size = (60,)
	config = <src.utils.config.Config object at 0x7f3481546450> 
		TRIAL_AT = 5000
		SAVE_AT = 1
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = sac
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f3480ffea90> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax
from src.utils.rand import ReplayBuffer

class SACActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config, use_discrete=False):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = use_discrete and type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		self.dist = lambda m,s: torch.distributions.Categorical(m.softmax(-1)) if self.discrete else torch.distributions.Normal(m,s)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).clamp(-5,0).exp()
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = dist.rsample() if sample else action_mu
		action_out = gsoftmax(action_mu, hard=False) if self.discrete else action.tanh()
		log_prob = torch.log(action_out+1e-6) if self.discrete else dist.log_prob(action)-torch.log(1-action_out.pow(2)+1e-6)
		return action_out, log_prob

class SACCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class SACNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=SACActor, critic=SACCritic, gpu=True, load=None, name="sac", use_discrete=False):
		self.discrete = use_discrete and critic==SACCritic and type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)
		self.log_alpha = torch.nn.Parameter(torch.zeros(1, requires_grad=True).to(self.device))
		self.alpha_optimizer = torch.optim.Adam([self.log_alpha], lr=config.LEARN_RATE)
		self.target_entropy = -np.product(action_size)

	def get_action_probs(self, state, action_in=None, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob = self.actor_local(state.to(self.device), action_in, sample)
			return [x.cpu().numpy() if numpy else x for x in [action, log_prob]]

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, targets, next_log_probs, dones, config):
		alpha = self.log_alpha.clamp(-5, 0).detach().exp()
		if not self.discrete: next_log_probs = next_log_probs.sum(-1, keepdim=True)
		q_targets = targets - config.DISCOUNT_RATE*alpha*next_log_probs*(1-dones.view(-1,*[1]*(len(targets.shape)-1)))
		q_targets = (actions*q_targets).mean(-1, keepdim=True) if self.discrete else q_targets

		q_values = self.get_q_value(states, actions, grad=True)
		q_values = q_values.gather(-1, actions.argmax(-1, keepdim=True)) if self.discrete else q_values
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss, self.critic_local.parameters())
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action, log_prob = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True)
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = alpha*log_prob - (q_actions - q_baseline.detach())
		actor_loss = actor_action*actor_loss if self.discrete else actor_loss
		self.step(self.actor_optimizer, actor_loss.mean(), self.actor_local.parameters())
		
		log_prob = (actor_action*log_prob).sum(-1) if self.discrete else log_prob
		alpha_loss = -(self.log_alpha * (log_prob.detach() + self.target_entropy)).mean()
		self.step(self.alpha_optimizer, alpha_loss, [self.log_alpha])
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss.mean(), alpha_loss=alpha_loss)

class SACAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, SACNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True, e_greedy=False):
		action, self.log_prob = self.network.get_action_probs(self.to_tensor(state), numpy=True, sample=sample)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, self.log_prob, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			next_action, next_log_prob = self.network.get_action_probs(states[-1])
			actions = torch.cat([actions, next_action.unsqueeze(0)], dim=0)
			log_probs = torch.cat([log_probs, next_log_prob.unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets, next_log_probs, dones = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets, log_probs[1:], dones)]
			self.replay_buffer.extend(list(zip(states, actions, targets, next_log_probs, dones)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets, next_log_probs, dones = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets, next_log_probs, dones, config=self.config)


Step:       0, Reward:    -0.894 [   0.000], Avg:    -0.894 (1.000) <0-00:00:00> ({'r_t':   0.00e+00, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    5000, Reward:    14.767 [   0.000], Avg:     6.936 (1.000) <0-00:01:41> ({'r_t':    31.2819, 'eps':     1.0000, 'critic_loss':   271.6837, 'actor_loss':    -0.6487, 'alpha_loss':    -0.8201, 'eps_e':     1.0000})
Step:   10000, Reward:    28.273 [   0.000], Avg:    14.049 (1.000) <0-00:03:22> ({'r_t':   323.4589, 'eps':     1.0000, 'critic_loss':    16.9855, 'actor_loss':    -0.3818, 'alpha_loss':    -2.5572, 'eps_e':     1.0000})
Step:   15000, Reward:    28.889 [   0.000], Avg:    17.759 (1.000) <0-00:05:03> ({'r_t':   663.7020, 'eps':     1.0000, 'critic_loss':     0.5326, 'actor_loss':    -0.2004, 'alpha_loss':    -4.3014, 'eps_e':     1.0000})
Step:   20000, Reward:    70.147 [   0.000], Avg:    28.236 (1.000) <0-00:06:44> ({'r_t':  1218.7321, 'eps':     1.0000, 'critic_loss':     9.3590, 'actor_loss':    -0.1730, 'alpha_loss':    -5.4969, 'eps_e':     1.0000})
Step:   25000, Reward:    50.887 [   0.000], Avg:    32.011 (1.000) <0-00:08:26> ({'r_t':  1224.7405, 'eps':     1.0000, 'critic_loss':    28.6070, 'actor_loss':    -0.1588, 'alpha_loss':    -6.5074, 'eps_e':     1.0000})
Step:   30000, Reward:    48.357 [   0.000], Avg:    34.346 (1.000) <0-00:10:07> ({'r_t':  1656.4560, 'eps':     1.0000, 'critic_loss':   117.7757, 'actor_loss':    -0.1098, 'alpha_loss':    -7.0745, 'eps_e':     1.0000})
Step:   35000, Reward:    75.901 [   0.000], Avg:    39.541 (1.000) <0-00:11:50> ({'r_t':  2061.0259, 'eps':     1.0000, 'critic_loss':   191.4408, 'actor_loss':    -0.2003, 'alpha_loss':    -5.2214, 'eps_e':     1.0000})
Step:   40000, Reward:   103.701 [   0.000], Avg:    46.670 (1.000) <0-00:13:32> ({'r_t':  2461.2170, 'eps':     1.0000, 'critic_loss':   309.9331, 'actor_loss':    -0.3221, 'alpha_loss':    -3.2337, 'eps_e':     1.0000})
Step:   45000, Reward:  -188.232 [   0.000], Avg:    23.180 (1.000) <0-00:15:14> ({'r_t':  3222.1962, 'eps':     1.0000, 'critic_loss':   179.9290, 'actor_loss':    -0.4240, 'alpha_loss':    -1.4438, 'eps_e':     1.0000})
Step:   50000, Reward:   104.047 [   0.000], Avg:    30.531 (1.000) <0-00:16:56> ({'r_t':  2935.6591, 'eps':     1.0000, 'critic_loss':   216.7514, 'actor_loss':    -0.4251, 'alpha_loss':    -0.2499, 'eps_e':     1.0000})
Step:   55000, Reward:    93.734 [   0.000], Avg:    35.798 (1.000) <0-00:18:38> ({'r_t':  3219.5242, 'eps':     1.0000, 'critic_loss':   272.4537, 'actor_loss':    -0.4165, 'alpha_loss':     0.3455, 'eps_e':     1.0000})
Step:   60000, Reward:   104.472 [   0.000], Avg:    41.081 (1.000) <0-00:20:20> ({'r_t':  3481.8196, 'eps':     1.0000, 'critic_loss':   275.0047, 'actor_loss':    -0.3871, 'alpha_loss':     0.0821, 'eps_e':     1.0000})
Step:   65000, Reward:   126.464 [   0.000], Avg:    47.179 (1.000) <0-00:22:02> ({'r_t':  3597.0071, 'eps':     1.0000, 'critic_loss':   206.5845, 'actor_loss':    -0.2919, 'alpha_loss':    -0.1066, 'eps_e':     1.0000})
Step:   70000, Reward:   114.674 [   0.000], Avg:    51.679 (1.000) <0-00:23:45> ({'r_t':  3773.3988, 'eps':     1.0000, 'critic_loss':   198.6102, 'actor_loss':    -0.2789, 'alpha_loss':    -0.0860, 'eps_e':     1.0000})
Step:   75000, Reward:   104.523 [   0.000], Avg:    54.982 (1.000) <0-00:25:27> ({'r_t':  3520.3999, 'eps':     1.0000, 'critic_loss':   199.5133, 'actor_loss':    -0.2252, 'alpha_loss':     0.1654, 'eps_e':     1.0000})
Step:   80000, Reward:   120.759 [   0.000], Avg:    58.851 (1.000) <0-00:27:09> ({'r_t':  3973.9933, 'eps':     1.0000, 'critic_loss':   177.8850, 'actor_loss':    -0.1951, 'alpha_loss':     0.0492, 'eps_e':     1.0000})
Step:   85000, Reward:   121.455 [   0.000], Avg:    62.329 (1.000) <0-00:28:51> ({'r_t':  4024.6370, 'eps':     1.0000, 'critic_loss':   124.6605, 'actor_loss':    -0.1837, 'alpha_loss':     0.3606, 'eps_e':     1.0000})
Step:   90000, Reward:   116.727 [   0.000], Avg:    65.192 (1.000) <0-00:30:34> ({'r_t':  3874.6513, 'eps':     1.0000, 'critic_loss':   183.5268, 'actor_loss':    -0.1673, 'alpha_loss':     0.3908, 'eps_e':     1.0000})
Step:   95000, Reward:   111.680 [   0.000], Avg:    67.516 (1.000) <0-00:32:16> ({'r_t':  3998.0562, 'eps':     1.0000, 'critic_loss':   162.6303, 'actor_loss':    -0.1642, 'alpha_loss':     0.1406, 'eps_e':     1.0000})
Step:  100000, Reward:   136.540 [   0.000], Avg:    70.803 (1.000) <0-00:33:58> ({'r_t':  4042.7324, 'eps':     1.0000, 'critic_loss':   126.0047, 'actor_loss':    -0.1366, 'alpha_loss':     0.3713, 'eps_e':     1.0000})
Step:  105000, Reward:   127.541 [   0.000], Avg:    73.382 (1.000) <0-00:35:41> ({'r_t':  3974.9337, 'eps':     1.0000, 'critic_loss':   139.9503, 'actor_loss':    -0.1335, 'alpha_loss':    -0.2197, 'eps_e':     1.0000})
Step:  110000, Reward:   143.453 [   0.000], Avg:    76.429 (1.000) <0-00:37:24> ({'r_t':  4077.4857, 'eps':     1.0000, 'critic_loss':    99.9359, 'actor_loss':    -0.1374, 'alpha_loss':     0.1013, 'eps_e':     1.0000})
Step:  115000, Reward:  -156.043 [   0.000], Avg:    66.743 (1.000) <0-00:39:08> ({'r_t':  3914.2117, 'eps':     1.0000, 'critic_loss':   222.9621, 'actor_loss':    -0.1248, 'alpha_loss':     0.3171, 'eps_e':     1.0000})
Step:  120000, Reward:   125.751 [   0.000], Avg:    69.103 (1.000) <0-00:40:50> ({'r_t':  4188.7610, 'eps':     1.0000, 'critic_loss':   242.7943, 'actor_loss':    -0.1683, 'alpha_loss':     0.3439, 'eps_e':     1.0000})
Step:  125000, Reward:   125.750 [   0.000], Avg:    71.282 (1.000) <0-00:42:32> ({'r_t':  4291.7150, 'eps':     1.0000, 'critic_loss':    93.0311, 'actor_loss':    -0.0998, 'alpha_loss':    -0.0062, 'eps_e':     1.0000})
Step:  130000, Reward:   116.242 [   0.000], Avg:    72.947 (1.000) <0-00:44:14> ({'r_t':  4366.6789, 'eps':     1.0000, 'critic_loss':    65.0262, 'actor_loss':    -0.0846, 'alpha_loss':     0.0054, 'eps_e':     1.0000})
Step:  135000, Reward:   147.662 [   0.000], Avg:    75.615 (1.000) <0-00:45:57> ({'r_t':  4117.7067, 'eps':     1.0000, 'critic_loss':    97.3205, 'actor_loss':    -0.0796, 'alpha_loss':     0.1117, 'eps_e':     1.0000})
Step:  140000, Reward:   142.995 [   0.000], Avg:    77.939 (1.000) <0-00:47:40> ({'r_t':  4151.2110, 'eps':     1.0000, 'critic_loss':   199.1637, 'actor_loss':    -0.0650, 'alpha_loss':     0.0574, 'eps_e':     1.0000})
Step:  145000, Reward:   151.605 [   0.000], Avg:    80.394 (1.000) <0-00:49:22> ({'r_t':  4175.5662, 'eps':     1.0000, 'critic_loss':   183.4328, 'actor_loss':    -0.1212, 'alpha_loss':    -0.1745, 'eps_e':     1.0000})
Step:  150000, Reward:   144.975 [   0.000], Avg:    82.477 (1.000) <0-00:51:05> ({'r_t':  4152.0652, 'eps':     1.0000, 'critic_loss':   213.6052, 'actor_loss':    -0.0728, 'alpha_loss':    -0.1209, 'eps_e':     1.0000})
Step:  155000, Reward:   120.277 [   0.000], Avg:    83.659 (1.000) <0-00:52:47> ({'r_t':  4213.4324, 'eps':     1.0000, 'critic_loss':   232.5078, 'actor_loss':    -0.0956, 'alpha_loss':    -0.0293, 'eps_e':     1.0000})
Step:  160000, Reward:   134.746 [   0.000], Avg:    85.207 (1.000) <0-00:54:30> ({'r_t':  4255.0288, 'eps':     1.0000, 'critic_loss':   134.8226, 'actor_loss':    -0.0716, 'alpha_loss':    -0.1108, 'eps_e':     1.0000})
Step:  165000, Reward:   146.985 [   0.000], Avg:    87.024 (1.000) <0-00:56:12> ({'r_t':  4154.4541, 'eps':     1.0000, 'critic_loss':   153.5660, 'actor_loss':    -0.1043, 'alpha_loss':     0.1590, 'eps_e':     1.0000})
Step:  170000, Reward:   124.963 [   0.000], Avg:    88.108 (1.000) <0-00:57:54> ({'r_t':  4386.0983, 'eps':     1.0000, 'critic_loss':   120.5612, 'actor_loss':    -0.0677, 'alpha_loss':     0.3375, 'eps_e':     1.0000})
Step:  175000, Reward:   139.982 [   0.000], Avg:    89.549 (1.000) <0-00:59:37> ({'r_t':  4462.6075, 'eps':     1.0000, 'critic_loss':   112.7182, 'actor_loss':    -0.0534, 'alpha_loss':     0.0255, 'eps_e':     1.0000})
Step:  180000, Reward:   145.956 [   0.000], Avg:    91.073 (1.000) <0-01:01:19> ({'r_t':  3907.8980, 'eps':     1.0000, 'critic_loss':   205.8527, 'actor_loss':    -0.0404, 'alpha_loss':    -0.1477, 'eps_e':     1.0000})
Step:  185000, Reward:   125.834 [   0.000], Avg:    91.988 (1.000) <0-01:03:02> ({'r_t':  4297.0631, 'eps':     1.0000, 'critic_loss':   186.9550, 'actor_loss':    -0.0941, 'alpha_loss':    -0.2300, 'eps_e':     1.0000})
Step:  190000, Reward:   134.224 [   0.000], Avg:    93.071 (1.000) <0-01:04:44> ({'r_t':  4271.9199, 'eps':     1.0000, 'critic_loss':   128.0409, 'actor_loss':    -0.0786, 'alpha_loss':    -0.2510, 'eps_e':     1.0000})
Step:  195000, Reward:   147.592 [   0.000], Avg:    94.434 (1.000) <0-01:06:27> ({'r_t':  4218.0952, 'eps':     1.0000, 'critic_loss':   113.5830, 'actor_loss':    -0.0743, 'alpha_loss':    -0.1051, 'eps_e':     1.0000})
Step:  200000, Reward:   129.286 [   0.000], Avg:    95.284 (1.000) <0-01:08:09> ({'r_t':  4125.7009, 'eps':     1.0000, 'critic_loss':   216.7379, 'actor_loss':    -0.0696, 'alpha_loss':    -0.1395, 'eps_e':     1.0000})
Step:  205000, Reward:   147.657 [   0.000], Avg:    96.531 (1.000) <0-01:09:52> ({'r_t':  4124.7114, 'eps':     1.0000, 'critic_loss':   220.3477, 'actor_loss':    -0.0897, 'alpha_loss':    -0.2359, 'eps_e':     1.0000})
Step:  210000, Reward:   122.878 [   0.000], Avg:    97.144 (1.000) <0-01:11:34> ({'r_t':  3867.2319, 'eps':     1.0000, 'critic_loss':   162.6031, 'actor_loss':    -0.1043, 'alpha_loss':    -0.4975, 'eps_e':     1.0000})
Step:  215000, Reward:   132.317 [   0.000], Avg:    97.943 (1.000) <0-01:13:17> ({'r_t':  3651.1613, 'eps':     1.0000, 'critic_loss':   189.8409, 'actor_loss':    -0.1490, 'alpha_loss':     0.1422, 'eps_e':     1.0000})
Step:  220000, Reward:    64.705 [   0.000], Avg:    97.205 (1.000) <0-01:14:59> ({'r_t':  4110.4601, 'eps':     1.0000, 'critic_loss':   307.8352, 'actor_loss':    -0.1169, 'alpha_loss':     0.4158, 'eps_e':     1.0000})
Step:  225000, Reward:   141.945 [   0.000], Avg:    98.177 (1.000) <0-01:16:42> ({'r_t':  4034.9369, 'eps':     1.0000, 'critic_loss':   228.1745, 'actor_loss':    -0.1063, 'alpha_loss':     0.5085, 'eps_e':     1.0000})
Step:  230000, Reward:   135.308 [   0.000], Avg:    98.967 (1.000) <0-01:18:24> ({'r_t':  3842.3941, 'eps':     1.0000, 'critic_loss':   413.9142, 'actor_loss':    -0.0708, 'alpha_loss':     0.1896, 'eps_e':     1.0000})
Step:  235000, Reward:   141.643 [   0.000], Avg:    99.856 (1.000) <0-01:20:07> ({'r_t':  4369.7593, 'eps':     1.0000, 'critic_loss':   283.3039, 'actor_loss':    -0.1279, 'alpha_loss':    -0.1205, 'eps_e':     1.0000})
Step:  240000, Reward:   144.295 [   0.000], Avg:   100.763 (1.000) <0-01:21:49> ({'r_t':  4163.2407, 'eps':     1.0000, 'critic_loss':   282.7368, 'actor_loss':    -0.0817, 'alpha_loss':     0.1052, 'eps_e':     1.0000})
Step:  245000, Reward:   150.859 [   0.000], Avg:   101.765 (1.000) <0-01:23:32> ({'r_t':  4544.9937, 'eps':     1.0000, 'critic_loss':   158.7692, 'actor_loss':    -0.0800, 'alpha_loss':    -0.0673, 'eps_e':     1.0000})
Step:  250000, Reward:   143.496 [   0.000], Avg:   102.583 (1.000) <0-01:25:14> ({'r_t':  4069.5559, 'eps':     1.0000, 'critic_loss':   181.7077, 'actor_loss':    -0.0672, 'alpha_loss':    -0.1755, 'eps_e':     1.0000})
Step:  255000, Reward:   151.149 [   0.000], Avg:   103.517 (1.000) <0-01:26:57> ({'r_t':  4301.7372, 'eps':     1.0000, 'critic_loss':   289.5064, 'actor_loss':    -0.0881, 'alpha_loss':    -0.1324, 'eps_e':     1.0000})
Step:  260000, Reward:   145.409 [   0.000], Avg:   104.308 (1.000) <0-01:28:39> ({'r_t':  4262.4425, 'eps':     1.0000, 'critic_loss':   195.0519, 'actor_loss':    -0.0839, 'alpha_loss':     0.0199, 'eps_e':     1.0000})
Step:  265000, Reward:   146.647 [   0.000], Avg:   105.092 (1.000) <0-01:30:22> ({'r_t':  4072.9875, 'eps':     1.0000, 'critic_loss':   280.9645, 'actor_loss':    -0.0838, 'alpha_loss':     0.0304, 'eps_e':     1.0000})
Step:  270000, Reward:   139.669 [   0.000], Avg:   105.720 (1.000) <0-01:32:04> ({'r_t':  3776.1021, 'eps':     1.0000, 'critic_loss':   153.8211, 'actor_loss':    -0.1118, 'alpha_loss':    -0.4566, 'eps_e':     1.0000})
Step:  275000, Reward:   137.959 [   0.000], Avg:   106.296 (1.000) <0-01:33:47> ({'r_t':  3080.9021, 'eps':     1.0000, 'critic_loss':   308.6611, 'actor_loss':    -0.1729, 'alpha_loss':    -0.4347, 'eps_e':     1.0000})
Step:  280000, Reward:   135.043 [   0.000], Avg:   106.800 (1.000) <0-01:35:29> ({'r_t':  3531.3084, 'eps':     1.0000, 'critic_loss':   207.8329, 'actor_loss':    -0.2260, 'alpha_loss':    -1.1727, 'eps_e':     1.0000})
Step:  285000, Reward:   142.777 [   0.000], Avg:   107.421 (1.000) <0-01:37:12> ({'r_t':  4036.6808, 'eps':     1.0000, 'critic_loss':   112.0278, 'actor_loss':    -0.1157, 'alpha_loss':     0.1828, 'eps_e':     1.0000})
Step:  290000, Reward:   137.011 [   0.000], Avg:   107.922 (1.000) <0-01:38:54> ({'r_t':  3400.7574, 'eps':     1.0000, 'critic_loss':   334.4008, 'actor_loss':    -0.0864, 'alpha_loss':     0.3874, 'eps_e':     1.0000})
Step:  295000, Reward:   140.816 [   0.000], Avg:   108.471 (1.000) <0-01:40:37> ({'r_t':  3910.1816, 'eps':     1.0000, 'critic_loss':   392.6073, 'actor_loss':    -0.1466, 'alpha_loss':     0.2595, 'eps_e':     1.0000})
Step:  300000, Reward:   150.774 [   0.000], Avg:   109.164 (1.000) <0-01:42:19> ({'r_t':  4473.9396, 'eps':     1.0000, 'critic_loss':   206.7042, 'actor_loss':    -0.1379, 'alpha_loss':     0.7590, 'eps_e':     1.0000})
Step:  305000, Reward:   163.643 [   0.000], Avg:   110.043 (1.000) <0-01:44:02> ({'r_t':  4336.5312, 'eps':     1.0000, 'critic_loss':   118.6233, 'actor_loss':    -0.0777, 'alpha_loss':     0.1618, 'eps_e':     1.0000})
Step:  310000, Reward:   152.336 [   0.000], Avg:   110.714 (1.000) <0-01:45:44> ({'r_t':  4292.7954, 'eps':     1.0000, 'critic_loss':    78.3316, 'actor_loss':    -0.0496, 'alpha_loss':    -0.0917, 'eps_e':     1.0000})
Step:  315000, Reward:   126.693 [   0.000], Avg:   110.964 (1.000) <0-01:47:27> ({'r_t':  3923.4380, 'eps':     1.0000, 'critic_loss':   352.3595, 'actor_loss':    -0.0944, 'alpha_loss':     0.3756, 'eps_e':     1.0000})
Step:  320000, Reward:   161.640 [   0.000], Avg:   111.743 (1.000) <0-01:49:10> ({'r_t':  4232.5598, 'eps':     1.0000, 'critic_loss':   270.3886, 'actor_loss':    -0.1004, 'alpha_loss':     0.3703, 'eps_e':     1.0000})
Step:  325000, Reward:   163.278 [   0.000], Avg:   112.524 (1.000) <0-01:50:52> ({'r_t':  4286.0450, 'eps':     1.0000, 'critic_loss':   207.8002, 'actor_loss':    -0.0671, 'alpha_loss':     0.0561, 'eps_e':     1.0000})
Step:  330000, Reward:   146.104 [   0.000], Avg:   113.025 (1.000) <0-01:52:35> ({'r_t':  4006.2025, 'eps':     1.0000, 'critic_loss':   349.6884, 'actor_loss':    -0.1091, 'alpha_loss':     0.3106, 'eps_e':     1.0000})
Step:  335000, Reward:   140.810 [   0.000], Avg:   113.434 (1.000) <0-01:54:17> ({'r_t':  3774.4061, 'eps':     1.0000, 'critic_loss':   313.6713, 'actor_loss':    -0.1080, 'alpha_loss':     0.0982, 'eps_e':     1.0000})
Step:  340000, Reward:   154.205 [   0.000], Avg:   114.025 (1.000) <0-01:56:00> ({'r_t':  3939.0553, 'eps':     1.0000, 'critic_loss':   402.4337, 'actor_loss':    -0.0744, 'alpha_loss':    -0.0103, 'eps_e':     1.0000})
Step:  345000, Reward:   160.851 [   0.000], Avg:   114.694 (1.000) <0-01:57:43> ({'r_t':  4236.7768, 'eps':     1.0000, 'critic_loss':   346.9095, 'actor_loss':    -0.0909, 'alpha_loss':    -0.1012, 'eps_e':     1.0000})
Step:  350000, Reward:   147.346 [   0.000], Avg:   115.154 (1.000) <0-01:59:25> ({'r_t':  4109.5113, 'eps':     1.0000, 'critic_loss':   239.0025, 'actor_loss':    -0.1333, 'alpha_loss':     0.3125, 'eps_e':     1.0000})
Step:  355000, Reward:   163.810 [   0.000], Avg:   115.829 (1.000) <0-02:01:08> ({'r_t':  4422.3744, 'eps':     1.0000, 'critic_loss':   364.4934, 'actor_loss':    -0.0503, 'alpha_loss':     0.0007, 'eps_e':     1.0000})
Step:  360000, Reward:   163.176 [   0.000], Avg:   116.478 (1.000) <0-02:02:50> ({'r_t':  4279.9519, 'eps':     1.0000, 'critic_loss':   244.1655, 'actor_loss':    -0.0555, 'alpha_loss':    -0.0564, 'eps_e':     1.0000})
Step:  365000, Reward:   141.028 [   0.000], Avg:   116.810 (1.000) <0-02:04:33> ({'r_t':  4371.1579, 'eps':     1.0000, 'critic_loss':   252.7693, 'actor_loss':    -0.0626, 'alpha_loss':    -0.0232, 'eps_e':     1.0000})
Step:  370000, Reward:   116.038 [   0.000], Avg:   116.800 (1.000) <0-02:06:15> ({'r_t':  4220.7061, 'eps':     1.0000, 'critic_loss':   232.5252, 'actor_loss':    -0.0397, 'alpha_loss':    -0.1308, 'eps_e':     1.0000})
Step:  375000, Reward:   142.245 [   0.000], Avg:   117.134 (1.000) <0-02:07:57> ({'r_t':  4218.7495, 'eps':     1.0000, 'critic_loss':   343.0691, 'actor_loss':    -0.0562, 'alpha_loss':    -0.1023, 'eps_e':     1.0000})
Step:  380000, Reward:   124.880 [   0.000], Avg:   117.235 (1.000) <0-02:09:40> ({'r_t':  3711.9503, 'eps':     1.0000, 'critic_loss':   529.5745, 'actor_loss':    -0.0725, 'alpha_loss':     0.1236, 'eps_e':     1.0000})
Step:  385000, Reward:   151.101 [   0.000], Avg:   117.669 (1.000) <0-02:11:22> ({'r_t':  4267.1161, 'eps':     1.0000, 'critic_loss':   528.4068, 'actor_loss':    -0.0885, 'alpha_loss':    -0.0503, 'eps_e':     1.0000})
Step:  390000, Reward:   143.255 [   0.000], Avg:   117.993 (1.000) <0-02:13:05> ({'r_t':  4191.7241, 'eps':     1.0000, 'critic_loss':   402.8766, 'actor_loss':    -0.1422, 'alpha_loss':     0.3248, 'eps_e':     1.0000})
Step:  395000, Reward:   137.464 [   0.000], Avg:   118.236 (1.000) <0-02:14:47> ({'r_t':  4658.9143, 'eps':     1.0000, 'critic_loss':   267.1435, 'actor_loss':    -0.0572, 'alpha_loss':     0.2985, 'eps_e':     1.0000})
Step:  400000, Reward:   131.756 [   0.000], Avg:   118.403 (1.000) <0-02:16:30> ({'r_t':  4233.1161, 'eps':     1.0000, 'critic_loss':   228.2336, 'actor_loss':    -0.0029, 'alpha_loss':    -0.0364, 'eps_e':     1.0000})
Step:  405000, Reward:   138.810 [   0.000], Avg:   118.652 (1.000) <0-02:18:12> ({'r_t':  3983.4469, 'eps':     1.0000, 'critic_loss':   462.2956, 'actor_loss':    -0.0362, 'alpha_loss':    -0.2694, 'eps_e':     1.0000})
Step:  410000, Reward:   129.475 [   0.000], Avg:   118.783 (1.000) <0-02:19:58> ({'r_t':  3439.0038, 'eps':     1.0000, 'critic_loss':   484.6012, 'actor_loss':    -0.0720, 'alpha_loss':    -0.7702, 'eps_e':     1.0000})
Step:  415000, Reward:   154.260 [   0.000], Avg:   119.205 (1.000) <0-02:21:41> ({'r_t':  3245.8086, 'eps':     1.0000, 'critic_loss':   466.1003, 'actor_loss':    -0.1491, 'alpha_loss':    -1.1391, 'eps_e':     1.0000})
Step:  420000, Reward:   152.953 [   0.000], Avg:   119.602 (1.000) <0-02:23:30> ({'r_t':  2550.5380, 'eps':     1.0000, 'critic_loss':   207.9733, 'actor_loss':    -0.1606, 'alpha_loss':    -1.0683, 'eps_e':     1.0000})
Step:  425000, Reward:   155.302 [   0.000], Avg:   120.017 (1.000) <0-02:25:20> ({'r_t':  2179.0711, 'eps':     1.0000, 'critic_loss':   261.4356, 'actor_loss':    -0.1312, 'alpha_loss':    -2.0758, 'eps_e':     1.0000})
Step:  430000, Reward:   157.600 [   0.000], Avg:   120.449 (1.000) <0-02:27:09> ({'r_t':  3639.3912, 'eps':     1.0000, 'critic_loss':   311.4598, 'actor_loss':    -0.1721, 'alpha_loss':     0.2286, 'eps_e':     1.0000})
Step:  435000, Reward:   159.576 [   0.000], Avg:   120.894 (1.000) <0-02:28:52> ({'r_t':  2824.7395, 'eps':     1.0000, 'critic_loss':   360.3792, 'actor_loss':    -0.1433, 'alpha_loss':     0.7683, 'eps_e':     1.0000})
Step:  440000, Reward:   139.615 [   0.000], Avg:   121.104 (1.000) <0-02:30:34> ({'r_t':  3082.1136, 'eps':     1.0000, 'critic_loss':   295.4513, 'actor_loss':    -0.1537, 'alpha_loss':     0.0248, 'eps_e':     1.0000})
Step:  445000, Reward:   158.512 [   0.000], Avg:   121.520 (1.000) <0-02:32:17> ({'r_t':  2462.3266, 'eps':     1.0000, 'critic_loss':   223.0077, 'actor_loss':    -0.0944, 'alpha_loss':    -0.8770, 'eps_e':     1.0000})
Step:  450000, Reward:   151.139 [   0.000], Avg:   121.845 (1.000) <0-02:34:02> ({'r_t':  2871.7342, 'eps':     1.0000, 'critic_loss':   422.4650, 'actor_loss':    -0.1490, 'alpha_loss':     0.8588, 'eps_e':     1.0000})
Step:  455000, Reward:   140.870 [   0.000], Avg:   122.052 (1.000) <0-02:35:45> ({'r_t':  3358.2243, 'eps':     1.0000, 'critic_loss':   412.5672, 'actor_loss':    -0.1304, 'alpha_loss':     0.5769, 'eps_e':     1.0000})
Step:  460000, Reward:   147.522 [   0.000], Avg:   122.326 (1.000) <0-02:37:28> ({'r_t':  3749.5448, 'eps':     1.0000, 'critic_loss':   289.6693, 'actor_loss':    -0.1201, 'alpha_loss':     0.8216, 'eps_e':     1.0000})
Step:  465000, Reward:   150.537 [   0.000], Avg:   122.626 (1.000) <0-02:39:11> ({'r_t':  3703.6720, 'eps':     1.0000, 'critic_loss':   363.9395, 'actor_loss':    -0.1039, 'alpha_loss':     0.4484, 'eps_e':     1.0000})
Step:  470000, Reward:   167.436 [   0.000], Avg:   123.098 (1.000) <0-02:40:53> ({'r_t':  4011.1920, 'eps':     1.0000, 'critic_loss':   189.4467, 'actor_loss':    -0.1073, 'alpha_loss':    -0.1168, 'eps_e':     1.0000})
Step:  475000, Reward:   148.804 [   0.000], Avg:   123.365 (1.000) <0-02:42:36> ({'r_t':  3939.2137, 'eps':     1.0000, 'critic_loss':   243.2884, 'actor_loss':    -0.0878, 'alpha_loss':     0.3798, 'eps_e':     1.0000})
Step:  480000, Reward:   134.282 [   0.000], Avg:   123.478 (1.000) <0-02:44:19> ({'r_t':  3805.2200, 'eps':     1.0000, 'critic_loss':   349.1259, 'actor_loss':    -0.0850, 'alpha_loss':     0.3906, 'eps_e':     1.0000})
Step:  485000, Reward:   155.855 [   0.000], Avg:   123.808 (1.000) <0-02:46:01> ({'r_t':  4399.0637, 'eps':     1.0000, 'critic_loss':   212.7964, 'actor_loss':    -0.1210, 'alpha_loss':    -0.0267, 'eps_e':     1.0000})
Step:  490000, Reward:   154.829 [   0.000], Avg:   124.122 (1.000) <0-02:47:44> ({'r_t':  4191.5918, 'eps':     1.0000, 'critic_loss':   172.5792, 'actor_loss':    -0.0694, 'alpha_loss':     0.1343, 'eps_e':     1.0000})
Step:  495000, Reward:   150.476 [   0.000], Avg:   124.385 (1.000) <0-02:49:27> ({'r_t':  3964.9076, 'eps':     1.0000, 'critic_loss':   218.9209, 'actor_loss':    -0.0780, 'alpha_loss':     0.0572, 'eps_e':     1.0000})
Step:  500000, Reward:   162.608 [   0.000], Avg:   124.764 (1.000) <0-02:51:09> ({'r_t':  4077.1785, 'eps':     1.0000, 'critic_loss':   274.8993, 'actor_loss':    -0.0708, 'alpha_loss':    -0.0001, 'eps_e':     1.0000})
