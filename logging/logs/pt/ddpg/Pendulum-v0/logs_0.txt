Model: <class 'src.models.pytorch.agents.ddpg.DDPGAgent'>, Env: Pendulum-v0, Date: 07/06/2020 01:04:22
CPU: 20 Core, 0.0GHz, 377.59 GB, Linux-4.14.175-llgrid-10ms-x86_64-with-debian-buster-sid
GPU 0: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
GPU 1: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
Git URL: https://github.com/shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: df05964fa4262840095e5c93d6ca54a9f32dc498
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   dynamics_size = 3
   state_size = (3,)
   action_size = (1,)
   env_name = Pendulum-v0
   rank = 0
   size = 17
   split = 17
   model = ddpg
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f7f7ba89ba8> 
	env = <GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>> 
		env = <TimeLimit<PendulumEnv<Pendulum-v0>>> 
			env = <PendulumEnv<Pendulum-v0>> 
				max_speed = 8
				max_torque = 2.0
				dt = 0.05
				g = 10.0
				m = 1.0
				l = 1.0
				viewer = None
				action_space = Box(1,) 
					dtype = float32
					shape = (1,)
					low = [-2.000]
					high = [ 2.000]
					bounded_below = [ True]
					bounded_above = [ True]
					np_random = RandomState(MT19937)
				observation_space = Box(3,) 
					dtype = float32
					shape = (3,)
					low = [-1.000 -1.000 -8.000]
					high = [ 1.000  1.000  8.000]
					bounded_below = [ True  True  True]
					bounded_above = [ True  True  True]
					np_random = RandomState(MT19937)
				np_random = RandomState(MT19937)
				spec = EnvSpec(Pendulum-v0) 
					id = Pendulum-v0
					entry_point = gym.envs.classic_control:PendulumEnv
					reward_threshold = None
					nondeterministic = False
					max_episode_steps = 200
				verbose = 0
			action_space = Box(1,) 
				dtype = float32
				shape = (1,)
				low = [-2.000]
				high = [ 2.000]
				bounded_below = [ True]
				bounded_above = [ True]
				np_random = RandomState(MT19937)
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		action_space = Box(1,) 
			dtype = float32
			shape = (1,)
			low = [-2.000]
			high = [ 2.000]
			bounded_below = [ True]
			bounded_above = [ True]
			np_random = RandomState(MT19937)
		observation_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -8.000]
			high = [ 1.000  1.000  8.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f7f7ba9f9b0> 
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
	state_size = (3,)
	action_size = (1,)
	action_space = Box(1,) 
		dtype = float32
		shape = (1,)
		low = [-2.000]
		high = [ 2.000]
		bounded_below = [ True]
		bounded_above = [ True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.MPIConnection object at 0x7f7f7baa2080> 
		root = 0
		rank = 0
		cluster = <list len=16>
	num_envs = 16
	max_steps = 200,
agent: <src.models.wrappers.ParallelAgent object at 0x7f7f7baa20b8> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f7f7b9f77f0> 
		state_size = (3,)
	agent = <src.models.pytorch.agents.ddpg.DDPGAgent object at 0x7f7f7ba09c18> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f7f7ba09c50> 
			size = (1,)
			dt = 0.2
			action = [-0.889]
			daction_dt = [ 0.445]
		discrete = False
		action_size = (1,)
		state_size = (3,)
		config = <src.utils.config.Config object at 0x7f7f7bd7ea58> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			dynamics_size = 3
			state_size = (3,)
			action_size = (1,)
			env_name = Pendulum-v0
			rank = 0
			size = 17
			split = 17
			model = ddpg
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f7f7ba09c88> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = DDPGNetwork(
			  (actor_local): DDPGActor(
			    (layer1): Linear(in_features=3, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=1, bias=True)
			    (action_sig): Linear(in_features=256, out_features=1, bias=True)
			  )
			  (actor_target): DDPGActor(
			    (layer1): Linear(in_features=3, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=1, bias=True)
			    (action_sig): Linear(in_features=256, out_features=1, bias=True)
			  )
			  (critic_local): DDPGCritic(
			    (net_state): Linear(in_features=3, out_features=512, bias=True)
			    (net_action): Linear(in_features=1, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): DDPGCritic(
			    (net_state): Linear(in_features=3, out_features=512, bias=True)
			    (net_action): Linear(in_features=1, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = ddpg
			stats = <src.utils.logger.Stats object at 0x7f7f7ba09cf8> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f7f7bd7ea58> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				dynamics_size = 3
				state_size = (3,)
				action_size = (1,)
				env_name = Pendulum-v0
				rank = 0
				size = 17
				split = 17
				model = ddpg
				framework = pt
				train_prop = 1.0
				tcp_ports = []
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class DDPGActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, sample=True):\n\t\tstate = self.layer1(state).relu() \n\t\tstate = self.layer2(state).relu() \n\t\tstate = self.layer3(state).relu() \n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).exp()\n\t\tepsilon = torch.randn_like(action_sig)\n\t\taction = action_mu + epsilon.mul(action_sig) if sample else action_mu\n\t\treturn action.tanh() if not self.discrete else gsoftmax(action)\n', 'class DDPGCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f7f7ba1d438> 
			buffer = deque([], maxlen=1000000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f7f7ba1d470> 
		size = (1,)
		dt = 0.2
		action = [-0.083]
		daction_dt = [-0.915]
	discrete = False
	action_size = (1,)
	state_size = (3,)
	config = <src.utils.config.Config object at 0x7f7f7bd7ea58> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		dynamics_size = 3
		state_size = (3,)
		action_size = (1,)
		env_name = Pendulum-v0
		rank = 0
		size = 17
		split = 17
		model = ddpg
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f7f7ba1d4a8> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import random
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax, one_hot
from src.utils.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh() if not self.discrete else gsoftmax(action)
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=DDPGActor, critic=DDPGCritic, gpu=True, load=None, name="ddpg"): 
		self.discrete = type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)

	def get_action(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			q_value = q_value.gather(-1, action.argmax(-1, keepdim=True)) if self.discrete and not probs else q_value
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, q_targets):
		actions = one_hot(actions) if self.actor_local.discrete else actions
		q_values = self.get_q_value(states, actions, grad=True, probs=False)
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True, probs=True)
		q_actions = (actor_action*q_actions).sum(-1) if self.discrete else q_actions
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = -(q_actions - q_baseline.detach()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		self.soft_copy(self.actor_local, self.actor_target)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)
		
class DDPGAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, DDPGNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if self.discrete and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), numpy=True, sample=sample)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			actions = torch.cat([actions, self.network.get_action(states[-1], use_target=True).unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets)
			if np.any(done[0]): self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward: -1346.805 [ 237.547], Avg: -1346.805 (1.000) <0-00:00:00> ({'r_t':    -3.2476, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward: -1392.947 [ 216.750], Avg: -1369.876 (0.990) <0-00:00:10> ({'r_t': -6197.5417, 'eps':     0.9900, 'critic_loss':  1052.8762, 'actor_loss':    -0.5827, 'eps_e':     0.9900})
Step:    2000, Reward: -1482.399 [ 120.836], Avg: -1407.384 (0.980) <0-00:00:21> ({'r_t': -6156.9246, 'eps':     0.9802, 'critic_loss':   491.6535, 'actor_loss':    -0.4249, 'eps_e':     0.9802})
Step:    3000, Reward: -1140.524 [ 152.754], Avg: -1340.669 (0.970) <0-00:00:33> ({'r_t': -6137.1582, 'eps':     0.9704, 'critic_loss':   517.4554, 'actor_loss':    -0.5719, 'eps_e':     0.9704})
Step:    4000, Reward: -1114.484 [ 110.968], Avg: -1295.432 (0.961) <0-00:00:45> ({'r_t': -6140.9112, 'eps':     0.9608, 'critic_loss':   588.2876, 'actor_loss':    -0.9301, 'eps_e':     0.9608})
Step:    5000, Reward: -1076.267 [ 106.889], Avg: -1258.904 (0.951) <0-00:00:57> ({'r_t': -6157.3072, 'eps':     0.9512, 'critic_loss':   708.8489, 'actor_loss':    -1.2968, 'eps_e':     0.9512})
Step:    6000, Reward:  -838.064 [ 104.694], Avg: -1198.784 (0.942) <0-00:01:09> ({'r_t': -6058.8144, 'eps':     0.9417, 'critic_loss':   867.6696, 'actor_loss':    -1.6858, 'eps_e':     0.9417})
Step:    7000, Reward: -1193.145 [ 254.911], Avg: -1198.079 (0.932) <0-00:01:21> ({'r_t': -5955.6109, 'eps':     0.9323, 'critic_loss':  1073.9821, 'actor_loss':    -1.8586, 'eps_e':     0.9323})
Step:    8000, Reward:  -695.887 [  90.394], Avg: -1142.280 (0.923) <0-00:01:43> ({'r_t': -6085.7019, 'eps':     0.9230, 'critic_loss':  1290.6697, 'actor_loss':    -1.8993, 'eps_e':     0.9230})
Step:    9000, Reward: -1232.093 [ 234.375], Avg: -1151.261 (0.914) <0-00:01:56> ({'r_t': -6052.8548, 'eps':     0.9138, 'critic_loss':  1501.1361, 'actor_loss':    -2.0064, 'eps_e':     0.9138})
Step:   10000, Reward:  -903.449 [ 510.029], Avg: -1128.733 (0.905) <0-00:02:07> ({'r_t': -6095.2239, 'eps':     0.9047, 'critic_loss':  1681.3588, 'actor_loss':    -2.3246, 'eps_e':     0.9047})
Step:   11000, Reward: -1107.225 [ 307.601], Avg: -1126.941 (0.896) <0-00:02:20> ({'r_t': -6017.9157, 'eps':     0.8957, 'critic_loss':  1867.6937, 'actor_loss':    -2.1271, 'eps_e':     0.8957})
Step:   12000, Reward: -1263.552 [ 154.327], Avg: -1137.449 (0.887) <0-00:02:32> ({'r_t': -6084.9221, 'eps':     0.8868, 'critic_loss':  2032.2040, 'actor_loss':    -2.5337, 'eps_e':     0.8868})
Step:   13000, Reward:  -338.839 [ 306.559], Avg: -1080.406 (0.878) <0-00:02:44> ({'r_t': -5693.7365, 'eps':     0.8780, 'critic_loss':  2186.2319, 'actor_loss':    -4.1789, 'eps_e':     0.8780})
Step:   14000, Reward:  -214.768 [ 139.622], Avg: -1022.696 (0.869) <0-00:02:56> ({'r_t': -5551.6390, 'eps':     0.8692, 'critic_loss':  2236.9580, 'actor_loss':    -4.7001, 'eps_e':     0.8692})
Step:   15000, Reward:  -418.247 [  80.140], Avg:  -984.918 (0.861) <0-00:03:08> ({'r_t': -5729.2258, 'eps':     0.8606, 'critic_loss':  2338.0791, 'actor_loss':    -5.2448, 'eps_e':     0.8606})
Step:   16000, Reward:  -158.220 [  89.480], Avg:  -936.289 (0.852) <0-00:03:24> ({'r_t': -5734.1625, 'eps':     0.8520, 'critic_loss':  2418.0076, 'actor_loss':    -5.7421, 'eps_e':     0.8520})
Step:   17000, Reward:  -157.684 [ 111.640], Avg:  -893.033 (0.844) <0-00:03:36> ({'r_t': -5638.6603, 'eps':     0.8435, 'critic_loss':  2504.4761, 'actor_loss':    -6.6804, 'eps_e':     0.8435})
Step:   18000, Reward:  -140.423 [  89.456], Avg:  -853.422 (0.835) <0-00:04:00> ({'r_t': -5591.2418, 'eps':     0.8351, 'critic_loss':  2546.7048, 'actor_loss':    -7.3912, 'eps_e':     0.8351})
Step:   19000, Reward:  -222.701 [  97.116], Avg:  -821.886 (0.827) <0-00:04:12> ({'r_t': -5476.6722, 'eps':     0.8268, 'critic_loss':  2639.1694, 'actor_loss':    -8.0343, 'eps_e':     0.8268})
Step:   20000, Reward:  -569.329 [ 135.992], Avg:  -809.860 (0.819) <0-00:04:25> ({'r_t': -5482.2361, 'eps':     0.8186, 'critic_loss':  2718.6746, 'actor_loss':    -8.4468, 'eps_e':     0.8186})
Step:   21000, Reward:  -583.479 [  97.757], Avg:  -799.570 (0.810) <0-00:04:37> ({'r_t': -5504.2154, 'eps':     0.8104, 'critic_loss':  2687.4543, 'actor_loss':    -9.0399, 'eps_e':     0.8104})
Step:   22000, Reward:  -766.911 [  57.520], Avg:  -798.150 (0.802) <0-00:04:49> ({'r_t': -5524.8531, 'eps':     0.8023, 'critic_loss':  2747.8433, 'actor_loss':    -9.4817, 'eps_e':     0.8023})
Step:   23000, Reward:  -213.557 [ 141.418], Avg:  -773.792 (0.794) <0-00:05:01> ({'r_t': -5357.7609, 'eps':     0.7944, 'critic_loss':  2778.6855, 'actor_loss':   -10.5150, 'eps_e':     0.7944})
Step:   24000, Reward:  -630.526 [ 118.457], Avg:  -768.061 (0.786) <0-00:05:14> ({'r_t': -5319.0225, 'eps':     0.7864, 'critic_loss':  2807.3254, 'actor_loss':   -11.2694, 'eps_e':     0.7864})
Step:   25000, Reward:  -180.399 [  97.557], Avg:  -745.459 (0.779) <0-00:05:26> ({'r_t': -5161.3233, 'eps':     0.7786, 'critic_loss':  2814.1299, 'actor_loss':   -12.3953, 'eps_e':     0.7786})
Step:   26000, Reward:  -192.572 [  94.617], Avg:  -724.981 (0.771) <0-00:05:38> ({'r_t': -5110.3188, 'eps':     0.7709, 'critic_loss':  2798.9062, 'actor_loss':   -12.8344, 'eps_e':     0.7709})
Step:   27000, Reward:  -177.965 [  89.080], Avg:  -705.445 (0.763) <0-00:05:50> ({'r_t': -5304.1144, 'eps':     0.7632, 'critic_loss':  2896.8474, 'actor_loss':   -13.0424, 'eps_e':     0.7632})
Step:   28000, Reward:  -193.920 [ 114.338], Avg:  -687.806 (0.756) <0-00:06:02> ({'r_t': -5236.3322, 'eps':     0.7556, 'critic_loss':  2843.1538, 'actor_loss':   -13.6500, 'eps_e':     0.7556})
Step:   29000, Reward:  -218.788 [ 131.206], Avg:  -672.172 (0.748) <0-00:06:15> ({'r_t': -5064.6267, 'eps':     0.7480, 'critic_loss':  2872.8318, 'actor_loss':   -14.1700, 'eps_e':     0.7480})
Step:   30000, Reward:  -402.711 [ 126.261], Avg:  -663.480 (0.741) <0-00:06:27> ({'r_t': -5055.2680, 'eps':     0.7406, 'critic_loss':  2904.8623, 'actor_loss':   -14.6199, 'eps_e':     0.7406})
Step:   31000, Reward:  -251.746 [ 148.867], Avg:  -650.613 (0.733) <0-00:06:40> ({'r_t': -5263.2999, 'eps':     0.7332, 'critic_loss':  2895.5496, 'actor_loss':   -15.4452, 'eps_e':     0.7332})
Step:   32000, Reward:  -170.012 [  75.183], Avg:  -636.050 (0.726) <0-00:06:52> ({'r_t': -4951.0071, 'eps':     0.7259, 'critic_loss':  2924.9189, 'actor_loss':   -16.2822, 'eps_e':     0.7259})
Step:   33000, Reward:  -244.921 [ 341.436], Avg:  -624.546 (0.719) <0-00:07:04> ({'r_t': -4952.7008, 'eps':     0.7187, 'critic_loss':  2915.9080, 'actor_loss':   -16.2237, 'eps_e':     0.7187})
Step:   34000, Reward:  -145.993 [  93.001], Avg:  -610.873 (0.712) <0-00:07:17> ({'r_t': -4982.0081, 'eps':     0.7115, 'critic_loss':  2898.6362, 'actor_loss':   -16.9116, 'eps_e':     0.7115})
Step:   35000, Reward:  -123.756 [  71.880], Avg:  -597.342 (0.704) <0-00:07:29> ({'r_t': -5027.1451, 'eps':     0.7044, 'critic_loss':  2930.6423, 'actor_loss':   -17.5626, 'eps_e':     0.7044})
Step:   36000, Reward:  -157.555 [ 115.012], Avg:  -585.456 (0.697) <0-00:07:42> ({'r_t': -4881.9149, 'eps':     0.6974, 'critic_loss':  2886.3254, 'actor_loss':   -17.5724, 'eps_e':     0.6974})
Step:   37000, Reward:  -129.891 [  94.131], Avg:  -573.467 (0.690) <0-00:07:55> ({'r_t': -4822.1838, 'eps':     0.6905, 'critic_loss':  2889.2241, 'actor_loss':   -18.0064, 'eps_e':     0.6905})
Step:   38000, Reward:  -663.318 [  41.797], Avg:  -575.771 (0.684) <0-00:08:07> ({'r_t': -4842.3887, 'eps':     0.6836, 'critic_loss':  2866.7068, 'actor_loss':   -18.5727, 'eps_e':     0.6836})
Step:   39000, Reward:  -128.110 [  91.696], Avg:  -564.580 (0.677) <0-00:08:20> ({'r_t': -4620.0492, 'eps':     0.6768, 'critic_loss':  2890.5173, 'actor_loss':   -18.0290, 'eps_e':     0.6768})
Step:   40000, Reward:  -523.177 [  77.769], Avg:  -563.570 (0.670) <0-00:08:33> ({'r_t': -4640.2265, 'eps':     0.6701, 'critic_loss':  2913.5605, 'actor_loss':   -17.5594, 'eps_e':     0.6701})
Step:   41000, Reward:  -139.501 [  86.577], Avg:  -553.473 (0.663) <0-00:08:46> ({'r_t': -4628.1531, 'eps':     0.6634, 'critic_loss':  2881.7146, 'actor_loss':   -18.1014, 'eps_e':     0.6634})
Step:   42000, Reward: -1047.707 [  83.616], Avg:  -564.967 (0.657) <0-00:08:58> ({'r_t': -4750.8596, 'eps':     0.6568, 'critic_loss':  2868.7473, 'actor_loss':   -18.1549, 'eps_e':     0.6568})
Step:   43000, Reward:  -822.209 [  52.180], Avg:  -570.813 (0.650) <0-00:09:11> ({'r_t': -4919.6139, 'eps':     0.6502, 'critic_loss':  2913.2620, 'actor_loss':   -18.3314, 'eps_e':     0.6502})
Step:   44000, Reward:  -770.362 [  31.011], Avg:  -575.247 (0.644) <0-00:09:24> ({'r_t': -4873.5858, 'eps':     0.6438, 'critic_loss':  2875.3340, 'actor_loss':   -18.6600, 'eps_e':     0.6438})
Step:   45000, Reward:  -596.318 [  93.190], Avg:  -575.706 (0.637) <0-00:09:37> ({'r_t': -4769.3618, 'eps':     0.6373, 'critic_loss':  2892.0852, 'actor_loss':   -18.8236, 'eps_e':     0.6373})
Step:   46000, Reward:  -272.800 [ 197.213], Avg:  -569.261 (0.631) <0-00:09:50> ({'r_t': -4694.3788, 'eps':     0.6310, 'critic_loss':  2876.5022, 'actor_loss':   -17.8076, 'eps_e':     0.6310})
Step:   47000, Reward: -1552.574 [  56.354], Avg:  -589.746 (0.625) <0-00:10:03> ({'r_t': -5522.5577, 'eps':     0.6247, 'critic_loss':  2870.6182, 'actor_loss':   -17.4626, 'eps_e':     0.6247})
Step:   48000, Reward: -1497.553 [  62.618], Avg:  -608.273 (0.618) <0-00:10:16> ({'r_t': -5889.8730, 'eps':     0.6185, 'critic_loss':  2884.0359, 'actor_loss':   -15.5056, 'eps_e':     0.6185})
Step:   49000, Reward: -1564.791 [  31.231], Avg:  -627.403 (0.612) <0-00:10:28> ({'r_t': -5943.9298, 'eps':     0.6123, 'critic_loss':  2908.8818, 'actor_loss':   -15.4787, 'eps_e':     0.6123})
Step:   50000, Reward: -1510.492 [  68.906], Avg:  -644.719 (0.606) <0-00:10:41> ({'r_t': -6043.2916, 'eps':     0.6062, 'critic_loss':  2974.7017, 'actor_loss':   -13.9767, 'eps_e':     0.6062})
Step:   51000, Reward: -1545.633 [  45.460], Avg:  -662.044 (0.600) <0-00:10:54> ({'r_t': -5852.3735, 'eps':     0.6002, 'critic_loss':  3005.7124, 'actor_loss':   -13.7791, 'eps_e':     0.6002})
Step:   52000, Reward: -1541.528 [  72.381], Avg:  -678.638 (0.594) <0-00:11:07> ({'r_t': -5810.7408, 'eps':     0.5942, 'critic_loss':  2944.0925, 'actor_loss':   -13.2559, 'eps_e':     0.5942})
Step:   53000, Reward: -1421.777 [  89.122], Avg:  -692.400 (0.588) <0-00:11:20> ({'r_t': -5837.2952, 'eps':     0.5883, 'critic_loss':  3007.0557, 'actor_loss':   -12.5136, 'eps_e':     0.5883})
Step:   54000, Reward: -1504.844 [  97.186], Avg:  -707.172 (0.582) <0-00:11:33> ({'r_t': -5836.2842, 'eps':     0.5824, 'critic_loss':  3004.0864, 'actor_loss':   -11.4448, 'eps_e':     0.5824})
Step:   55000, Reward: -1517.064 [  50.728], Avg:  -721.634 (0.577) <0-00:11:46> ({'r_t': -5853.2315, 'eps':     0.5766, 'critic_loss':  3019.9045, 'actor_loss':   -11.7346, 'eps_e':     0.5766})
Step:   56000, Reward:  -971.183 [ 707.029], Avg:  -726.012 (0.571) <0-00:11:59> ({'r_t': -5982.8154, 'eps':     0.5709, 'critic_loss':  3053.3904, 'actor_loss':   -11.0667, 'eps_e':     0.5709})
Step:   57000, Reward: -1558.860 [  40.704], Avg:  -740.372 (0.565) <0-00:12:12> ({'r_t': -6019.5731, 'eps':     0.5652, 'critic_loss':  3058.0940, 'actor_loss':    -9.8229, 'eps_e':     0.5652})
Step:   58000, Reward: -1553.781 [  47.244], Avg:  -754.158 (0.560) <0-00:12:26> ({'r_t': -6078.2270, 'eps':     0.5596, 'critic_loss':  3065.9434, 'actor_loss':    -9.2681, 'eps_e':     0.5596})
Step:   59000, Reward: -1529.154 [  83.112], Avg:  -767.075 (0.554) <0-00:12:39> ({'r_t': -6270.5592, 'eps':     0.5540, 'critic_loss':  3113.4199, 'actor_loss':    -8.4170, 'eps_e':     0.5540})
Step:   60000, Reward: -1418.700 [ 146.438], Avg:  -777.757 (0.548) <0-00:12:52> ({'r_t': -5962.4557, 'eps':     0.5485, 'critic_loss':  3176.3855, 'actor_loss':    -7.9441, 'eps_e':     0.5485})
Step:   61000, Reward: -1254.796 [ 203.988], Avg:  -785.451 (0.543) <0-00:13:05> ({'r_t': -6071.7913, 'eps':     0.5430, 'critic_loss':  3171.2810, 'actor_loss':   -11.0386, 'eps_e':     0.5430})
Step:   62000, Reward: -1308.175 [ 205.948], Avg:  -793.749 (0.538) <0-00:13:19> ({'r_t': -6185.4417, 'eps':     0.5376, 'critic_loss':  3228.7778, 'actor_loss':   -26.1449, 'eps_e':     0.5376})
Step:   63000, Reward: -1167.406 [ 173.713], Avg:  -799.587 (0.532) <0-00:13:32> ({'r_t': -6337.4319, 'eps':     0.5323, 'critic_loss':  3174.5967, 'actor_loss':   -25.6931, 'eps_e':     0.5323})
Step:   64000, Reward: -1291.141 [ 154.067], Avg:  -807.149 (0.527) <0-00:13:45> ({'r_t': -6352.2023, 'eps':     0.5270, 'critic_loss':  3120.8208, 'actor_loss':   -25.1924, 'eps_e':     0.5270})
Step:   65000, Reward: -1415.554 [ 147.852], Avg:  -816.368 (0.522) <0-00:13:59> ({'r_t': -6545.4159, 'eps':     0.5217, 'critic_loss':  2965.0708, 'actor_loss':   -22.2727, 'eps_e':     0.5217})
Step:   66000, Reward: -1456.479 [ 165.047], Avg:  -825.921 (0.517) <0-00:14:12> ({'r_t': -6659.7203, 'eps':     0.5165, 'critic_loss':  2845.8123, 'actor_loss':   -21.1079, 'eps_e':     0.5165})
Step:   67000, Reward: -1479.565 [ 122.967], Avg:  -835.534 (0.511) <0-00:14:26> ({'r_t': -6743.5944, 'eps':     0.5114, 'critic_loss':  2750.9536, 'actor_loss':   -18.8427, 'eps_e':     0.5114})
Step:   68000, Reward: -1469.504 [ 185.091], Avg:  -844.722 (0.506) <0-00:14:39> ({'r_t': -6755.5093, 'eps':     0.5063, 'critic_loss':  2696.1985, 'actor_loss':   -17.5056, 'eps_e':     0.5063})
Step:   69000, Reward: -1395.655 [ 182.954], Avg:  -852.592 (0.501) <0-00:14:52> ({'r_t': -6607.8682, 'eps':     0.5012, 'critic_loss':  2614.8059, 'actor_loss':   -16.1476, 'eps_e':     0.5012})
Step:   70000, Reward: -1455.695 [ 141.741], Avg:  -861.087 (0.496) <0-00:15:06> ({'r_t': -6919.6220, 'eps':     0.4962, 'critic_loss':  2610.5591, 'actor_loss':   -14.8414, 'eps_e':     0.4962})
Step:   71000, Reward: -1421.250 [ 192.369], Avg:  -868.867 (0.491) <0-00:15:19> ({'r_t': -6780.3957, 'eps':     0.4913, 'critic_loss':  2579.9995, 'actor_loss':   -12.8385, 'eps_e':     0.4913})
Step:   72000, Reward: -1431.334 [ 174.926], Avg:  -876.572 (0.486) <0-00:15:32> ({'r_t': -6666.0396, 'eps':     0.4864, 'critic_loss':  2594.9976, 'actor_loss':   -10.9437, 'eps_e':     0.4864})
Step:   73000, Reward: -1182.747 [ 286.165], Avg:  -880.709 (0.482) <0-00:15:46> ({'r_t': -6465.8801, 'eps':     0.4816, 'critic_loss':  2609.1282, 'actor_loss':   -12.3639, 'eps_e':     0.4816})
Step:   74000, Reward: -1123.441 [ 240.820], Avg:  -883.946 (0.477) <0-00:15:59> ({'r_t': -6120.0905, 'eps':     0.4768, 'critic_loss':  2643.9905, 'actor_loss':   -16.5605, 'eps_e':     0.4768})
Step:   75000, Reward: -1207.963 [ 310.230], Avg:  -888.209 (0.472) <0-00:16:12> ({'r_t': -6204.1688, 'eps':     0.4720, 'critic_loss':  2609.0547, 'actor_loss':   -15.1335, 'eps_e':     0.4720})
Step:   76000, Reward: -1076.237 [ 443.305], Avg:  -890.651 (0.467) <0-00:16:26> ({'r_t': -6354.7847, 'eps':     0.4673, 'critic_loss':  2681.5911, 'actor_loss':   -14.7992, 'eps_e':     0.4673})
Step:   77000, Reward: -1161.826 [ 330.996], Avg:  -894.128 (0.463) <0-00:16:39> ({'r_t': -6154.6164, 'eps':     0.4627, 'critic_loss':  2681.1860, 'actor_loss':   -14.6007, 'eps_e':     0.4627})
Step:   78000, Reward: -1116.040 [ 332.223], Avg:  -896.937 (0.458) <0-00:16:53> ({'r_t': -6416.8054, 'eps':     0.4580, 'critic_loss':  2595.8252, 'actor_loss':   -13.3030, 'eps_e':     0.4580})
Step:   79000, Reward: -1093.472 [ 444.835], Avg:  -899.393 (0.453) <0-00:17:06> ({'r_t': -6212.2769, 'eps':     0.4535, 'critic_loss':  2712.1809, 'actor_loss':   -13.0969, 'eps_e':     0.4535})
Step:   80000, Reward: -1196.044 [ 193.680], Avg:  -903.056 (0.449) <0-00:17:19> ({'r_t': -6266.4317, 'eps':     0.4490, 'critic_loss':  2753.3779, 'actor_loss':   -12.8634, 'eps_e':     0.4490})
Step:   81000, Reward:  -965.109 [ 474.693], Avg:  -903.812 (0.444) <0-00:17:33> ({'r_t': -5890.5938, 'eps':     0.4445, 'critic_loss':  2828.4451, 'actor_loss':   -12.3025, 'eps_e':     0.4445})
Step:   82000, Reward: -1025.964 [ 435.372], Avg:  -905.284 (0.440) <0-00:17:46> ({'r_t': -6114.0957, 'eps':     0.4401, 'critic_loss':  2799.9504, 'actor_loss':   -11.7806, 'eps_e':     0.4401})
Step:   83000, Reward:  -913.134 [ 542.206], Avg:  -905.378 (0.436) <0-00:18:00> ({'r_t': -6078.6891, 'eps':     0.4357, 'critic_loss':  2854.3984, 'actor_loss':   -11.6389, 'eps_e':     0.4357})
Step:   84000, Reward:  -794.503 [ 414.775], Avg:  -904.073 (0.431) <0-00:18:13> ({'r_t': -5548.5221, 'eps':     0.4313, 'critic_loss':  2870.6877, 'actor_loss':   -10.6512, 'eps_e':     0.4313})
Step:   85000, Reward: -1054.122 [ 369.980], Avg:  -905.818 (0.427) <0-00:18:27> ({'r_t': -6035.3646, 'eps':     0.4271, 'critic_loss':  2891.2273, 'actor_loss':   -10.4067, 'eps_e':     0.4271})
Step:   86000, Reward:  -963.690 [ 363.069], Avg:  -906.483 (0.423) <0-00:18:40> ({'r_t': -6028.7684, 'eps':     0.4228, 'critic_loss':  2869.4050, 'actor_loss':   -10.7838, 'eps_e':     0.4228})
Step:   87000, Reward:  -851.971 [ 421.158], Avg:  -905.864 (0.419) <0-00:18:53> ({'r_t': -6417.1098, 'eps':     0.4186, 'critic_loss':  3013.6509, 'actor_loss':   -10.3140, 'eps_e':     0.4186})
Step:   88000, Reward:  -634.350 [ 380.734], Avg:  -902.813 (0.414) <0-00:19:07> ({'r_t': -5280.1851, 'eps':     0.4144, 'critic_loss':  3053.2505, 'actor_loss':   -11.0315, 'eps_e':     0.4144})
Step:   89000, Reward: -1099.579 [ 465.744], Avg:  -904.999 (0.410) <0-00:19:21> ({'r_t': -5839.2471, 'eps':     0.4103, 'critic_loss':  3163.6025, 'actor_loss':   -11.0184, 'eps_e':     0.4103})
Step:   90000, Reward: -1067.254 [ 346.960], Avg:  -906.782 (0.406) <0-00:19:34> ({'r_t': -6170.8246, 'eps':     0.4062, 'critic_loss':  3134.4854, 'actor_loss':    -9.5436, 'eps_e':     0.4062})
Step:   91000, Reward:  -963.846 [ 472.525], Avg:  -907.403 (0.402) <0-00:19:47> ({'r_t': -5278.5842, 'eps':     0.4022, 'critic_loss':  3239.1543, 'actor_loss':    -9.5238, 'eps_e':     0.4022})
Step:   92000, Reward: -1152.019 [ 440.890], Avg:  -910.033 (0.398) <0-00:20:01> ({'r_t': -5151.9264, 'eps':     0.3982, 'critic_loss':  3251.2307, 'actor_loss':   -10.0272, 'eps_e':     0.3982})
Step:   93000, Reward:  -904.282 [ 361.030], Avg:  -909.972 (0.394) <0-00:20:14> ({'r_t': -5115.0568, 'eps':     0.3942, 'critic_loss':  3210.8276, 'actor_loss':    -9.9045, 'eps_e':     0.3942})
Step:   94000, Reward: -1081.726 [ 310.312], Avg:  -911.780 (0.390) <0-00:20:27> ({'r_t': -5280.1260, 'eps':     0.3903, 'critic_loss':  3188.4976, 'actor_loss':    -9.1227, 'eps_e':     0.3903})
Step:   95000, Reward:  -878.555 [ 488.818], Avg:  -911.433 (0.386) <0-00:20:41> ({'r_t': -5433.5773, 'eps':     0.3864, 'critic_loss':  3225.1362, 'actor_loss':    -9.0630, 'eps_e':     0.3864})
Step:   96000, Reward: -1141.101 [ 265.762], Avg:  -913.801 (0.383) <0-00:20:54> ({'r_t': -5577.3027, 'eps':     0.3825, 'critic_loss':  3220.0239, 'actor_loss':    -8.5138, 'eps_e':     0.3825})
Step:   97000, Reward: -1037.178 [ 376.153], Avg:  -915.060 (0.379) <0-00:21:08> ({'r_t': -5659.2466, 'eps':     0.3787, 'critic_loss':  3333.2695, 'actor_loss':    -8.5923, 'eps_e':     0.3787})
Step:   98000, Reward:  -952.287 [ 396.901], Avg:  -915.436 (0.375) <0-00:21:21> ({'r_t': -5614.7484, 'eps':     0.3749, 'critic_loss':  3399.8613, 'actor_loss':    -9.3913, 'eps_e':     0.3749})
Step:   99000, Reward:  -903.870 [ 396.114], Avg:  -915.321 (0.371) <0-00:21:35> ({'r_t': -5490.0474, 'eps':     0.3712, 'critic_loss':  3327.1064, 'actor_loss':    -9.5869, 'eps_e':     0.3712})
Step:  100000, Reward: -1075.248 [ 370.412], Avg:  -916.904 (0.368) <0-00:21:49> ({'r_t': -5363.3494, 'eps':     0.3675, 'critic_loss':  3361.4119, 'actor_loss':    -9.4894, 'eps_e':     0.3675})
Step:  101000, Reward:  -862.338 [ 481.868], Avg:  -916.369 (0.364) <0-00:22:02> ({'r_t': -5203.4612, 'eps':     0.3639, 'critic_loss':  3349.2861, 'actor_loss':    -9.5557, 'eps_e':     0.3639})
Step:  102000, Reward: -1036.368 [ 450.129], Avg:  -917.534 (0.360) <0-00:22:15> ({'r_t': -4835.5195, 'eps':     0.3602, 'critic_loss':  3440.6621, 'actor_loss':    -9.8120, 'eps_e':     0.3602})
Step:  103000, Reward: -1124.138 [ 410.472], Avg:  -919.521 (0.357) <0-00:22:29> ({'r_t': -5082.7845, 'eps':     0.3566, 'critic_loss':  3405.5671, 'actor_loss':    -9.2409, 'eps_e':     0.3566})
Step:  104000, Reward:  -824.860 [ 644.138], Avg:  -918.619 (0.353) <0-00:22:42> ({'r_t': -5346.5253, 'eps':     0.3531, 'critic_loss':  3570.9172, 'actor_loss':    -8.8590, 'eps_e':     0.3531})
Step:  105000, Reward: -1043.574 [ 352.933], Avg:  -919.798 (0.350) <0-00:22:56> ({'r_t': -5044.8992, 'eps':     0.3496, 'critic_loss':  3528.0042, 'actor_loss':    -9.5949, 'eps_e':     0.3496})
Step:  106000, Reward: -1201.507 [ 300.444], Avg:  -922.431 (0.346) <0-00:23:09> ({'r_t': -5442.1584, 'eps':     0.3461, 'critic_loss':  3602.9714, 'actor_loss':    -9.3532, 'eps_e':     0.3461})
Step:  107000, Reward:  -968.635 [ 328.934], Avg:  -922.858 (0.343) <0-00:23:23> ({'r_t': -5257.1079, 'eps':     0.3426, 'critic_loss':  3526.1294, 'actor_loss':    -9.4583, 'eps_e':     0.3426})
Step:  108000, Reward:  -817.436 [ 402.625], Avg:  -921.891 (0.339) <0-00:23:36> ({'r_t': -5221.0872, 'eps':     0.3392, 'critic_loss':  3516.8318, 'actor_loss':    -9.6093, 'eps_e':     0.3392})
Step:  109000, Reward:  -867.233 [ 578.537], Avg:  -921.394 (0.336) <0-00:23:50> ({'r_t': -4644.7141, 'eps':     0.3358, 'critic_loss':  3627.7515, 'actor_loss':   -10.4422, 'eps_e':     0.3358})
Step:  110000, Reward: -1088.042 [ 407.947], Avg:  -922.896 (0.333) <0-00:24:03> ({'r_t': -4444.0999, 'eps':     0.3325, 'critic_loss':  3649.2896, 'actor_loss':    -9.8123, 'eps_e':     0.3325})
Step:  111000, Reward:  -974.413 [ 390.806], Avg:  -923.356 (0.329) <0-00:24:16> ({'r_t': -5195.0629, 'eps':     0.3292, 'critic_loss':  3575.5735, 'actor_loss':    -9.3610, 'eps_e':     0.3292})
Step:  112000, Reward:  -654.786 [ 557.756], Avg:  -920.979 (0.326) <0-00:24:30> ({'r_t': -4913.2935, 'eps':     0.3259, 'critic_loss':  3734.3916, 'actor_loss':    -8.9280, 'eps_e':     0.3259})
Step:  113000, Reward:  -897.332 [ 628.160], Avg:  -920.772 (0.323) <0-00:24:43> ({'r_t': -4740.7839, 'eps':     0.3227, 'critic_loss':  3772.5281, 'actor_loss':    -8.8869, 'eps_e':     0.3227})
Step:  114000, Reward:  -592.099 [ 591.661], Avg:  -917.914 (0.319) <0-00:24:56> ({'r_t': -4510.5661, 'eps':     0.3195, 'critic_loss':  3595.4534, 'actor_loss':    -8.2841, 'eps_e':     0.3195})
Step:  115000, Reward: -1037.028 [ 527.578], Avg:  -918.940 (0.316) <0-00:25:09> ({'r_t': -4517.0746, 'eps':     0.3163, 'critic_loss':  3729.9221, 'actor_loss':    -8.0210, 'eps_e':     0.3163})
Step:  116000, Reward:  -813.557 [ 556.321], Avg:  -918.040 (0.313) <0-00:25:23> ({'r_t': -4794.3538, 'eps':     0.3131, 'critic_loss':  3805.7129, 'actor_loss':    -8.7649, 'eps_e':     0.3131})
Step:  117000, Reward:  -772.100 [ 615.852], Avg:  -916.803 (0.310) <0-00:25:36> ({'r_t': -4629.4257, 'eps':     0.3100, 'critic_loss':  3664.7625, 'actor_loss':    -8.5674, 'eps_e':     0.3100})
Step:  118000, Reward:  -763.941 [ 441.114], Avg:  -915.518 (0.307) <0-00:25:50> ({'r_t': -5411.2001, 'eps':     0.3069, 'critic_loss':  3865.9575, 'actor_loss':    -7.6989, 'eps_e':     0.3069})
Step:  119000, Reward: -1125.636 [ 461.885], Avg:  -917.269 (0.304) <0-00:26:03> ({'r_t': -5369.2296, 'eps':     0.3039, 'critic_loss':  3863.2773, 'actor_loss':    -6.9271, 'eps_e':     0.3039})
Step:  120000, Reward:  -835.231 [ 551.492], Avg:  -916.591 (0.301) <0-00:26:16> ({'r_t': -5557.1170, 'eps':     0.3008, 'critic_loss':  3921.6877, 'actor_loss':    -6.8573, 'eps_e':     0.3008})
Step:  121000, Reward: -1186.804 [ 235.849], Avg:  -918.806 (0.298) <0-00:26:30> ({'r_t': -6058.5280, 'eps':     0.2978, 'critic_loss':  3936.1562, 'actor_loss':    -6.4862, 'eps_e':     0.2978})
Step:  122000, Reward:  -932.707 [ 614.966], Avg:  -918.919 (0.295) <0-00:26:42> ({'r_t': -5551.0649, 'eps':     0.2949, 'critic_loss':  4036.8420, 'actor_loss':    -6.3185, 'eps_e':     0.2949})
Step:  123000, Reward: -1076.229 [ 355.682], Avg:  -920.188 (0.292) <0-00:26:56> ({'r_t': -5288.0581, 'eps':     0.2919, 'critic_loss':  3962.0930, 'actor_loss':    -6.3955, 'eps_e':     0.2919})
Step:  124000, Reward: -1088.464 [ 362.914], Avg:  -921.534 (0.289) <0-00:27:10> ({'r_t': -5641.5425, 'eps':     0.2890, 'critic_loss':  3991.1345, 'actor_loss':    -5.2472, 'eps_e':     0.2890})
Step:  125000, Reward:  -942.474 [ 586.405], Avg:  -921.700 (0.286) <0-00:27:23> ({'r_t': -5281.3927, 'eps':     0.2861, 'critic_loss':  3908.6836, 'actor_loss':    -4.6876, 'eps_e':     0.2861})
Step:  126000, Reward:  -734.705 [ 559.635], Avg:  -920.228 (0.283) <0-00:27:36> ({'r_t': -5109.6539, 'eps':     0.2833, 'critic_loss':  4004.2275, 'actor_loss':    -5.6494, 'eps_e':     0.2833})
Step:  127000, Reward:  -817.564 [ 515.377], Avg:  -919.426 (0.280) <0-00:27:49> ({'r_t': -5353.2311, 'eps':     0.2805, 'critic_loss':  3990.5312, 'actor_loss':    -5.0246, 'eps_e':     0.2805})
Step:  128000, Reward: -1129.647 [ 435.072], Avg:  -921.055 (0.278) <0-00:28:03> ({'r_t': -5434.4010, 'eps':     0.2777, 'critic_loss':  4116.4653, 'actor_loss':    -5.4714, 'eps_e':     0.2777})
Step:  129000, Reward: -1141.212 [ 336.534], Avg:  -922.749 (0.275) <0-00:28:16> ({'r_t': -5717.8456, 'eps':     0.2749, 'critic_loss':  4055.9700, 'actor_loss':    -5.2938, 'eps_e':     0.2749})
Step:  130000, Reward: -1276.368 [ 253.879], Avg:  -925.448 (0.272) <0-00:28:29> ({'r_t': -6125.4510, 'eps':     0.2722, 'critic_loss':  4161.9009, 'actor_loss':    -4.2989, 'eps_e':     0.2722})
Step:  131000, Reward:  -853.255 [ 592.298], Avg:  -924.901 (0.269) <0-00:28:42> ({'r_t': -5972.6992, 'eps':     0.2695, 'critic_loss':  4055.7947, 'actor_loss':    -4.1195, 'eps_e':     0.2695})
Step:  132000, Reward: -1085.124 [ 275.103], Avg:  -926.106 (0.267) <0-00:28:55> ({'r_t': -5879.0477, 'eps':     0.2668, 'critic_loss':  4156.1807, 'actor_loss':    -3.8151, 'eps_e':     0.2668})
Step:  133000, Reward: -1216.125 [ 175.075], Avg:  -928.270 (0.264) <0-00:29:08> ({'r_t': -6136.3127, 'eps':     0.2641, 'critic_loss':  4086.1892, 'actor_loss':    -2.8457, 'eps_e':     0.2641})
Step:  134000, Reward:  -973.654 [ 576.664], Avg:  -928.607 (0.261) <0-00:29:21> ({'r_t': -5400.4612, 'eps':     0.2615, 'critic_loss':  4133.1689, 'actor_loss':    -2.9975, 'eps_e':     0.2615})
Step:  135000, Reward: -1032.019 [ 414.765], Avg:  -929.367 (0.259) <0-00:29:33> ({'r_t': -5170.6325, 'eps':     0.2589, 'critic_loss':  4295.7642, 'actor_loss':    -2.6882, 'eps_e':     0.2589})
Step:  136000, Reward: -1072.166 [ 557.991], Avg:  -930.409 (0.256) <0-00:29:46> ({'r_t': -5346.2710, 'eps':     0.2563, 'critic_loss':  4276.8345, 'actor_loss':    -3.4265, 'eps_e':     0.2563})
Step:  137000, Reward:  -803.583 [ 636.281], Avg:  -929.490 (0.254) <0-00:29:58> ({'r_t': -4136.4311, 'eps':     0.2538, 'critic_loss':  4112.6040, 'actor_loss':    -3.5691, 'eps_e':     0.2538})
Step:  138000, Reward:  -604.704 [ 638.334], Avg:  -927.154 (0.251) <0-00:30:11> ({'r_t': -4243.0526, 'eps':     0.2512, 'critic_loss':  4194.3560, 'actor_loss':    -3.5821, 'eps_e':     0.2512})
Step:  139000, Reward:  -960.225 [ 612.253], Avg:  -927.390 (0.249) <0-00:30:24> ({'r_t': -4425.5729, 'eps':     0.2487, 'critic_loss':  4142.3057, 'actor_loss':    -3.1659, 'eps_e':     0.2487})
Step:  140000, Reward:  -995.677 [ 490.465], Avg:  -927.874 (0.246) <0-00:30:37> ({'r_t': -5802.3774, 'eps':     0.2463, 'critic_loss':  4157.6489, 'actor_loss':    -2.1839, 'eps_e':     0.2463})
Step:  141000, Reward:  -728.035 [ 531.354], Avg:  -926.467 (0.244) <0-00:30:50> ({'r_t': -4945.6152, 'eps':     0.2438, 'critic_loss':  4183.3813, 'actor_loss':    -2.7594, 'eps_e':     0.2438})
Step:  142000, Reward: -1003.959 [ 609.415], Avg:  -927.009 (0.241) <0-00:31:02> ({'r_t': -3915.0679, 'eps':     0.2414, 'critic_loss':  4120.4590, 'actor_loss':    -4.6760, 'eps_e':     0.2414})
Step:  143000, Reward: -1024.757 [ 579.896], Avg:  -927.688 (0.239) <0-00:31:15> ({'r_t': -4111.5413, 'eps':     0.2390, 'critic_loss':  3968.9172, 'actor_loss':    -4.3389, 'eps_e':     0.2390})
Step:  144000, Reward: -1232.954 [ 361.430], Avg:  -929.793 (0.237) <0-00:31:27> ({'r_t': -4788.8086, 'eps':     0.2366, 'critic_loss':  4178.1797, 'actor_loss':    -3.8843, 'eps_e':     0.2366})
Step:  145000, Reward:  -652.453 [ 607.547], Avg:  -927.893 (0.234) <0-00:31:40> ({'r_t': -4820.8899, 'eps':     0.2342, 'critic_loss':  3994.2061, 'actor_loss':    -4.0804, 'eps_e':     0.2342})
Step:  146000, Reward:  -771.018 [ 654.714], Avg:  -926.826 (0.232) <0-00:31:53> ({'r_t': -3730.3392, 'eps':     0.2319, 'critic_loss':  4062.3062, 'actor_loss':    -4.2203, 'eps_e':     0.2319})
Step:  147000, Reward:  -628.550 [ 584.623], Avg:  -924.811 (0.230) <0-00:32:05> ({'r_t': -4910.2836, 'eps':     0.2296, 'critic_loss':  3973.1919, 'actor_loss':    -4.3579, 'eps_e':     0.2296})
Step:  148000, Reward: -1020.162 [ 637.501], Avg:  -925.451 (0.227) <0-00:32:18> ({'r_t': -4501.8828, 'eps':     0.2273, 'critic_loss':  4154.0122, 'actor_loss':    -5.3301, 'eps_e':     0.2273})
Step:  149000, Reward: -1162.409 [ 263.295], Avg:  -927.030 (0.225) <0-00:32:31> ({'r_t': -4066.7518, 'eps':     0.2250, 'critic_loss':  3984.6785, 'actor_loss':    -4.4474, 'eps_e':     0.2250})
Step:  150000, Reward: -1025.288 [ 487.304], Avg:  -927.681 (0.223) <0-00:32:43> ({'r_t': -5877.7077, 'eps':     0.2228, 'critic_loss':  4172.3442, 'actor_loss':    -3.7009, 'eps_e':     0.2228})
Step:  151000, Reward:  -858.631 [ 563.794], Avg:  -927.227 (0.221) <0-00:32:56> ({'r_t': -5145.7946, 'eps':     0.2206, 'critic_loss':  4201.4106, 'actor_loss':    -4.2887, 'eps_e':     0.2206})
Step:  152000, Reward:  -639.617 [ 618.849], Avg:  -925.347 (0.218) <0-00:33:08> ({'r_t': -4242.4034, 'eps':     0.2184, 'critic_loss':  4183.6035, 'actor_loss':    -4.3683, 'eps_e':     0.2184})
Step:  153000, Reward:  -761.977 [ 588.691], Avg:  -924.286 (0.216) <0-00:33:21> ({'r_t': -4494.6189, 'eps':     0.2162, 'critic_loss':  4142.7437, 'actor_loss':    -4.7964, 'eps_e':     0.2162})
Step:  154000, Reward:  -661.888 [ 546.244], Avg:  -922.593 (0.214) <0-00:33:34> ({'r_t': -4099.8842, 'eps':     0.2141, 'critic_loss':  3995.2041, 'actor_loss':    -4.5343, 'eps_e':     0.2141})
Step:  155000, Reward: -1090.107 [ 590.061], Avg:  -923.667 (0.212) <0-00:33:46> ({'r_t': -3631.8459, 'eps':     0.2119, 'critic_loss':  4191.5352, 'actor_loss':    -4.6460, 'eps_e':     0.2119})
Step:  156000, Reward:  -686.428 [ 629.326], Avg:  -922.156 (0.210) <0-00:33:59> ({'r_t': -4319.0323, 'eps':     0.2098, 'critic_loss':  4283.1270, 'actor_loss':    -4.6107, 'eps_e':     0.2098})
Step:  157000, Reward: -1020.107 [ 516.830], Avg:  -922.776 (0.208) <0-00:34:11> ({'r_t': -4634.2737, 'eps':     0.2077, 'critic_loss':  4113.6172, 'actor_loss':    -5.1849, 'eps_e':     0.2077})
Step:  158000, Reward: -1027.090 [ 436.032], Avg:  -923.432 (0.206) <0-00:34:24> ({'r_t': -4867.8830, 'eps':     0.2056, 'critic_loss':  4172.7969, 'actor_loss':    -4.3463, 'eps_e':     0.2056})
Step:  159000, Reward:  -789.669 [ 564.424], Avg:  -922.596 (0.204) <0-00:34:37> ({'r_t': -4364.8452, 'eps':     0.2036, 'critic_loss':  4096.6992, 'actor_loss':    -4.6913, 'eps_e':     0.2036})
Step:  160000, Reward:  -997.434 [ 531.785], Avg:  -923.061 (0.202) <0-00:34:49> ({'r_t': -4753.9485, 'eps':     0.2016, 'critic_loss':  4184.2046, 'actor_loss':    -4.6599, 'eps_e':     0.2016})
Step:  161000, Reward:  -838.243 [ 661.336], Avg:  -922.537 (0.200) <0-00:35:02> ({'r_t': -4027.5409, 'eps':     0.1996, 'critic_loss':  4167.7637, 'actor_loss':    -5.3457, 'eps_e':     0.1996})
Step:  162000, Reward:  -848.106 [ 658.638], Avg:  -922.081 (0.198) <0-00:35:14> ({'r_t': -4019.0895, 'eps':     0.1976, 'critic_loss':  4444.3848, 'actor_loss':    -3.8140, 'eps_e':     0.1976})
Step:  163000, Reward:  -640.126 [ 541.505], Avg:  -920.361 (0.196) <0-00:35:26> ({'r_t': -3372.4216, 'eps':     0.1956, 'critic_loss':  3999.1716, 'actor_loss':    -3.3063, 'eps_e':     0.1956})
Step:  164000, Reward:  -914.152 [ 577.463], Avg:  -920.324 (0.194) <0-00:35:39> ({'r_t': -4359.0888, 'eps':     0.1937, 'critic_loss':  4224.7739, 'actor_loss':    -4.6769, 'eps_e':     0.1937})
Step:  165000, Reward: -1034.579 [ 511.944], Avg:  -921.012 (0.192) <0-00:35:52> ({'r_t': -4191.5600, 'eps':     0.1917, 'critic_loss':  4224.1860, 'actor_loss':    -4.5847, 'eps_e':     0.1917})
Step:  166000, Reward:  -827.313 [ 624.401], Avg:  -920.451 (0.190) <0-00:36:04> ({'r_t': -4209.4002, 'eps':     0.1898, 'critic_loss':  4209.3179, 'actor_loss':    -4.2901, 'eps_e':     0.1898})
Step:  167000, Reward:  -672.309 [ 630.693], Avg:  -918.974 (0.188) <0-00:36:17> ({'r_t': -4017.5700, 'eps':     0.1879, 'critic_loss':  4227.2612, 'actor_loss':    -4.8663, 'eps_e':     0.1879})
Step:  168000, Reward: -1002.963 [ 564.582], Avg:  -919.471 (0.186) <0-00:36:29> ({'r_t': -3579.8244, 'eps':     0.1861, 'critic_loss':  4148.9810, 'actor_loss':    -4.8308, 'eps_e':     0.1861})
Step:  169000, Reward: -1142.843 [ 422.390], Avg:  -920.785 (0.184) <0-00:36:42> ({'r_t': -4641.8689, 'eps':     0.1842, 'critic_loss':  4067.8740, 'actor_loss':    -2.6245, 'eps_e':     0.1842})
Step:  170000, Reward:  -856.139 [ 599.509], Avg:  -920.407 (0.182) <0-00:36:54> ({'r_t': -4177.7979, 'eps':     0.1824, 'critic_loss':  4179.6157, 'actor_loss':    -3.5379, 'eps_e':     0.1824})
Step:  171000, Reward: -1142.372 [ 400.000], Avg:  -921.697 (0.181) <0-00:37:07> ({'r_t': -5194.7953, 'eps':     0.1806, 'critic_loss':  4156.8071, 'actor_loss':    -1.6684, 'eps_e':     0.1806})
Step:  172000, Reward:  -917.568 [ 495.530], Avg:  -921.673 (0.179) <0-00:37:19> ({'r_t': -5234.9744, 'eps':     0.1788, 'critic_loss':  4129.1299, 'actor_loss':    -1.7677, 'eps_e':     0.1788})
Step:  173000, Reward: -1021.597 [ 407.787], Avg:  -922.248 (0.177) <0-00:37:31> ({'r_t': -5001.2672, 'eps':     0.1770, 'critic_loss':  4304.2524, 'actor_loss':    -1.1930, 'eps_e':     0.1770})
Step:  174000, Reward: -1032.421 [ 418.442], Avg:  -922.877 (0.175) <0-00:37:44> ({'r_t': -5507.7587, 'eps':     0.1752, 'critic_loss':  4188.0298, 'actor_loss':    -1.1595, 'eps_e':     0.1752})
Step:  175000, Reward:  -981.545 [ 425.020], Avg:  -923.211 (0.173) <0-00:37:57> ({'r_t': -4883.0929, 'eps':     0.1735, 'critic_loss':  4185.4907, 'actor_loss':    -0.8755, 'eps_e':     0.1735})
Step:  176000, Reward:  -909.422 [ 464.333], Avg:  -923.133 (0.172) <0-00:38:09> ({'r_t': -4751.1348, 'eps':     0.1717, 'critic_loss':  4191.5117, 'actor_loss':    -1.9747, 'eps_e':     0.1717})
Step:  177000, Reward: -1077.860 [ 384.964], Avg:  -924.002 (0.170) <0-00:38:22> ({'r_t': -5343.6967, 'eps':     0.1700, 'critic_loss':  4226.7925, 'actor_loss':    -1.7591, 'eps_e':     0.1700})
Step:  178000, Reward: -1258.898 [ 385.962], Avg:  -925.873 (0.168) <0-00:38:34> ({'r_t': -5274.1275, 'eps':     0.1683, 'critic_loss':  4300.8740, 'actor_loss':    -1.6400, 'eps_e':     0.1683})
Step:  179000, Reward:  -722.892 [ 386.279], Avg:  -924.745 (0.167) <0-00:38:47> ({'r_t': -5314.3654, 'eps':     0.1667, 'critic_loss':  4408.9531, 'actor_loss':    -1.7911, 'eps_e':     0.1667})
Step:  180000, Reward:  -692.383 [ 461.182], Avg:  -923.461 (0.165) <0-00:39:00> ({'r_t': -4516.7946, 'eps':     0.1650, 'critic_loss':  4283.9600, 'actor_loss':    -1.9819, 'eps_e':     0.1650})
Step:  181000, Reward:  -735.512 [ 379.973], Avg:  -922.429 (0.163) <0-00:39:12> ({'r_t': -5253.9793, 'eps':     0.1634, 'critic_loss':  4408.3428, 'actor_loss':    -2.9491, 'eps_e':     0.1634})
Step:  182000, Reward:  -900.888 [ 581.844], Avg:  -922.311 (0.162) <0-00:39:25> ({'r_t': -4566.2944, 'eps':     0.1617, 'critic_loss':  4258.0410, 'actor_loss':    -3.3690, 'eps_e':     0.1617})
Step:  183000, Reward: -1042.188 [ 544.898], Avg:  -922.963 (0.160) <0-00:39:37> ({'r_t': -4534.6614, 'eps':     0.1601, 'critic_loss':  4296.0029, 'actor_loss':    -3.6536, 'eps_e':     0.1601})
Step:  184000, Reward: -1157.478 [ 365.223], Avg:  -924.230 (0.159) <0-00:39:50> ({'r_t': -4389.2869, 'eps':     0.1585, 'critic_loss':  4287.0820, 'actor_loss':    -1.3506, 'eps_e':     0.1585})
Step:  185000, Reward: -1011.744 [ 336.287], Avg:  -924.701 (0.157) <0-00:40:02> ({'r_t': -5319.5369, 'eps':     0.1569, 'critic_loss':  4377.1060, 'actor_loss':    -0.5779, 'eps_e':     0.1569})
Step:  186000, Reward:  -987.425 [ 435.725], Avg:  -925.036 (0.155) <0-00:40:15> ({'r_t': -4906.8570, 'eps':     0.1554, 'critic_loss':  4316.5298, 'actor_loss':    -1.2925, 'eps_e':     0.1554})
Step:  187000, Reward:  -822.268 [ 550.376], Avg:  -924.489 (0.154) <0-00:40:27> ({'r_t': -4722.9931, 'eps':     0.1538, 'critic_loss':  4242.9399, 'actor_loss':    -3.4640, 'eps_e':     0.1538})
Step:  188000, Reward:  -762.099 [ 628.600], Avg:  -923.630 (0.152) <0-00:40:40> ({'r_t': -4500.3812, 'eps':     0.1523, 'critic_loss':  4366.7061, 'actor_loss':    -2.0744, 'eps_e':     0.1523})
Step:  189000, Reward:  -773.402 [ 528.728], Avg:  -922.840 (0.151) <0-00:40:52> ({'r_t': -4604.3595, 'eps':     0.1508, 'critic_loss':  4211.9287, 'actor_loss':    -3.2273, 'eps_e':     0.1508})
Step:  190000, Reward:  -421.534 [ 508.816], Avg:  -920.215 (0.149) <0-00:41:05> ({'r_t': -4139.1202, 'eps':     0.1493, 'critic_loss':  4397.8550, 'actor_loss':    -2.7535, 'eps_e':     0.1493})
Step:  191000, Reward:  -968.558 [ 642.142], Avg:  -920.467 (0.148) <0-00:41:17> ({'r_t': -4406.2704, 'eps':     0.1478, 'critic_loss':  4191.0249, 'actor_loss':    -2.2126, 'eps_e':     0.1478})
Step:  192000, Reward:  -582.528 [ 597.437], Avg:  -918.716 (0.146) <0-00:41:30> ({'r_t': -4289.7799, 'eps':     0.1463, 'critic_loss':  4167.1309, 'actor_loss':    -2.5966, 'eps_e':     0.1463})
Step:  193000, Reward:  -797.610 [ 390.190], Avg:  -918.092 (0.145) <0-00:41:43> ({'r_t': -5066.5142, 'eps':     0.1449, 'critic_loss':  4186.1860, 'actor_loss':    -1.8307, 'eps_e':     0.1449})
Step:  194000, Reward: -1038.333 [ 549.992], Avg:  -918.708 (0.143) <0-00:41:55> ({'r_t': -4859.4940, 'eps':     0.1434, 'critic_loss':  4213.8174, 'actor_loss':    -1.5530, 'eps_e':     0.1434})
Step:  195000, Reward:  -914.549 [ 536.359], Avg:  -918.687 (0.142) <0-00:42:08> ({'r_t': -4419.5802, 'eps':     0.1420, 'critic_loss':  4342.2319, 'actor_loss':    -2.7209, 'eps_e':     0.1420})
Step:  196000, Reward:  -987.522 [ 401.201], Avg:  -919.036 (0.141) <0-00:42:20> ({'r_t': -4572.5212, 'eps':     0.1406, 'critic_loss':  4081.1826, 'actor_loss':    -2.0065, 'eps_e':     0.1406})
Step:  197000, Reward: -1093.303 [ 313.228], Avg:  -919.916 (0.139) <0-00:42:33> ({'r_t': -5089.0353, 'eps':     0.1392, 'critic_loss':  4102.6660, 'actor_loss':    -0.1597, 'eps_e':     0.1392})
Step:  198000, Reward: -1022.912 [ 363.991], Avg:  -920.434 (0.138) <0-00:42:46> ({'r_t': -5243.5087, 'eps':     0.1378, 'critic_loss':  4056.4785, 'actor_loss':     0.7180, 'eps_e':     0.1378})
Step:  199000, Reward:  -957.815 [ 439.022], Avg:  -920.621 (0.136) <0-00:42:58> ({'r_t': -5272.4837, 'eps':     0.1364, 'critic_loss':  4220.2793, 'actor_loss':     0.0486, 'eps_e':     0.1364})
Step:  200000, Reward:  -849.457 [ 687.360], Avg:  -920.267 (0.135) <0-00:43:11> ({'r_t': -4654.0233, 'eps':     0.1351, 'critic_loss':  4262.2104, 'actor_loss':    -2.0372, 'eps_e':     0.1351})
Step:  201000, Reward:  -922.538 [ 552.601], Avg:  -920.278 (0.134) <0-00:43:24> ({'r_t': -4104.2271, 'eps':     0.1337, 'critic_loss':  4368.8428, 'actor_loss':    -3.1748, 'eps_e':     0.1337})
Step:  202000, Reward:  -929.481 [ 480.221], Avg:  -920.323 (0.132) <0-00:43:37> ({'r_t': -4499.1590, 'eps':     0.1324, 'critic_loss':  4133.0586, 'actor_loss':    -2.2892, 'eps_e':     0.1324})
Step:  203000, Reward:  -733.742 [ 584.168], Avg:  -919.409 (0.131) <0-00:43:50> ({'r_t': -4652.4443, 'eps':     0.1311, 'critic_loss':  4301.5410, 'actor_loss':    -1.9869, 'eps_e':     0.1311})
Step:  204000, Reward:  -980.016 [ 408.388], Avg:  -919.704 (0.130) <0-00:44:02> ({'r_t': -4442.9676, 'eps':     0.1298, 'critic_loss':  4014.8428, 'actor_loss':    -1.8213, 'eps_e':     0.1298})
Step:  205000, Reward:  -749.983 [ 666.267], Avg:  -918.881 (0.128) <0-00:44:15> ({'r_t': -4363.0617, 'eps':     0.1285, 'critic_loss':  4311.0278, 'actor_loss':    -1.5475, 'eps_e':     0.1285})
Step:  206000, Reward:  -794.013 [ 362.103], Avg:  -918.277 (0.127) <0-00:44:27> ({'r_t': -4482.8762, 'eps':     0.1272, 'critic_loss':  4222.3159, 'actor_loss':    -2.4991, 'eps_e':     0.1272})
Step:  207000, Reward:  -968.965 [ 496.991], Avg:  -918.521 (0.126) <0-00:44:40> ({'r_t': -4665.4084, 'eps':     0.1259, 'critic_loss':  4260.1631, 'actor_loss':    -2.7144, 'eps_e':     0.1259})
Step:  208000, Reward: -1038.346 [ 435.788], Avg:  -919.094 (0.125) <0-00:44:53> ({'r_t': -4864.4314, 'eps':     0.1247, 'critic_loss':  4242.1968, 'actor_loss':    -0.3937, 'eps_e':     0.1247})
Step:  209000, Reward:  -400.588 [ 517.950], Avg:  -916.625 (0.123) <0-00:45:05> ({'r_t': -3839.1163, 'eps':     0.1234, 'critic_loss':  4164.0400, 'actor_loss':    -2.2488, 'eps_e':     0.1234})
Step:  210000, Reward:  -844.205 [ 598.414], Avg:  -916.282 (0.122) <0-00:45:18> ({'r_t': -3761.7646, 'eps':     0.1222, 'critic_loss':  4288.8540, 'actor_loss':    -3.1338, 'eps_e':     0.1222})
Step:  211000, Reward:  -591.410 [ 633.192], Avg:  -914.750 (0.121) <0-00:45:31> ({'r_t': -4054.2641, 'eps':     0.1210, 'critic_loss':  4320.8252, 'actor_loss':    -3.4452, 'eps_e':     0.1210})
Step:  212000, Reward:  -944.087 [ 585.602], Avg:  -914.887 (0.120) <0-00:45:44> ({'r_t': -3642.5251, 'eps':     0.1198, 'critic_loss':  4348.5464, 'actor_loss':    -3.7054, 'eps_e':     0.1198})
Step:  213000, Reward:  -786.317 [ 662.215], Avg:  -914.287 (0.119) <0-00:45:56> ({'r_t': -4079.3088, 'eps':     0.1186, 'critic_loss':  4257.7690, 'actor_loss':    -3.6621, 'eps_e':     0.1186})
Step:  214000, Reward:  -798.533 [ 558.797], Avg:  -913.748 (0.117) <0-00:46:09> ({'r_t': -4443.5436, 'eps':     0.1174, 'critic_loss':  4413.7310, 'actor_loss':    -3.8671, 'eps_e':     0.1174})
Step:  215000, Reward: -1066.957 [ 543.822], Avg:  -914.458 (0.116) <0-00:46:22> ({'r_t': -4097.0229, 'eps':     0.1162, 'critic_loss':  4104.0669, 'actor_loss':    -3.8129, 'eps_e':     0.1162})
Step:  216000, Reward:  -771.689 [ 604.331], Avg:  -913.800 (0.115) <0-00:46:34> ({'r_t': -4052.2151, 'eps':     0.1151, 'critic_loss':  4285.4888, 'actor_loss':    -4.1235, 'eps_e':     0.1151})
Step:  217000, Reward:  -674.235 [ 576.962], Avg:  -912.701 (0.114) <0-00:46:47> ({'r_t': -3994.9571, 'eps':     0.1139, 'critic_loss':  4165.5137, 'actor_loss':    -4.1417, 'eps_e':     0.1139})
Step:  218000, Reward:  -877.011 [ 596.990], Avg:  -912.538 (0.113) <0-00:47:00> ({'r_t': -3629.0876, 'eps':     0.1128, 'critic_loss':  4136.2856, 'actor_loss':    -3.8526, 'eps_e':     0.1128})
Step:  219000, Reward:  -940.236 [ 646.974], Avg:  -912.664 (0.112) <0-00:47:13> ({'r_t': -3854.4583, 'eps':     0.1117, 'critic_loss':  4293.7119, 'actor_loss':    -4.0037, 'eps_e':     0.1117})
Step:  220000, Reward:  -793.777 [ 615.127], Avg:  -912.126 (0.111) <0-00:47:26> ({'r_t': -4192.1726, 'eps':     0.1106, 'critic_loss':  4370.9175, 'actor_loss':    -4.0080, 'eps_e':     0.1106})
Step:  221000, Reward: -1084.409 [ 515.997], Avg:  -912.902 (0.109) <0-00:47:38> ({'r_t': -3367.4711, 'eps':     0.1095, 'critic_loss':  4185.7354, 'actor_loss':    -3.8362, 'eps_e':     0.1095})
Step:  222000, Reward:  -523.056 [ 493.225], Avg:  -911.154 (0.108) <0-00:47:52> ({'r_t': -4020.7826, 'eps':     0.1084, 'critic_loss':  4226.9136, 'actor_loss':    -3.2765, 'eps_e':     0.1084})
Step:  223000, Reward:  -603.147 [ 637.876], Avg:  -909.779 (0.107) <0-00:48:04> ({'r_t': -4084.1345, 'eps':     0.1073, 'critic_loss':  4304.4102, 'actor_loss':    -3.5397, 'eps_e':     0.1073})
Step:  224000, Reward:  -813.558 [ 670.318], Avg:  -909.351 (0.106) <0-00:48:17> ({'r_t': -4190.6192, 'eps':     0.1062, 'critic_loss':  4160.1587, 'actor_loss':    -3.7113, 'eps_e':     0.1062})
Step:  225000, Reward: -1266.565 [ 348.114], Avg:  -910.931 (0.105) <0-00:48:30> ({'r_t': -3593.0625, 'eps':     0.1052, 'critic_loss':  4201.5396, 'actor_loss':    -3.8700, 'eps_e':     0.1052})
Step:  226000, Reward:  -883.437 [ 535.296], Avg:  -910.810 (0.104) <0-00:48:43> ({'r_t': -3641.2872, 'eps':     0.1041, 'critic_loss':  4367.3125, 'actor_loss':    -3.7575, 'eps_e':     0.1041})
Step:  227000, Reward:  -722.727 [ 565.441], Avg:  -909.985 (0.103) <0-00:48:56> ({'r_t': -3854.2753, 'eps':     0.1031, 'critic_loss':  4219.9121, 'actor_loss':    -3.7309, 'eps_e':     0.1031})
Step:  228000, Reward:  -665.712 [ 644.504], Avg:  -908.919 (0.102) <0-00:49:09> ({'r_t': -3766.1158, 'eps':     0.1021, 'critic_loss':  4213.0449, 'actor_loss':    -3.7037, 'eps_e':     0.1021})
Step:  229000, Reward:  -674.613 [ 604.750], Avg:  -907.900 (0.101) <0-00:49:22> ({'r_t': -3814.0908, 'eps':     0.1010, 'critic_loss':  4249.9551, 'actor_loss':    -3.2799, 'eps_e':     0.1010})
Step:  230000, Reward: -1081.186 [ 501.892], Avg:  -908.650 (0.100) <0-00:49:35> ({'r_t': -3794.2789, 'eps':     0.1000, 'critic_loss':  4130.2754, 'actor_loss':    -3.1916, 'eps_e':     0.1000})
Step:  231000, Reward:  -807.555 [ 597.370], Avg:  -908.214 (0.100) <0-00:49:48> ({'r_t': -4111.8146, 'eps':     0.1000, 'critic_loss':  4441.1709, 'actor_loss':    -3.5292, 'eps_e':     0.1000})
Step:  232000, Reward:  -527.033 [ 562.223], Avg:  -906.578 (0.100) <0-00:50:00> ({'r_t': -3585.9499, 'eps':     0.1000, 'critic_loss':  4396.1938, 'actor_loss':    -3.8504, 'eps_e':     0.1000})
Step:  233000, Reward: -1028.712 [ 618.886], Avg:  -907.100 (0.100) <0-00:50:14> ({'r_t': -4029.7540, 'eps':     0.1000, 'critic_loss':  4432.1611, 'actor_loss':    -4.3785, 'eps_e':     0.1000})
Step:  234000, Reward:  -868.068 [ 587.912], Avg:  -906.934 (0.100) <0-00:50:27> ({'r_t': -3726.1343, 'eps':     0.1000, 'critic_loss':  4219.5562, 'actor_loss':    -4.1246, 'eps_e':     0.1000})
Step:  235000, Reward: -1029.427 [ 583.750], Avg:  -907.453 (0.100) <0-00:50:40> ({'r_t': -4418.0068, 'eps':     0.1000, 'critic_loss':  4209.2002, 'actor_loss':    -4.1463, 'eps_e':     0.1000})
Step:  236000, Reward:  -969.658 [ 550.480], Avg:  -907.716 (0.100) <0-00:50:53> ({'r_t': -4746.9465, 'eps':     0.1000, 'critic_loss':  4360.1709, 'actor_loss':    -4.2080, 'eps_e':     0.1000})
Step:  237000, Reward:  -892.487 [ 576.323], Avg:  -907.652 (0.100) <0-00:51:06> ({'r_t': -3497.7086, 'eps':     0.1000, 'critic_loss':  4228.9321, 'actor_loss':    -4.2412, 'eps_e':     0.1000})
Step:  238000, Reward:  -612.238 [ 575.170], Avg:  -906.416 (0.100) <0-00:51:19> ({'r_t': -4713.3330, 'eps':     0.1000, 'critic_loss':  4090.1892, 'actor_loss':    -4.5329, 'eps_e':     0.1000})
Step:  239000, Reward:  -793.428 [ 560.509], Avg:  -905.945 (0.100) <0-00:51:32> ({'r_t': -4261.1102, 'eps':     0.1000, 'critic_loss':  4221.4834, 'actor_loss':    -4.5975, 'eps_e':     0.1000})
Step:  240000, Reward:  -853.571 [ 581.049], Avg:  -905.728 (0.100) <0-00:51:45> ({'r_t': -4080.7519, 'eps':     0.1000, 'critic_loss':  4402.0430, 'actor_loss':    -4.2948, 'eps_e':     0.1000})
Step:  241000, Reward:  -734.879 [ 576.476], Avg:  -905.022 (0.100) <0-00:51:58> ({'r_t': -4533.4968, 'eps':     0.1000, 'critic_loss':  4245.0840, 'actor_loss':    -4.3370, 'eps_e':     0.1000})
Step:  242000, Reward:  -905.204 [ 544.448], Avg:  -905.022 (0.100) <0-00:52:12> ({'r_t': -4124.1015, 'eps':     0.1000, 'critic_loss':  4175.6685, 'actor_loss':    -4.4182, 'eps_e':     0.1000})
Step:  243000, Reward:  -965.251 [ 548.272], Avg:  -905.269 (0.100) <0-00:52:25> ({'r_t': -3794.7220, 'eps':     0.1000, 'critic_loss':  4300.4414, 'actor_loss':    -4.3556, 'eps_e':     0.1000})
Step:  244000, Reward: -1001.480 [ 572.864], Avg:  -905.662 (0.100) <0-00:52:39> ({'r_t': -4110.0219, 'eps':     0.1000, 'critic_loss':  4255.2930, 'actor_loss':    -4.5493, 'eps_e':     0.1000})
Step:  245000, Reward:  -794.799 [ 564.260], Avg:  -905.211 (0.100) <0-00:52:52> ({'r_t': -3711.6739, 'eps':     0.1000, 'critic_loss':  4207.1992, 'actor_loss':    -4.9325, 'eps_e':     0.1000})
Step:  246000, Reward:  -982.061 [ 570.195], Avg:  -905.522 (0.100) <0-00:53:06> ({'r_t': -3684.9356, 'eps':     0.1000, 'critic_loss':  4236.6362, 'actor_loss':    -4.9812, 'eps_e':     0.1000})
Step:  247000, Reward:  -756.543 [ 513.302], Avg:  -904.922 (0.100) <0-00:53:19> ({'r_t': -4133.5650, 'eps':     0.1000, 'critic_loss':  4332.6719, 'actor_loss':    -4.9153, 'eps_e':     0.1000})
Step:  248000, Reward:  -766.023 [ 578.157], Avg:  -904.364 (0.100) <0-00:53:33> ({'r_t': -3960.9045, 'eps':     0.1000, 'critic_loss':  4139.8569, 'actor_loss':    -4.3160, 'eps_e':     0.1000})
Step:  249000, Reward:  -948.042 [ 561.932], Avg:  -904.539 (0.100) <0-00:53:46> ({'r_t': -3664.0461, 'eps':     0.1000, 'critic_loss':  4247.3589, 'actor_loss':    -4.3938, 'eps_e':     0.1000})
Step:  250000, Reward:  -723.155 [ 578.970], Avg:  -903.816 (0.100) <0-00:54:00> ({'r_t': -4263.6526, 'eps':     0.1000, 'critic_loss':  4144.3862, 'actor_loss':    -4.4757, 'eps_e':     0.1000})
Step:  251000, Reward:  -872.397 [ 570.260], Avg:  -903.691 (0.100) <0-00:54:14> ({'r_t': -4283.9084, 'eps':     0.1000, 'critic_loss':  4284.6401, 'actor_loss':    -4.2562, 'eps_e':     0.1000})
Step:  252000, Reward:  -873.855 [ 625.921], Avg:  -903.573 (0.100) <0-00:54:27> ({'r_t': -3628.4735, 'eps':     0.1000, 'critic_loss':  4246.1631, 'actor_loss':    -4.3436, 'eps_e':     0.1000})
Step:  253000, Reward:  -815.785 [ 594.996], Avg:  -903.228 (0.100) <0-00:54:41> ({'r_t': -4025.2915, 'eps':     0.1000, 'critic_loss':  4133.5957, 'actor_loss':    -4.5689, 'eps_e':     0.1000})
Step:  254000, Reward:  -909.229 [ 518.790], Avg:  -903.251 (0.100) <0-00:54:54> ({'r_t': -3756.9392, 'eps':     0.1000, 'critic_loss':  4069.7456, 'actor_loss':    -4.8650, 'eps_e':     0.1000})
Step:  255000, Reward:  -808.690 [ 569.251], Avg:  -902.882 (0.100) <0-00:55:08> ({'r_t': -4317.3179, 'eps':     0.1000, 'critic_loss':  4312.0059, 'actor_loss':    -4.6767, 'eps_e':     0.1000})
Step:  256000, Reward:  -816.419 [ 625.082], Avg:  -902.545 (0.100) <0-00:55:22> ({'r_t': -3384.1381, 'eps':     0.1000, 'critic_loss':  3973.4910, 'actor_loss':    -4.8386, 'eps_e':     0.1000})
Step:  257000, Reward:  -958.835 [ 559.363], Avg:  -902.764 (0.100) <0-00:55:35> ({'r_t': -3729.3118, 'eps':     0.1000, 'critic_loss':  4147.6533, 'actor_loss':    -4.7996, 'eps_e':     0.1000})
Step:  258000, Reward:  -653.454 [ 591.858], Avg:  -901.801 (0.100) <0-00:55:49> ({'r_t': -3951.1157, 'eps':     0.1000, 'critic_loss':  4202.6538, 'actor_loss':    -4.5322, 'eps_e':     0.1000})
Step:  259000, Reward:  -762.530 [ 623.506], Avg:  -901.265 (0.100) <0-00:56:02> ({'r_t': -4123.3039, 'eps':     0.1000, 'critic_loss':  4203.7358, 'actor_loss':    -4.7588, 'eps_e':     0.1000})
Step:  260000, Reward:  -794.365 [ 621.417], Avg:  -900.856 (0.100) <0-00:56:16> ({'r_t': -4450.2743, 'eps':     0.1000, 'critic_loss':  4064.2249, 'actor_loss':    -4.5561, 'eps_e':     0.1000})
Step:  261000, Reward:  -808.497 [ 603.397], Avg:  -900.503 (0.100) <0-00:56:29> ({'r_t': -4205.9695, 'eps':     0.1000, 'critic_loss':  4035.5796, 'actor_loss':    -4.7414, 'eps_e':     0.1000})
Step:  262000, Reward:  -427.772 [ 557.189], Avg:  -898.706 (0.100) <0-00:56:43> ({'r_t': -3853.2634, 'eps':     0.1000, 'critic_loss':  4233.2139, 'actor_loss':    -4.7649, 'eps_e':     0.1000})
Step:  263000, Reward:  -939.790 [ 573.202], Avg:  -898.861 (0.100) <0-00:56:57> ({'r_t': -3629.1863, 'eps':     0.1000, 'critic_loss':  4184.0923, 'actor_loss':    -4.5782, 'eps_e':     0.1000})
Step:  264000, Reward:  -983.197 [ 555.324], Avg:  -899.180 (0.100) <0-00:57:10> ({'r_t': -4579.3713, 'eps':     0.1000, 'critic_loss':  3956.3669, 'actor_loss':    -4.2599, 'eps_e':     0.1000})
Step:  265000, Reward:  -999.842 [ 588.189], Avg:  -899.558 (0.100) <0-00:57:24> ({'r_t': -4247.5868, 'eps':     0.1000, 'critic_loss':  4095.6052, 'actor_loss':    -4.3512, 'eps_e':     0.1000})
Step:  266000, Reward:  -596.984 [ 571.534], Avg:  -898.425 (0.100) <0-00:57:38> ({'r_t': -4422.6344, 'eps':     0.1000, 'critic_loss':  4165.4004, 'actor_loss':    -4.3341, 'eps_e':     0.1000})
Step:  267000, Reward:  -554.673 [ 551.191], Avg:  -897.142 (0.100) <0-00:57:51> ({'r_t': -3053.5430, 'eps':     0.1000, 'critic_loss':  4047.7251, 'actor_loss':    -4.1050, 'eps_e':     0.1000})
Step:  268000, Reward:  -801.878 [ 671.466], Avg:  -896.788 (0.100) <0-00:58:05> ({'r_t': -3747.3948, 'eps':     0.1000, 'critic_loss':  4005.0444, 'actor_loss':    -3.9541, 'eps_e':     0.1000})
Step:  269000, Reward:  -939.403 [ 564.934], Avg:  -896.946 (0.100) <0-00:58:18> ({'r_t': -4198.1882, 'eps':     0.1000, 'critic_loss':  4027.2036, 'actor_loss':    -3.7891, 'eps_e':     0.1000})
Step:  270000, Reward:  -862.138 [ 599.392], Avg:  -896.817 (0.100) <0-00:58:32> ({'r_t': -3935.5801, 'eps':     0.1000, 'critic_loss':  4065.0010, 'actor_loss':    -4.2221, 'eps_e':     0.1000})
Step:  271000, Reward:  -730.151 [ 647.063], Avg:  -896.205 (0.100) <0-00:58:46> ({'r_t': -3654.3123, 'eps':     0.1000, 'critic_loss':  4088.9548, 'actor_loss':    -4.2448, 'eps_e':     0.1000})
Step:  272000, Reward: -1115.150 [ 552.775], Avg:  -897.007 (0.100) <0-00:58:59> ({'r_t': -4378.7491, 'eps':     0.1000, 'critic_loss':  3900.4050, 'actor_loss':    -4.2265, 'eps_e':     0.1000})
Step:  273000, Reward:  -884.913 [ 615.911], Avg:  -896.963 (0.100) <0-00:59:13> ({'r_t': -4306.7106, 'eps':     0.1000, 'critic_loss':  4257.5034, 'actor_loss':    -4.4830, 'eps_e':     0.1000})
Step:  274000, Reward:  -924.595 [ 661.257], Avg:  -897.063 (0.100) <0-00:59:27> ({'r_t': -4327.1192, 'eps':     0.1000, 'critic_loss':  4116.8477, 'actor_loss':    -4.7475, 'eps_e':     0.1000})
Step:  275000, Reward:  -594.668 [ 600.590], Avg:  -895.967 (0.100) <0-00:59:40> ({'r_t': -3632.7092, 'eps':     0.1000, 'critic_loss':  3906.3706, 'actor_loss':    -4.5999, 'eps_e':     0.1000})
Step:  276000, Reward:  -717.149 [ 591.067], Avg:  -895.322 (0.100) <0-00:59:54> ({'r_t': -3823.9258, 'eps':     0.1000, 'critic_loss':  4013.0867, 'actor_loss':    -4.7278, 'eps_e':     0.1000})
Step:  277000, Reward: -1018.865 [ 572.861], Avg:  -895.766 (0.100) <0-01:00:08> ({'r_t': -3741.2733, 'eps':     0.1000, 'critic_loss':  3990.9504, 'actor_loss':    -4.7132, 'eps_e':     0.1000})
Step:  278000, Reward:  -788.678 [ 587.092], Avg:  -895.382 (0.100) <0-01:00:21> ({'r_t': -3710.4748, 'eps':     0.1000, 'critic_loss':  4222.7646, 'actor_loss':    -4.6425, 'eps_e':     0.1000})
Step:  279000, Reward:  -838.945 [ 604.622], Avg:  -895.181 (0.100) <0-01:00:35> ({'r_t': -3894.2211, 'eps':     0.1000, 'critic_loss':  3992.8445, 'actor_loss':    -4.9410, 'eps_e':     0.1000})
Step:  280000, Reward: -1031.624 [ 573.401], Avg:  -895.666 (0.100) <0-01:00:48> ({'r_t': -3441.9424, 'eps':     0.1000, 'critic_loss':  4104.8940, 'actor_loss':    -4.8794, 'eps_e':     0.1000})
Step:  281000, Reward:  -408.705 [ 585.803], Avg:  -893.940 (0.100) <0-01:01:02> ({'r_t': -3872.7991, 'eps':     0.1000, 'critic_loss':  3996.8701, 'actor_loss':    -5.1898, 'eps_e':     0.1000})
Step:  282000, Reward:  -963.465 [ 525.699], Avg:  -894.185 (0.100) <0-01:01:16> ({'r_t': -4057.3895, 'eps':     0.1000, 'critic_loss':  3999.7227, 'actor_loss':    -5.4196, 'eps_e':     0.1000})
Step:  283000, Reward:  -523.732 [ 535.864], Avg:  -892.881 (0.100) <0-01:01:29> ({'r_t': -3246.6804, 'eps':     0.1000, 'critic_loss':  3846.8457, 'actor_loss':    -5.7098, 'eps_e':     0.1000})
Step:  284000, Reward:  -484.555 [ 606.370], Avg:  -891.448 (0.100) <0-01:01:43> ({'r_t': -4109.5236, 'eps':     0.1000, 'critic_loss':  4069.7896, 'actor_loss':    -5.3237, 'eps_e':     0.1000})
Step:  285000, Reward:  -837.529 [ 656.018], Avg:  -891.260 (0.100) <0-01:01:56> ({'r_t': -3980.6296, 'eps':     0.1000, 'critic_loss':  3962.3652, 'actor_loss':    -5.6519, 'eps_e':     0.1000})
Step:  286000, Reward:  -684.578 [ 608.717], Avg:  -890.539 (0.100) <0-01:02:10> ({'r_t': -4410.3682, 'eps':     0.1000, 'critic_loss':  3993.7588, 'actor_loss':    -5.6878, 'eps_e':     0.1000})
Step:  287000, Reward: -1029.966 [ 593.156], Avg:  -891.024 (0.100) <0-01:02:24> ({'r_t': -3790.4072, 'eps':     0.1000, 'critic_loss':  4127.5215, 'actor_loss':    -5.9112, 'eps_e':     0.1000})
Step:  288000, Reward:  -649.648 [ 622.752], Avg:  -890.188 (0.100) <0-01:02:37> ({'r_t': -4035.5837, 'eps':     0.1000, 'critic_loss':  4223.2480, 'actor_loss':    -6.2914, 'eps_e':     0.1000})
Step:  289000, Reward:  -653.140 [ 627.628], Avg:  -889.371 (0.100) <0-01:02:51> ({'r_t': -3818.2890, 'eps':     0.1000, 'critic_loss':  4008.6631, 'actor_loss':    -6.5947, 'eps_e':     0.1000})
Step:  290000, Reward:  -587.725 [ 593.209], Avg:  -888.334 (0.100) <0-01:03:04> ({'r_t': -3629.5617, 'eps':     0.1000, 'critic_loss':  4027.8406, 'actor_loss':    -6.6278, 'eps_e':     0.1000})
Step:  291000, Reward:  -660.267 [ 641.956], Avg:  -887.553 (0.100) <0-01:03:18> ({'r_t': -4427.3467, 'eps':     0.1000, 'critic_loss':  4120.4248, 'actor_loss':    -7.7546, 'eps_e':     0.1000})
Step:  292000, Reward:  -750.358 [ 566.050], Avg:  -887.085 (0.100) <0-01:03:31> ({'r_t': -3481.5487, 'eps':     0.1000, 'critic_loss':  4164.8267, 'actor_loss':    -7.1078, 'eps_e':     0.1000})
Step:  293000, Reward:  -905.959 [ 646.711], Avg:  -887.149 (0.100) <0-01:03:45> ({'r_t': -4546.1253, 'eps':     0.1000, 'critic_loss':  4201.3809, 'actor_loss':    -6.2393, 'eps_e':     0.1000})
Step:  294000, Reward:  -888.312 [ 654.294], Avg:  -887.153 (0.100) <0-01:03:59> ({'r_t': -3463.2947, 'eps':     0.1000, 'critic_loss':  4084.2329, 'actor_loss':    -6.1084, 'eps_e':     0.1000})
Step:  295000, Reward:  -844.571 [ 620.472], Avg:  -887.009 (0.100) <0-01:04:12> ({'r_t': -3729.1541, 'eps':     0.1000, 'critic_loss':  4095.8252, 'actor_loss':    -6.5861, 'eps_e':     0.1000})
Step:  296000, Reward:  -654.812 [ 685.476], Avg:  -886.228 (0.100) <0-01:04:26> ({'r_t': -3455.9559, 'eps':     0.1000, 'critic_loss':  4051.0305, 'actor_loss':    -6.4404, 'eps_e':     0.1000})
Step:  297000, Reward: -1073.289 [ 466.137], Avg:  -886.855 (0.100) <0-01:04:39> ({'r_t': -4062.6521, 'eps':     0.1000, 'critic_loss':  4209.8809, 'actor_loss':    -7.1597, 'eps_e':     0.1000})
Step:  298000, Reward: -1066.583 [ 475.504], Avg:  -887.456 (0.100) <0-01:04:53> ({'r_t': -5090.1084, 'eps':     0.1000, 'critic_loss':  4094.2852, 'actor_loss':    -6.0575, 'eps_e':     0.1000})
Step:  299000, Reward:  -492.005 [ 573.066], Avg:  -886.138 (0.100) <0-01:05:06> ({'r_t': -3723.8309, 'eps':     0.1000, 'critic_loss':  4119.2988, 'actor_loss':    -5.6710, 'eps_e':     0.1000})
Step:  300000, Reward:  -761.377 [ 589.404], Avg:  -885.724 (0.100) <0-01:05:20> ({'r_t': -4375.0814, 'eps':     0.1000, 'critic_loss':  4021.1174, 'actor_loss':    -7.0907, 'eps_e':     0.1000})
Step:  301000, Reward:  -631.750 [ 613.113], Avg:  -884.883 (0.100) <0-01:05:33> ({'r_t': -4292.2572, 'eps':     0.1000, 'critic_loss':  4106.0293, 'actor_loss':    -7.6304, 'eps_e':     0.1000})
Step:  302000, Reward:  -752.146 [ 639.747], Avg:  -884.445 (0.100) <0-01:05:47> ({'r_t': -3753.5703, 'eps':     0.1000, 'critic_loss':  4175.2134, 'actor_loss':    -7.3466, 'eps_e':     0.1000})
Step:  303000, Reward:  -583.030 [ 615.689], Avg:  -883.453 (0.100) <0-01:06:00> ({'r_t': -4117.9641, 'eps':     0.1000, 'critic_loss':  4059.9722, 'actor_loss':    -8.0353, 'eps_e':     0.1000})
Step:  304000, Reward: -1119.999 [ 457.150], Avg:  -884.229 (0.100) <0-01:06:14> ({'r_t': -4561.1002, 'eps':     0.1000, 'critic_loss':  4003.7717, 'actor_loss':    -8.3540, 'eps_e':     0.1000})
Step:  305000, Reward:  -711.200 [ 649.052], Avg:  -883.663 (0.100) <0-01:06:27> ({'r_t': -3862.1291, 'eps':     0.1000, 'critic_loss':  3809.0896, 'actor_loss':    -7.9393, 'eps_e':     0.1000})
Step:  306000, Reward:  -789.822 [ 629.782], Avg:  -883.358 (0.100) <0-01:06:41> ({'r_t': -3856.9986, 'eps':     0.1000, 'critic_loss':  3958.8325, 'actor_loss':    -7.7470, 'eps_e':     0.1000})
Step:  307000, Reward:  -833.931 [ 659.010], Avg:  -883.197 (0.100) <0-01:06:54> ({'r_t': -3923.2858, 'eps':     0.1000, 'critic_loss':  4001.6716, 'actor_loss':    -8.5393, 'eps_e':     0.1000})
Step:  308000, Reward:  -535.106 [ 589.003], Avg:  -882.071 (0.100) <0-01:07:08> ({'r_t': -3558.1839, 'eps':     0.1000, 'critic_loss':  4074.7480, 'actor_loss':    -8.3937, 'eps_e':     0.1000})
Step:  309000, Reward:  -949.658 [ 558.030], Avg:  -882.289 (0.100) <0-01:07:21> ({'r_t': -3962.6544, 'eps':     0.1000, 'critic_loss':  4197.9116, 'actor_loss':    -8.1252, 'eps_e':     0.1000})
Step:  310000, Reward:  -717.985 [ 594.697], Avg:  -881.760 (0.100) <0-01:07:35> ({'r_t': -4132.7313, 'eps':     0.1000, 'critic_loss':  4187.6069, 'actor_loss':    -7.9050, 'eps_e':     0.1000})
Step:  311000, Reward:  -824.708 [ 613.660], Avg:  -881.578 (0.100) <0-01:07:48> ({'r_t': -3651.1622, 'eps':     0.1000, 'critic_loss':  4305.7012, 'actor_loss':    -8.1077, 'eps_e':     0.1000})
Step:  312000, Reward:  -877.208 [ 633.301], Avg:  -881.564 (0.100) <0-01:08:01> ({'r_t': -4164.2016, 'eps':     0.1000, 'critic_loss':  4081.2249, 'actor_loss':    -8.1567, 'eps_e':     0.1000})
Step:  313000, Reward:  -661.034 [ 605.236], Avg:  -880.861 (0.100) <0-01:08:15> ({'r_t': -4160.7747, 'eps':     0.1000, 'critic_loss':  4198.7422, 'actor_loss':    -8.0181, 'eps_e':     0.1000})
Step:  314000, Reward: -1101.070 [ 429.047], Avg:  -881.560 (0.100) <0-01:08:28> ({'r_t': -4174.7321, 'eps':     0.1000, 'critic_loss':  4226.8755, 'actor_loss':    -7.7532, 'eps_e':     0.1000})
Step:  315000, Reward:  -727.623 [ 591.000], Avg:  -881.073 (0.100) <0-01:08:42> ({'r_t': -4573.1680, 'eps':     0.1000, 'critic_loss':  4095.6062, 'actor_loss':    -7.4902, 'eps_e':     0.1000})
Step:  316000, Reward: -1079.057 [ 531.199], Avg:  -881.698 (0.100) <0-01:08:55> ({'r_t': -4008.8487, 'eps':     0.1000, 'critic_loss':  4208.0063, 'actor_loss':    -7.0278, 'eps_e':     0.1000})
Step:  317000, Reward:  -604.217 [ 581.472], Avg:  -880.825 (0.100) <0-01:09:08> ({'r_t': -4011.7090, 'eps':     0.1000, 'critic_loss':  4208.4702, 'actor_loss':    -6.6141, 'eps_e':     0.1000})
Step:  318000, Reward:  -700.690 [ 601.583], Avg:  -880.260 (0.100) <0-01:09:22> ({'r_t': -4510.9638, 'eps':     0.1000, 'critic_loss':  4170.8936, 'actor_loss':    -7.1188, 'eps_e':     0.1000})
Step:  319000, Reward:  -660.401 [ 619.707], Avg:  -879.573 (0.100) <0-01:09:35> ({'r_t': -3618.4023, 'eps':     0.1000, 'critic_loss':  4165.2354, 'actor_loss':    -7.0466, 'eps_e':     0.1000})
Step:  320000, Reward:  -533.597 [ 544.712], Avg:  -878.496 (0.100) <0-01:09:49> ({'r_t': -4444.3846, 'eps':     0.1000, 'critic_loss':  4160.3511, 'actor_loss':    -6.3317, 'eps_e':     0.1000})
Step:  321000, Reward: -1056.526 [ 476.258], Avg:  -879.048 (0.100) <0-01:10:02> ({'r_t': -4288.9164, 'eps':     0.1000, 'critic_loss':  4162.2832, 'actor_loss':    -5.9831, 'eps_e':     0.1000})
Step:  322000, Reward:  -722.331 [ 666.572], Avg:  -878.563 (0.100) <0-01:10:16> ({'r_t': -3269.1996, 'eps':     0.1000, 'critic_loss':  4166.4175, 'actor_loss':    -6.0995, 'eps_e':     0.1000})
Step:  323000, Reward:  -895.161 [ 510.062], Avg:  -878.614 (0.100) <0-01:10:29> ({'r_t': -3813.4152, 'eps':     0.1000, 'critic_loss':  4332.4131, 'actor_loss':    -5.9430, 'eps_e':     0.1000})
Step:  324000, Reward: -1161.827 [ 361.219], Avg:  -879.486 (0.100) <0-01:10:42> ({'r_t': -5148.9944, 'eps':     0.1000, 'critic_loss':  4258.9673, 'actor_loss':    -5.3927, 'eps_e':     0.1000})
Step:  325000, Reward: -1184.041 [ 306.608], Avg:  -880.420 (0.100) <0-01:10:56> ({'r_t': -5294.4960, 'eps':     0.1000, 'critic_loss':  4217.5288, 'actor_loss':    -5.2350, 'eps_e':     0.1000})
Step:  326000, Reward: -1120.178 [ 502.234], Avg:  -881.153 (0.100) <0-01:11:09> ({'r_t': -5635.6915, 'eps':     0.1000, 'critic_loss':  4359.2412, 'actor_loss':    -4.7751, 'eps_e':     0.1000})
Step:  327000, Reward: -1189.525 [ 224.680], Avg:  -882.093 (0.100) <0-01:11:23> ({'r_t': -5111.8912, 'eps':     0.1000, 'critic_loss':  4454.6631, 'actor_loss':    -4.0714, 'eps_e':     0.1000})
Step:  328000, Reward: -1030.920 [ 282.438], Avg:  -882.546 (0.100) <0-01:11:36> ({'r_t': -5537.1159, 'eps':     0.1000, 'critic_loss':  4481.1494, 'actor_loss':    -3.0653, 'eps_e':     0.1000})
Step:  329000, Reward: -1110.307 [ 291.597], Avg:  -883.236 (0.100) <0-01:11:49> ({'r_t': -5797.9042, 'eps':     0.1000, 'critic_loss':  4416.9438, 'actor_loss':    -2.5634, 'eps_e':     0.1000})
Step:  330000, Reward: -1171.826 [ 309.041], Avg:  -884.108 (0.100) <0-01:12:03> ({'r_t': -5577.7380, 'eps':     0.1000, 'critic_loss':  4598.2100, 'actor_loss':    -1.8702, 'eps_e':     0.1000})
Step:  331000, Reward:  -901.767 [ 542.228], Avg:  -884.161 (0.100) <0-01:12:16> ({'r_t': -4972.2144, 'eps':     0.1000, 'critic_loss':  4584.0239, 'actor_loss':    -3.1323, 'eps_e':     0.1000})
Step:  332000, Reward:  -769.902 [ 533.692], Avg:  -883.818 (0.100) <0-01:12:30> ({'r_t': -4224.3480, 'eps':     0.1000, 'critic_loss':  4480.7466, 'actor_loss':    -4.2127, 'eps_e':     0.1000})
Step:  333000, Reward:  -847.809 [ 653.182], Avg:  -883.710 (0.100) <0-01:12:43> ({'r_t': -3884.3534, 'eps':     0.1000, 'critic_loss':  4590.6299, 'actor_loss':    -3.9358, 'eps_e':     0.1000})
Step:  334000, Reward:  -815.221 [ 558.741], Avg:  -883.506 (0.100) <0-01:12:57> ({'r_t': -4734.9983, 'eps':     0.1000, 'critic_loss':  4524.6440, 'actor_loss':    -4.1469, 'eps_e':     0.1000})
Step:  335000, Reward: -1021.892 [ 566.354], Avg:  -883.918 (0.100) <0-01:13:10> ({'r_t': -4668.3695, 'eps':     0.1000, 'critic_loss':  4615.1333, 'actor_loss':    -4.1448, 'eps_e':     0.1000})
Step:  336000, Reward: -1057.978 [ 506.243], Avg:  -884.434 (0.100) <0-01:13:24> ({'r_t': -4169.4481, 'eps':     0.1000, 'critic_loss':  4565.8198, 'actor_loss':    -3.8134, 'eps_e':     0.1000})
Step:  337000, Reward: -1002.253 [ 503.932], Avg:  -884.783 (0.100) <0-01:13:37> ({'r_t': -5546.9038, 'eps':     0.1000, 'critic_loss':  4601.1431, 'actor_loss':    -3.8135, 'eps_e':     0.1000})
Step:  338000, Reward: -1197.406 [ 367.935], Avg:  -885.705 (0.100) <0-01:13:51> ({'r_t': -4944.2449, 'eps':     0.1000, 'critic_loss':  4784.7495, 'actor_loss':    -3.8679, 'eps_e':     0.1000})
Step:  339000, Reward:  -705.886 [ 612.664], Avg:  -885.176 (0.100) <0-01:14:04> ({'r_t': -3832.5996, 'eps':     0.1000, 'critic_loss':  4489.7261, 'actor_loss':    -4.3166, 'eps_e':     0.1000})
Step:  340000, Reward:  -745.858 [ 638.765], Avg:  -884.767 (0.100) <0-01:14:18> ({'r_t': -4031.8959, 'eps':     0.1000, 'critic_loss':  4580.8403, 'actor_loss':    -3.5289, 'eps_e':     0.1000})
Step:  341000, Reward:  -783.957 [ 629.119], Avg:  -884.473 (0.100) <0-01:14:31> ({'r_t': -3901.4685, 'eps':     0.1000, 'critic_loss':  4726.3457, 'actor_loss':    -3.4935, 'eps_e':     0.1000})
Step:  342000, Reward:  -920.714 [ 588.335], Avg:  -884.578 (0.100) <0-01:14:45> ({'r_t': -4294.4195, 'eps':     0.1000, 'critic_loss':  4504.3091, 'actor_loss':    -3.5118, 'eps_e':     0.1000})
Step:  343000, Reward:  -953.824 [ 575.782], Avg:  -884.780 (0.100) <0-01:14:59> ({'r_t': -4118.4288, 'eps':     0.1000, 'critic_loss':  4579.2920, 'actor_loss':    -3.1413, 'eps_e':     0.1000})
Step:  344000, Reward:  -678.108 [ 593.738], Avg:  -884.181 (0.100) <0-01:15:12> ({'r_t': -4421.8832, 'eps':     0.1000, 'critic_loss':  4440.4868, 'actor_loss':    -2.5152, 'eps_e':     0.1000})
Step:  345000, Reward:  -924.653 [ 600.944], Avg:  -884.298 (0.100) <0-01:15:26> ({'r_t': -4875.4268, 'eps':     0.1000, 'critic_loss':  4554.1362, 'actor_loss':    -2.9471, 'eps_e':     0.1000})
Step:  346000, Reward:  -751.915 [ 647.927], Avg:  -883.916 (0.100) <0-01:15:39> ({'r_t': -3141.5635, 'eps':     0.1000, 'critic_loss':  4593.8501, 'actor_loss':    -3.1265, 'eps_e':     0.1000})
Step:  347000, Reward:  -798.752 [ 563.924], Avg:  -883.671 (0.100) <0-01:15:53> ({'r_t': -4293.7462, 'eps':     0.1000, 'critic_loss':  4722.8330, 'actor_loss':    -3.0062, 'eps_e':     0.1000})
Step:  348000, Reward:  -915.614 [ 635.899], Avg:  -883.763 (0.100) <0-01:16:07> ({'r_t': -4052.2134, 'eps':     0.1000, 'critic_loss':  4779.3613, 'actor_loss':    -2.9710, 'eps_e':     0.1000})
Step:  349000, Reward:  -783.758 [ 595.005], Avg:  -883.477 (0.100) <0-01:16:20> ({'r_t': -4217.0124, 'eps':     0.1000, 'critic_loss':  4792.5688, 'actor_loss':    -3.3493, 'eps_e':     0.1000})
Step:  350000, Reward:  -895.587 [ 589.101], Avg:  -883.512 (0.100) <0-01:16:34> ({'r_t': -4208.6499, 'eps':     0.1000, 'critic_loss':  4471.0718, 'actor_loss':    -3.4778, 'eps_e':     0.1000})
Step:  351000, Reward:  -921.886 [ 633.482], Avg:  -883.621 (0.100) <0-01:16:47> ({'r_t': -3934.0261, 'eps':     0.1000, 'critic_loss':  4865.5200, 'actor_loss':    -3.4135, 'eps_e':     0.1000})
Step:  352000, Reward:  -857.911 [ 613.960], Avg:  -883.548 (0.100) <0-01:17:01> ({'r_t': -4489.2392, 'eps':     0.1000, 'critic_loss':  4687.3003, 'actor_loss':    -2.8211, 'eps_e':     0.1000})
Step:  353000, Reward:  -753.282 [ 618.186], Avg:  -883.180 (0.100) <0-01:17:15> ({'r_t': -4037.7365, 'eps':     0.1000, 'critic_loss':  4618.3608, 'actor_loss':    -2.8269, 'eps_e':     0.1000})
Step:  354000, Reward:  -928.040 [ 528.235], Avg:  -883.306 (0.100) <0-01:17:28> ({'r_t': -3581.6078, 'eps':     0.1000, 'critic_loss':  4732.7134, 'actor_loss':    -2.4303, 'eps_e':     0.1000})
Step:  355000, Reward:  -809.153 [ 650.356], Avg:  -883.098 (0.100) <0-01:17:42> ({'r_t': -4437.5321, 'eps':     0.1000, 'critic_loss':  4644.6465, 'actor_loss':    -2.7769, 'eps_e':     0.1000})
Step:  356000, Reward:  -707.522 [ 650.658], Avg:  -882.606 (0.100) <0-01:17:56> ({'r_t': -4621.4602, 'eps':     0.1000, 'critic_loss':  4672.8340, 'actor_loss':    -2.4816, 'eps_e':     0.1000})
Step:  357000, Reward:  -866.340 [ 592.655], Avg:  -882.561 (0.100) <0-01:18:09> ({'r_t': -3939.2906, 'eps':     0.1000, 'critic_loss':  4609.8906, 'actor_loss':    -2.5095, 'eps_e':     0.1000})
Step:  358000, Reward:  -802.716 [ 603.225], Avg:  -882.338 (0.100) <0-01:18:23> ({'r_t': -3705.7367, 'eps':     0.1000, 'critic_loss':  4589.3149, 'actor_loss':    -2.8087, 'eps_e':     0.1000})
Step:  359000, Reward:  -818.379 [ 599.214], Avg:  -882.161 (0.100) <0-01:18:36> ({'r_t': -4499.6066, 'eps':     0.1000, 'critic_loss':  4690.9209, 'actor_loss':    -2.5966, 'eps_e':     0.1000})
Step:  360000, Reward:  -844.512 [ 606.530], Avg:  -882.056 (0.100) <0-01:18:50> ({'r_t': -4033.0455, 'eps':     0.1000, 'critic_loss':  4709.3994, 'actor_loss':    -1.8437, 'eps_e':     0.1000})
Step:  361000, Reward:  -618.245 [ 581.400], Avg:  -881.328 (0.100) <0-01:19:04> ({'r_t': -3407.5891, 'eps':     0.1000, 'critic_loss':  4582.4072, 'actor_loss':    -2.3691, 'eps_e':     0.1000})
Step:  362000, Reward: -1011.304 [ 590.719], Avg:  -881.686 (0.100) <0-01:19:17> ({'r_t': -3747.8776, 'eps':     0.1000, 'critic_loss':  4736.6567, 'actor_loss':    -2.3103, 'eps_e':     0.1000})
Step:  363000, Reward:  -778.226 [ 620.964], Avg:  -881.401 (0.100) <0-01:19:31> ({'r_t': -4409.4586, 'eps':     0.1000, 'critic_loss':  4808.7861, 'actor_loss':    -1.9504, 'eps_e':     0.1000})
Step:  364000, Reward: -1085.304 [ 478.939], Avg:  -881.960 (0.100) <0-01:19:44> ({'r_t': -4465.9538, 'eps':     0.1000, 'critic_loss':  4635.6411, 'actor_loss':    -2.1212, 'eps_e':     0.1000})
Step:  365000, Reward: -1134.686 [ 380.153], Avg:  -882.650 (0.100) <0-01:19:58> ({'r_t': -3877.2881, 'eps':     0.1000, 'critic_loss':  4633.2568, 'actor_loss':    -2.1829, 'eps_e':     0.1000})
Step:  366000, Reward: -1002.637 [ 632.235], Avg:  -882.977 (0.100) <0-01:20:12> ({'r_t': -3823.6146, 'eps':     0.1000, 'critic_loss':  4737.7749, 'actor_loss':    -2.7284, 'eps_e':     0.1000})
Step:  367000, Reward:  -829.291 [ 642.343], Avg:  -882.832 (0.100) <0-01:20:25> ({'r_t': -4273.8482, 'eps':     0.1000, 'critic_loss':  4643.2832, 'actor_loss':    -3.4188, 'eps_e':     0.1000})
Step:  368000, Reward:  -873.203 [ 667.777], Avg:  -882.805 (0.100) <0-01:20:39> ({'r_t': -4543.4474, 'eps':     0.1000, 'critic_loss':  4645.6743, 'actor_loss':    -3.5223, 'eps_e':     0.1000})
Step:  369000, Reward:  -938.806 [ 607.043], Avg:  -882.957 (0.100) <0-01:20:53> ({'r_t': -4117.1322, 'eps':     0.1000, 'critic_loss':  4781.8501, 'actor_loss':    -3.7947, 'eps_e':     0.1000})
Step:  370000, Reward:  -920.178 [ 580.996], Avg:  -883.057 (0.100) <0-01:21:06> ({'r_t': -3923.2213, 'eps':     0.1000, 'critic_loss':  4566.4995, 'actor_loss':    -3.6035, 'eps_e':     0.1000})
Step:  371000, Reward:  -627.290 [ 605.281], Avg:  -882.370 (0.100) <0-01:21:20> ({'r_t': -3748.3975, 'eps':     0.1000, 'critic_loss':  4696.7715, 'actor_loss':    -3.4914, 'eps_e':     0.1000})
Step:  372000, Reward:  -956.558 [ 558.691], Avg:  -882.568 (0.100) <0-01:21:33> ({'r_t': -4079.0747, 'eps':     0.1000, 'critic_loss':  4689.1714, 'actor_loss':    -3.3779, 'eps_e':     0.1000})
Step:  373000, Reward:  -771.690 [ 650.882], Avg:  -882.272 (0.100) <0-01:21:47> ({'r_t': -4251.2004, 'eps':     0.1000, 'critic_loss':  4628.6270, 'actor_loss':    -3.1195, 'eps_e':     0.1000})
Step:  374000, Reward:  -918.585 [ 565.456], Avg:  -882.369 (0.100) <0-01:22:01> ({'r_t': -4588.7020, 'eps':     0.1000, 'critic_loss':  4767.0195, 'actor_loss':    -3.3967, 'eps_e':     0.1000})
Step:  375000, Reward:  -556.673 [ 622.570], Avg:  -881.503 (0.100) <0-01:22:14> ({'r_t': -3908.1580, 'eps':     0.1000, 'critic_loss':  4750.8579, 'actor_loss':    -3.4210, 'eps_e':     0.1000})
Step:  376000, Reward:  -476.497 [ 586.823], Avg:  -880.428 (0.100) <0-01:22:28> ({'r_t': -4093.4286, 'eps':     0.1000, 'critic_loss':  4713.7100, 'actor_loss':    -3.0194, 'eps_e':     0.1000})
Step:  377000, Reward:  -899.963 [ 631.257], Avg:  -880.480 (0.100) <0-01:22:42> ({'r_t': -4405.9158, 'eps':     0.1000, 'critic_loss':  4679.1299, 'actor_loss':    -3.4407, 'eps_e':     0.1000})
Step:  378000, Reward:  -629.499 [ 555.630], Avg:  -879.818 (0.100) <0-01:22:55> ({'r_t': -3715.7708, 'eps':     0.1000, 'critic_loss':  4798.0532, 'actor_loss':    -3.3424, 'eps_e':     0.1000})
Step:  379000, Reward:  -802.874 [ 614.666], Avg:  -879.615 (0.100) <0-01:23:09> ({'r_t': -3883.5731, 'eps':     0.1000, 'critic_loss':  4878.6343, 'actor_loss':    -3.3701, 'eps_e':     0.1000})
Step:  380000, Reward: -1038.745 [ 550.341], Avg:  -880.033 (0.100) <0-01:23:23> ({'r_t': -3715.5359, 'eps':     0.1000, 'critic_loss':  4708.7998, 'actor_loss':    -3.7750, 'eps_e':     0.1000})
Step:  381000, Reward:  -789.294 [ 702.266], Avg:  -879.795 (0.100) <0-01:23:36> ({'r_t': -3274.5833, 'eps':     0.1000, 'critic_loss':  4594.4917, 'actor_loss':    -3.4054, 'eps_e':     0.1000})
Step:  382000, Reward:  -814.945 [ 583.420], Avg:  -879.626 (0.100) <0-01:23:50> ({'r_t': -3807.1237, 'eps':     0.1000, 'critic_loss':  4630.9517, 'actor_loss':    -3.3305, 'eps_e':     0.1000})
Step:  383000, Reward:  -695.367 [ 649.907], Avg:  -879.146 (0.100) <0-01:24:04> ({'r_t': -4361.7234, 'eps':     0.1000, 'critic_loss':  4851.6089, 'actor_loss':    -3.3874, 'eps_e':     0.1000})
Step:  384000, Reward: -1050.846 [ 465.565], Avg:  -879.592 (0.100) <0-01:24:18> ({'r_t': -4146.4366, 'eps':     0.1000, 'critic_loss':  4485.1328, 'actor_loss':    -3.4488, 'eps_e':     0.1000})
Step:  385000, Reward:  -868.997 [ 694.091], Avg:  -879.565 (0.100) <0-01:24:31> ({'r_t': -3915.4741, 'eps':     0.1000, 'critic_loss':  4729.2280, 'actor_loss':    -3.3930, 'eps_e':     0.1000})
Step:  386000, Reward:  -670.281 [ 644.959], Avg:  -879.024 (0.100) <0-01:24:45> ({'r_t': -4084.8420, 'eps':     0.1000, 'critic_loss':  4654.3208, 'actor_loss':    -3.2128, 'eps_e':     0.1000})
Step:  387000, Reward:  -842.207 [ 663.580], Avg:  -878.929 (0.100) <0-01:24:59> ({'r_t': -3681.1197, 'eps':     0.1000, 'critic_loss':  4552.1602, 'actor_loss':    -3.2285, 'eps_e':     0.1000})
Step:  388000, Reward:  -811.833 [ 607.891], Avg:  -878.757 (0.100) <0-01:25:12> ({'r_t': -3719.9949, 'eps':     0.1000, 'critic_loss':  4487.9512, 'actor_loss':    -3.4095, 'eps_e':     0.1000})
Step:  389000, Reward:  -848.923 [ 520.151], Avg:  -878.680 (0.100) <0-01:25:27> ({'r_t': -3140.9478, 'eps':     0.1000, 'critic_loss':  4524.6973, 'actor_loss':    -3.5556, 'eps_e':     0.1000})
Step:  390000, Reward:  -644.232 [ 623.561], Avg:  -878.081 (0.100) <0-01:25:40> ({'r_t': -4405.9868, 'eps':     0.1000, 'critic_loss':  4530.9619, 'actor_loss':    -3.5025, 'eps_e':     0.1000})
Step:  391000, Reward:  -872.062 [ 600.032], Avg:  -878.065 (0.100) <0-01:25:54> ({'r_t': -4219.7092, 'eps':     0.1000, 'critic_loss':  4687.2451, 'actor_loss':    -3.7737, 'eps_e':     0.1000})
Step:  392000, Reward:  -830.060 [ 608.968], Avg:  -877.943 (0.100) <0-01:26:07> ({'r_t': -4271.3575, 'eps':     0.1000, 'critic_loss':  4364.9131, 'actor_loss':    -3.8740, 'eps_e':     0.1000})
Step:  393000, Reward:  -436.498 [ 503.404], Avg:  -876.823 (0.100) <0-01:26:21> ({'r_t': -3384.9366, 'eps':     0.1000, 'critic_loss':  4147.1523, 'actor_loss':    -3.6896, 'eps_e':     0.1000})
Step:  394000, Reward:  -749.841 [ 680.532], Avg:  -876.501 (0.100) <0-01:26:35> ({'r_t': -4243.7882, 'eps':     0.1000, 'critic_loss':  4410.2754, 'actor_loss':    -3.5239, 'eps_e':     0.1000})
Step:  395000, Reward:  -798.339 [ 643.300], Avg:  -876.304 (0.100) <0-01:26:48> ({'r_t': -3934.7038, 'eps':     0.1000, 'critic_loss':  4417.3169, 'actor_loss':    -3.9786, 'eps_e':     0.1000})
Step:  396000, Reward:  -842.057 [ 641.189], Avg:  -876.218 (0.100) <0-01:27:02> ({'r_t': -4184.0567, 'eps':     0.1000, 'critic_loss':  4311.6592, 'actor_loss':    -3.9709, 'eps_e':     0.1000})
Step:  397000, Reward:  -675.987 [ 582.762], Avg:  -875.714 (0.100) <0-01:27:16> ({'r_t': -4107.2391, 'eps':     0.1000, 'critic_loss':  4476.1484, 'actor_loss':    -3.8148, 'eps_e':     0.1000})
Step:  398000, Reward:  -748.762 [ 672.515], Avg:  -875.396 (0.100) <0-01:27:29> ({'r_t': -3930.2823, 'eps':     0.1000, 'critic_loss':  4424.1328, 'actor_loss':    -3.6982, 'eps_e':     0.1000})
Step:  399000, Reward:  -690.080 [ 612.684], Avg:  -874.933 (0.100) <0-01:27:43> ({'r_t': -4295.4517, 'eps':     0.1000, 'critic_loss':  4448.3721, 'actor_loss':    -3.8488, 'eps_e':     0.1000})
Step:  400000, Reward:  -738.443 [ 607.029], Avg:  -874.593 (0.100) <0-01:27:57> ({'r_t': -3787.3761, 'eps':     0.1000, 'critic_loss':  4472.7480, 'actor_loss':    -3.5995, 'eps_e':     0.1000})
Step:  401000, Reward:  -650.425 [ 628.813], Avg:  -874.035 (0.100) <0-01:28:10> ({'r_t': -3316.5409, 'eps':     0.1000, 'critic_loss':  4542.3682, 'actor_loss':    -2.9997, 'eps_e':     0.1000})
Step:  402000, Reward:  -655.116 [ 656.637], Avg:  -873.492 (0.100) <0-01:28:24> ({'r_t': -4102.3299, 'eps':     0.1000, 'critic_loss':  4528.0479, 'actor_loss':    -2.8616, 'eps_e':     0.1000})
Step:  403000, Reward:  -579.438 [ 605.804], Avg:  -872.764 (0.100) <0-01:28:37> ({'r_t': -4083.7845, 'eps':     0.1000, 'critic_loss':  4286.6909, 'actor_loss':    -3.0688, 'eps_e':     0.1000})
Step:  404000, Reward:  -978.700 [ 502.196], Avg:  -873.025 (0.100) <0-01:28:51> ({'r_t': -4152.2973, 'eps':     0.1000, 'critic_loss':  4313.8721, 'actor_loss':    -2.9995, 'eps_e':     0.1000})
Step:  405000, Reward:  -783.650 [ 623.115], Avg:  -872.805 (0.100) <0-01:29:05> ({'r_t': -3985.6770, 'eps':     0.1000, 'critic_loss':  4311.6611, 'actor_loss':    -3.3015, 'eps_e':     0.1000})
Step:  406000, Reward:  -780.925 [ 566.353], Avg:  -872.580 (0.100) <0-01:29:18> ({'r_t': -3509.9293, 'eps':     0.1000, 'critic_loss':  4458.2988, 'actor_loss':    -3.2277, 'eps_e':     0.1000})
Step:  407000, Reward:  -687.033 [ 525.119], Avg:  -872.125 (0.100) <0-01:29:32> ({'r_t': -3496.0672, 'eps':     0.1000, 'critic_loss':  4191.4492, 'actor_loss':    -2.9097, 'eps_e':     0.1000})
Step:  408000, Reward:  -901.594 [ 614.167], Avg:  -872.197 (0.100) <0-01:29:45> ({'r_t': -3753.1464, 'eps':     0.1000, 'critic_loss':  4315.1396, 'actor_loss':    -3.1427, 'eps_e':     0.1000})
Step:  409000, Reward:  -501.738 [ 593.426], Avg:  -871.293 (0.100) <0-01:29:59> ({'r_t': -3758.1859, 'eps':     0.1000, 'critic_loss':  4445.9619, 'actor_loss':    -2.9612, 'eps_e':     0.1000})
Step:  410000, Reward:  -793.822 [ 631.132], Avg:  -871.105 (0.100) <0-01:30:12> ({'r_t': -3819.5668, 'eps':     0.1000, 'critic_loss':  4311.7783, 'actor_loss':    -2.9725, 'eps_e':     0.1000})
Step:  411000, Reward: -1166.206 [ 533.293], Avg:  -871.821 (0.100) <0-01:30:26> ({'r_t': -3917.7388, 'eps':     0.1000, 'critic_loss':  4379.8682, 'actor_loss':    -3.1393, 'eps_e':     0.1000})
Step:  412000, Reward:  -685.503 [ 638.341], Avg:  -871.370 (0.100) <0-01:30:40> ({'r_t': -4272.8053, 'eps':     0.1000, 'critic_loss':  4365.7861, 'actor_loss':    -2.7679, 'eps_e':     0.1000})
Step:  413000, Reward:  -744.542 [ 620.316], Avg:  -871.064 (0.100) <0-01:30:53> ({'r_t': -4314.1590, 'eps':     0.1000, 'critic_loss':  4449.0610, 'actor_loss':    -2.7236, 'eps_e':     0.1000})
Step:  414000, Reward:  -694.600 [ 626.297], Avg:  -870.638 (0.100) <0-01:31:07> ({'r_t': -4118.7234, 'eps':     0.1000, 'critic_loss':  4500.8462, 'actor_loss':    -2.8663, 'eps_e':     0.1000})
Step:  415000, Reward:  -579.981 [ 583.403], Avg:  -869.940 (0.100) <0-01:31:21> ({'r_t': -4166.2476, 'eps':     0.1000, 'critic_loss':  4322.5518, 'actor_loss':    -3.0656, 'eps_e':     0.1000})
Step:  416000, Reward:  -917.986 [ 640.094], Avg:  -870.055 (0.100) <0-01:31:34> ({'r_t': -3954.1646, 'eps':     0.1000, 'critic_loss':  4377.5415, 'actor_loss':    -2.8366, 'eps_e':     0.1000})
Step:  417000, Reward:  -839.631 [ 629.293], Avg:  -869.982 (0.100) <0-01:31:48> ({'r_t': -3553.8412, 'eps':     0.1000, 'critic_loss':  4589.5562, 'actor_loss':    -2.8539, 'eps_e':     0.1000})
Step:  418000, Reward:  -750.335 [ 656.205], Avg:  -869.697 (0.100) <0-01:32:01> ({'r_t': -3977.3829, 'eps':     0.1000, 'critic_loss':  4378.0464, 'actor_loss':    -2.6177, 'eps_e':     0.1000})
Step:  419000, Reward:  -959.729 [ 609.684], Avg:  -869.911 (0.100) <0-01:32:15> ({'r_t': -3946.0461, 'eps':     0.1000, 'critic_loss':  4226.5210, 'actor_loss':    -2.8921, 'eps_e':     0.1000})
Step:  420000, Reward:  -628.616 [ 603.566], Avg:  -869.338 (0.100) <0-01:32:28> ({'r_t': -3250.5351, 'eps':     0.1000, 'critic_loss':  4388.9468, 'actor_loss':    -2.9150, 'eps_e':     0.1000})
Step:  421000, Reward:  -610.378 [ 618.179], Avg:  -868.724 (0.100) <0-01:32:42> ({'r_t': -4037.7647, 'eps':     0.1000, 'critic_loss':  4296.6997, 'actor_loss':    -2.8586, 'eps_e':     0.1000})
Step:  422000, Reward:  -910.169 [ 598.867], Avg:  -868.822 (0.100) <0-01:32:56> ({'r_t': -4263.8340, 'eps':     0.1000, 'critic_loss':  4330.6245, 'actor_loss':    -2.5934, 'eps_e':     0.1000})
Step:  423000, Reward: -1067.585 [ 601.679], Avg:  -869.291 (0.100) <0-01:33:09> ({'r_t': -4457.3349, 'eps':     0.1000, 'critic_loss':  4228.9448, 'actor_loss':    -2.5579, 'eps_e':     0.1000})
Step:  424000, Reward:  -901.903 [ 657.112], Avg:  -869.368 (0.100) <0-01:33:23> ({'r_t': -3646.2502, 'eps':     0.1000, 'critic_loss':  4421.8789, 'actor_loss':    -2.3890, 'eps_e':     0.1000})
Step:  425000, Reward:  -729.650 [ 602.975], Avg:  -869.040 (0.100) <0-01:33:36> ({'r_t': -4644.4980, 'eps':     0.1000, 'critic_loss':  4386.9888, 'actor_loss':    -2.2577, 'eps_e':     0.1000})
Step:  426000, Reward:  -817.336 [ 630.532], Avg:  -868.919 (0.100) <0-01:33:49> ({'r_t': -3778.4003, 'eps':     0.1000, 'critic_loss':  4555.0962, 'actor_loss':    -2.4746, 'eps_e':     0.1000})
Step:  427000, Reward:  -588.672 [ 581.858], Avg:  -868.264 (0.100) <0-01:34:03> ({'r_t': -4135.0477, 'eps':     0.1000, 'critic_loss':  4272.5898, 'actor_loss':    -2.0221, 'eps_e':     0.1000})
Step:  428000, Reward:  -818.612 [ 659.647], Avg:  -868.148 (0.100) <0-01:34:17> ({'r_t': -4368.7535, 'eps':     0.1000, 'critic_loss':  4352.7251, 'actor_loss':    -1.9385, 'eps_e':     0.1000})
Step:  429000, Reward:  -604.300 [ 539.476], Avg:  -867.534 (0.100) <0-01:34:31> ({'r_t': -3637.1725, 'eps':     0.1000, 'critic_loss':  4405.5352, 'actor_loss':    -2.1043, 'eps_e':     0.1000})
Step:  430000, Reward:  -885.951 [ 594.209], Avg:  -867.577 (0.100) <0-01:34:44> ({'r_t': -3706.8207, 'eps':     0.1000, 'critic_loss':  4403.9971, 'actor_loss':    -2.3139, 'eps_e':     0.1000})
Step:  431000, Reward:  -808.604 [ 630.622], Avg:  -867.441 (0.100) <0-01:34:58> ({'r_t': -4180.7892, 'eps':     0.1000, 'critic_loss':  4370.1802, 'actor_loss':    -2.8074, 'eps_e':     0.1000})
Step:  432000, Reward:  -759.786 [ 649.662], Avg:  -867.192 (0.100) <0-01:35:12> ({'r_t': -3701.0036, 'eps':     0.1000, 'critic_loss':  4208.5308, 'actor_loss':    -2.4757, 'eps_e':     0.1000})
Step:  433000, Reward:  -777.525 [ 622.728], Avg:  -866.985 (0.100) <0-01:35:25> ({'r_t': -3555.6674, 'eps':     0.1000, 'critic_loss':  4200.9932, 'actor_loss':    -2.3512, 'eps_e':     0.1000})
Step:  434000, Reward:  -832.066 [ 671.880], Avg:  -866.905 (0.100) <0-01:35:39> ({'r_t': -4167.3475, 'eps':     0.1000, 'critic_loss':  4365.4487, 'actor_loss':    -2.1616, 'eps_e':     0.1000})
Step:  435000, Reward: -1049.814 [ 618.010], Avg:  -867.325 (0.100) <0-01:35:52> ({'r_t': -3702.9738, 'eps':     0.1000, 'critic_loss':  4254.2041, 'actor_loss':    -1.9329, 'eps_e':     0.1000})
Step:  436000, Reward:  -923.201 [ 573.654], Avg:  -867.453 (0.100) <0-01:36:06> ({'r_t': -3698.6993, 'eps':     0.1000, 'critic_loss':  4242.6265, 'actor_loss':    -2.1855, 'eps_e':     0.1000})
Step:  437000, Reward:  -646.363 [ 653.214], Avg:  -866.948 (0.100) <0-01:36:19> ({'r_t': -4817.2481, 'eps':     0.1000, 'critic_loss':  4366.5767, 'actor_loss':    -2.2491, 'eps_e':     0.1000})
Step:  438000, Reward:  -908.122 [ 542.615], Avg:  -867.042 (0.100) <0-01:36:33> ({'r_t': -4438.9246, 'eps':     0.1000, 'critic_loss':  4407.8901, 'actor_loss':    -2.0111, 'eps_e':     0.1000})
Step:  439000, Reward:  -725.937 [ 607.677], Avg:  -866.721 (0.100) <0-01:36:46> ({'r_t': -3970.8481, 'eps':     0.1000, 'critic_loss':  4187.6367, 'actor_loss':    -1.8824, 'eps_e':     0.1000})
Step:  440000, Reward:  -869.383 [ 596.523], Avg:  -866.727 (0.100) <0-01:37:00> ({'r_t': -3642.0403, 'eps':     0.1000, 'critic_loss':  4468.3604, 'actor_loss':    -1.6547, 'eps_e':     0.1000})
Step:  441000, Reward:  -904.297 [ 666.618], Avg:  -866.812 (0.100) <0-01:37:13> ({'r_t': -3312.3362, 'eps':     0.1000, 'critic_loss':  4278.5781, 'actor_loss':    -1.7456, 'eps_e':     0.1000})
Step:  442000, Reward:  -507.947 [ 558.160], Avg:  -866.002 (0.100) <0-01:37:27> ({'r_t': -4009.5782, 'eps':     0.1000, 'critic_loss':  4190.8809, 'actor_loss':    -1.2541, 'eps_e':     0.1000})
Step:  443000, Reward:  -814.464 [ 647.542], Avg:  -865.886 (0.100) <0-01:37:41> ({'r_t': -4126.9912, 'eps':     0.1000, 'critic_loss':  4262.2632, 'actor_loss':    -1.9393, 'eps_e':     0.1000})
Step:  444000, Reward:  -789.294 [ 642.037], Avg:  -865.714 (0.100) <0-01:37:54> ({'r_t': -3691.8834, 'eps':     0.1000, 'critic_loss':  4197.0464, 'actor_loss':    -1.8452, 'eps_e':     0.1000})
Step:  445000, Reward: -1114.845 [ 548.371], Avg:  -866.272 (0.100) <0-01:38:08> ({'r_t': -3921.9879, 'eps':     0.1000, 'critic_loss':  4218.8130, 'actor_loss':    -1.6548, 'eps_e':     0.1000})
Step:  446000, Reward:  -781.082 [ 606.882], Avg:  -866.082 (0.100) <0-01:38:21> ({'r_t': -4022.8108, 'eps':     0.1000, 'critic_loss':  4341.8398, 'actor_loss':    -1.5313, 'eps_e':     0.1000})
Step:  447000, Reward:  -896.008 [ 641.845], Avg:  -866.148 (0.100) <0-01:38:35> ({'r_t': -3916.9227, 'eps':     0.1000, 'critic_loss':  4345.1909, 'actor_loss':    -1.0950, 'eps_e':     0.1000})
Step:  448000, Reward:  -785.350 [ 626.786], Avg:  -865.968 (0.100) <0-01:38:49> ({'r_t': -4338.6118, 'eps':     0.1000, 'critic_loss':  4374.2139, 'actor_loss':    -1.3043, 'eps_e':     0.1000})
Step:  449000, Reward:  -765.424 [ 562.029], Avg:  -865.745 (0.100) <0-01:39:02> ({'r_t': -4392.6011, 'eps':     0.1000, 'critic_loss':  4314.7026, 'actor_loss':    -1.7535, 'eps_e':     0.1000})
Step:  450000, Reward:  -563.407 [ 584.403], Avg:  -865.075 (0.100) <0-01:39:16> ({'r_t': -3816.3412, 'eps':     0.1000, 'critic_loss':  4440.5288, 'actor_loss':    -1.8146, 'eps_e':     0.1000})
Step:  451000, Reward:  -861.767 [ 641.324], Avg:  -865.067 (0.100) <0-01:39:29> ({'r_t': -3503.4164, 'eps':     0.1000, 'critic_loss':  4459.2739, 'actor_loss':    -1.3383, 'eps_e':     0.1000})
Step:  452000, Reward:  -846.186 [ 659.384], Avg:  -865.026 (0.100) <0-01:39:43> ({'r_t': -3845.5557, 'eps':     0.1000, 'critic_loss':  4308.7856, 'actor_loss':    -1.4050, 'eps_e':     0.1000})
Step:  453000, Reward:  -858.524 [ 595.565], Avg:  -865.011 (0.100) <0-01:39:57> ({'r_t': -3553.6667, 'eps':     0.1000, 'critic_loss':  4276.6938, 'actor_loss':    -2.1356, 'eps_e':     0.1000})
Step:  454000, Reward:  -638.607 [ 580.037], Avg:  -864.514 (0.100) <0-01:40:10> ({'r_t': -3701.3602, 'eps':     0.1000, 'critic_loss':  4282.3740, 'actor_loss':    -2.2360, 'eps_e':     0.1000})
Step:  455000, Reward:  -527.855 [ 606.904], Avg:  -863.775 (0.100) <0-01:40:24> ({'r_t': -3954.3156, 'eps':     0.1000, 'critic_loss':  4411.3174, 'actor_loss':    -2.2416, 'eps_e':     0.1000})
Step:  456000, Reward:  -907.274 [ 654.620], Avg:  -863.871 (0.100) <0-01:40:37> ({'r_t': -4062.9340, 'eps':     0.1000, 'critic_loss':  4509.0820, 'actor_loss':    -1.5969, 'eps_e':     0.1000})
Step:  457000, Reward:  -651.827 [ 592.270], Avg:  -863.408 (0.100) <0-01:40:51> ({'r_t': -3594.7114, 'eps':     0.1000, 'critic_loss':  4306.2173, 'actor_loss':    -1.8754, 'eps_e':     0.1000})
Step:  458000, Reward:  -502.892 [ 512.356], Avg:  -862.622 (0.100) <0-01:41:04> ({'r_t': -5143.4465, 'eps':     0.1000, 'critic_loss':  4409.9995, 'actor_loss':    -1.8050, 'eps_e':     0.1000})
Step:  459000, Reward:  -752.184 [ 665.228], Avg:  -862.382 (0.100) <0-01:41:18> ({'r_t': -3482.0441, 'eps':     0.1000, 'critic_loss':  4309.3931, 'actor_loss':    -2.0107, 'eps_e':     0.1000})
Step:  460000, Reward: -1014.561 [ 611.900], Avg:  -862.712 (0.100) <0-01:41:31> ({'r_t': -4638.2191, 'eps':     0.1000, 'critic_loss':  4438.3818, 'actor_loss':    -2.1051, 'eps_e':     0.1000})
Step:  461000, Reward:  -763.825 [ 641.448], Avg:  -862.498 (0.100) <0-01:41:45> ({'r_t': -3624.2441, 'eps':     0.1000, 'critic_loss':  4312.5308, 'actor_loss':    -1.9591, 'eps_e':     0.1000})
Step:  462000, Reward:  -861.048 [ 585.400], Avg:  -862.495 (0.100) <0-01:41:59> ({'r_t': -3779.9831, 'eps':     0.1000, 'critic_loss':  4555.2969, 'actor_loss':    -1.9765, 'eps_e':     0.1000})
Step:  463000, Reward: -1101.341 [ 567.505], Avg:  -863.010 (0.100) <0-01:42:12> ({'r_t': -3831.4620, 'eps':     0.1000, 'critic_loss':  4465.4585, 'actor_loss':    -2.2661, 'eps_e':     0.1000})
Step:  464000, Reward:  -616.261 [ 618.245], Avg:  -862.479 (0.100) <0-01:42:26> ({'r_t': -4064.1683, 'eps':     0.1000, 'critic_loss':  4341.7324, 'actor_loss':    -2.1720, 'eps_e':     0.1000})
Step:  465000, Reward:  -775.263 [ 619.916], Avg:  -862.292 (0.100) <0-01:42:40> ({'r_t': -3797.6913, 'eps':     0.1000, 'critic_loss':  4409.3213, 'actor_loss':    -2.0913, 'eps_e':     0.1000})
Step:  466000, Reward:  -792.338 [ 627.438], Avg:  -862.142 (0.100) <0-01:42:53> ({'r_t': -4280.9151, 'eps':     0.1000, 'critic_loss':  4305.1880, 'actor_loss':    -1.9727, 'eps_e':     0.1000})
Step:  467000, Reward:  -838.528 [ 645.497], Avg:  -862.092 (0.100) <0-01:43:07> ({'r_t': -3586.9169, 'eps':     0.1000, 'critic_loss':  4446.0210, 'actor_loss':    -1.8468, 'eps_e':     0.1000})
Step:  468000, Reward:  -783.766 [ 578.777], Avg:  -861.925 (0.100) <0-01:43:20> ({'r_t': -3734.5367, 'eps':     0.1000, 'critic_loss':  4404.3857, 'actor_loss':    -1.7680, 'eps_e':     0.1000})
Step:  469000, Reward:  -787.140 [ 640.800], Avg:  -861.766 (0.100) <0-01:43:34> ({'r_t': -3866.4626, 'eps':     0.1000, 'critic_loss':  4291.4541, 'actor_loss':    -1.8103, 'eps_e':     0.1000})
Step:  470000, Reward:  -920.086 [ 580.225], Avg:  -861.889 (0.100) <0-01:43:48> ({'r_t': -4229.5370, 'eps':     0.1000, 'critic_loss':  4523.8760, 'actor_loss':    -1.7368, 'eps_e':     0.1000})
Step:  471000, Reward:  -828.005 [ 652.359], Avg:  -861.818 (0.100) <0-01:44:01> ({'r_t': -3823.0325, 'eps':     0.1000, 'critic_loss':  4175.6792, 'actor_loss':    -2.0484, 'eps_e':     0.1000})
Step:  472000, Reward:  -668.986 [ 609.783], Avg:  -861.410 (0.100) <0-01:44:15> ({'r_t': -4278.3615, 'eps':     0.1000, 'critic_loss':  4524.3970, 'actor_loss':    -2.0448, 'eps_e':     0.1000})
Step:  473000, Reward:  -684.188 [ 592.688], Avg:  -861.036 (0.100) <0-01:44:29> ({'r_t': -3527.9968, 'eps':     0.1000, 'critic_loss':  4468.1230, 'actor_loss':    -1.6718, 'eps_e':     0.1000})
Step:  474000, Reward:  -757.922 [ 595.447], Avg:  -860.819 (0.100) <0-01:44:42> ({'r_t': -4564.1597, 'eps':     0.1000, 'critic_loss':  4680.1958, 'actor_loss':    -2.0341, 'eps_e':     0.1000})
Step:  475000, Reward: -1043.814 [ 584.661], Avg:  -861.203 (0.100) <0-01:44:56> ({'r_t': -4131.2574, 'eps':     0.1000, 'critic_loss':  4439.2271, 'actor_loss':    -2.3040, 'eps_e':     0.1000})
Step:  476000, Reward:  -916.716 [ 592.045], Avg:  -861.320 (0.100) <0-01:45:10> ({'r_t': -3722.3190, 'eps':     0.1000, 'critic_loss':  4501.5981, 'actor_loss':    -2.3615, 'eps_e':     0.1000})
Step:  477000, Reward:  -760.719 [ 622.616], Avg:  -861.109 (0.100) <0-01:45:23> ({'r_t': -4589.4786, 'eps':     0.1000, 'critic_loss':  4406.3931, 'actor_loss':    -1.5923, 'eps_e':     0.1000})
Step:  478000, Reward: -1028.348 [ 519.628], Avg:  -861.459 (0.100) <0-01:45:37> ({'r_t': -4033.1406, 'eps':     0.1000, 'critic_loss':  4400.2344, 'actor_loss':    -1.4512, 'eps_e':     0.1000})
Step:  479000, Reward:  -552.867 [ 460.261], Avg:  -860.816 (0.100) <0-01:45:50> ({'r_t': -3824.0192, 'eps':     0.1000, 'critic_loss':  4324.2280, 'actor_loss':    -2.0349, 'eps_e':     0.1000})
Step:  480000, Reward:  -516.608 [ 568.156], Avg:  -860.100 (0.100) <0-01:46:04> ({'r_t': -4241.8717, 'eps':     0.1000, 'critic_loss':  4231.1982, 'actor_loss':    -2.1897, 'eps_e':     0.1000})
Step:  481000, Reward: -1075.187 [ 595.594], Avg:  -860.546 (0.100) <0-01:46:18> ({'r_t': -4177.0259, 'eps':     0.1000, 'critic_loss':  4299.3848, 'actor_loss':    -1.8763, 'eps_e':     0.1000})
Step:  482000, Reward:  -864.703 [ 578.271], Avg:  -860.555 (0.100) <0-01:46:31> ({'r_t': -4335.0581, 'eps':     0.1000, 'critic_loss':  4443.8418, 'actor_loss':    -1.9410, 'eps_e':     0.1000})
Step:  483000, Reward:  -971.428 [ 568.014], Avg:  -860.784 (0.100) <0-01:46:45> ({'r_t': -3891.7967, 'eps':     0.1000, 'critic_loss':  4432.2627, 'actor_loss':    -1.3850, 'eps_e':     0.1000})
Step:  484000, Reward:  -877.151 [ 618.529], Avg:  -860.818 (0.100) <0-01:46:58> ({'r_t': -3576.9227, 'eps':     0.1000, 'critic_loss':  4651.7109, 'actor_loss':    -2.2062, 'eps_e':     0.1000})
Step:  485000, Reward:  -814.530 [ 627.001], Avg:  -860.722 (0.100) <0-01:47:12> ({'r_t': -4566.8875, 'eps':     0.1000, 'critic_loss':  4310.3608, 'actor_loss':    -1.5124, 'eps_e':     0.1000})
Step:  486000, Reward:  -742.801 [ 638.587], Avg:  -860.480 (0.100) <0-01:47:26> ({'r_t': -4059.4372, 'eps':     0.1000, 'critic_loss':  4519.6157, 'actor_loss':    -1.5982, 'eps_e':     0.1000})
Step:  487000, Reward:  -795.030 [ 651.995], Avg:  -860.346 (0.100) <0-01:47:39> ({'r_t': -4239.3221, 'eps':     0.1000, 'critic_loss':  4485.9043, 'actor_loss':    -1.7666, 'eps_e':     0.1000})
Step:  488000, Reward:  -640.482 [ 661.801], Avg:  -859.897 (0.100) <0-01:47:53> ({'r_t': -4155.2576, 'eps':     0.1000, 'critic_loss':  4491.8320, 'actor_loss':    -1.9512, 'eps_e':     0.1000})
Step:  489000, Reward:  -906.397 [ 588.584], Avg:  -859.991 (0.100) <0-01:48:07> ({'r_t': -4456.8177, 'eps':     0.1000, 'critic_loss':  4430.0000, 'actor_loss':    -1.5391, 'eps_e':     0.1000})
Step:  490000, Reward:  -621.153 [ 644.935], Avg:  -859.505 (0.100) <0-01:48:20> ({'r_t': -3770.7432, 'eps':     0.1000, 'critic_loss':  4420.9780, 'actor_loss':    -1.7468, 'eps_e':     0.1000})
Step:  491000, Reward:  -413.059 [ 530.830], Avg:  -858.598 (0.100) <0-01:48:34> ({'r_t': -4073.1950, 'eps':     0.1000, 'critic_loss':  4615.1694, 'actor_loss':    -1.8820, 'eps_e':     0.1000})
Step:  492000, Reward:  -848.407 [ 593.077], Avg:  -858.577 (0.100) <0-01:48:47> ({'r_t': -3301.3337, 'eps':     0.1000, 'critic_loss':  4433.2412, 'actor_loss':    -2.1248, 'eps_e':     0.1000})
Step:  493000, Reward:  -637.570 [ 627.010], Avg:  -858.130 (0.100) <0-01:49:01> ({'r_t': -3951.5928, 'eps':     0.1000, 'critic_loss':  4620.4834, 'actor_loss':    -2.2682, 'eps_e':     0.1000})
Step:  494000, Reward: -1028.815 [ 641.483], Avg:  -858.474 (0.100) <0-01:49:15> ({'r_t': -3890.9707, 'eps':     0.1000, 'critic_loss':  4528.9810, 'actor_loss':    -1.9117, 'eps_e':     0.1000})
Step:  495000, Reward:  -926.016 [ 660.102], Avg:  -858.611 (0.100) <0-01:49:28> ({'r_t': -3803.5061, 'eps':     0.1000, 'critic_loss':  4563.6445, 'actor_loss':    -1.9612, 'eps_e':     0.1000})
Step:  496000, Reward:  -753.237 [ 590.882], Avg:  -858.399 (0.100) <0-01:49:42> ({'r_t': -3647.5694, 'eps':     0.1000, 'critic_loss':  4360.5757, 'actor_loss':    -1.7898, 'eps_e':     0.1000})
Step:  497000, Reward:  -814.084 [ 658.643], Avg:  -858.310 (0.100) <0-01:49:56> ({'r_t': -3751.3162, 'eps':     0.1000, 'critic_loss':  4401.6567, 'actor_loss':    -1.5980, 'eps_e':     0.1000})
Step:  498000, Reward:  -769.941 [ 613.115], Avg:  -858.132 (0.100) <0-01:50:09> ({'r_t': -4438.8232, 'eps':     0.1000, 'critic_loss':  4513.5547, 'actor_loss':    -1.6450, 'eps_e':     0.1000})
Step:  499000, Reward:  -859.040 [ 579.196], Avg:  -858.134 (0.100) <0-01:50:23> ({'r_t': -4247.8235, 'eps':     0.1000, 'critic_loss':  4557.9585, 'actor_loss':    -1.3446, 'eps_e':     0.1000})
Step:  500000, Reward:  -842.961 [ 680.692], Avg:  -858.104 (0.100) <0-01:50:36> ({'r_t': -3891.6008, 'eps':     0.1000, 'critic_loss':  4603.0439, 'actor_loss':    -1.6711, 'eps_e':     0.1000})
