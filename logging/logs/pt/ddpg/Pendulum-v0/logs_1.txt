Model: <class 'src.models.pytorch.agents.ddpg.DDPGAgent'>, Env: Pendulum-v0, Date: 07/06/2020 23:12:02
CPU: 20 Core, 0.0GHz, 377.59 GB, Linux-4.14.175-llgrid-10ms-x86_64-with-debian-buster-sid
GPU 0: Tesla V100-PCIE-32GB, 32.51 GB (Driver: 440.33.01)
Git URL: https://github.com/shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 3f3603c74c268cebd30d88bd58d2c7e5940054e4
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.98
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   dynamics_size = 3
   state_size = (3,)
   action_size = (1,)
   env_name = Pendulum-v0
   rank = 0
   size = 17
   split = 17
   model = ddpg
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f2b9bf75f98> 
	env = <GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>> 
		env = <TimeLimit<PendulumEnv<Pendulum-v0>>> 
			env = <PendulumEnv<Pendulum-v0>> 
				max_speed = 8
				max_torque = 2.0
				dt = 0.05
				g = 10.0
				m = 1.0
				l = 1.0
				viewer = None
				action_space = Box(1,) 
					dtype = float32
					shape = (1,)
					low = [-2.000]
					high = [ 2.000]
					bounded_below = [ True]
					bounded_above = [ True]
					np_random = RandomState(MT19937)
				observation_space = Box(3,) 
					dtype = float32
					shape = (3,)
					low = [-1.000 -1.000 -8.000]
					high = [ 1.000  1.000  8.000]
					bounded_below = [ True  True  True]
					bounded_above = [ True  True  True]
					np_random = RandomState(MT19937)
				np_random = RandomState(MT19937)
				spec = EnvSpec(Pendulum-v0) 
					id = Pendulum-v0
					entry_point = gym.envs.classic_control:PendulumEnv
					reward_threshold = None
					nondeterministic = False
					max_episode_steps = 200
				verbose = 0
			action_space = Box(1,) 
				dtype = float32
				shape = (1,)
				low = [-2.000]
				high = [ 2.000]
				bounded_below = [ True]
				bounded_above = [ True]
				np_random = RandomState(MT19937)
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		action_space = Box(1,) 
			dtype = float32
			shape = (1,)
			low = [-2.000]
			high = [ 2.000]
			bounded_below = [ True]
			bounded_above = [ True]
			np_random = RandomState(MT19937)
		observation_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -8.000]
			high = [ 1.000  1.000  8.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f2b9bf8aba8> 
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
	state_size = (3,)
	action_size = (1,)
	action_space = Box(1,) 
		dtype = float32
		shape = (1,)
		low = [-2.000]
		high = [ 2.000]
		bounded_below = [ True]
		bounded_above = [ True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.MPIConnection object at 0x7f2b9bed5278> 
		root = 0
		rank = 0
		cluster = <list len=16>
	num_envs = 16
	max_steps = 200,
agent: <src.models.wrappers.ParallelAgent object at 0x7f2b9bed52b0> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f2b9bee49e8> 
		state_size = (3,)
	agent = <src.models.pytorch.agents.ddpg.DDPGAgent object at 0x7f2b9bef8e10> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f2b9bef8e48> 
			size = (1,)
			dt = 0.2
			action = [ 0.527]
			daction_dt = [ 0.077]
		discrete = False
		action_size = (1,)
		state_size = (3,)
		config = <src.utils.config.Config object at 0x7f2b9c262c50> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.98
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			dynamics_size = 3
			state_size = (3,)
			action_size = (1,)
			env_name = Pendulum-v0
			rank = 0
			size = 17
			split = 17
			model = ddpg
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f2b9bef8e80> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = DDPGNetwork(
			  (actor_local): DDPGActor(
			    (layer1): Linear(in_features=3, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=1, bias=True)
			    (action_sig): Linear(in_features=256, out_features=1, bias=True)
			  )
			  (actor_target): DDPGActor(
			    (layer1): Linear(in_features=3, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=1, bias=True)
			    (action_sig): Linear(in_features=256, out_features=1, bias=True)
			  )
			  (critic_local): DDPGCritic(
			    (net_state): Linear(in_features=3, out_features=512, bias=True)
			    (net_action): Linear(in_features=1, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): DDPGCritic(
			    (net_state): Linear(in_features=3, out_features=512, bias=True)
			    (net_action): Linear(in_features=1, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = ddpg
			stats = <src.utils.logger.Stats object at 0x7f2b9bef8ef0> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f2b9c262c50> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.98
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 1000000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				dynamics_size = 3
				state_size = (3,)
				action_size = (1,)
				env_name = Pendulum-v0
				rank = 0
				size = 17
				split = 17
				model = ddpg
				framework = pt
				train_prop = 1.0
				tcp_ports = []
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class DDPGActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, sample=True):\n\t\tstate = self.layer1(state).relu() \n\t\tstate = self.layer2(state).relu() \n\t\tstate = self.layer3(state).relu() \n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).exp()\n\t\tepsilon = torch.randn_like(action_sig)\n\t\taction = action_mu + epsilon.mul(action_sig) if sample else action_mu\n\t\treturn action.tanh() if not self.discrete else gsoftmax(action)\n', 'class DDPGCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f2b9befb630> 
			buffer = deque([], maxlen=1000000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f2b9befb668> 
		size = (1,)
		dt = 0.2
		action = [-0.849]
		daction_dt = [ 1.427]
	discrete = False
	action_size = (1,)
	state_size = (3,)
	config = <src.utils.config.Config object at 0x7f2b9c262c50> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.98
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		dynamics_size = 3
		state_size = (3,)
		action_size = (1,)
		env_name = Pendulum-v0
		rank = 0
		size = 17
		split = 17
		model = ddpg
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f2b9befb6a0> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import random
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax, one_hot
from src.utils.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh() if not self.discrete else gsoftmax(action)
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=DDPGActor, critic=DDPGCritic, gpu=True, load=None, name="ddpg"): 
		self.discrete = type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)

	def get_action(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			q_value = q_value.gather(-1, action.argmax(-1, keepdim=True)) if self.discrete and not probs else q_value
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, q_targets):
		actions = one_hot(actions) if self.actor_local.discrete else actions
		q_values = self.get_q_value(states, actions, grad=True, probs=False)
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True, probs=True)
		q_actions = (actor_action*q_actions).sum(-1) if self.discrete else q_actions
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = -(q_actions - q_baseline.detach()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		self.soft_copy(self.actor_local, self.actor_target)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)
		
class DDPGAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, DDPGNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if self.discrete and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), numpy=True, sample=sample)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			actions = torch.cat([actions, self.network.get_action(states[-1], use_target=True).unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets)
			if np.any(done[0]): self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward: -1516.297 [ 293.712], Avg: -1516.297 (1.000) <0-00:00:00> ({'r_t':    -2.2129, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward: -1357.798 [ 124.481], Avg: -1437.047 (0.904) <0-00:00:09> ({'r_t': -6141.3456, 'eps':     0.9039, 'critic_loss':  1051.2671, 'actor_loss':    -0.1996, 'eps_e':     0.9039})
Step:    2000, Reward: -1300.580 [ 243.207], Avg: -1391.558 (0.817) <0-00:00:20> ({'r_t': -6115.4118, 'eps':     0.8171, 'critic_loss':   509.2815, 'actor_loss':    -0.5919, 'eps_e':     0.8171})
Step:    3000, Reward: -1328.536 [ 184.573], Avg: -1375.803 (0.739) <0-00:00:29> ({'r_t': -6129.5845, 'eps':     0.7386, 'critic_loss':   491.1013, 'actor_loss':    -0.7688, 'eps_e':     0.7386})
Step:    4000, Reward: -1074.701 [  92.294], Avg: -1315.582 (0.668) <0-00:00:37> ({'r_t': -6046.7364, 'eps':     0.6676, 'critic_loss':   556.4412, 'actor_loss':    -0.6103, 'eps_e':     0.6676})
Step:    5000, Reward: -1375.078 [ 228.778], Avg: -1325.498 (0.603) <0-00:00:46> ({'r_t': -5927.9077, 'eps':     0.6035, 'critic_loss':   644.5659, 'actor_loss':    -0.6761, 'eps_e':     0.6035})
Step:    6000, Reward: -1476.092 [ 177.150], Avg: -1347.012 (0.545) <0-00:00:54> ({'r_t': -6345.3156, 'eps':     0.5455, 'critic_loss':   832.6781, 'actor_loss':    -2.0350, 'eps_e':     0.5455})
Step:    7000, Reward: -1340.999 [ 262.653], Avg: -1346.260 (0.493) <0-00:01:03> ({'r_t': -6527.1798, 'eps':     0.4931, 'critic_loss':  1062.1732, 'actor_loss':    -0.0076, 'eps_e':     0.4931})
Step:    8000, Reward: -1085.094 [ 338.951], Avg: -1317.242 (0.446) <0-00:01:11> ({'r_t': -6800.7108, 'eps':     0.4457, 'critic_loss':  1294.6642, 'actor_loss':     4.4966, 'eps_e':     0.4457})
Step:    9000, Reward: -1415.160 [ 204.240], Avg: -1327.034 (0.403) <0-00:01:20> ({'r_t': -6797.9285, 'eps':     0.4029, 'critic_loss':  1535.7125, 'actor_loss':   -13.9865, 'eps_e':     0.4029})
Step:   10000, Reward: -1423.056 [ 202.590], Avg: -1335.763 (0.364) <0-00:01:29> ({'r_t': -6970.4519, 'eps':     0.3642, 'critic_loss':  1792.5106, 'actor_loss':    -4.3145, 'eps_e':     0.3642})
Step:   11000, Reward: -1481.889 [ 132.268], Avg: -1347.940 (0.329) <0-00:01:37> ({'r_t': -6915.5547, 'eps':     0.3292, 'critic_loss':  1940.1222, 'actor_loss':     2.6084, 'eps_e':     0.3292})
Step:   12000, Reward: -1430.996 [ 179.265], Avg: -1354.329 (0.298) <0-00:01:45> ({'r_t': -7014.6580, 'eps':     0.2976, 'critic_loss':  2096.5149, 'actor_loss':     6.8225, 'eps_e':     0.2976})
Step:   13000, Reward: -1378.879 [ 202.587], Avg: -1356.082 (0.269) <0-00:01:54> ({'r_t': -7089.4909, 'eps':     0.2690, 'critic_loss':  2187.5349, 'actor_loss':    10.4321, 'eps_e':     0.2690})
Step:   14000, Reward: -1424.177 [ 191.775], Avg: -1360.622 (0.243) <0-00:02:03> ({'r_t': -7082.3490, 'eps':     0.2431, 'critic_loss':  2386.5266, 'actor_loss':    12.6893, 'eps_e':     0.2431})
Step:   15000, Reward: -1464.398 [ 164.533], Avg: -1367.108 (0.220) <0-00:02:11> ({'r_t': -7097.6942, 'eps':     0.2198, 'critic_loss':  2508.8621, 'actor_loss':    15.5328, 'eps_e':     0.2198})
Step:   16000, Reward: -1339.361 [ 160.310], Avg: -1365.476 (0.199) <0-00:02:20> ({'r_t': -6934.3007, 'eps':     0.1986, 'critic_loss':  2598.9775, 'actor_loss':    17.1871, 'eps_e':     0.1986})
Step:   17000, Reward: -1412.506 [ 166.680], Avg: -1368.089 (0.180) <0-00:02:28> ({'r_t': -7030.9007, 'eps':     0.1796, 'critic_loss':  2699.8201, 'actor_loss':    18.9386, 'eps_e':     0.1796})
Step:   18000, Reward:  -993.051 [ 312.651], Avg: -1348.350 (0.162) <0-00:02:36> ({'r_t': -6890.0738, 'eps':     0.1623, 'critic_loss':  2874.6396, 'actor_loss':    -0.2540, 'eps_e':     0.1623})
Step:   19000, Reward: -1191.643 [ 153.015], Avg: -1340.515 (0.147) <0-00:02:45> ({'r_t': -6147.3545, 'eps':     0.1467, 'critic_loss':  2973.5317, 'actor_loss':   -51.8147, 'eps_e':     0.1467})
Step:   20000, Reward: -1220.782 [ 147.865], Avg: -1334.813 (0.133) <0-00:02:53> ({'r_t': -5976.0138, 'eps':     0.1326, 'critic_loss':  3074.3293, 'actor_loss':   -46.1831, 'eps_e':     0.1326})
Step:   21000, Reward: -1215.750 [  59.038], Avg: -1329.401 (0.120) <0-00:03:02> ({'r_t': -6148.3439, 'eps':     0.1199, 'critic_loss':  3019.8513, 'actor_loss':   -40.0543, 'eps_e':     0.1199})
Step:   22000, Reward: -1165.159 [  12.938], Avg: -1322.260 (0.108) <0-00:03:10> ({'r_t': -6183.6498, 'eps':     0.1084, 'critic_loss':  3031.9900, 'actor_loss':   -34.7594, 'eps_e':     0.1084})
Step:   23000, Reward: -1090.187 [ 279.557], Avg: -1312.590 (0.100) <0-00:03:19> ({'r_t': -5328.6438, 'eps':     0.1000, 'critic_loss':  3087.4595, 'actor_loss':   -31.2511, 'eps_e':     0.1000})
Step:   24000, Reward: -1025.495 [ 182.491], Avg: -1301.107 (0.100) <0-00:03:27> ({'r_t': -5140.4896, 'eps':     0.1000, 'critic_loss':  2971.7793, 'actor_loss':   -29.5609, 'eps_e':     0.1000})
Step:   25000, Reward: -1008.784 [ 121.856], Avg: -1289.863 (0.100) <0-00:03:36> ({'r_t': -4840.6641, 'eps':     0.1000, 'critic_loss':  2991.0928, 'actor_loss':   -27.1886, 'eps_e':     0.1000})
Step:   26000, Reward:  -675.294 [ 155.922], Avg: -1267.102 (0.100) <0-00:03:44> ({'r_t': -4002.4668, 'eps':     0.1000, 'critic_loss':  2953.0493, 'actor_loss':   -26.2365, 'eps_e':     0.1000})
Step:   27000, Reward:  -831.004 [ 102.136], Avg: -1251.527 (0.100) <0-00:03:53> ({'r_t': -3569.0959, 'eps':     0.1000, 'critic_loss':  2913.6052, 'actor_loss':   -25.6497, 'eps_e':     0.1000})
Step:   28000, Reward:  -721.674 [ 109.268], Avg: -1233.256 (0.100) <0-00:04:01> ({'r_t': -3687.4765, 'eps':     0.1000, 'critic_loss':  2852.7827, 'actor_loss':   -24.9361, 'eps_e':     0.1000})
Step:   29000, Reward:  -996.591 [  76.044], Avg: -1225.367 (0.100) <0-00:04:10> ({'r_t': -4493.7033, 'eps':     0.1000, 'critic_loss':  2778.5791, 'actor_loss':   -24.5121, 'eps_e':     0.1000})
Step:   30000, Reward: -1138.637 [  65.901], Avg: -1222.569 (0.100) <0-00:04:18> ({'r_t': -5272.9058, 'eps':     0.1000, 'critic_loss':  2789.0679, 'actor_loss':   -23.7532, 'eps_e':     0.1000})
Step:   31000, Reward: -1265.688 [  94.802], Avg: -1223.917 (0.100) <0-00:04:27> ({'r_t': -5994.7245, 'eps':     0.1000, 'critic_loss':  2761.9358, 'actor_loss':   -23.6755, 'eps_e':     0.1000})
Step:   32000, Reward:  -673.489 [ 523.034], Avg: -1207.237 (0.100) <0-00:04:40> ({'r_t': -5698.6871, 'eps':     0.1000, 'critic_loss':  2830.3210, 'actor_loss':   -22.6233, 'eps_e':     0.1000})
Step:   33000, Reward:  -841.413 [ 287.476], Avg: -1196.478 (0.100) <0-00:04:49> ({'r_t': -4042.6087, 'eps':     0.1000, 'critic_loss':  2798.0710, 'actor_loss':   -22.1492, 'eps_e':     0.1000})
Step:   34000, Reward:  -740.108 [  87.034], Avg: -1183.438 (0.100) <0-00:04:57> ({'r_t': -3766.4819, 'eps':     0.1000, 'critic_loss':  2813.7253, 'actor_loss':   -21.7635, 'eps_e':     0.1000})
Step:   35000, Reward:  -643.685 [  67.225], Avg: -1168.445 (0.100) <0-00:05:16> ({'r_t': -2931.8401, 'eps':     0.1000, 'critic_loss':  2790.8665, 'actor_loss':   -21.5616, 'eps_e':     0.1000})
Step:   36000, Reward: -1110.553 [ 373.045], Avg: -1166.881 (0.100) <0-00:05:25> ({'r_t': -2540.2552, 'eps':     0.1000, 'critic_loss':  2682.2039, 'actor_loss':   -21.3687, 'eps_e':     0.1000})
Step:   37000, Reward:  -734.392 [ 126.391], Avg: -1155.499 (0.100) <0-00:05:34> ({'r_t': -3336.9705, 'eps':     0.1000, 'critic_loss':  2709.4692, 'actor_loss':   -20.6067, 'eps_e':     0.1000})
Step:   38000, Reward:  -279.850 [ 184.551], Avg: -1133.047 (0.100) <0-00:05:43> ({'r_t': -2769.4833, 'eps':     0.1000, 'critic_loss':  2633.8450, 'actor_loss':   -21.2726, 'eps_e':     0.1000})
Step:   39000, Reward:  -300.493 [ 205.168], Avg: -1112.233 (0.100) <0-00:05:51> ({'r_t': -2355.3013, 'eps':     0.1000, 'critic_loss':  2609.4939, 'actor_loss':   -20.8810, 'eps_e':     0.1000})
Step:   40000, Reward:  -925.035 [ 148.069], Avg: -1107.667 (0.100) <0-00:06:00> ({'r_t': -2485.8836, 'eps':     0.1000, 'critic_loss':  2574.7710, 'actor_loss':   -20.2279, 'eps_e':     0.1000})
Step:   41000, Reward:  -748.253 [ 185.896], Avg: -1099.110 (0.100) <0-00:06:09> ({'r_t': -3882.4918, 'eps':     0.1000, 'critic_loss':  2532.1560, 'actor_loss':   -19.6048, 'eps_e':     0.1000})
Step:   42000, Reward:  -612.009 [  91.525], Avg: -1087.782 (0.100) <0-00:06:18> ({'r_t': -3612.2834, 'eps':     0.1000, 'critic_loss':  2536.6604, 'actor_loss':   -18.9828, 'eps_e':     0.1000})
Step:   43000, Reward:  -612.456 [ 159.336], Avg: -1076.979 (0.100) <0-00:06:26> ({'r_t': -3533.2928, 'eps':     0.1000, 'critic_loss':  2491.2805, 'actor_loss':   -18.2772, 'eps_e':     0.1000})
Step:   44000, Reward:  -349.319 [  96.495], Avg: -1060.809 (0.100) <0-00:06:35> ({'r_t': -3013.5164, 'eps':     0.1000, 'critic_loss':  2487.8247, 'actor_loss':   -17.9048, 'eps_e':     0.1000})
Step:   45000, Reward:  -182.207 [ 188.298], Avg: -1041.709 (0.100) <0-00:06:44> ({'r_t': -1617.3034, 'eps':     0.1000, 'critic_loss':  2449.7805, 'actor_loss':   -18.4606, 'eps_e':     0.1000})
Step:   46000, Reward:  -248.205 [ 153.778], Avg: -1024.826 (0.100) <0-00:06:53> ({'r_t': -1317.5149, 'eps':     0.1000, 'critic_loss':  2344.7290, 'actor_loss':   -18.2237, 'eps_e':     0.1000})
Step:   47000, Reward:  -277.928 [ 162.971], Avg: -1009.265 (0.100) <0-00:07:02> ({'r_t': -1312.7592, 'eps':     0.1000, 'critic_loss':  2427.1077, 'actor_loss':   -17.8892, 'eps_e':     0.1000})
Step:   48000, Reward:  -276.039 [ 140.200], Avg:  -994.301 (0.100) <0-00:07:11> ({'r_t': -1332.4017, 'eps':     0.1000, 'critic_loss':  2354.7205, 'actor_loss':   -16.8008, 'eps_e':     0.1000})
Step:   49000, Reward:  -274.420 [ 205.764], Avg:  -979.904 (0.100) <0-00:07:20> ({'r_t': -1755.7711, 'eps':     0.1000, 'critic_loss':  2245.6606, 'actor_loss':   -16.4053, 'eps_e':     0.1000})
Step:   50000, Reward:  -352.018 [ 242.309], Avg:  -967.592 (0.100) <0-00:07:29> ({'r_t': -2133.1892, 'eps':     0.1000, 'critic_loss':  2243.9290, 'actor_loss':   -16.3558, 'eps_e':     0.1000})
Step:   51000, Reward:  -510.477 [ 232.249], Avg:  -958.802 (0.100) <0-00:07:38> ({'r_t': -1558.5445, 'eps':     0.1000, 'critic_loss':  2221.8889, 'actor_loss':   -16.8946, 'eps_e':     0.1000})
Step:   52000, Reward:  -173.171 [ 121.992], Avg:  -943.978 (0.100) <0-00:07:47> ({'r_t': -1310.1724, 'eps':     0.1000, 'critic_loss':  2244.5369, 'actor_loss':   -16.3780, 'eps_e':     0.1000})
Step:   53000, Reward:  -260.251 [ 155.058], Avg:  -931.317 (0.100) <0-00:07:56> ({'r_t': -1036.4999, 'eps':     0.1000, 'critic_loss':  2150.3789, 'actor_loss':   -15.9797, 'eps_e':     0.1000})
Step:   54000, Reward:  -214.306 [ 160.519], Avg:  -918.280 (0.100) <0-00:08:05> ({'r_t': -1296.4984, 'eps':     0.1000, 'critic_loss':  2099.4629, 'actor_loss':   -15.7884, 'eps_e':     0.1000})
Step:   55000, Reward:  -468.375 [ 346.242], Avg:  -910.246 (0.100) <0-00:08:14> ({'r_t': -1605.8599, 'eps':     0.1000, 'critic_loss':  2071.4495, 'actor_loss':   -15.6101, 'eps_e':     0.1000})
Step:   56000, Reward:  -226.069 [ 266.861], Avg:  -898.243 (0.100) <0-00:08:24> ({'r_t': -1423.6433, 'eps':     0.1000, 'critic_loss':  2018.6261, 'actor_loss':   -15.8946, 'eps_e':     0.1000})
Step:   57000, Reward:  -297.008 [ 200.565], Avg:  -887.877 (0.100) <0-00:08:33> ({'r_t': -1775.7429, 'eps':     0.1000, 'critic_loss':  2056.7339, 'actor_loss':   -16.0607, 'eps_e':     0.1000})
Step:   58000, Reward:  -627.307 [ 499.438], Avg:  -883.461 (0.100) <0-00:08:42> ({'r_t': -1189.5934, 'eps':     0.1000, 'critic_loss':  2006.9901, 'actor_loss':   -15.5112, 'eps_e':     0.1000})
Step:   59000, Reward:  -163.431 [ 102.995], Avg:  -871.460 (0.100) <0-00:08:51> ({'r_t': -1386.1885, 'eps':     0.1000, 'critic_loss':  1969.8297, 'actor_loss':   -15.6356, 'eps_e':     0.1000})
Step:   60000, Reward:  -199.723 [ 104.859], Avg:  -860.448 (0.100) <0-00:09:00> ({'r_t': -1111.3431, 'eps':     0.1000, 'critic_loss':  1941.1919, 'actor_loss':   -15.5092, 'eps_e':     0.1000})
Step:   61000, Reward:  -224.971 [ 118.138], Avg:  -850.198 (0.100) <0-00:09:10> ({'r_t': -1211.0833, 'eps':     0.1000, 'critic_loss':  1922.8557, 'actor_loss':   -15.1739, 'eps_e':     0.1000})
Step:   62000, Reward:  -290.337 [ 228.259], Avg:  -841.312 (0.100) <0-00:09:19> ({'r_t': -1210.7472, 'eps':     0.1000, 'critic_loss':  1859.9252, 'actor_loss':   -15.4665, 'eps_e':     0.1000})
Step:   63000, Reward:  -203.471 [ 240.783], Avg:  -831.345 (0.100) <0-00:09:28> ({'r_t': -1516.7143, 'eps':     0.1000, 'critic_loss':  1819.8285, 'actor_loss':   -14.8461, 'eps_e':     0.1000})
Step:   64000, Reward:  -271.126 [ 261.911], Avg:  -822.727 (0.100) <0-00:09:37> ({'r_t': -1830.6636, 'eps':     0.1000, 'critic_loss':  1740.4662, 'actor_loss':   -15.4584, 'eps_e':     0.1000})
Step:   65000, Reward:  -235.089 [ 282.754], Avg:  -813.823 (0.100) <0-00:09:47> ({'r_t': -1429.7167, 'eps':     0.1000, 'critic_loss':  1645.3170, 'actor_loss':   -13.9622, 'eps_e':     0.1000})
Step:   66000, Reward:  -151.704 [ 154.471], Avg:  -803.941 (0.100) <0-00:09:59> ({'r_t': -1212.9902, 'eps':     0.1000, 'critic_loss':  1521.9950, 'actor_loss':   -13.9922, 'eps_e':     0.1000})
Step:   67000, Reward:  -152.367 [ 123.180], Avg:  -794.359 (0.100) <0-00:10:08> ({'r_t': -1005.0703, 'eps':     0.1000, 'critic_loss':  1424.8309, 'actor_loss':   -13.2872, 'eps_e':     0.1000})
Step:   68000, Reward:  -204.025 [ 120.541], Avg:  -785.803 (0.100) <0-00:10:18> ({'r_t':  -883.6691, 'eps':     0.1000, 'critic_loss':  1343.5746, 'actor_loss':   -13.3255, 'eps_e':     0.1000})
Step:   69000, Reward:  -254.793 [ 137.254], Avg:  -778.217 (0.100) <0-00:10:27> ({'r_t':  -920.4920, 'eps':     0.1000, 'critic_loss':  1280.8995, 'actor_loss':   -13.6931, 'eps_e':     0.1000})
Step:   70000, Reward:  -180.633 [ 143.396], Avg:  -769.801 (0.100) <0-00:10:36> ({'r_t': -1029.3746, 'eps':     0.1000, 'critic_loss':  1222.2520, 'actor_loss':   -12.8862, 'eps_e':     0.1000})
Step:   71000, Reward:  -178.852 [ 119.953], Avg:  -761.593 (0.100) <0-00:10:45> ({'r_t':  -982.5171, 'eps':     0.1000, 'critic_loss':  1198.1895, 'actor_loss':   -12.9386, 'eps_e':     0.1000})
Step:   72000, Reward:  -106.939 [  55.725], Avg:  -752.625 (0.100) <0-00:10:54> ({'r_t':  -907.7072, 'eps':     0.1000, 'critic_loss':  1063.8683, 'actor_loss':   -12.7240, 'eps_e':     0.1000})
Step:   73000, Reward:  -189.118 [  80.020], Avg:  -745.010 (0.100) <0-00:11:04> ({'r_t':  -893.7946, 'eps':     0.1000, 'critic_loss':  1085.0573, 'actor_loss':   -12.2798, 'eps_e':     0.1000})
Step:   74000, Reward:  -173.467 [  80.129], Avg:  -737.390 (0.100) <0-00:11:13> ({'r_t':  -872.2305, 'eps':     0.1000, 'critic_loss':   985.9343, 'actor_loss':   -11.5971, 'eps_e':     0.1000})
Step:   75000, Reward:  -178.959 [  96.944], Avg:  -730.042 (0.100) <0-00:11:22> ({'r_t':  -835.4924, 'eps':     0.1000, 'critic_loss':   993.3845, 'actor_loss':   -11.2631, 'eps_e':     0.1000})
Step:   76000, Reward:  -125.606 [  57.973], Avg:  -722.192 (0.100) <0-00:11:31> ({'r_t':  -839.7218, 'eps':     0.1000, 'critic_loss':   952.6224, 'actor_loss':   -10.8120, 'eps_e':     0.1000})
Step:   77000, Reward:  -150.328 [ 106.023], Avg:  -714.860 (0.100) <0-00:11:41> ({'r_t':  -876.8952, 'eps':     0.1000, 'critic_loss':   904.3594, 'actor_loss':    -9.8327, 'eps_e':     0.1000})
Step:   78000, Reward:  -144.718 [  93.849], Avg:  -707.643 (0.100) <0-00:11:50> ({'r_t':  -918.8051, 'eps':     0.1000, 'critic_loss':   819.7610, 'actor_loss':    -9.0842, 'eps_e':     0.1000})
Step:   79000, Reward:  -154.078 [  95.762], Avg:  -700.724 (0.100) <0-00:11:59> ({'r_t':  -912.2201, 'eps':     0.1000, 'critic_loss':   809.1567, 'actor_loss':    -8.2522, 'eps_e':     0.1000})
Step:   80000, Reward:  -201.943 [ 114.408], Avg:  -694.566 (0.100) <0-00:12:09> ({'r_t':  -849.0120, 'eps':     0.1000, 'critic_loss':   771.7061, 'actor_loss':    -7.2542, 'eps_e':     0.1000})
Step:   81000, Reward:  -186.335 [ 114.325], Avg:  -688.368 (0.100) <0-00:12:18> ({'r_t':  -962.9549, 'eps':     0.1000, 'critic_loss':   732.9069, 'actor_loss':    -6.6115, 'eps_e':     0.1000})
Step:   82000, Reward:  -157.428 [ 127.662], Avg:  -681.971 (0.100) <0-00:12:27> ({'r_t':  -870.2088, 'eps':     0.1000, 'critic_loss':   661.4374, 'actor_loss':    -6.5912, 'eps_e':     0.1000})
Step:   83000, Reward:  -140.900 [  72.841], Avg:  -675.530 (0.100) <0-00:12:36> ({'r_t':  -885.8030, 'eps':     0.1000, 'critic_loss':   639.0105, 'actor_loss':    -6.6045, 'eps_e':     0.1000})
Step:   84000, Reward:  -153.421 [ 114.269], Avg:  -669.387 (0.100) <0-00:12:46> ({'r_t':  -940.3337, 'eps':     0.1000, 'critic_loss':   649.2095, 'actor_loss':    -6.7081, 'eps_e':     0.1000})
Step:   85000, Reward:  -222.952 [ 117.147], Avg:  -664.196 (0.100) <0-00:12:55> ({'r_t':  -842.6137, 'eps':     0.1000, 'critic_loss':   613.3456, 'actor_loss':    -6.5631, 'eps_e':     0.1000})
Step:   86000, Reward:  -152.326 [  94.221], Avg:  -658.313 (0.100) <0-00:13:04> ({'r_t':  -891.8507, 'eps':     0.1000, 'critic_loss':   579.8336, 'actor_loss':    -6.8263, 'eps_e':     0.1000})
Step:   87000, Reward:  -128.524 [  92.919], Avg:  -652.292 (0.100) <0-00:13:14> ({'r_t':  -766.8727, 'eps':     0.1000, 'critic_loss':   582.9689, 'actor_loss':    -6.8558, 'eps_e':     0.1000})
Step:   88000, Reward:  -194.525 [  97.819], Avg:  -647.149 (0.100) <0-00:13:23> ({'r_t':  -814.4051, 'eps':     0.1000, 'critic_loss':   572.7964, 'actor_loss':    -6.9703, 'eps_e':     0.1000})
Step:   89000, Reward:  -200.545 [ 112.178], Avg:  -642.187 (0.100) <0-00:13:33> ({'r_t':  -750.9541, 'eps':     0.1000, 'critic_loss':   521.1284, 'actor_loss':    -7.1346, 'eps_e':     0.1000})
Step:   90000, Reward:  -216.379 [ 123.919], Avg:  -637.508 (0.100) <0-00:13:42> ({'r_t':  -823.5947, 'eps':     0.1000, 'critic_loss':   533.4580, 'actor_loss':    -7.2192, 'eps_e':     0.1000})
Step:   91000, Reward:  -172.374 [ 103.127], Avg:  -632.452 (0.100) <0-00:13:51> ({'r_t':  -906.1965, 'eps':     0.1000, 'critic_loss':   497.9243, 'actor_loss':    -6.9735, 'eps_e':     0.1000})
Step:   92000, Reward:  -165.841 [  99.869], Avg:  -627.434 (0.100) <0-00:14:01> ({'r_t':  -867.2151, 'eps':     0.1000, 'critic_loss':   510.0436, 'actor_loss':    -6.6218, 'eps_e':     0.1000})
Step:   93000, Reward:  -250.524 [ 204.083], Avg:  -623.425 (0.100) <0-00:14:10> ({'r_t':  -865.6802, 'eps':     0.1000, 'critic_loss':   449.5757, 'actor_loss':    -6.9814, 'eps_e':     0.1000})
Step:   94000, Reward:  -169.551 [ 121.181], Avg:  -618.647 (0.100) <0-00:14:19> ({'r_t': -1150.6213, 'eps':     0.1000, 'critic_loss':   437.0383, 'actor_loss':    -6.6783, 'eps_e':     0.1000})
Step:   95000, Reward:  -207.036 [ 177.238], Avg:  -614.360 (0.100) <0-00:14:29> ({'r_t':  -937.1891, 'eps':     0.1000, 'critic_loss':   398.6567, 'actor_loss':    -6.5327, 'eps_e':     0.1000})
Step:   96000, Reward:  -232.361 [ 205.715], Avg:  -610.421 (0.100) <0-00:14:38> ({'r_t':  -991.7691, 'eps':     0.1000, 'critic_loss':   368.9786, 'actor_loss':    -6.1648, 'eps_e':     0.1000})
Step:   97000, Reward:  -185.716 [ 118.428], Avg:  -606.088 (0.100) <0-00:14:48> ({'r_t':  -834.7109, 'eps':     0.1000, 'critic_loss':   343.3801, 'actor_loss':    -6.5113, 'eps_e':     0.1000})
Step:   98000, Reward:  -188.815 [ 222.159], Avg:  -601.873 (0.100) <0-00:14:57> ({'r_t':  -962.1544, 'eps':     0.1000, 'critic_loss':   353.0582, 'actor_loss':    -6.4789, 'eps_e':     0.1000})
Step:   99000, Reward:  -323.630 [ 275.374], Avg:  -599.090 (0.100) <0-00:15:06> ({'r_t': -1815.9779, 'eps':     0.1000, 'critic_loss':   325.5256, 'actor_loss':    -6.3951, 'eps_e':     0.1000})
Step:  100000, Reward:  -399.141 [ 386.218], Avg:  -597.111 (0.100) <0-00:15:16> ({'r_t': -1941.3855, 'eps':     0.1000, 'critic_loss':   322.6806, 'actor_loss':    -6.4767, 'eps_e':     0.1000})
Step:  101000, Reward:  -207.188 [ 134.451], Avg:  -593.288 (0.100) <0-00:15:25> ({'r_t': -1111.5629, 'eps':     0.1000, 'critic_loss':   320.8610, 'actor_loss':    -6.4133, 'eps_e':     0.1000})
Step:  102000, Reward:  -200.668 [  97.870], Avg:  -589.476 (0.100) <0-00:15:35> ({'r_t': -1052.6379, 'eps':     0.1000, 'critic_loss':   297.1937, 'actor_loss':    -6.8762, 'eps_e':     0.1000})
Step:  103000, Reward:  -201.602 [  87.206], Avg:  -585.746 (0.100) <0-00:15:44> ({'r_t':  -994.2811, 'eps':     0.1000, 'critic_loss':   296.3346, 'actor_loss':    -7.9269, 'eps_e':     0.1000})
Step:  104000, Reward:  -177.784 [ 109.613], Avg:  -581.861 (0.100) <0-00:15:53> ({'r_t': -1196.5181, 'eps':     0.1000, 'critic_loss':   265.3120, 'actor_loss':    -7.4003, 'eps_e':     0.1000})
Step:  105000, Reward:  -318.326 [ 385.499], Avg:  -579.375 (0.100) <0-00:16:03> ({'r_t': -1709.7109, 'eps':     0.1000, 'critic_loss':   241.6324, 'actor_loss':    -7.5897, 'eps_e':     0.1000})
Step:  106000, Reward:  -618.055 [ 459.488], Avg:  -579.736 (0.100) <0-00:16:12> ({'r_t': -2642.0945, 'eps':     0.1000, 'critic_loss':   237.1496, 'actor_loss':    -8.0049, 'eps_e':     0.1000})
Step:  107000, Reward:  -189.991 [ 103.367], Avg:  -576.128 (0.100) <0-00:16:22> ({'r_t': -2466.1976, 'eps':     0.1000, 'critic_loss':   221.5578, 'actor_loss':    -7.2171, 'eps_e':     0.1000})
Step:  108000, Reward:  -231.058 [ 178.524], Avg:  -572.962 (0.100) <0-00:16:31> ({'r_t': -1212.8942, 'eps':     0.1000, 'critic_loss':   225.0805, 'actor_loss':    -8.0993, 'eps_e':     0.1000})
Step:  109000, Reward:  -177.213 [  88.552], Avg:  -569.364 (0.100) <0-00:16:40> ({'r_t':  -898.4238, 'eps':     0.1000, 'critic_loss':   226.4437, 'actor_loss':    -8.8893, 'eps_e':     0.1000})
Step:  110000, Reward:  -186.737 [ 175.192], Avg:  -565.917 (0.100) <0-00:16:50> ({'r_t':  -910.9057, 'eps':     0.1000, 'critic_loss':   209.9125, 'actor_loss':   -10.2729, 'eps_e':     0.1000})
Step:  111000, Reward:  -135.057 [  35.489], Avg:  -562.070 (0.100) <0-00:16:59> ({'r_t':  -828.1744, 'eps':     0.1000, 'critic_loss':   197.6531, 'actor_loss':   -12.0520, 'eps_e':     0.1000})
Step:  112000, Reward:  -215.301 [ 108.546], Avg:  -559.001 (0.100) <0-00:17:09> ({'r_t':  -856.7519, 'eps':     0.1000, 'critic_loss':   202.7732, 'actor_loss':   -12.1275, 'eps_e':     0.1000})
Step:  113000, Reward:  -137.263 [ 102.137], Avg:  -555.302 (0.100) <0-00:17:18> ({'r_t':  -834.1411, 'eps':     0.1000, 'critic_loss':   185.6310, 'actor_loss':   -12.2279, 'eps_e':     0.1000})
Step:  114000, Reward:  -169.672 [  86.339], Avg:  -551.949 (0.100) <0-00:17:27> ({'r_t':  -834.4704, 'eps':     0.1000, 'critic_loss':   178.1907, 'actor_loss':   -12.0090, 'eps_e':     0.1000})
Step:  115000, Reward:  -163.496 [ 129.191], Avg:  -548.600 (0.100) <0-00:17:37> ({'r_t':  -951.4419, 'eps':     0.1000, 'critic_loss':   175.8946, 'actor_loss':   -12.4746, 'eps_e':     0.1000})
Step:  116000, Reward:  -177.191 [ 115.091], Avg:  -545.425 (0.100) <0-00:17:46> ({'r_t': -1016.5931, 'eps':     0.1000, 'critic_loss':   183.3615, 'actor_loss':   -12.7493, 'eps_e':     0.1000})
Step:  117000, Reward:  -281.733 [ 201.363], Avg:  -543.191 (0.100) <0-00:17:55> ({'r_t':  -831.7983, 'eps':     0.1000, 'critic_loss':   169.0468, 'actor_loss':   -12.6904, 'eps_e':     0.1000})
Step:  118000, Reward:  -143.452 [  71.255], Avg:  -539.832 (0.100) <0-00:18:05> ({'r_t':  -823.4539, 'eps':     0.1000, 'critic_loss':   163.6218, 'actor_loss':   -11.9874, 'eps_e':     0.1000})
Step:  119000, Reward:  -183.105 [ 102.130], Avg:  -536.859 (0.100) <0-00:18:14> ({'r_t':  -769.7617, 'eps':     0.1000, 'critic_loss':   172.2953, 'actor_loss':   -12.6127, 'eps_e':     0.1000})
Step:  120000, Reward:  -742.462 [ 486.984], Avg:  -538.558 (0.100) <0-00:18:23> ({'r_t':  -871.3577, 'eps':     0.1000, 'critic_loss':   161.0452, 'actor_loss':   -11.3912, 'eps_e':     0.1000})
Step:  121000, Reward:  -219.405 [ 154.107], Avg:  -535.942 (0.100) <0-00:18:32> ({'r_t':  -942.9748, 'eps':     0.1000, 'critic_loss':   168.4515, 'actor_loss':   -10.7374, 'eps_e':     0.1000})
Step:  122000, Reward:  -137.818 [  61.074], Avg:  -532.705 (0.100) <0-00:18:42> ({'r_t':  -860.9801, 'eps':     0.1000, 'critic_loss':   158.6335, 'actor_loss':    -9.9944, 'eps_e':     0.1000})
Step:  123000, Reward:  -159.729 [  86.688], Avg:  -529.697 (0.100) <0-00:18:51> ({'r_t':  -807.4817, 'eps':     0.1000, 'critic_loss':   173.1486, 'actor_loss':    -9.2506, 'eps_e':     0.1000})
Step:  124000, Reward:  -226.215 [ 144.214], Avg:  -527.270 (0.100) <0-00:19:00> ({'r_t':  -888.2866, 'eps':     0.1000, 'critic_loss':   160.8068, 'actor_loss':    -9.1399, 'eps_e':     0.1000})
Step:  125000, Reward:  -493.281 [ 122.872], Avg:  -527.000 (0.100) <0-00:19:10> ({'r_t': -1686.7413, 'eps':     0.1000, 'critic_loss':   169.6016, 'actor_loss':    -9.0309, 'eps_e':     0.1000})
Step:  126000, Reward:  -320.241 [ 116.173], Avg:  -525.372 (0.100) <0-00:19:19> ({'r_t': -2620.4286, 'eps':     0.1000, 'critic_loss':   178.5717, 'actor_loss':    -8.0610, 'eps_e':     0.1000})
Step:  127000, Reward:  -612.660 [  71.169], Avg:  -526.054 (0.100) <0-00:19:28> ({'r_t': -2739.3157, 'eps':     0.1000, 'critic_loss':   191.2772, 'actor_loss':    -7.8479, 'eps_e':     0.1000})
Step:  128000, Reward:  -564.563 [  75.135], Avg:  -526.352 (0.100) <0-00:19:37> ({'r_t': -2391.4651, 'eps':     0.1000, 'critic_loss':   206.9936, 'actor_loss':    -7.5853, 'eps_e':     0.1000})
Step:  129000, Reward:  -601.131 [ 106.783], Avg:  -526.927 (0.100) <0-00:19:47> ({'r_t': -2852.3188, 'eps':     0.1000, 'critic_loss':   230.9786, 'actor_loss':    -7.1570, 'eps_e':     0.1000})
Step:  130000, Reward:  -335.991 [ 302.191], Avg:  -525.470 (0.100) <0-00:19:56> ({'r_t': -2419.6510, 'eps':     0.1000, 'critic_loss':   235.4193, 'actor_loss':    -7.6341, 'eps_e':     0.1000})
Step:  131000, Reward:  -175.294 [  64.571], Avg:  -522.817 (0.100) <0-00:20:05> ({'r_t': -1023.7492, 'eps':     0.1000, 'critic_loss':   252.5215, 'actor_loss':    -6.9555, 'eps_e':     0.1000})
Step:  132000, Reward:  -161.638 [ 114.716], Avg:  -520.101 (0.100) <0-00:20:15> ({'r_t':  -920.2532, 'eps':     0.1000, 'critic_loss':   255.5353, 'actor_loss':    -6.5371, 'eps_e':     0.1000})
Step:  133000, Reward:  -207.287 [ 131.266], Avg:  -517.767 (0.100) <0-00:20:24> ({'r_t':  -831.9261, 'eps':     0.1000, 'critic_loss':   249.2400, 'actor_loss':    -6.3605, 'eps_e':     0.1000})
Step:  134000, Reward:  -187.074 [ 121.278], Avg:  -515.317 (0.100) <0-00:20:33> ({'r_t':  -946.1601, 'eps':     0.1000, 'critic_loss':   249.7535, 'actor_loss':    -6.1448, 'eps_e':     0.1000})
Step:  135000, Reward:  -267.859 [ 143.545], Avg:  -513.498 (0.100) <0-00:20:43> ({'r_t':  -998.4574, 'eps':     0.1000, 'critic_loss':   250.4984, 'actor_loss':    -5.6674, 'eps_e':     0.1000})
Step:  136000, Reward:  -391.824 [ 135.670], Avg:  -512.610 (0.100) <0-00:20:52> ({'r_t': -2031.7610, 'eps':     0.1000, 'critic_loss':   249.2855, 'actor_loss':    -4.6075, 'eps_e':     0.1000})
Step:  137000, Reward:  -615.086 [  74.406], Avg:  -513.352 (0.100) <0-00:21:01> ({'r_t': -2631.6896, 'eps':     0.1000, 'critic_loss':   272.6044, 'actor_loss':    -4.3035, 'eps_e':     0.1000})
Step:  138000, Reward:  -173.218 [ 118.902], Avg:  -510.905 (0.100) <0-00:21:10> ({'r_t': -1699.4778, 'eps':     0.1000, 'critic_loss':   277.5631, 'actor_loss':    -4.1050, 'eps_e':     0.1000})
Step:  139000, Reward:  -157.499 [ 110.053], Avg:  -508.381 (0.100) <0-00:21:20> ({'r_t':  -838.5388, 'eps':     0.1000, 'critic_loss':   280.0441, 'actor_loss':    -4.9716, 'eps_e':     0.1000})
Step:  140000, Reward:  -231.672 [ 111.394], Avg:  -506.419 (0.100) <0-00:21:29> ({'r_t':  -802.8455, 'eps':     0.1000, 'critic_loss':   281.1636, 'actor_loss':    -5.4487, 'eps_e':     0.1000})
Step:  141000, Reward:  -430.404 [ 283.895], Avg:  -505.883 (0.100) <0-00:21:38> ({'r_t': -1139.9576, 'eps':     0.1000, 'critic_loss':   283.4609, 'actor_loss':    -5.0040, 'eps_e':     0.1000})
Step:  142000, Reward:  -178.827 [  91.072], Avg:  -503.596 (0.100) <0-00:21:47> ({'r_t':  -901.7275, 'eps':     0.1000, 'critic_loss':   284.5782, 'actor_loss':    -4.6860, 'eps_e':     0.1000})
Step:  143000, Reward:  -230.587 [ 116.525], Avg:  -501.700 (0.100) <0-00:21:56> ({'r_t':  -874.1868, 'eps':     0.1000, 'critic_loss':   291.5498, 'actor_loss':    -4.4761, 'eps_e':     0.1000})
Step:  144000, Reward:  -161.688 [  96.749], Avg:  -499.355 (0.100) <0-00:22:06> ({'r_t':  -968.9489, 'eps':     0.1000, 'critic_loss':   287.0159, 'actor_loss':    -4.0366, 'eps_e':     0.1000})
Step:  145000, Reward:  -134.653 [  88.829], Avg:  -496.857 (0.100) <0-00:22:15> ({'r_t':  -773.7826, 'eps':     0.1000, 'critic_loss':   288.4306, 'actor_loss':    -4.9341, 'eps_e':     0.1000})
Step:  146000, Reward:  -159.989 [ 111.806], Avg:  -494.566 (0.100) <0-00:22:24> ({'r_t':  -898.7011, 'eps':     0.1000, 'critic_loss':   286.7153, 'actor_loss':    -4.8299, 'eps_e':     0.1000})
Step:  147000, Reward:  -206.247 [ 140.381], Avg:  -492.618 (0.100) <0-00:22:34> ({'r_t':  -872.0441, 'eps':     0.1000, 'critic_loss':   278.4238, 'actor_loss':    -4.2037, 'eps_e':     0.1000})
Step:  148000, Reward:  -153.589 [ 100.860], Avg:  -490.342 (0.100) <0-00:22:43> ({'r_t':  -913.5349, 'eps':     0.1000, 'critic_loss':   289.8067, 'actor_loss':    -3.6556, 'eps_e':     0.1000})
Step:  149000, Reward:  -139.651 [  57.550], Avg:  -488.004 (0.100) <0-00:22:52> ({'r_t':  -873.2454, 'eps':     0.1000, 'critic_loss':   282.5797, 'actor_loss':    -4.0346, 'eps_e':     0.1000})
Step:  150000, Reward:  -160.811 [ 121.380], Avg:  -485.837 (0.100) <0-00:23:01> ({'r_t':  -865.9489, 'eps':     0.1000, 'critic_loss':   287.6109, 'actor_loss':    -3.7418, 'eps_e':     0.1000})
Step:  151000, Reward:  -156.954 [ 103.847], Avg:  -483.674 (0.100) <0-00:23:11> ({'r_t':  -748.4197, 'eps':     0.1000, 'critic_loss':   287.0281, 'actor_loss':    -3.9188, 'eps_e':     0.1000})
Step:  152000, Reward:  -196.193 [ 101.907], Avg:  -481.795 (0.100) <0-00:23:20> ({'r_t':  -798.6535, 'eps':     0.1000, 'critic_loss':   292.6487, 'actor_loss':    -3.4987, 'eps_e':     0.1000})
Step:  153000, Reward:  -170.543 [  94.523], Avg:  -479.774 (0.100) <0-00:23:29> ({'r_t':  -884.6701, 'eps':     0.1000, 'critic_loss':   291.2087, 'actor_loss':    -3.3266, 'eps_e':     0.1000})
Step:  154000, Reward:  -182.339 [ 109.565], Avg:  -477.855 (0.100) <0-00:23:39> ({'r_t':  -827.1968, 'eps':     0.1000, 'critic_loss':   298.6266, 'actor_loss':    -3.8706, 'eps_e':     0.1000})
Step:  155000, Reward:  -143.548 [ 103.246], Avg:  -475.712 (0.100) <0-00:23:48> ({'r_t':  -845.5059, 'eps':     0.1000, 'critic_loss':   282.2815, 'actor_loss':    -3.7189, 'eps_e':     0.1000})
Step:  156000, Reward:  -138.988 [  81.872], Avg:  -473.567 (0.100) <0-00:23:57> ({'r_t':  -794.8445, 'eps':     0.1000, 'critic_loss':   281.3661, 'actor_loss':    -3.4908, 'eps_e':     0.1000})
Step:  157000, Reward:  -176.995 [ 114.417], Avg:  -471.690 (0.100) <0-00:24:07> ({'r_t':  -840.7170, 'eps':     0.1000, 'critic_loss':   288.3621, 'actor_loss':    -3.0426, 'eps_e':     0.1000})
Step:  158000, Reward:  -195.043 [ 141.823], Avg:  -469.950 (0.100) <0-00:24:16> ({'r_t':  -775.4284, 'eps':     0.1000, 'critic_loss':   290.6416, 'actor_loss':    -2.9286, 'eps_e':     0.1000})
Step:  159000, Reward:  -136.367 [  80.541], Avg:  -467.865 (0.100) <0-00:24:25> ({'r_t':  -812.7375, 'eps':     0.1000, 'critic_loss':   279.5386, 'actor_loss':    -3.0941, 'eps_e':     0.1000})
Step:  160000, Reward:  -186.309 [  93.168], Avg:  -466.116 (0.100) <0-00:24:35> ({'r_t':  -799.0973, 'eps':     0.1000, 'critic_loss':   290.8489, 'actor_loss':    -2.8598, 'eps_e':     0.1000})
Step:  161000, Reward:  -162.688 [ 104.146], Avg:  -464.243 (0.100) <0-00:24:44> ({'r_t':  -829.8773, 'eps':     0.1000, 'critic_loss':   285.6959, 'actor_loss':    -2.7557, 'eps_e':     0.1000})
Step:  162000, Reward:  -170.532 [  77.212], Avg:  -462.441 (0.100) <0-00:24:53> ({'r_t':  -804.7733, 'eps':     0.1000, 'critic_loss':   281.1777, 'actor_loss':    -2.5302, 'eps_e':     0.1000})
Step:  163000, Reward:  -128.219 [  95.527], Avg:  -460.404 (0.100) <0-00:25:03> ({'r_t':  -855.9245, 'eps':     0.1000, 'critic_loss':   284.8169, 'actor_loss':    -2.5512, 'eps_e':     0.1000})
Step:  164000, Reward:  -135.955 [ 107.023], Avg:  -458.437 (0.100) <0-00:25:12> ({'r_t':  -773.4821, 'eps':     0.1000, 'critic_loss':   269.0921, 'actor_loss':    -2.3441, 'eps_e':     0.1000})
Step:  165000, Reward:  -193.410 [  91.724], Avg:  -456.841 (0.100) <0-00:25:22> ({'r_t':  -816.4675, 'eps':     0.1000, 'critic_loss':   277.5432, 'actor_loss':    -2.4228, 'eps_e':     0.1000})
Step:  166000, Reward:  -167.611 [  72.356], Avg:  -455.109 (0.100) <0-00:25:32> ({'r_t':  -701.4489, 'eps':     0.1000, 'critic_loss':   267.5213, 'actor_loss':    -2.2126, 'eps_e':     0.1000})
Step:  167000, Reward:  -173.503 [  92.762], Avg:  -453.432 (0.100) <0-00:25:41> ({'r_t':  -839.6553, 'eps':     0.1000, 'critic_loss':   265.2465, 'actor_loss':    -1.8759, 'eps_e':     0.1000})
Step:  168000, Reward:  -230.929 [  87.911], Avg:  -452.116 (0.100) <0-00:25:50> ({'r_t':  -961.4561, 'eps':     0.1000, 'critic_loss':   264.1255, 'actor_loss':    -2.1821, 'eps_e':     0.1000})
Step:  169000, Reward:  -159.755 [ 103.315], Avg:  -450.396 (0.100) <0-00:26:00> ({'r_t':  -846.8776, 'eps':     0.1000, 'critic_loss':   246.1260, 'actor_loss':    -1.2228, 'eps_e':     0.1000})
Step:  170000, Reward:  -185.556 [  91.716], Avg:  -448.847 (0.100) <0-00:26:09> ({'r_t':  -862.8857, 'eps':     0.1000, 'critic_loss':   221.0224, 'actor_loss':    -1.0516, 'eps_e':     0.1000})
Step:  171000, Reward:  -139.301 [  97.628], Avg:  -447.048 (0.100) <0-00:26:18> ({'r_t':  -869.1284, 'eps':     0.1000, 'critic_loss':   231.4933, 'actor_loss':    -0.9449, 'eps_e':     0.1000})
Step:  172000, Reward:  -162.728 [  91.265], Avg:  -445.404 (0.100) <0-00:26:28> ({'r_t':  -904.2854, 'eps':     0.1000, 'critic_loss':   216.8360, 'actor_loss':    -1.6518, 'eps_e':     0.1000})
Step:  173000, Reward:  -145.124 [  91.608], Avg:  -443.678 (0.100) <0-00:26:37> ({'r_t':  -831.4355, 'eps':     0.1000, 'critic_loss':   207.8766, 'actor_loss':    -2.5040, 'eps_e':     0.1000})
Step:  174000, Reward:  -140.383 [  67.100], Avg:  -441.945 (0.100) <0-00:26:46> ({'r_t':  -854.6948, 'eps':     0.1000, 'critic_loss':   218.1995, 'actor_loss':    -2.8064, 'eps_e':     0.1000})
Step:  175000, Reward:  -200.816 [  77.637], Avg:  -440.575 (0.100) <0-00:26:56> ({'r_t':  -952.4705, 'eps':     0.1000, 'critic_loss':   212.9527, 'actor_loss':    -2.9191, 'eps_e':     0.1000})
Step:  176000, Reward:  -168.744 [ 113.836], Avg:  -439.040 (0.100) <0-00:27:05> ({'r_t':  -782.5348, 'eps':     0.1000, 'critic_loss':   229.2645, 'actor_loss':    -3.0633, 'eps_e':     0.1000})
Step:  177000, Reward:  -220.593 [ 106.972], Avg:  -437.812 (0.100) <0-00:27:14> ({'r_t':  -775.8665, 'eps':     0.1000, 'critic_loss':   219.0666, 'actor_loss':    -2.7551, 'eps_e':     0.1000})
Step:  178000, Reward:  -179.258 [  89.997], Avg:  -436.368 (0.100) <0-00:27:23> ({'r_t':  -770.8463, 'eps':     0.1000, 'critic_loss':   219.7137, 'actor_loss':    -2.9914, 'eps_e':     0.1000})
Step:  179000, Reward:  -136.694 [ 101.013], Avg:  -434.703 (0.100) <0-00:27:33> ({'r_t':  -868.2895, 'eps':     0.1000, 'critic_loss':   222.5091, 'actor_loss':    -2.6087, 'eps_e':     0.1000})
Step:  180000, Reward:  -133.364 [  64.315], Avg:  -433.038 (0.100) <0-00:27:42> ({'r_t':  -743.7420, 'eps':     0.1000, 'critic_loss':   230.4725, 'actor_loss':    -3.1206, 'eps_e':     0.1000})
Step:  181000, Reward:  -168.361 [  81.750], Avg:  -431.584 (0.100) <0-00:27:52> ({'r_t':  -932.8535, 'eps':     0.1000, 'critic_loss':   216.6106, 'actor_loss':    -3.0608, 'eps_e':     0.1000})
Step:  182000, Reward:  -126.671 [  52.943], Avg:  -429.918 (0.100) <0-00:28:01> ({'r_t':  -770.9144, 'eps':     0.1000, 'critic_loss':   211.1751, 'actor_loss':    -3.2548, 'eps_e':     0.1000})
Step:  183000, Reward:  -186.152 [ 107.163], Avg:  -428.593 (0.100) <0-00:28:10> ({'r_t':  -929.7760, 'eps':     0.1000, 'critic_loss':   211.1777, 'actor_loss':    -3.1376, 'eps_e':     0.1000})
Step:  184000, Reward:  -188.607 [ 114.561], Avg:  -427.296 (0.100) <0-00:28:19> ({'r_t':  -909.4995, 'eps':     0.1000, 'critic_loss':   206.6215, 'actor_loss':    -3.1911, 'eps_e':     0.1000})
Step:  185000, Reward:  -175.164 [  87.821], Avg:  -425.940 (0.100) <0-00:28:29> ({'r_t':  -954.6124, 'eps':     0.1000, 'critic_loss':   210.2139, 'actor_loss':    -3.2631, 'eps_e':     0.1000})
Step:  186000, Reward:  -150.214 [  80.144], Avg:  -424.466 (0.100) <0-00:28:38> ({'r_t': -1006.3519, 'eps':     0.1000, 'critic_loss':   209.0421, 'actor_loss':    -3.2558, 'eps_e':     0.1000})
Step:  187000, Reward:  -309.497 [ 153.146], Avg:  -423.854 (0.100) <0-00:28:47> ({'r_t':  -882.5942, 'eps':     0.1000, 'critic_loss':   201.2852, 'actor_loss':    -3.3069, 'eps_e':     0.1000})
Step:  188000, Reward:  -195.265 [  98.872], Avg:  -422.645 (0.100) <0-00:28:57> ({'r_t': -1114.8102, 'eps':     0.1000, 'critic_loss':   195.8798, 'actor_loss':    -4.0608, 'eps_e':     0.1000})
Step:  189000, Reward:  -191.467 [ 100.887], Avg:  -421.428 (0.100) <0-00:29:06> ({'r_t':  -867.0070, 'eps':     0.1000, 'critic_loss':   180.3932, 'actor_loss':    -4.2546, 'eps_e':     0.1000})
Step:  190000, Reward:  -153.475 [  95.842], Avg:  -420.025 (0.100) <0-00:29:15> ({'r_t':  -943.6928, 'eps':     0.1000, 'critic_loss':   170.7824, 'actor_loss':    -4.2165, 'eps_e':     0.1000})
Step:  191000, Reward:  -209.090 [  99.217], Avg:  -418.926 (0.100) <0-00:29:24> ({'r_t':  -842.3791, 'eps':     0.1000, 'critic_loss':   152.2966, 'actor_loss':    -3.9891, 'eps_e':     0.1000})
Step:  192000, Reward:  -166.131 [  86.537], Avg:  -417.617 (0.100) <0-00:29:33> ({'r_t':  -947.4486, 'eps':     0.1000, 'critic_loss':   134.1975, 'actor_loss':    -3.8614, 'eps_e':     0.1000})
Step:  193000, Reward:  -199.571 [  95.523], Avg:  -416.493 (0.100) <0-00:29:43> ({'r_t':  -870.2332, 'eps':     0.1000, 'critic_loss':   117.7834, 'actor_loss':    -3.5760, 'eps_e':     0.1000})
Step:  194000, Reward:  -222.269 [ 111.218], Avg:  -415.497 (0.100) <0-00:29:52> ({'r_t': -1024.9476, 'eps':     0.1000, 'critic_loss':   114.6343, 'actor_loss':    -3.5911, 'eps_e':     0.1000})
Step:  195000, Reward:  -143.351 [  73.572], Avg:  -414.108 (0.100) <0-00:30:01> ({'r_t':  -902.0524, 'eps':     0.1000, 'critic_loss':   114.9619, 'actor_loss':    -3.5743, 'eps_e':     0.1000})
Step:  196000, Reward:  -181.187 [  92.176], Avg:  -412.926 (0.100) <0-00:30:10> ({'r_t':  -827.3804, 'eps':     0.1000, 'critic_loss':   108.2957, 'actor_loss':    -3.7590, 'eps_e':     0.1000})
Step:  197000, Reward:  -168.663 [  81.769], Avg:  -411.692 (0.100) <0-00:30:19> ({'r_t':  -904.4764, 'eps':     0.1000, 'critic_loss':   106.2822, 'actor_loss':    -3.4773, 'eps_e':     0.1000})
Step:  198000, Reward:  -166.227 [  98.983], Avg:  -410.459 (0.100) <0-00:30:29> ({'r_t':  -791.9154, 'eps':     0.1000, 'critic_loss':   108.1556, 'actor_loss':    -3.5226, 'eps_e':     0.1000})
Step:  199000, Reward:  -191.304 [  81.172], Avg:  -409.363 (0.100) <0-00:30:38> ({'r_t':  -876.4192, 'eps':     0.1000, 'critic_loss':    88.5465, 'actor_loss':    -3.1644, 'eps_e':     0.1000})
Step:  200000, Reward:  -132.776 [  50.766], Avg:  -407.987 (0.100) <0-00:30:47> ({'r_t':  -877.9771, 'eps':     0.1000, 'critic_loss':    70.1381, 'actor_loss':    -3.2740, 'eps_e':     0.1000})
Step:  201000, Reward:  -170.058 [  78.492], Avg:  -406.809 (0.100) <0-00:30:56> ({'r_t':  -858.0718, 'eps':     0.1000, 'critic_loss':    61.0349, 'actor_loss':    -2.8269, 'eps_e':     0.1000})
Step:  202000, Reward:  -150.906 [  63.139], Avg:  -405.548 (0.100) <0-00:31:06> ({'r_t':  -796.2238, 'eps':     0.1000, 'critic_loss':    57.6319, 'actor_loss':    -2.7823, 'eps_e':     0.1000})
Step:  203000, Reward:  -192.916 [  91.891], Avg:  -404.506 (0.100) <0-00:31:15> ({'r_t':  -925.4084, 'eps':     0.1000, 'critic_loss':    58.1386, 'actor_loss':    -2.9955, 'eps_e':     0.1000})
Step:  204000, Reward:  -187.742 [  96.158], Avg:  -403.449 (0.100) <0-00:31:24> ({'r_t':  -770.0503, 'eps':     0.1000, 'critic_loss':    56.0028, 'actor_loss':    -2.8265, 'eps_e':     0.1000})
Step:  205000, Reward:  -151.005 [ 115.438], Avg:  -402.223 (0.100) <0-00:31:33> ({'r_t':  -804.1027, 'eps':     0.1000, 'critic_loss':    51.9000, 'actor_loss':    -2.8262, 'eps_e':     0.1000})
Step:  206000, Reward:  -151.966 [  93.407], Avg:  -401.014 (0.100) <0-00:31:43> ({'r_t':  -822.2841, 'eps':     0.1000, 'critic_loss':    50.5519, 'actor_loss':    -2.7057, 'eps_e':     0.1000})
Step:  207000, Reward:  -160.804 [  90.513], Avg:  -399.859 (0.100) <0-00:31:52> ({'r_t':  -862.6616, 'eps':     0.1000, 'critic_loss':    48.9802, 'actor_loss':    -2.6300, 'eps_e':     0.1000})
Step:  208000, Reward:  -118.639 [  80.679], Avg:  -398.514 (0.100) <0-00:32:01> ({'r_t':  -727.5797, 'eps':     0.1000, 'critic_loss':    46.4481, 'actor_loss':    -2.6983, 'eps_e':     0.1000})
Step:  209000, Reward:  -161.484 [  68.289], Avg:  -397.385 (0.100) <0-00:32:10> ({'r_t':  -831.1626, 'eps':     0.1000, 'critic_loss':    47.4204, 'actor_loss':    -2.9913, 'eps_e':     0.1000})
Step:  210000, Reward:  -192.356 [  71.965], Avg:  -396.413 (0.100) <0-00:32:20> ({'r_t':  -816.0940, 'eps':     0.1000, 'critic_loss':    46.6182, 'actor_loss':    -2.8144, 'eps_e':     0.1000})
Step:  211000, Reward:  -176.089 [ 102.276], Avg:  -395.374 (0.100) <0-00:32:29> ({'r_t':  -766.7197, 'eps':     0.1000, 'critic_loss':    45.2545, 'actor_loss':    -2.8944, 'eps_e':     0.1000})
Step:  212000, Reward:  -141.103 [  58.279], Avg:  -394.180 (0.100) <0-00:32:38> ({'r_t':  -768.1234, 'eps':     0.1000, 'critic_loss':    46.5154, 'actor_loss':    -2.9444, 'eps_e':     0.1000})
Step:  213000, Reward:  -187.492 [  98.726], Avg:  -393.214 (0.100) <0-00:32:47> ({'r_t':  -844.0630, 'eps':     0.1000, 'critic_loss':    46.7266, 'actor_loss':    -2.9924, 'eps_e':     0.1000})
Step:  214000, Reward:  -226.258 [  99.103], Avg:  -392.438 (0.100) <0-00:32:57> ({'r_t':  -836.2205, 'eps':     0.1000, 'critic_loss':    44.0325, 'actor_loss':    -2.8557, 'eps_e':     0.1000})
Step:  215000, Reward:  -154.730 [  73.739], Avg:  -391.337 (0.100) <0-00:33:06> ({'r_t':  -805.8104, 'eps':     0.1000, 'critic_loss':    45.7764, 'actor_loss':    -3.1476, 'eps_e':     0.1000})
Step:  216000, Reward:  -154.187 [  50.181], Avg:  -390.245 (0.100) <0-00:33:15> ({'r_t':  -904.7214, 'eps':     0.1000, 'critic_loss':    43.9283, 'actor_loss':    -2.9269, 'eps_e':     0.1000})
Step:  217000, Reward:  -183.168 [  82.250], Avg:  -389.295 (0.100) <0-00:33:25> ({'r_t':  -798.8383, 'eps':     0.1000, 'critic_loss':    41.5358, 'actor_loss':    -3.1147, 'eps_e':     0.1000})
Step:  218000, Reward:  -168.528 [ 121.493], Avg:  -388.287 (0.100) <0-00:33:34> ({'r_t':  -846.9799, 'eps':     0.1000, 'critic_loss':    46.3661, 'actor_loss':    -3.1157, 'eps_e':     0.1000})
Step:  219000, Reward:  -133.629 [  93.822], Avg:  -387.129 (0.100) <0-00:33:43> ({'r_t':  -846.8029, 'eps':     0.1000, 'critic_loss':    43.6701, 'actor_loss':    -3.0984, 'eps_e':     0.1000})
Step:  220000, Reward:  -151.009 [  82.442], Avg:  -386.061 (0.100) <0-00:33:53> ({'r_t':  -919.3736, 'eps':     0.1000, 'critic_loss':    45.4238, 'actor_loss':    -3.0707, 'eps_e':     0.1000})
Step:  221000, Reward:  -169.940 [  98.402], Avg:  -385.087 (0.100) <0-00:34:02> ({'r_t':  -708.1890, 'eps':     0.1000, 'critic_loss':    45.7442, 'actor_loss':    -3.0792, 'eps_e':     0.1000})
Step:  222000, Reward:  -144.295 [ 103.522], Avg:  -384.007 (0.100) <0-00:34:11> ({'r_t':  -818.2420, 'eps':     0.1000, 'critic_loss':    42.6773, 'actor_loss':    -3.1307, 'eps_e':     0.1000})
Step:  223000, Reward:  -178.588 [  84.679], Avg:  -383.090 (0.100) <0-00:34:21> ({'r_t':  -858.4675, 'eps':     0.1000, 'critic_loss':    43.1981, 'actor_loss':    -2.9038, 'eps_e':     0.1000})
Step:  224000, Reward:  -106.718 [  57.359], Avg:  -381.862 (0.100) <0-00:34:30> ({'r_t':  -863.2278, 'eps':     0.1000, 'critic_loss':    43.6659, 'actor_loss':    -3.0307, 'eps_e':     0.1000})
Step:  225000, Reward:  -205.637 [ 107.037], Avg:  -381.082 (0.100) <0-00:34:39> ({'r_t':  -756.1744, 'eps':     0.1000, 'critic_loss':    46.2700, 'actor_loss':    -3.1669, 'eps_e':     0.1000})
Step:  226000, Reward:  -143.140 [  89.132], Avg:  -380.034 (0.100) <0-00:34:49> ({'r_t':  -825.0893, 'eps':     0.1000, 'critic_loss':    42.1105, 'actor_loss':    -2.9273, 'eps_e':     0.1000})
Step:  227000, Reward:  -170.919 [  86.977], Avg:  -379.117 (0.100) <0-00:34:58> ({'r_t':  -700.1840, 'eps':     0.1000, 'critic_loss':    43.0501, 'actor_loss':    -3.1335, 'eps_e':     0.1000})
Step:  228000, Reward:  -182.110 [  80.132], Avg:  -378.257 (0.100) <0-00:35:08> ({'r_t':  -729.0580, 'eps':     0.1000, 'critic_loss':    45.5379, 'actor_loss':    -3.1095, 'eps_e':     0.1000})
Step:  229000, Reward:  -145.802 [  87.272], Avg:  -377.246 (0.100) <0-00:35:17> ({'r_t':  -857.0726, 'eps':     0.1000, 'critic_loss':    43.0338, 'actor_loss':    -3.4066, 'eps_e':     0.1000})
Step:  230000, Reward:  -147.414 [  91.902], Avg:  -376.251 (0.100) <0-00:35:26> ({'r_t':  -754.4612, 'eps':     0.1000, 'critic_loss':    41.5424, 'actor_loss':    -3.6835, 'eps_e':     0.1000})
Step:  231000, Reward:  -190.615 [  84.465], Avg:  -375.451 (0.100) <0-00:35:36> ({'r_t':  -831.5324, 'eps':     0.1000, 'critic_loss':    41.5214, 'actor_loss':    -3.6647, 'eps_e':     0.1000})
Step:  232000, Reward:  -188.610 [ 116.702], Avg:  -374.649 (0.100) <0-00:35:45> ({'r_t':  -826.6395, 'eps':     0.1000, 'critic_loss':    41.0927, 'actor_loss':    -3.8444, 'eps_e':     0.1000})
Step:  233000, Reward:  -158.111 [ 107.272], Avg:  -373.724 (0.100) <0-00:35:54> ({'r_t':  -823.1541, 'eps':     0.1000, 'critic_loss':    43.6931, 'actor_loss':    -3.8168, 'eps_e':     0.1000})
Step:  234000, Reward:  -167.543 [ 113.357], Avg:  -372.846 (0.100) <0-00:36:04> ({'r_t':  -868.7559, 'eps':     0.1000, 'critic_loss':    42.4996, 'actor_loss':    -3.7892, 'eps_e':     0.1000})
Step:  235000, Reward:  -207.845 [  79.198], Avg:  -372.147 (0.100) <0-00:36:13> ({'r_t':  -839.8223, 'eps':     0.1000, 'critic_loss':    40.3933, 'actor_loss':    -4.2538, 'eps_e':     0.1000})
Step:  236000, Reward:  -172.270 [  97.505], Avg:  -371.304 (0.100) <0-00:36:22> ({'r_t':  -909.8430, 'eps':     0.1000, 'critic_loss':    44.1609, 'actor_loss':    -3.8796, 'eps_e':     0.1000})
Step:  237000, Reward:  -188.462 [  82.207], Avg:  -370.535 (0.100) <0-00:36:32> ({'r_t':  -753.0467, 'eps':     0.1000, 'critic_loss':    40.1097, 'actor_loss':    -4.1033, 'eps_e':     0.1000})
Step:  238000, Reward:  -161.652 [  96.777], Avg:  -369.661 (0.100) <0-00:36:41> ({'r_t':  -878.1313, 'eps':     0.1000, 'critic_loss':    41.4244, 'actor_loss':    -4.0251, 'eps_e':     0.1000})
Step:  239000, Reward:  -170.404 [ 100.312], Avg:  -368.831 (0.100) <0-00:36:50> ({'r_t':  -831.1779, 'eps':     0.1000, 'critic_loss':    41.2752, 'actor_loss':    -4.0135, 'eps_e':     0.1000})
Step:  240000, Reward:  -267.123 [ 133.534], Avg:  -368.409 (0.100) <0-00:37:00> ({'r_t':  -943.5459, 'eps':     0.1000, 'critic_loss':    41.5987, 'actor_loss':    -3.9771, 'eps_e':     0.1000})
Step:  241000, Reward:  -232.915 [ 104.545], Avg:  -367.849 (0.100) <0-00:37:09> ({'r_t': -1117.6793, 'eps':     0.1000, 'critic_loss':    43.2362, 'actor_loss':    -3.7337, 'eps_e':     0.1000})
Step:  242000, Reward:  -192.914 [  91.124], Avg:  -367.129 (0.100) <0-00:37:18> ({'r_t':  -790.5949, 'eps':     0.1000, 'critic_loss':    46.2796, 'actor_loss':    -3.9855, 'eps_e':     0.1000})
Step:  243000, Reward:  -188.163 [ 117.068], Avg:  -366.396 (0.100) <0-00:37:27> ({'r_t':  -975.3712, 'eps':     0.1000, 'critic_loss':    45.3792, 'actor_loss':    -3.9197, 'eps_e':     0.1000})
Step:  244000, Reward:  -213.363 [ 106.571], Avg:  -365.771 (0.100) <0-00:37:37> ({'r_t':  -963.3268, 'eps':     0.1000, 'critic_loss':    46.2831, 'actor_loss':    -3.3996, 'eps_e':     0.1000})
Step:  245000, Reward:  -171.411 [  89.595], Avg:  -364.981 (0.100) <0-00:37:46> ({'r_t':  -978.0051, 'eps':     0.1000, 'critic_loss':    48.2377, 'actor_loss':    -3.4148, 'eps_e':     0.1000})
Step:  246000, Reward:  -175.064 [  77.958], Avg:  -364.212 (0.100) <0-00:37:55> ({'r_t':  -985.7849, 'eps':     0.1000, 'critic_loss':    50.7707, 'actor_loss':    -3.4814, 'eps_e':     0.1000})
Step:  247000, Reward:  -119.050 [  66.293], Avg:  -363.224 (0.100) <0-00:38:04> ({'r_t':  -961.3600, 'eps':     0.1000, 'critic_loss':    48.5370, 'actor_loss':    -3.4164, 'eps_e':     0.1000})
Step:  248000, Reward:  -155.497 [  93.917], Avg:  -362.390 (0.100) <0-00:38:14> ({'r_t':  -889.5876, 'eps':     0.1000, 'critic_loss':    44.8642, 'actor_loss':    -3.2913, 'eps_e':     0.1000})
Step:  249000, Reward:  -140.777 [  88.899], Avg:  -361.503 (0.100) <0-00:38:23> ({'r_t':  -933.0322, 'eps':     0.1000, 'critic_loss':    46.4088, 'actor_loss':    -3.3041, 'eps_e':     0.1000})
Step:  250000, Reward:  -155.338 [  91.333], Avg:  -360.682 (0.100) <0-00:38:32> ({'r_t':  -686.7138, 'eps':     0.1000, 'critic_loss':    41.2141, 'actor_loss':    -3.3406, 'eps_e':     0.1000})
Step:  251000, Reward:  -121.796 [  72.756], Avg:  -359.734 (0.100) <0-00:38:42> ({'r_t':  -775.9025, 'eps':     0.1000, 'critic_loss':    40.1778, 'actor_loss':    -3.2801, 'eps_e':     0.1000})
Step:  252000, Reward:  -163.758 [  86.045], Avg:  -358.959 (0.100) <0-00:38:51> ({'r_t':  -786.8573, 'eps':     0.1000, 'critic_loss':    39.3547, 'actor_loss':    -3.1420, 'eps_e':     0.1000})
Step:  253000, Reward:  -179.598 [ 100.001], Avg:  -358.253 (0.100) <0-00:39:00> ({'r_t':  -829.6774, 'eps':     0.1000, 'critic_loss':    35.7695, 'actor_loss':    -3.1588, 'eps_e':     0.1000})
Step:  254000, Reward:  -352.291 [ 241.565], Avg:  -358.230 (0.100) <0-00:39:09> ({'r_t': -1394.8140, 'eps':     0.1000, 'critic_loss':    39.3660, 'actor_loss':    -2.8475, 'eps_e':     0.1000})
Step:  255000, Reward:  -211.084 [  81.146], Avg:  -357.655 (0.100) <0-00:39:18> ({'r_t': -1229.9477, 'eps':     0.1000, 'critic_loss':    42.0202, 'actor_loss':    -2.8855, 'eps_e':     0.1000})
Step:  256000, Reward:  -182.434 [ 121.544], Avg:  -356.973 (0.100) <0-00:39:27> ({'r_t':  -863.0807, 'eps':     0.1000, 'critic_loss':    44.2424, 'actor_loss':    -3.0824, 'eps_e':     0.1000})
Step:  257000, Reward:  -197.627 [  84.158], Avg:  -356.355 (0.100) <0-00:39:36> ({'r_t':  -983.6025, 'eps':     0.1000, 'critic_loss':    42.5908, 'actor_loss':    -3.4107, 'eps_e':     0.1000})
Step:  258000, Reward:  -163.139 [  87.443], Avg:  -355.609 (0.100) <0-00:39:45> ({'r_t': -1105.5744, 'eps':     0.1000, 'critic_loss':    41.3245, 'actor_loss':    -2.2148, 'eps_e':     0.1000})
Step:  259000, Reward:  -171.484 [ 104.300], Avg:  -354.901 (0.100) <0-00:39:54> ({'r_t':  -836.5052, 'eps':     0.1000, 'critic_loss':    43.6198, 'actor_loss':    -2.3410, 'eps_e':     0.1000})
Step:  260000, Reward:  -183.002 [ 132.214], Avg:  -354.243 (0.100) <0-00:40:03> ({'r_t':  -796.3088, 'eps':     0.1000, 'critic_loss':    44.7358, 'actor_loss':    -2.9223, 'eps_e':     0.1000})
Step:  261000, Reward:  -161.384 [  78.374], Avg:  -353.506 (0.100) <0-00:40:12> ({'r_t':  -798.0208, 'eps':     0.1000, 'critic_loss':    44.3019, 'actor_loss':    -2.6181, 'eps_e':     0.1000})
Step:  262000, Reward:  -159.977 [  86.499], Avg:  -352.771 (0.100) <0-00:40:20> ({'r_t':  -808.6341, 'eps':     0.1000, 'critic_loss':    42.8621, 'actor_loss':    -2.5459, 'eps_e':     0.1000})
Step:  263000, Reward:  -189.038 [ 108.446], Avg:  -352.150 (0.100) <0-00:40:29> ({'r_t':  -771.0756, 'eps':     0.1000, 'critic_loss':    41.7798, 'actor_loss':    -2.5976, 'eps_e':     0.1000})
Step:  264000, Reward:  -140.707 [  72.747], Avg:  -351.353 (0.100) <0-00:40:38> ({'r_t':  -820.9433, 'eps':     0.1000, 'critic_loss':    43.4900, 'actor_loss':    -3.0776, 'eps_e':     0.1000})
Step:  265000, Reward:  -196.355 [  88.174], Avg:  -350.770 (0.100) <0-00:40:47> ({'r_t':  -969.8316, 'eps':     0.1000, 'critic_loss':    44.1404, 'actor_loss':    -3.2600, 'eps_e':     0.1000})
Step:  266000, Reward:  -143.526 [ 118.684], Avg:  -349.994 (0.100) <0-00:40:56> ({'r_t':  -811.3895, 'eps':     0.1000, 'critic_loss':    41.7088, 'actor_loss':    -3.0676, 'eps_e':     0.1000})
Step:  267000, Reward:  -199.688 [  81.893], Avg:  -349.433 (0.100) <0-00:41:05> ({'r_t':  -810.6850, 'eps':     0.1000, 'critic_loss':    43.6098, 'actor_loss':    -3.1525, 'eps_e':     0.1000})
Step:  268000, Reward:  -205.900 [  81.800], Avg:  -348.899 (0.100) <0-00:41:13> ({'r_t':  -829.0855, 'eps':     0.1000, 'critic_loss':    42.0784, 'actor_loss':    -3.1573, 'eps_e':     0.1000})
Step:  269000, Reward:  -140.018 [  72.699], Avg:  -348.126 (0.100) <0-00:41:22> ({'r_t':  -778.0550, 'eps':     0.1000, 'critic_loss':    41.0493, 'actor_loss':    -3.3779, 'eps_e':     0.1000})
Step:  270000, Reward:  -181.427 [  85.551], Avg:  -347.510 (0.100) <0-00:41:31> ({'r_t':  -841.7445, 'eps':     0.1000, 'critic_loss':    40.2357, 'actor_loss':    -3.2977, 'eps_e':     0.1000})
Step:  271000, Reward:  -234.837 [ 118.426], Avg:  -347.096 (0.100) <0-00:41:40> ({'r_t':  -840.6026, 'eps':     0.1000, 'critic_loss':    40.6577, 'actor_loss':    -3.1320, 'eps_e':     0.1000})
Step:  272000, Reward:  -158.823 [ 110.811], Avg:  -346.407 (0.100) <0-00:41:49> ({'r_t':  -821.7098, 'eps':     0.1000, 'critic_loss':    39.9695, 'actor_loss':    -3.2120, 'eps_e':     0.1000})
Step:  273000, Reward:  -155.146 [  84.829], Avg:  -345.709 (0.100) <0-00:41:58> ({'r_t':  -795.0391, 'eps':     0.1000, 'critic_loss':    41.4367, 'actor_loss':    -2.9647, 'eps_e':     0.1000})
Step:  274000, Reward:  -160.050 [ 109.633], Avg:  -345.033 (0.100) <0-00:42:07> ({'r_t':  -750.8904, 'eps':     0.1000, 'critic_loss':    41.6480, 'actor_loss':    -2.9936, 'eps_e':     0.1000})
Step:  275000, Reward:  -142.262 [ 109.596], Avg:  -344.299 (0.100) <0-00:42:15> ({'r_t':  -815.8261, 'eps':     0.1000, 'critic_loss':    44.9240, 'actor_loss':    -3.1815, 'eps_e':     0.1000})
Step:  276000, Reward:  -164.455 [  88.502], Avg:  -343.649 (0.100) <0-00:42:24> ({'r_t':  -876.4228, 'eps':     0.1000, 'critic_loss':    41.9155, 'actor_loss':    -2.9254, 'eps_e':     0.1000})
Step:  277000, Reward:  -168.098 [ 135.784], Avg:  -343.018 (0.100) <0-00:42:33> ({'r_t':  -874.8835, 'eps':     0.1000, 'critic_loss':    40.2084, 'actor_loss':    -2.7800, 'eps_e':     0.1000})
Step:  278000, Reward:  -215.118 [  91.324], Avg:  -342.560 (0.100) <0-00:42:42> ({'r_t':  -687.2550, 'eps':     0.1000, 'critic_loss':    41.4723, 'actor_loss':    -2.8154, 'eps_e':     0.1000})
Step:  279000, Reward:  -187.976 [  77.758], Avg:  -342.007 (0.100) <0-00:42:51> ({'r_t':  -789.8135, 'eps':     0.1000, 'critic_loss':    41.0713, 'actor_loss':    -2.6482, 'eps_e':     0.1000})
Step:  280000, Reward:  -136.987 [ 100.935], Avg:  -341.278 (0.100) <0-00:43:00> ({'r_t':  -767.4417, 'eps':     0.1000, 'critic_loss':    43.0474, 'actor_loss':    -2.9621, 'eps_e':     0.1000})
Step:  281000, Reward:  -160.521 [  90.630], Avg:  -340.637 (0.100) <0-00:43:08> ({'r_t':  -861.2512, 'eps':     0.1000, 'critic_loss':    40.3895, 'actor_loss':    -2.8619, 'eps_e':     0.1000})
Step:  282000, Reward:  -171.735 [  99.610], Avg:  -340.040 (0.100) <0-00:43:17> ({'r_t':  -799.2850, 'eps':     0.1000, 'critic_loss':    39.8508, 'actor_loss':    -2.8787, 'eps_e':     0.1000})
Step:  283000, Reward:  -148.304 [  84.177], Avg:  -339.365 (0.100) <0-00:43:26> ({'r_t':  -802.0400, 'eps':     0.1000, 'critic_loss':    39.1868, 'actor_loss':    -2.8057, 'eps_e':     0.1000})
Step:  284000, Reward:  -202.596 [  94.649], Avg:  -338.885 (0.100) <0-00:43:35> ({'r_t':  -860.3259, 'eps':     0.1000, 'critic_loss':    45.3803, 'actor_loss':    -2.7416, 'eps_e':     0.1000})
Step:  285000, Reward:  -188.162 [  76.344], Avg:  -338.358 (0.100) <0-00:43:44> ({'r_t':  -812.9372, 'eps':     0.1000, 'critic_loss':    43.6919, 'actor_loss':    -2.6500, 'eps_e':     0.1000})
Step:  286000, Reward:  -165.286 [  99.066], Avg:  -337.755 (0.100) <0-00:43:53> ({'r_t':  -840.8106, 'eps':     0.1000, 'critic_loss':    37.9909, 'actor_loss':    -2.7082, 'eps_e':     0.1000})
Step:  287000, Reward:  -193.105 [  89.048], Avg:  -337.253 (0.100) <0-00:44:02> ({'r_t':  -840.9443, 'eps':     0.1000, 'critic_loss':    42.4382, 'actor_loss':    -2.7325, 'eps_e':     0.1000})
Step:  288000, Reward:  -167.171 [  80.022], Avg:  -336.664 (0.100) <0-00:44:10> ({'r_t':  -747.1848, 'eps':     0.1000, 'critic_loss':    42.9097, 'actor_loss':    -2.7877, 'eps_e':     0.1000})
Step:  289000, Reward:  -171.090 [  89.124], Avg:  -336.093 (0.100) <0-00:44:19> ({'r_t':  -807.5125, 'eps':     0.1000, 'critic_loss':    39.7613, 'actor_loss':    -2.6732, 'eps_e':     0.1000})
Step:  290000, Reward:  -139.316 [  95.517], Avg:  -335.417 (0.100) <0-00:44:28> ({'r_t':  -778.6793, 'eps':     0.1000, 'critic_loss':    39.6419, 'actor_loss':    -2.4077, 'eps_e':     0.1000})
Step:  291000, Reward:  -119.876 [  99.273], Avg:  -334.679 (0.100) <0-00:44:37> ({'r_t':  -835.5650, 'eps':     0.1000, 'critic_loss':    41.6986, 'actor_loss':    -2.6007, 'eps_e':     0.1000})
Step:  292000, Reward:  -151.192 [ 104.373], Avg:  -334.053 (0.100) <0-00:44:46> ({'r_t':  -804.9154, 'eps':     0.1000, 'critic_loss':    42.3134, 'actor_loss':    -2.4456, 'eps_e':     0.1000})
Step:  293000, Reward:  -173.719 [  90.713], Avg:  -333.507 (0.100) <0-00:44:54> ({'r_t':  -863.6567, 'eps':     0.1000, 'critic_loss':    41.1738, 'actor_loss':    -2.4933, 'eps_e':     0.1000})
Step:  294000, Reward:  -190.824 [  72.250], Avg:  -333.024 (0.100) <0-00:45:03> ({'r_t':  -766.0791, 'eps':     0.1000, 'critic_loss':    40.5181, 'actor_loss':    -2.4605, 'eps_e':     0.1000})
Step:  295000, Reward:  -170.988 [ 115.130], Avg:  -332.476 (0.100) <0-00:45:12> ({'r_t':  -838.2605, 'eps':     0.1000, 'critic_loss':    42.4388, 'actor_loss':    -2.3240, 'eps_e':     0.1000})
Step:  296000, Reward:  -173.084 [  89.404], Avg:  -331.940 (0.100) <0-00:45:21> ({'r_t':  -820.5670, 'eps':     0.1000, 'critic_loss':    40.2611, 'actor_loss':    -2.1669, 'eps_e':     0.1000})
Step:  297000, Reward:  -197.575 [  91.227], Avg:  -331.489 (0.100) <0-00:45:30> ({'r_t':  -915.2701, 'eps':     0.1000, 'critic_loss':    40.4940, 'actor_loss':    -2.3851, 'eps_e':     0.1000})
Step:  298000, Reward:  -154.253 [  91.809], Avg:  -330.896 (0.100) <0-00:45:38> ({'r_t':  -799.1407, 'eps':     0.1000, 'critic_loss':    41.9129, 'actor_loss':    -2.2999, 'eps_e':     0.1000})
Step:  299000, Reward:  -137.442 [  82.670], Avg:  -330.251 (0.100) <0-00:45:47> ({'r_t':  -765.3527, 'eps':     0.1000, 'critic_loss':    38.5061, 'actor_loss':    -2.0162, 'eps_e':     0.1000})
Step:  300000, Reward:  -159.825 [ 101.315], Avg:  -329.685 (0.100) <0-00:45:56> ({'r_t':  -882.3571, 'eps':     0.1000, 'critic_loss':    38.5558, 'actor_loss':    -2.0630, 'eps_e':     0.1000})
Step:  301000, Reward:  -173.535 [  99.331], Avg:  -329.168 (0.100) <0-00:46:05> ({'r_t':  -791.2436, 'eps':     0.1000, 'critic_loss':    34.8457, 'actor_loss':    -2.1594, 'eps_e':     0.1000})
Step:  302000, Reward:  -117.393 [  66.758], Avg:  -328.469 (0.100) <0-00:46:14> ({'r_t':  -799.3797, 'eps':     0.1000, 'critic_loss':    36.6643, 'actor_loss':    -2.3492, 'eps_e':     0.1000})
Step:  303000, Reward:  -182.041 [ 114.933], Avg:  -327.987 (0.100) <0-00:46:23> ({'r_t':  -750.7411, 'eps':     0.1000, 'critic_loss':    35.6179, 'actor_loss':    -2.3614, 'eps_e':     0.1000})
Step:  304000, Reward:  -202.615 [ 123.069], Avg:  -327.576 (0.100) <0-00:46:31> ({'r_t':  -925.4867, 'eps':     0.1000, 'critic_loss':    32.5896, 'actor_loss':    -2.2730, 'eps_e':     0.1000})
Step:  305000, Reward:  -184.189 [ 148.493], Avg:  -327.108 (0.100) <0-00:46:40> ({'r_t':  -716.9877, 'eps':     0.1000, 'critic_loss':    34.0659, 'actor_loss':    -2.3660, 'eps_e':     0.1000})
Step:  306000, Reward:  -173.613 [ 110.455], Avg:  -326.608 (0.100) <0-00:46:49> ({'r_t':  -822.8737, 'eps':     0.1000, 'critic_loss':    35.1071, 'actor_loss':    -2.1317, 'eps_e':     0.1000})
Step:  307000, Reward:  -160.832 [  95.673], Avg:  -326.069 (0.100) <0-00:46:58> ({'r_t':  -851.3547, 'eps':     0.1000, 'critic_loss':    26.7292, 'actor_loss':    -1.8921, 'eps_e':     0.1000})
Step:  308000, Reward:  -150.140 [  59.915], Avg:  -325.500 (0.100) <0-00:47:07> ({'r_t':  -863.6882, 'eps':     0.1000, 'critic_loss':    25.3775, 'actor_loss':    -1.7406, 'eps_e':     0.1000})
Step:  309000, Reward:  -149.756 [  85.052], Avg:  -324.933 (0.100) <0-00:47:16> ({'r_t':  -914.1647, 'eps':     0.1000, 'critic_loss':    25.4241, 'actor_loss':    -1.5551, 'eps_e':     0.1000})
Step:  310000, Reward:  -194.360 [  93.362], Avg:  -324.513 (0.100) <0-00:47:24> ({'r_t':  -803.0712, 'eps':     0.1000, 'critic_loss':    25.2289, 'actor_loss':    -1.5756, 'eps_e':     0.1000})
Step:  311000, Reward:  -179.995 [  76.802], Avg:  -324.050 (0.100) <0-00:47:33> ({'r_t':  -798.0816, 'eps':     0.1000, 'critic_loss':    25.4148, 'actor_loss':    -1.3388, 'eps_e':     0.1000})
Step:  312000, Reward:  -117.293 [  71.710], Avg:  -323.389 (0.100) <0-00:47:42> ({'r_t':  -834.1019, 'eps':     0.1000, 'critic_loss':    22.5546, 'actor_loss':    -1.2121, 'eps_e':     0.1000})
Step:  313000, Reward:  -107.708 [  61.802], Avg:  -322.703 (0.100) <0-00:47:51> ({'r_t':  -807.7376, 'eps':     0.1000, 'critic_loss':    26.3458, 'actor_loss':    -1.2094, 'eps_e':     0.1000})
Step:  314000, Reward:  -197.973 [ 112.340], Avg:  -322.307 (0.100) <0-00:48:00> ({'r_t':  -800.6249, 'eps':     0.1000, 'critic_loss':    29.8857, 'actor_loss':    -1.1289, 'eps_e':     0.1000})
Step:  315000, Reward:  -162.815 [  57.239], Avg:  -321.802 (0.100) <0-00:48:08> ({'r_t':  -774.4865, 'eps':     0.1000, 'critic_loss':    23.6577, 'actor_loss':    -1.1574, 'eps_e':     0.1000})
Step:  316000, Reward:  -207.406 [  62.052], Avg:  -321.441 (0.100) <0-00:48:17> ({'r_t':  -697.3057, 'eps':     0.1000, 'critic_loss':    24.9909, 'actor_loss':    -1.3640, 'eps_e':     0.1000})
Step:  317000, Reward:  -154.653 [  91.005], Avg:  -320.917 (0.100) <0-00:48:26> ({'r_t':  -842.7919, 'eps':     0.1000, 'critic_loss':    23.6288, 'actor_loss':    -1.2655, 'eps_e':     0.1000})
Step:  318000, Reward:  -187.677 [  90.649], Avg:  -320.499 (0.100) <0-00:48:35> ({'r_t':  -847.5795, 'eps':     0.1000, 'critic_loss':    17.9324, 'actor_loss':    -1.3601, 'eps_e':     0.1000})
Step:  319000, Reward:  -167.360 [  88.041], Avg:  -320.020 (0.100) <0-00:48:44> ({'r_t':  -831.7165, 'eps':     0.1000, 'critic_loss':    18.0271, 'actor_loss':    -1.2830, 'eps_e':     0.1000})
Step:  320000, Reward:  -144.108 [  87.108], Avg:  -319.472 (0.100) <0-00:48:52> ({'r_t':  -811.2845, 'eps':     0.1000, 'critic_loss':    17.5375, 'actor_loss':    -1.2139, 'eps_e':     0.1000})
Step:  321000, Reward:  -176.150 [ 107.231], Avg:  -319.027 (0.100) <0-00:49:01> ({'r_t':  -829.7053, 'eps':     0.1000, 'critic_loss':    15.9928, 'actor_loss':    -1.2708, 'eps_e':     0.1000})
Step:  322000, Reward:  -166.966 [  90.968], Avg:  -318.556 (0.100) <0-00:49:10> ({'r_t':  -863.2489, 'eps':     0.1000, 'critic_loss':    14.5907, 'actor_loss':    -1.2470, 'eps_e':     0.1000})
Step:  323000, Reward:  -166.945 [  65.539], Avg:  -318.088 (0.100) <0-00:49:19> ({'r_t':  -832.1343, 'eps':     0.1000, 'critic_loss':    15.1537, 'actor_loss':    -1.3248, 'eps_e':     0.1000})
Step:  324000, Reward:  -129.178 [  72.208], Avg:  -317.507 (0.100) <0-00:49:28> ({'r_t':  -758.9098, 'eps':     0.1000, 'critic_loss':    15.7389, 'actor_loss':    -1.3122, 'eps_e':     0.1000})
Step:  325000, Reward:  -121.488 [  77.283], Avg:  -316.906 (0.100) <0-00:49:36> ({'r_t':  -863.1552, 'eps':     0.1000, 'critic_loss':    15.1626, 'actor_loss':    -1.2948, 'eps_e':     0.1000})
Step:  326000, Reward:  -160.365 [  49.661], Avg:  -316.427 (0.100) <0-00:49:45> ({'r_t':  -826.0997, 'eps':     0.1000, 'critic_loss':    13.4327, 'actor_loss':    -1.2010, 'eps_e':     0.1000})
Step:  327000, Reward:  -150.162 [ 117.928], Avg:  -315.920 (0.100) <0-00:49:54> ({'r_t':  -794.6817, 'eps':     0.1000, 'critic_loss':    14.2483, 'actor_loss':    -1.2071, 'eps_e':     0.1000})
Step:  328000, Reward:  -164.305 [  63.742], Avg:  -315.459 (0.100) <0-00:50:03> ({'r_t':  -866.0184, 'eps':     0.1000, 'critic_loss':    12.4337, 'actor_loss':    -1.2676, 'eps_e':     0.1000})
Step:  329000, Reward:  -198.585 [ 110.147], Avg:  -315.105 (0.100) <0-00:50:12> ({'r_t':  -861.4552, 'eps':     0.1000, 'critic_loss':    15.6786, 'actor_loss':    -1.3095, 'eps_e':     0.1000})
Step:  330000, Reward:  -161.313 [  66.552], Avg:  -314.641 (0.100) <0-00:50:21> ({'r_t':  -743.5477, 'eps':     0.1000, 'critic_loss':    15.0204, 'actor_loss':    -1.4347, 'eps_e':     0.1000})
Step:  331000, Reward:  -191.634 [ 108.175], Avg:  -314.270 (0.100) <0-00:50:29> ({'r_t':  -966.9497, 'eps':     0.1000, 'critic_loss':    13.0618, 'actor_loss':    -1.3043, 'eps_e':     0.1000})
Step:  332000, Reward:  -192.380 [ 103.903], Avg:  -313.904 (0.100) <0-00:50:38> ({'r_t':  -823.8019, 'eps':     0.1000, 'critic_loss':    13.3321, 'actor_loss':    -1.2996, 'eps_e':     0.1000})
Step:  333000, Reward:   -96.485 [  76.255], Avg:  -313.253 (0.100) <0-00:50:47> ({'r_t':  -848.8017, 'eps':     0.1000, 'critic_loss':    14.8937, 'actor_loss':    -1.3194, 'eps_e':     0.1000})
Step:  334000, Reward:  -147.702 [  85.496], Avg:  -312.759 (0.100) <0-00:50:56> ({'r_t':  -775.3146, 'eps':     0.1000, 'critic_loss':    13.3710, 'actor_loss':    -1.2728, 'eps_e':     0.1000})
Step:  335000, Reward:  -142.473 [  78.280], Avg:  -312.252 (0.100) <0-00:51:05> ({'r_t':  -822.1694, 'eps':     0.1000, 'critic_loss':    13.5101, 'actor_loss':    -1.2237, 'eps_e':     0.1000})
Step:  336000, Reward:  -209.282 [  97.513], Avg:  -311.947 (0.100) <0-00:51:14> ({'r_t':  -800.9432, 'eps':     0.1000, 'critic_loss':    13.0300, 'actor_loss':    -1.2320, 'eps_e':     0.1000})
Step:  337000, Reward:  -189.597 [ 129.622], Avg:  -311.585 (0.100) <0-00:51:23> ({'r_t':  -931.2572, 'eps':     0.1000, 'critic_loss':    14.2437, 'actor_loss':    -1.2479, 'eps_e':     0.1000})
Step:  338000, Reward:  -191.412 [ 103.647], Avg:  -311.230 (0.100) <0-00:51:32> ({'r_t':  -739.6899, 'eps':     0.1000, 'critic_loss':    12.6786, 'actor_loss':    -1.2544, 'eps_e':     0.1000})
Step:  339000, Reward:  -177.221 [  76.942], Avg:  -310.836 (0.100) <0-00:51:40> ({'r_t':  -787.2661, 'eps':     0.1000, 'critic_loss':    15.9170, 'actor_loss':    -1.2546, 'eps_e':     0.1000})
Step:  340000, Reward:  -204.275 [ 116.061], Avg:  -310.524 (0.100) <0-00:51:49> ({'r_t':  -941.8342, 'eps':     0.1000, 'critic_loss':    14.6015, 'actor_loss':    -1.2357, 'eps_e':     0.1000})
Step:  341000, Reward:  -231.793 [ 119.145], Avg:  -310.293 (0.100) <0-00:51:58> ({'r_t':  -818.4341, 'eps':     0.1000, 'critic_loss':    13.0677, 'actor_loss':    -1.2517, 'eps_e':     0.1000})
Step:  342000, Reward:  -195.647 [  87.806], Avg:  -309.959 (0.100) <0-00:52:07> ({'r_t':  -863.8886, 'eps':     0.1000, 'critic_loss':    13.8902, 'actor_loss':    -1.0942, 'eps_e':     0.1000})
Step:  343000, Reward:  -154.700 [  81.222], Avg:  -309.508 (0.100) <0-00:52:16> ({'r_t':  -831.5988, 'eps':     0.1000, 'critic_loss':    15.2034, 'actor_loss':    -0.9978, 'eps_e':     0.1000})
Step:  344000, Reward:  -161.245 [  84.560], Avg:  -309.078 (0.100) <0-00:52:25> ({'r_t':  -829.1371, 'eps':     0.1000, 'critic_loss':    13.4077, 'actor_loss':    -1.0529, 'eps_e':     0.1000})
Step:  345000, Reward:  -136.265 [  80.869], Avg:  -308.579 (0.100) <0-00:52:33> ({'r_t':  -858.6725, 'eps':     0.1000, 'critic_loss':    13.8179, 'actor_loss':    -1.0511, 'eps_e':     0.1000})
Step:  346000, Reward:  -164.822 [  91.618], Avg:  -308.164 (0.100) <0-00:52:42> ({'r_t':  -770.7030, 'eps':     0.1000, 'critic_loss':    13.7139, 'actor_loss':    -1.0006, 'eps_e':     0.1000})
Step:  347000, Reward:  -155.297 [  82.776], Avg:  -307.725 (0.100) <0-00:52:51> ({'r_t':  -881.8454, 'eps':     0.1000, 'critic_loss':    14.0755, 'actor_loss':    -0.9396, 'eps_e':     0.1000})
Step:  348000, Reward:  -137.340 [  92.636], Avg:  -307.237 (0.100) <0-00:53:00> ({'r_t':  -794.1272, 'eps':     0.1000, 'critic_loss':    13.2475, 'actor_loss':    -0.9758, 'eps_e':     0.1000})
Step:  349000, Reward:  -165.466 [ 123.041], Avg:  -306.832 (0.100) <0-00:53:09> ({'r_t':  -816.1214, 'eps':     0.1000, 'critic_loss':    12.7498, 'actor_loss':    -0.9232, 'eps_e':     0.1000})
Step:  350000, Reward:  -173.322 [ 107.914], Avg:  -306.451 (0.100) <0-00:53:17> ({'r_t':  -757.4428, 'eps':     0.1000, 'critic_loss':    13.5736, 'actor_loss':    -0.8536, 'eps_e':     0.1000})
Step:  351000, Reward:  -148.449 [  91.728], Avg:  -306.002 (0.100) <0-00:53:26> ({'r_t':  -772.4370, 'eps':     0.1000, 'critic_loss':    15.5377, 'actor_loss':    -0.7907, 'eps_e':     0.1000})
Step:  352000, Reward:  -150.114 [ 110.103], Avg:  -305.561 (0.100) <0-00:53:35> ({'r_t':  -830.2897, 'eps':     0.1000, 'critic_loss':    13.3659, 'actor_loss':    -0.8016, 'eps_e':     0.1000})
Step:  353000, Reward:  -120.449 [  80.327], Avg:  -305.038 (0.100) <0-00:53:44> ({'r_t':  -863.0626, 'eps':     0.1000, 'critic_loss':    13.0430, 'actor_loss':    -0.8216, 'eps_e':     0.1000})
Step:  354000, Reward:  -136.723 [  79.314], Avg:  -304.564 (0.100) <0-00:53:52> ({'r_t':  -795.2584, 'eps':     0.1000, 'critic_loss':    13.6294, 'actor_loss':    -0.8561, 'eps_e':     0.1000})
Step:  355000, Reward:  -138.297 [  95.027], Avg:  -304.097 (0.100) <0-00:54:01> ({'r_t':  -748.3136, 'eps':     0.1000, 'critic_loss':    14.4226, 'actor_loss':    -0.8568, 'eps_e':     0.1000})
Step:  356000, Reward:  -163.646 [  75.462], Avg:  -303.703 (0.100) <0-00:54:10> ({'r_t':  -811.0393, 'eps':     0.1000, 'critic_loss':    12.8073, 'actor_loss':    -0.8041, 'eps_e':     0.1000})
Step:  357000, Reward:  -133.405 [  74.077], Avg:  -303.228 (0.100) <0-00:54:19> ({'r_t':  -830.6010, 'eps':     0.1000, 'critic_loss':    12.5823, 'actor_loss':    -0.8292, 'eps_e':     0.1000})
Step:  358000, Reward:  -141.257 [  78.084], Avg:  -302.776 (0.100) <0-00:54:28> ({'r_t':  -864.7327, 'eps':     0.1000, 'critic_loss':    14.6611, 'actor_loss':    -0.8558, 'eps_e':     0.1000})
Step:  359000, Reward:  -199.295 [  92.172], Avg:  -302.489 (0.100) <0-00:54:36> ({'r_t':  -837.8476, 'eps':     0.1000, 'critic_loss':    13.9718, 'actor_loss':    -0.8213, 'eps_e':     0.1000})
Step:  360000, Reward:  -155.914 [  93.738], Avg:  -302.083 (0.100) <0-00:54:45> ({'r_t':  -785.4162, 'eps':     0.1000, 'critic_loss':    14.1319, 'actor_loss':    -0.8538, 'eps_e':     0.1000})
Step:  361000, Reward:  -124.812 [  58.448], Avg:  -301.593 (0.100) <0-00:54:54> ({'r_t':  -812.4973, 'eps':     0.1000, 'critic_loss':    15.4201, 'actor_loss':    -0.9036, 'eps_e':     0.1000})
Step:  362000, Reward:  -191.047 [  91.819], Avg:  -301.289 (0.100) <0-00:55:03> ({'r_t':  -738.4991, 'eps':     0.1000, 'critic_loss':    13.6683, 'actor_loss':    -0.9016, 'eps_e':     0.1000})
Step:  363000, Reward:  -113.228 [  84.081], Avg:  -300.772 (0.100) <0-00:55:12> ({'r_t':  -791.8529, 'eps':     0.1000, 'critic_loss':    14.6152, 'actor_loss':    -0.8897, 'eps_e':     0.1000})
Step:  364000, Reward:  -135.339 [  98.658], Avg:  -300.319 (0.100) <0-00:55:20> ({'r_t':  -802.6991, 'eps':     0.1000, 'critic_loss':    14.0552, 'actor_loss':    -0.9684, 'eps_e':     0.1000})
Step:  365000, Reward:  -131.861 [  65.622], Avg:  -299.859 (0.100) <0-00:55:30> ({'r_t':  -840.5997, 'eps':     0.1000, 'critic_loss':    16.1869, 'actor_loss':    -0.8331, 'eps_e':     0.1000})
Step:  366000, Reward:  -134.934 [  76.047], Avg:  -299.409 (0.100) <0-00:55:38> ({'r_t':  -784.2159, 'eps':     0.1000, 'critic_loss':    14.7372, 'actor_loss':    -0.9170, 'eps_e':     0.1000})
Step:  367000, Reward:  -166.735 [ 100.432], Avg:  -299.049 (0.100) <0-00:55:47> ({'r_t':  -831.6706, 'eps':     0.1000, 'critic_loss':    13.3638, 'actor_loss':    -0.9553, 'eps_e':     0.1000})
Step:  368000, Reward:  -164.120 [ 104.526], Avg:  -298.683 (0.100) <0-00:55:56> ({'r_t':  -824.6103, 'eps':     0.1000, 'critic_loss':    12.9869, 'actor_loss':    -0.8851, 'eps_e':     0.1000})
Step:  369000, Reward:  -159.248 [  79.984], Avg:  -298.306 (0.100) <0-00:56:05> ({'r_t':  -781.6343, 'eps':     0.1000, 'critic_loss':    12.8383, 'actor_loss':    -0.8853, 'eps_e':     0.1000})
Step:  370000, Reward:  -173.683 [ 114.895], Avg:  -297.970 (0.100) <0-00:56:14> ({'r_t':  -765.0596, 'eps':     0.1000, 'critic_loss':    12.3893, 'actor_loss':    -0.9181, 'eps_e':     0.1000})
Step:  371000, Reward:  -175.352 [ 108.098], Avg:  -297.641 (0.100) <0-00:56:22> ({'r_t':  -740.0261, 'eps':     0.1000, 'critic_loss':    12.3710, 'actor_loss':    -0.8582, 'eps_e':     0.1000})
Step:  372000, Reward:  -216.035 [  91.275], Avg:  -297.422 (0.100) <0-00:56:31> ({'r_t':  -852.2931, 'eps':     0.1000, 'critic_loss':    12.2360, 'actor_loss':    -0.9175, 'eps_e':     0.1000})
Step:  373000, Reward:  -193.940 [ 114.538], Avg:  -297.145 (0.100) <0-00:56:40> ({'r_t':  -785.8608, 'eps':     0.1000, 'critic_loss':    13.1666, 'actor_loss':    -0.8841, 'eps_e':     0.1000})
Step:  374000, Reward:  -200.391 [  92.992], Avg:  -296.887 (0.100) <0-00:56:49> ({'r_t':  -804.9513, 'eps':     0.1000, 'critic_loss':    11.4404, 'actor_loss':    -0.8199, 'eps_e':     0.1000})
Step:  375000, Reward:  -168.833 [  79.948], Avg:  -296.547 (0.100) <0-00:56:58> ({'r_t':  -782.2536, 'eps':     0.1000, 'critic_loss':    11.1072, 'actor_loss':    -0.8834, 'eps_e':     0.1000})
Step:  376000, Reward:  -126.007 [  84.856], Avg:  -296.094 (0.100) <0-00:57:06> ({'r_t':  -898.0295, 'eps':     0.1000, 'critic_loss':    12.8076, 'actor_loss':    -0.8768, 'eps_e':     0.1000})
Step:  377000, Reward:  -148.248 [  88.174], Avg:  -295.703 (0.100) <0-00:57:15> ({'r_t':  -863.0141, 'eps':     0.1000, 'critic_loss':    11.0641, 'actor_loss':    -0.7710, 'eps_e':     0.1000})
Step:  378000, Reward:   -99.277 [  74.942], Avg:  -295.185 (0.100) <0-00:57:24> ({'r_t':  -902.2805, 'eps':     0.1000, 'critic_loss':    11.5002, 'actor_loss':    -0.8262, 'eps_e':     0.1000})
Step:  379000, Reward:  -141.641 [  82.926], Avg:  -294.781 (0.100) <0-00:57:33> ({'r_t':  -820.3549, 'eps':     0.1000, 'critic_loss':    11.7534, 'actor_loss':    -0.7230, 'eps_e':     0.1000})
Step:  380000, Reward:  -131.186 [ 100.305], Avg:  -294.351 (0.100) <0-00:57:42> ({'r_t':  -755.6282, 'eps':     0.1000, 'critic_loss':    11.2352, 'actor_loss':    -0.7514, 'eps_e':     0.1000})
Step:  381000, Reward:  -179.388 [ 115.555], Avg:  -294.050 (0.100) <0-00:57:51> ({'r_t':  -843.4951, 'eps':     0.1000, 'critic_loss':    11.3146, 'actor_loss':    -0.8126, 'eps_e':     0.1000})
Step:  382000, Reward:  -155.122 [  75.161], Avg:  -293.688 (0.100) <0-00:57:59> ({'r_t':  -844.5187, 'eps':     0.1000, 'critic_loss':    13.0995, 'actor_loss':    -0.7746, 'eps_e':     0.1000})
Step:  383000, Reward:  -146.326 [ 108.857], Avg:  -293.304 (0.100) <0-00:58:08> ({'r_t':  -796.7936, 'eps':     0.1000, 'critic_loss':    11.3049, 'actor_loss':    -0.7528, 'eps_e':     0.1000})
Step:  384000, Reward:  -179.357 [  79.942], Avg:  -293.008 (0.100) <0-00:58:17> ({'r_t':  -735.8044, 'eps':     0.1000, 'critic_loss':    11.2906, 'actor_loss':    -0.7648, 'eps_e':     0.1000})
Step:  385000, Reward:  -158.920 [  78.872], Avg:  -292.661 (0.100) <0-00:58:26> ({'r_t':  -862.3256, 'eps':     0.1000, 'critic_loss':    12.9856, 'actor_loss':    -0.7552, 'eps_e':     0.1000})
Step:  386000, Reward:  -184.212 [  86.603], Avg:  -292.380 (0.100) <0-00:58:35> ({'r_t':  -854.3207, 'eps':     0.1000, 'critic_loss':    11.5631, 'actor_loss':    -0.7596, 'eps_e':     0.1000})
Step:  387000, Reward:  -149.575 [  83.711], Avg:  -292.012 (0.100) <0-00:58:43> ({'r_t':  -774.6888, 'eps':     0.1000, 'critic_loss':    11.2806, 'actor_loss':    -0.7251, 'eps_e':     0.1000})
Step:  388000, Reward:  -160.968 [ 119.826], Avg:  -291.675 (0.100) <0-00:58:52> ({'r_t':  -852.7837, 'eps':     0.1000, 'critic_loss':    11.3450, 'actor_loss':    -0.6824, 'eps_e':     0.1000})
Step:  389000, Reward:  -197.179 [ 101.258], Avg:  -291.433 (0.100) <0-00:59:01> ({'r_t':  -812.0631, 'eps':     0.1000, 'critic_loss':    11.5891, 'actor_loss':    -0.6696, 'eps_e':     0.1000})
Step:  390000, Reward:  -144.022 [  70.367], Avg:  -291.056 (0.100) <0-00:59:10> ({'r_t':  -809.6209, 'eps':     0.1000, 'critic_loss':    11.9795, 'actor_loss':    -0.7085, 'eps_e':     0.1000})
Step:  391000, Reward:  -149.370 [ 110.999], Avg:  -290.695 (0.100) <0-00:59:19> ({'r_t':  -849.5005, 'eps':     0.1000, 'critic_loss':    10.5481, 'actor_loss':    -0.7037, 'eps_e':     0.1000})
Step:  392000, Reward:  -164.888 [  88.797], Avg:  -290.375 (0.100) <0-00:59:28> ({'r_t':  -703.2952, 'eps':     0.1000, 'critic_loss':    11.8514, 'actor_loss':    -0.7256, 'eps_e':     0.1000})
Step:  393000, Reward:  -121.307 [  71.290], Avg:  -289.945 (0.100) <0-00:59:36> ({'r_t':  -855.7836, 'eps':     0.1000, 'critic_loss':    11.9862, 'actor_loss':    -0.6783, 'eps_e':     0.1000})
Step:  394000, Reward:  -151.754 [  48.577], Avg:  -289.596 (0.100) <0-00:59:45> ({'r_t':  -668.7797, 'eps':     0.1000, 'critic_loss':    11.3005, 'actor_loss':    -0.6518, 'eps_e':     0.1000})
Step:  395000, Reward:  -143.581 [  60.897], Avg:  -289.227 (0.100) <0-00:59:54> ({'r_t':  -871.8945, 'eps':     0.1000, 'critic_loss':    10.4051, 'actor_loss':    -0.6792, 'eps_e':     0.1000})
Step:  396000, Reward:  -208.987 [  93.641], Avg:  -289.025 (0.100) <0-01:00:03> ({'r_t':  -843.3214, 'eps':     0.1000, 'critic_loss':    11.6329, 'actor_loss':    -0.6895, 'eps_e':     0.1000})
Step:  397000, Reward:  -143.508 [  85.646], Avg:  -288.659 (0.100) <0-01:00:12> ({'r_t':  -832.8756, 'eps':     0.1000, 'critic_loss':    12.0520, 'actor_loss':    -0.7021, 'eps_e':     0.1000})
Step:  398000, Reward:  -175.142 [  93.413], Avg:  -288.375 (0.100) <0-01:00:20> ({'r_t':  -849.8492, 'eps':     0.1000, 'critic_loss':     9.9256, 'actor_loss':    -0.6881, 'eps_e':     0.1000})
Step:  399000, Reward:  -172.340 [ 101.631], Avg:  -288.085 (0.100) <0-01:00:29> ({'r_t':  -776.5284, 'eps':     0.1000, 'critic_loss':    10.8788, 'actor_loss':    -0.7072, 'eps_e':     0.1000})
Step:  400000, Reward:  -156.316 [  86.414], Avg:  -287.756 (0.100) <0-01:00:38> ({'r_t':  -741.8629, 'eps':     0.1000, 'critic_loss':    10.0353, 'actor_loss':    -0.7103, 'eps_e':     0.1000})
Step:  401000, Reward:  -187.549 [  86.311], Avg:  -287.507 (0.100) <0-01:00:47> ({'r_t':  -854.5867, 'eps':     0.1000, 'critic_loss':    11.3867, 'actor_loss':    -0.6676, 'eps_e':     0.1000})
Step:  402000, Reward:  -158.093 [  74.067], Avg:  -287.186 (0.100) <0-01:00:56> ({'r_t':  -851.6008, 'eps':     0.1000, 'critic_loss':    11.7162, 'actor_loss':    -0.6451, 'eps_e':     0.1000})
Step:  403000, Reward:  -162.794 [  79.807], Avg:  -286.878 (0.100) <0-01:01:05> ({'r_t':  -837.2051, 'eps':     0.1000, 'critic_loss':    11.4016, 'actor_loss':    -0.6480, 'eps_e':     0.1000})
Step:  404000, Reward:  -174.483 [ 106.758], Avg:  -286.600 (0.100) <0-01:01:13> ({'r_t':  -829.9129, 'eps':     0.1000, 'critic_loss':    10.6490, 'actor_loss':    -0.6693, 'eps_e':     0.1000})
Step:  405000, Reward:  -147.879 [  88.968], Avg:  -286.258 (0.100) <0-01:01:22> ({'r_t':  -791.2988, 'eps':     0.1000, 'critic_loss':    11.2634, 'actor_loss':    -0.6432, 'eps_e':     0.1000})
Step:  406000, Reward:  -191.181 [ 105.217], Avg:  -286.025 (0.100) <0-01:01:31> ({'r_t':  -899.4229, 'eps':     0.1000, 'critic_loss':    10.6925, 'actor_loss':    -0.6541, 'eps_e':     0.1000})
Step:  407000, Reward:  -136.499 [  80.778], Avg:  -285.658 (0.100) <0-01:01:40> ({'r_t':  -903.6637, 'eps':     0.1000, 'critic_loss':    11.6815, 'actor_loss':    -0.6878, 'eps_e':     0.1000})
Step:  408000, Reward:  -134.029 [  89.186], Avg:  -285.288 (0.100) <0-01:01:49> ({'r_t':  -795.6618, 'eps':     0.1000, 'critic_loss':    10.8085, 'actor_loss':    -0.6470, 'eps_e':     0.1000})
Step:  409000, Reward:  -167.132 [  79.064], Avg:  -284.999 (0.100) <0-01:01:57> ({'r_t':  -778.7724, 'eps':     0.1000, 'critic_loss':    11.4980, 'actor_loss':    -0.6560, 'eps_e':     0.1000})
Step:  410000, Reward:   -99.566 [  75.049], Avg:  -284.548 (0.100) <0-01:02:06> ({'r_t':  -771.6556, 'eps':     0.1000, 'critic_loss':    12.8112, 'actor_loss':    -0.6636, 'eps_e':     0.1000})
Step:  411000, Reward:  -154.567 [  82.487], Avg:  -284.233 (0.100) <0-01:02:15> ({'r_t':  -755.8591, 'eps':     0.1000, 'critic_loss':    10.1095, 'actor_loss':    -0.6127, 'eps_e':     0.1000})
Step:  412000, Reward:  -152.287 [ 105.878], Avg:  -283.913 (0.100) <0-01:02:24> ({'r_t':  -789.9790, 'eps':     0.1000, 'critic_loss':    10.8803, 'actor_loss':    -0.6400, 'eps_e':     0.1000})
Step:  413000, Reward:  -156.591 [  66.354], Avg:  -283.606 (0.100) <0-01:02:33> ({'r_t':  -772.5410, 'eps':     0.1000, 'critic_loss':    10.2060, 'actor_loss':    -0.5985, 'eps_e':     0.1000})
Step:  414000, Reward:  -180.456 [  91.307], Avg:  -283.357 (0.100) <0-01:02:42> ({'r_t':  -786.6179, 'eps':     0.1000, 'critic_loss':    10.5988, 'actor_loss':    -0.6419, 'eps_e':     0.1000})
Step:  415000, Reward:  -174.659 [ 104.641], Avg:  -283.096 (0.100) <0-01:02:50> ({'r_t':  -911.6354, 'eps':     0.1000, 'critic_loss':    10.4323, 'actor_loss':    -0.6101, 'eps_e':     0.1000})
Step:  416000, Reward:  -132.431 [  72.954], Avg:  -282.735 (0.100) <0-01:02:59> ({'r_t':  -778.0022, 'eps':     0.1000, 'critic_loss':    11.0292, 'actor_loss':    -0.5780, 'eps_e':     0.1000})
Step:  417000, Reward:  -173.740 [ 102.238], Avg:  -282.474 (0.100) <0-01:03:08> ({'r_t':  -734.2159, 'eps':     0.1000, 'critic_loss':    11.5471, 'actor_loss':    -0.6109, 'eps_e':     0.1000})
Step:  418000, Reward:  -167.497 [  83.116], Avg:  -282.199 (0.100) <0-01:03:17> ({'r_t':  -811.7897, 'eps':     0.1000, 'critic_loss':    10.7962, 'actor_loss':    -0.6121, 'eps_e':     0.1000})
Step:  419000, Reward:  -165.222 [  81.559], Avg:  -281.921 (0.100) <0-01:03:26> ({'r_t':  -764.6583, 'eps':     0.1000, 'critic_loss':    11.8572, 'actor_loss':    -0.5924, 'eps_e':     0.1000})
Step:  420000, Reward:  -198.074 [ 100.445], Avg:  -281.722 (0.100) <0-01:03:35> ({'r_t':  -763.3744, 'eps':     0.1000, 'critic_loss':    12.3432, 'actor_loss':    -0.6306, 'eps_e':     0.1000})
Step:  421000, Reward:  -233.341 [ 120.611], Avg:  -281.607 (0.100) <0-01:03:43> ({'r_t':  -850.7589, 'eps':     0.1000, 'critic_loss':    11.8274, 'actor_loss':    -0.6216, 'eps_e':     0.1000})
Step:  422000, Reward:  -180.178 [  69.673], Avg:  -281.367 (0.100) <0-01:03:52> ({'r_t':  -860.9324, 'eps':     0.1000, 'critic_loss':    11.7183, 'actor_loss':    -0.6310, 'eps_e':     0.1000})
Step:  423000, Reward:  -162.635 [  89.993], Avg:  -281.087 (0.100) <0-01:04:01> ({'r_t':  -830.3108, 'eps':     0.1000, 'critic_loss':    11.7882, 'actor_loss':    -0.5770, 'eps_e':     0.1000})
Step:  424000, Reward:  -157.383 [  65.278], Avg:  -280.796 (0.100) <0-01:04:10> ({'r_t':  -818.1073, 'eps':     0.1000, 'critic_loss':    12.2260, 'actor_loss':    -0.5906, 'eps_e':     0.1000})
Step:  425000, Reward:  -143.334 [  59.524], Avg:  -280.474 (0.100) <0-01:04:19> ({'r_t':  -893.2015, 'eps':     0.1000, 'critic_loss':    10.4149, 'actor_loss':    -0.6176, 'eps_e':     0.1000})
Step:  426000, Reward:  -177.327 [  96.865], Avg:  -280.232 (0.100) <0-01:04:28> ({'r_t':  -786.6128, 'eps':     0.1000, 'critic_loss':    11.7889, 'actor_loss':    -0.5986, 'eps_e':     0.1000})
Step:  427000, Reward:  -174.793 [  74.878], Avg:  -279.986 (0.100) <0-01:04:36> ({'r_t':  -721.1310, 'eps':     0.1000, 'critic_loss':    12.0343, 'actor_loss':    -0.6083, 'eps_e':     0.1000})
Step:  428000, Reward:  -171.478 [ 125.905], Avg:  -279.733 (0.100) <0-01:04:45> ({'r_t':  -744.7889, 'eps':     0.1000, 'critic_loss':    10.1354, 'actor_loss':    -0.6035, 'eps_e':     0.1000})
Step:  429000, Reward:  -194.995 [  69.693], Avg:  -279.536 (0.100) <0-01:04:54> ({'r_t':  -816.7151, 'eps':     0.1000, 'critic_loss':    12.6339, 'actor_loss':    -0.5817, 'eps_e':     0.1000})
Step:  430000, Reward:  -177.909 [  87.656], Avg:  -279.300 (0.100) <0-01:05:03> ({'r_t':  -831.1326, 'eps':     0.1000, 'critic_loss':    10.6966, 'actor_loss':    -0.5522, 'eps_e':     0.1000})
Step:  431000, Reward:  -164.935 [  80.042], Avg:  -279.035 (0.100) <0-01:05:12> ({'r_t':  -788.0440, 'eps':     0.1000, 'critic_loss':    11.1792, 'actor_loss':    -0.5430, 'eps_e':     0.1000})
Step:  432000, Reward:  -152.389 [  79.690], Avg:  -278.743 (0.100) <0-01:05:21> ({'r_t':  -684.9308, 'eps':     0.1000, 'critic_loss':    10.7045, 'actor_loss':    -0.5087, 'eps_e':     0.1000})
Step:  433000, Reward:  -157.385 [  69.233], Avg:  -278.463 (0.100) <0-01:05:30> ({'r_t':  -812.6050, 'eps':     0.1000, 'critic_loss':    10.7744, 'actor_loss':    -0.5747, 'eps_e':     0.1000})
Step:  434000, Reward:  -143.410 [  82.905], Avg:  -278.153 (0.100) <0-01:05:39> ({'r_t':  -713.4037, 'eps':     0.1000, 'critic_loss':    11.2217, 'actor_loss':    -0.5483, 'eps_e':     0.1000})
Step:  435000, Reward:  -157.375 [  76.677], Avg:  -277.876 (0.100) <0-01:05:47> ({'r_t':  -773.1742, 'eps':     0.1000, 'critic_loss':    11.3880, 'actor_loss':    -0.5911, 'eps_e':     0.1000})
Step:  436000, Reward:  -167.279 [  72.060], Avg:  -277.622 (0.100) <0-01:05:56> ({'r_t':  -814.1600, 'eps':     0.1000, 'critic_loss':     8.9794, 'actor_loss':    -0.6026, 'eps_e':     0.1000})
Step:  437000, Reward:  -190.732 [  95.516], Avg:  -277.424 (0.100) <0-01:06:05> ({'r_t':  -890.0419, 'eps':     0.1000, 'critic_loss':    10.8270, 'actor_loss':    -0.5934, 'eps_e':     0.1000})
Step:  438000, Reward:   -98.953 [  61.867], Avg:  -277.018 (0.100) <0-01:06:14> ({'r_t':  -797.5903, 'eps':     0.1000, 'critic_loss':    11.7249, 'actor_loss':    -0.5789, 'eps_e':     0.1000})
Step:  439000, Reward:  -163.923 [ 111.288], Avg:  -276.761 (0.100) <0-01:06:23> ({'r_t':  -872.8005, 'eps':     0.1000, 'critic_loss':    11.3442, 'actor_loss':    -0.5707, 'eps_e':     0.1000})
Step:  440000, Reward:  -183.895 [  97.682], Avg:  -276.550 (0.100) <0-01:06:31> ({'r_t':  -840.0312, 'eps':     0.1000, 'critic_loss':    10.9304, 'actor_loss':    -0.6061, 'eps_e':     0.1000})
Step:  441000, Reward:  -112.625 [  65.611], Avg:  -276.179 (0.100) <0-01:06:40> ({'r_t':  -785.1598, 'eps':     0.1000, 'critic_loss':    10.5346, 'actor_loss':    -0.5996, 'eps_e':     0.1000})
Step:  442000, Reward:  -145.844 [  98.425], Avg:  -275.885 (0.100) <0-01:06:49> ({'r_t':  -779.9725, 'eps':     0.1000, 'critic_loss':    10.6067, 'actor_loss':    -0.6110, 'eps_e':     0.1000})
Step:  443000, Reward:  -163.481 [  77.633], Avg:  -275.632 (0.100) <0-01:06:58> ({'r_t':  -818.4873, 'eps':     0.1000, 'critic_loss':    10.8333, 'actor_loss':    -0.6051, 'eps_e':     0.1000})
Step:  444000, Reward:  -139.838 [  83.241], Avg:  -275.327 (0.100) <0-01:07:07> ({'r_t':  -795.9158, 'eps':     0.1000, 'critic_loss':    10.2581, 'actor_loss':    -0.6387, 'eps_e':     0.1000})
Step:  445000, Reward:  -183.216 [  87.280], Avg:  -275.120 (0.100) <0-01:07:16> ({'r_t':  -844.4493, 'eps':     0.1000, 'critic_loss':     9.2277, 'actor_loss':    -0.6043, 'eps_e':     0.1000})
Step:  446000, Reward:  -155.684 [ 105.355], Avg:  -274.853 (0.100) <0-01:07:24> ({'r_t':  -800.2347, 'eps':     0.1000, 'critic_loss':    11.8179, 'actor_loss':    -0.5627, 'eps_e':     0.1000})
Step:  447000, Reward:  -156.664 [ 122.971], Avg:  -274.589 (0.100) <0-01:07:33> ({'r_t':  -862.3819, 'eps':     0.1000, 'critic_loss':    10.4318, 'actor_loss':    -0.5873, 'eps_e':     0.1000})
Step:  448000, Reward:  -184.697 [ 105.383], Avg:  -274.389 (0.100) <0-01:07:42> ({'r_t':  -788.3306, 'eps':     0.1000, 'critic_loss':     9.9030, 'actor_loss':    -0.5663, 'eps_e':     0.1000})
Step:  449000, Reward:  -134.580 [  91.071], Avg:  -274.078 (0.100) <0-01:07:51> ({'r_t':  -714.4556, 'eps':     0.1000, 'critic_loss':    10.1336, 'actor_loss':    -0.5720, 'eps_e':     0.1000})
Step:  450000, Reward:  -157.588 [ 107.658], Avg:  -273.820 (0.100) <0-01:08:00> ({'r_t':  -716.3179, 'eps':     0.1000, 'critic_loss':    10.6284, 'actor_loss':    -0.5686, 'eps_e':     0.1000})
Step:  451000, Reward:  -117.182 [ 113.108], Avg:  -273.473 (0.100) <0-01:08:09> ({'r_t':  -857.9769, 'eps':     0.1000, 'critic_loss':    11.1577, 'actor_loss':    -0.5987, 'eps_e':     0.1000})
Step:  452000, Reward:  -207.679 [ 105.239], Avg:  -273.328 (0.100) <0-01:08:17> ({'r_t':  -843.7717, 'eps':     0.1000, 'critic_loss':    10.2859, 'actor_loss':    -0.6333, 'eps_e':     0.1000})
Step:  453000, Reward:  -135.119 [  99.617], Avg:  -273.024 (0.100) <0-01:08:26> ({'r_t':  -791.1667, 'eps':     0.1000, 'critic_loss':    11.4530, 'actor_loss':    -0.6144, 'eps_e':     0.1000})
Step:  454000, Reward:  -181.039 [ 100.167], Avg:  -272.821 (0.100) <0-01:08:35> ({'r_t':  -756.9682, 'eps':     0.1000, 'critic_loss':    11.5763, 'actor_loss':    -0.6428, 'eps_e':     0.1000})
Step:  455000, Reward:  -161.635 [ 111.458], Avg:  -272.578 (0.100) <0-01:08:44> ({'r_t':  -761.7708, 'eps':     0.1000, 'critic_loss':    10.3066, 'actor_loss':    -0.6213, 'eps_e':     0.1000})
Step:  456000, Reward:  -166.780 [ 121.487], Avg:  -272.346 (0.100) <0-01:08:53> ({'r_t':  -811.3753, 'eps':     0.1000, 'critic_loss':     9.5659, 'actor_loss':    -0.6077, 'eps_e':     0.1000})
Step:  457000, Reward:  -158.443 [  71.632], Avg:  -272.097 (0.100) <0-01:09:02> ({'r_t':  -822.9338, 'eps':     0.1000, 'critic_loss':    12.1885, 'actor_loss':    -0.5934, 'eps_e':     0.1000})
Step:  458000, Reward:  -165.072 [  91.611], Avg:  -271.864 (0.100) <0-01:09:10> ({'r_t':  -801.5440, 'eps':     0.1000, 'critic_loss':     9.2750, 'actor_loss':    -0.5725, 'eps_e':     0.1000})
Step:  459000, Reward:  -137.419 [  95.630], Avg:  -271.572 (0.100) <0-01:09:19> ({'r_t':  -792.2122, 'eps':     0.1000, 'critic_loss':    10.8013, 'actor_loss':    -0.6023, 'eps_e':     0.1000})
Step:  460000, Reward:  -165.061 [  88.133], Avg:  -271.341 (0.100) <0-01:09:28> ({'r_t':  -789.2733, 'eps':     0.1000, 'critic_loss':    10.5738, 'actor_loss':    -0.6725, 'eps_e':     0.1000})
Step:  461000, Reward:  -138.282 [  86.214], Avg:  -271.053 (0.100) <0-01:09:37> ({'r_t':  -797.8946, 'eps':     0.1000, 'critic_loss':     9.8219, 'actor_loss':    -0.6207, 'eps_e':     0.1000})
Step:  462000, Reward:  -155.563 [ 101.584], Avg:  -270.804 (0.100) <0-01:09:46> ({'r_t': -1087.6040, 'eps':     0.1000, 'critic_loss':    10.9152, 'actor_loss':    -0.6303, 'eps_e':     0.1000})
Step:  463000, Reward:  -173.554 [  83.740], Avg:  -270.594 (0.100) <0-01:09:54> ({'r_t':  -854.7741, 'eps':     0.1000, 'critic_loss':    12.7019, 'actor_loss':    -0.5839, 'eps_e':     0.1000})
Step:  464000, Reward:  -187.342 [  80.243], Avg:  -270.415 (0.100) <0-01:10:03> ({'r_t':  -812.1706, 'eps':     0.1000, 'critic_loss':    16.6462, 'actor_loss':    -0.6004, 'eps_e':     0.1000})
Step:  465000, Reward:  -203.828 [  56.078], Avg:  -270.272 (0.100) <0-01:10:12> ({'r_t':  -854.1240, 'eps':     0.1000, 'critic_loss':    13.7338, 'actor_loss':    -0.6012, 'eps_e':     0.1000})
Step:  466000, Reward:  -118.593 [  72.584], Avg:  -269.947 (0.100) <0-01:10:21> ({'r_t':  -811.2926, 'eps':     0.1000, 'critic_loss':    15.7775, 'actor_loss':    -0.5949, 'eps_e':     0.1000})
Step:  467000, Reward:  -182.558 [  90.127], Avg:  -269.760 (0.100) <0-01:10:30> ({'r_t':  -874.6728, 'eps':     0.1000, 'critic_loss':    12.9399, 'actor_loss':    -0.6218, 'eps_e':     0.1000})
Step:  468000, Reward:  -114.417 [  64.494], Avg:  -269.429 (0.100) <0-01:10:39> ({'r_t':  -843.0505, 'eps':     0.1000, 'critic_loss':    12.6001, 'actor_loss':    -0.6371, 'eps_e':     0.1000})
Step:  469000, Reward:  -161.968 [  83.508], Avg:  -269.201 (0.100) <0-01:10:47> ({'r_t':  -752.9398, 'eps':     0.1000, 'critic_loss':    12.7799, 'actor_loss':    -0.6666, 'eps_e':     0.1000})
Step:  470000, Reward:  -182.881 [  87.007], Avg:  -269.017 (0.100) <0-01:10:56> ({'r_t':  -792.1710, 'eps':     0.1000, 'critic_loss':    14.3263, 'actor_loss':    -0.6417, 'eps_e':     0.1000})
Step:  471000, Reward:  -164.566 [  74.453], Avg:  -268.796 (0.100) <0-01:11:05> ({'r_t':  -869.4206, 'eps':     0.1000, 'critic_loss':    15.6907, 'actor_loss':    -0.6712, 'eps_e':     0.1000})
Step:  472000, Reward:  -158.933 [ 102.005], Avg:  -268.564 (0.100) <0-01:11:14> ({'r_t':  -834.9839, 'eps':     0.1000, 'critic_loss':    14.0220, 'actor_loss':    -0.5748, 'eps_e':     0.1000})
Step:  473000, Reward:  -148.050 [  98.989], Avg:  -268.310 (0.100) <0-01:11:23> ({'r_t':  -787.8176, 'eps':     0.1000, 'critic_loss':    16.0895, 'actor_loss':    -0.5877, 'eps_e':     0.1000})
Step:  474000, Reward:  -241.695 [ 346.879], Avg:  -268.253 (0.100) <0-01:11:32> ({'r_t': -1210.9955, 'eps':     0.1000, 'critic_loss':    14.6805, 'actor_loss':    -0.6082, 'eps_e':     0.1000})
Step:  475000, Reward:  -181.222 [ 111.426], Avg:  -268.071 (0.100) <0-01:11:40> ({'r_t':  -962.9157, 'eps':     0.1000, 'critic_loss':    21.3922, 'actor_loss':    -0.6519, 'eps_e':     0.1000})
Step:  476000, Reward:  -172.385 [  98.900], Avg:  -267.870 (0.100) <0-01:11:49> ({'r_t':  -795.0284, 'eps':     0.1000, 'critic_loss':    20.0878, 'actor_loss':    -0.6833, 'eps_e':     0.1000})
Step:  477000, Reward:  -192.644 [  83.400], Avg:  -267.713 (0.100) <0-01:11:58> ({'r_t':  -797.9706, 'eps':     0.1000, 'critic_loss':    19.1023, 'actor_loss':    -0.6889, 'eps_e':     0.1000})
Step:  478000, Reward:  -135.620 [  81.134], Avg:  -267.437 (0.100) <0-01:12:07> ({'r_t':  -789.4916, 'eps':     0.1000, 'critic_loss':    16.7110, 'actor_loss':    -0.6816, 'eps_e':     0.1000})
Step:  479000, Reward:  -187.603 [  82.110], Avg:  -267.271 (0.100) <0-01:12:16> ({'r_t':  -808.3410, 'eps':     0.1000, 'critic_loss':    20.6538, 'actor_loss':    -0.6254, 'eps_e':     0.1000})
Step:  480000, Reward:  -184.383 [  95.908], Avg:  -267.098 (0.100) <0-01:12:24> ({'r_t':  -709.2027, 'eps':     0.1000, 'critic_loss':    20.0370, 'actor_loss':    -0.6371, 'eps_e':     0.1000})
Step:  481000, Reward:  -184.986 [ 106.071], Avg:  -266.928 (0.100) <0-01:12:33> ({'r_t':  -783.3009, 'eps':     0.1000, 'critic_loss':    20.3963, 'actor_loss':    -0.7003, 'eps_e':     0.1000})
Step:  482000, Reward:  -150.571 [  62.785], Avg:  -266.687 (0.100) <0-01:12:42> ({'r_t':  -803.2711, 'eps':     0.1000, 'critic_loss':    16.6966, 'actor_loss':    -0.6798, 'eps_e':     0.1000})
Step:  483000, Reward:  -167.110 [ 110.607], Avg:  -266.481 (0.100) <0-01:12:51> ({'r_t':  -727.4146, 'eps':     0.1000, 'critic_loss':    18.0096, 'actor_loss':    -0.6587, 'eps_e':     0.1000})
Step:  484000, Reward:  -135.074 [  62.824], Avg:  -266.210 (0.100) <0-01:13:00> ({'r_t':  -907.8251, 'eps':     0.1000, 'critic_loss':    16.6053, 'actor_loss':    -0.5925, 'eps_e':     0.1000})
Step:  485000, Reward:  -148.054 [  83.161], Avg:  -265.967 (0.100) <0-01:13:09> ({'r_t':  -779.2333, 'eps':     0.1000, 'critic_loss':    18.5522, 'actor_loss':    -0.5579, 'eps_e':     0.1000})
Step:  486000, Reward:  -105.346 [  68.510], Avg:  -265.637 (0.100) <0-01:13:17> ({'r_t':  -745.8814, 'eps':     0.1000, 'critic_loss':    15.1212, 'actor_loss':    -0.5804, 'eps_e':     0.1000})
Step:  487000, Reward:  -201.044 [  93.993], Avg:  -265.505 (0.100) <0-01:13:26> ({'r_t':  -732.1066, 'eps':     0.1000, 'critic_loss':    19.0805, 'actor_loss':    -0.6113, 'eps_e':     0.1000})
Step:  488000, Reward:  -159.312 [  52.045], Avg:  -265.288 (0.100) <0-01:13:35> ({'r_t':  -787.8978, 'eps':     0.1000, 'critic_loss':    22.3602, 'actor_loss':    -0.5872, 'eps_e':     0.1000})
Step:  489000, Reward:  -169.655 [ 106.022], Avg:  -265.093 (0.100) <0-01:13:44> ({'r_t':  -801.6859, 'eps':     0.1000, 'critic_loss':    19.7803, 'actor_loss':    -0.5741, 'eps_e':     0.1000})
Step:  490000, Reward:  -144.252 [  87.382], Avg:  -264.847 (0.100) <0-01:13:53> ({'r_t':  -761.8477, 'eps':     0.1000, 'critic_loss':    14.4442, 'actor_loss':    -0.5381, 'eps_e':     0.1000})
Step:  491000, Reward:  -128.825 [  86.662], Avg:  -264.570 (0.100) <0-01:14:01> ({'r_t':  -840.8518, 'eps':     0.1000, 'critic_loss':    18.4448, 'actor_loss':    -0.5267, 'eps_e':     0.1000})
Step:  492000, Reward:  -143.200 [  93.106], Avg:  -264.324 (0.100) <0-01:14:10> ({'r_t':  -812.2093, 'eps':     0.1000, 'critic_loss':    15.0801, 'actor_loss':    -0.5392, 'eps_e':     0.1000})
Step:  493000, Reward:  -142.588 [  95.694], Avg:  -264.077 (0.100) <0-01:14:19> ({'r_t':  -808.8328, 'eps':     0.1000, 'critic_loss':    19.9807, 'actor_loss':    -0.5710, 'eps_e':     0.1000})
Step:  494000, Reward:  -174.096 [  92.216], Avg:  -263.896 (0.100) <0-01:14:28> ({'r_t':  -875.6061, 'eps':     0.1000, 'critic_loss':    18.9420, 'actor_loss':    -0.6235, 'eps_e':     0.1000})
Step:  495000, Reward:  -152.044 [ 106.014], Avg:  -263.670 (0.100) <0-01:14:37> ({'r_t':  -836.4816, 'eps':     0.1000, 'critic_loss':    14.7907, 'actor_loss':    -0.6126, 'eps_e':     0.1000})
Step:  496000, Reward:  -164.768 [  93.186], Avg:  -263.471 (0.100) <0-01:14:45> ({'r_t':  -728.1919, 'eps':     0.1000, 'critic_loss':    19.3351, 'actor_loss':    -0.6866, 'eps_e':     0.1000})
Step:  497000, Reward:  -139.198 [  95.969], Avg:  -263.222 (0.100) <0-01:14:54> ({'r_t':  -810.9970, 'eps':     0.1000, 'critic_loss':    15.2466, 'actor_loss':    -0.5535, 'eps_e':     0.1000})
Step:  498000, Reward:  -195.336 [  91.366], Avg:  -263.086 (0.100) <0-01:15:03> ({'r_t':  -814.4742, 'eps':     0.1000, 'critic_loss':    16.2788, 'actor_loss':    -0.5435, 'eps_e':     0.1000})
Step:  499000, Reward:  -181.722 [ 124.460], Avg:  -262.923 (0.100) <0-01:15:12> ({'r_t':  -839.7160, 'eps':     0.1000, 'critic_loss':    16.1024, 'actor_loss':    -0.6277, 'eps_e':     0.1000})
Step:  500000, Reward:  -185.496 [  87.549], Avg:  -262.768 (0.100) <0-01:15:21> ({'r_t':  -784.1993, 'eps':     0.1000, 'critic_loss':    19.8784, 'actor_loss':    -0.5616, 'eps_e':     0.1000})
