Model: <class 'src.models.pytorch.agents.ddpg.DDPGAgent'>, Env: CarRacing-v1, Date: 29/05/2020 03:26:19
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-53-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 6aa19f9a388401cd4695cd69c1022fc87755770a
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   dynamics_size = 10
   state_size = (40,)
   action_size = (3,)
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = ddpg
   framework = pt
   train_prop = 1.0
   tcp_ports = [11000, 11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008, 11009, 11010, 11011, 11012, 11013, 11014, 11015, 11016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7f04b4b5ba90> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f04b4eb7ad0>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f04b4ab5680>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f04b4afae50> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f04b4ab48d0> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				Z = [-0.894  8.722]
				cost_map = [[[ 214.381  214.381]
				  [ 214.299  214.299]
				  [ 214.217  214.217]
				  ...
				  [ 112.184  112.184]
				  [ 112.264  112.264]
				  [ 112.344  112.344]]
				
				 [[ 214.324  214.324]
				  [ 214.242  214.242]
				  [ 214.160  214.160]
				  ...
				  [ 112.124  112.124]
				  [ 112.204  112.204]
				  [ 112.284  112.284]]
				
				 [[ 214.267  214.267]
				  [ 214.185  214.185]
				  [ 214.103  214.103]
				  ...
				  [ 112.064  112.064]
				  [ 112.144  112.144]
				  [ 112.224  112.224]]
				
				 ...
				
				 [[  96.764   96.764]
				  [  96.690   96.690]
				  [  96.616   96.616]
				  ...
				  [ 242.661  242.661]
				  [ 242.689  242.689]
				  [ 242.717  242.717]]
				
				 [[  96.831   96.831]
				  [  96.757   96.757]
				  [  96.683   96.683]
				  ...
				  [ 242.757  242.757]
				  [ 242.785  242.785]
				  [ 242.813  242.813]]
				
				 [[  96.898   96.898]
				  [  96.824   96.824]
				  [  96.750   96.750]
				  ...
				  [ 242.852  242.852]
				  [ 242.881  242.881]
				  [ 242.909  242.909]]]
				res = 0.1
				min_point = [-215.266 -178.250   -0.894]
				max_point = [ 210.234  262.950    8.722]
				src = 
						def get_cost(self, state, prevstate=None):
							prevstate = state if prevstate is None else prevstate
							prevpos = prevstate["pos"][...,[0,2,1]]
							pos = state["pos"][...,[0,2,1]]
							vy = state["vel"][...,-1]
							cost = self.get_point_cost(pos, transform=True)
							progress = self.track.get_progress(prevpos, pos)
							# reward = np.minimum(progress,0) + 2*progress + np.tanh(vy/self.vtarget)-np.power(self.vtarget-vy,2)/self.vtarget**2 - cost**2
							reward = np.where(progress<0,4,2)*progress + np.tanh(vy/self.vtarget) - np.power(self.vtarget-vy,2)/self.vtarget**2 - cost**2
				
				vtarget = 20
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			cost_queries = <list len=25>
			dynamics_keys = ['pos', 'vel', 'angvel', 'steer_angle', 'rpm', 'idle', 'costs']
			dynamics_lens = [3, 3, 3, 1, 4, 1, 25]
			dynamics_size = 10
			observation_space = Box(40,) 
				dtype = float32
				shape = (40,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			src = 
					def step(self, action):
						self.time += 1
						next_state, reward, done, info = self.env.step(action)
						idle = next_state[29]
						done = done or idle>self.idle_timeout or self.time > self.max_time
						next_state, next_spec = self.observation(next_state)
						terminal = -(1-self.time/self.max_time)*int(done)
						reward = -self.cost_model.get_cost(next_spec, self.spec) + terminal
						self.state, self.spec = next_state, next_spec
						return self.state, reward, done, info
			
			max_time = 500
			time = 0
			idle_timeout = 10
			state = [ 1.617e-09 -3.908e-03 -7.273e-09  1.777e-12 -1.954e-01  3.555e-13  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  2.000e-02  3.519e+00  3.570e+00  3.638e+00  3.701e+00  3.753e+00  2.524e+00  2.571e+00  2.638e+00  2.701e+00  2.759e+00  1.535e+00  1.573e+00  1.639e+00  1.701e+00  1.770e+00  5.857e-01  5.825e-01  6.409e-01  7.016e-01  8.107e-01  5.745e-01  4.479e-01  3.679e-01  2.992e-01  4.244e-01]
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f0534a6a5f0>
					step = <function CarRacing.step at 0x7f0534a6a560>
					render = <function CarRacing.render at 0x7f055ced5950>
					dynamics_spec = <staticmethod object at 0x7f0534abbf90>
					track_spec = <function CarRacing.track_spec at 0x7f055ced5a70>
					observation = <function CarRacing.observation at 0x7f055ced5b00>
					observation_spec = <staticmethod object at 0x7f0534a6d590>
					close = <function CarRacing.close at 0x7f055ced5c20>
					id = 2
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(40,) 
			dtype = float32
			shape = (40,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f04b4afaa10> 
			observation_space = Box(40,) 
				dtype = float32
				shape = (40,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (40,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f04b4afa950> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {11001: <socket.socket fd=35, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57870), raddr=('127.0.0.1', 11001)>, 11002: <socket.socket fd=36, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 58622), raddr=('127.0.0.1', 11002)>, 11003: <socket.socket fd=37, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33268), raddr=('127.0.0.1', 11003)>, 11004: <socket.socket fd=38, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54700), raddr=('127.0.0.1', 11004)>, 11005: <socket.socket fd=39, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38916), raddr=('127.0.0.1', 11005)>, 11006: <socket.socket fd=40, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53224), raddr=('127.0.0.1', 11006)>, 11007: <socket.socket fd=41, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 45386), raddr=('127.0.0.1', 11007)>, 11008: <socket.socket fd=42, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53252), raddr=('127.0.0.1', 11008)>, 11009: <socket.socket fd=43, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 57254), raddr=('127.0.0.1', 11009)>, 11010: <socket.socket fd=44, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36606), raddr=('127.0.0.1', 11010)>, 11011: <socket.socket fd=45, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56726), raddr=('127.0.0.1', 11011)>, 11012: <socket.socket fd=46, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40158), raddr=('127.0.0.1', 11012)>, 11013: <socket.socket fd=47, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50066), raddr=('127.0.0.1', 11013)>, 11014: <socket.socket fd=48, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38094), raddr=('127.0.0.1', 11014)>, 11015: <socket.socket fd=49, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 56194), raddr=('127.0.0.1', 11015)>, 11016: <socket.socket fd=50, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59368), raddr=('127.0.0.1', 11016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f04b4ab4790> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f04b4ab4910> 
		state_size = (40,)
	agent = <src.models.pytorch.agents.ddpg.DDPGAgent object at 0x7f04b4ab4e10> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f04b4ab4850> 
			size = (3,)
			dt = 0.2
			action = [ 0.948  1.000  0.798]
			daction_dt = [-1.093 -0.007 -0.147]
		discrete = False
		action_size = (3,)
		state_size = (40,)
		config = <src.utils.config.Config object at 0x7f04bc0c0e90> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			dynamics_size = 10
			state_size = (40,)
			action_size = (3,)
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = ddpg
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f04b4ab49d0> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = DDPGNetwork(
			  (actor_local): DDPGActor(
			    (layer1): Linear(in_features=40, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): DDPGActor(
			    (layer1): Linear(in_features=40, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): DDPGCritic(
			    (net_state): Linear(in_features=40, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): DDPGCritic(
			    (net_state): Linear(in_features=40, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = ddpg
			stats = <src.utils.logger.Stats object at 0x7f04b4ab4710> 
				mean_dict = {}
				sum_dict = {}
			config = <src.utils.config.Config object at 0x7f04bc0c0e90> 
				TRIAL_AT = 1000
				SAVE_AT = 1
				SEED = 0
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				dynamics_size = 10
				state_size = (40,)
				action_size = (3,)
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = ddpg
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class DDPGActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, sample=True):\n\t\tstate = self.layer1(state).relu() \n\t\tstate = self.layer2(state).relu() \n\t\tstate = self.layer3(state).relu() \n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).exp()\n\t\tepsilon = torch.randn_like(action_sig)\n\t\taction = action_mu + epsilon.mul(action_sig) if sample else action_mu\n\t\treturn action.tanh() if not self.discrete else gsoftmax(action)\n', 'class DDPGCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f04b4a7c5d0> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f04b4a7c550> 
		size = (3,)
		dt = 0.2
		action = [-0.595  1.000 -0.363]
		daction_dt = [-2.011 -0.548 -1.499]
	discrete = False
	action_size = (3,)
	state_size = (40,)
	config = <src.utils.config.Config object at 0x7f04bc0c0e90> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		dynamics_size = 10
		state_size = (40,)
		action_size = (3,)
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = ddpg
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f04b4a7c650> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import random
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax, one_hot
from src.utils.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh() if not self.discrete else gsoftmax(action)
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=DDPGActor, critic=DDPGCritic, gpu=True, load=None, name="ddpg"): 
		self.discrete = type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)

	def get_action(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			q_value = q_value.gather(-1, action.argmax(-1, keepdim=True)) if self.discrete and not probs else q_value
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, q_targets):
		actions = one_hot(actions) if self.actor_local.discrete else actions
		q_values = self.get_q_value(states, actions, grad=True, probs=False)
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True, probs=True)
		q_actions = (actor_action*q_actions).sum(-1) if self.discrete else q_actions
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = -(q_actions - q_baseline.detach()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		self.soft_copy(self.actor_local, self.actor_target)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)
		
class DDPGAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, DDPGNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if self.discrete and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), numpy=True, sample=sample)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			actions = torch.cat([actions, self.network.get_action(states[-1], use_target=True).unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets)
			if np.any(done[0]): self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward:  -228.986 [ 171.197], Avg:  -228.986 (1.000) <0-00:00:00> ({'r_t':    -1.1736, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward:  -468.138 [ 690.140], Avg:  -348.562 (0.994) <0-00:00:25> ({'r_t': -2138.0965, 'eps':     0.9940, 'critic_loss':  7863.4702, 'actor_loss':    -3.4726, 'eps_e':     0.9940})
Step:    2000, Reward:  -442.781 [ 732.863], Avg:  -379.968 (0.984) <0-00:00:51> ({'r_t': -1851.1770, 'eps':     0.9841, 'critic_loss':  6511.7803, 'actor_loss':    -5.0053, 'eps_e':     0.9841})
Step:    3000, Reward:  -534.931 [1000.375], Avg:  -418.709 (0.968) <0-00:01:19> ({'r_t': -1703.4503, 'eps':     0.9685, 'critic_loss':  4252.6533, 'actor_loss':    -5.2949, 'eps_e':     0.9685})
Step:    4000, Reward:  -341.163 [ 282.599], Avg:  -403.200 (0.963) <0-00:01:48> ({'r_t': -1935.9220, 'eps':     0.9627, 'critic_loss':  3860.5671, 'actor_loss':    -5.2725, 'eps_e':     0.9627})
Step:    5000, Reward:  -227.873 [ 201.315], Avg:  -373.979 (0.955) <0-00:02:16> ({'r_t': -1763.0005, 'eps':     0.9550, 'critic_loss':  4262.7749, 'actor_loss':    -4.6358, 'eps_e':     0.9550})
Step:    6000, Reward:  -192.022 [ 118.279], Avg:  -347.985 (0.942) <0-00:02:41> ({'r_t': -2195.1213, 'eps':     0.9417, 'critic_loss':  4937.0806, 'actor_loss':    -6.6163, 'eps_e':     0.9417})
Step:    7000, Reward:  -229.094 [ 209.129], Avg:  -333.124 (0.929) <0-00:03:10> ({'r_t': -1784.1864, 'eps':     0.9286, 'critic_loss':  5390.0405, 'actor_loss':    -7.9849, 'eps_e':     0.9286})
Step:    8000, Reward:  -181.711 [  88.214], Avg:  -316.300 (0.916) <0-00:03:35> ({'r_t': -1884.2678, 'eps':     0.9157, 'critic_loss':  4345.3018, 'actor_loss':    -7.4881, 'eps_e':     0.9157})
Step:    9000, Reward:  -154.135 [  77.562], Avg:  -300.083 (0.899) <0-00:03:59> ({'r_t': -1381.2107, 'eps':     0.8993, 'critic_loss':  3920.8164, 'actor_loss':    -7.0033, 'eps_e':     0.8993})
Step:   10000, Reward:  -277.795 [ 232.691], Avg:  -298.057 (0.887) <0-00:04:28> ({'r_t': -1845.6510, 'eps':     0.8868, 'critic_loss':  3612.3127, 'actor_loss':    -8.5160, 'eps_e':     0.8868})
Step:   11000, Reward:  -280.952 [ 242.978], Avg:  -296.632 (0.876) <0-00:04:57> ({'r_t': -1600.1958, 'eps':     0.8762, 'critic_loss':  4689.3262, 'actor_loss':    -8.4693, 'eps_e':     0.8762})
Step:   12000, Reward:  -118.399 [  48.493], Avg:  -282.922 (0.862) <0-00:05:20> ({'r_t': -1423.9662, 'eps':     0.8623, 'critic_loss':  4348.3740, 'actor_loss':    -8.6799, 'eps_e':     0.8623})
Step:   13000, Reward:  -138.794 [  65.338], Avg:  -272.627 (0.850) <0-00:05:43> ({'r_t': -1327.7888, 'eps':     0.8503, 'critic_loss':  2758.9417, 'actor_loss':    -6.7988, 'eps_e':     0.8503})
Step:   14000, Reward:  -188.252 [ 187.412], Avg:  -267.002 (0.840) <0-00:06:12> ({'r_t': -1302.3529, 'eps':     0.8402, 'critic_loss':  2992.3416, 'actor_loss':    -6.3615, 'eps_e':     0.8402})
Step:   15000, Reward:  -215.880 [ 193.932], Avg:  -263.807 (0.827) <0-00:06:37> ({'r_t': -1337.6132, 'eps':     0.8268, 'critic_loss':  2024.2081, 'actor_loss':    -5.2051, 'eps_e':     0.8268})
Step:   16000, Reward:  -140.203 [  72.501], Avg:  -256.536 (0.815) <0-00:07:01> ({'r_t': -1283.6574, 'eps':     0.8153, 'critic_loss':  1765.4603, 'actor_loss':    -5.5113, 'eps_e':     0.8153})
Step:   17000, Reward:  -138.142 [  73.614], Avg:  -249.958 (0.806) <0-00:07:25> ({'r_t': -1269.3495, 'eps':     0.8056, 'critic_loss':   505.1246, 'actor_loss':    -5.0316, 'eps_e':     0.8056})
Step:   18000, Reward:  -227.190 [ 225.044], Avg:  -248.760 (0.791) <0-00:07:51> ({'r_t': -1256.4107, 'eps':     0.7912, 'critic_loss':   301.3805, 'actor_loss':    -4.8928, 'eps_e':     0.7912})
Step:   19000, Reward:  -171.950 [  67.178], Avg:  -244.920 (0.779) <0-00:08:16> ({'r_t': -1261.5160, 'eps':     0.7786, 'critic_loss':   233.0878, 'actor_loss':    -4.9377, 'eps_e':     0.7786})
Step:   20000, Reward:  -151.600 [ 105.628], Avg:  -240.476 (0.768) <0-00:08:41> ({'r_t': -1161.8862, 'eps':     0.7678, 'critic_loss':   234.7812, 'actor_loss':    -4.9484, 'eps_e':     0.7678})
Step:   21000, Reward:  -114.915 [  55.601], Avg:  -234.768 (0.756) <0-00:09:04> ({'r_t': -1204.8239, 'eps':     0.7556, 'critic_loss':   236.6569, 'actor_loss':    -5.0086, 'eps_e':     0.7556})
Step:   22000, Reward:  -180.672 [ 221.985], Avg:  -232.416 (0.745) <0-00:09:29> ({'r_t': -1177.2379, 'eps':     0.7451, 'critic_loss':   161.4705, 'actor_loss':    -5.0758, 'eps_e':     0.7451})
Step:   23000, Reward:  -116.161 [  62.147], Avg:  -227.573 (0.736) <0-00:09:52> ({'r_t': -1171.8818, 'eps':     0.7362, 'critic_loss':   183.1055, 'actor_loss':    -5.1375, 'eps_e':     0.7362})
Step:   24000, Reward:  -119.193 [  79.503], Avg:  -223.237 (0.726) <0-00:10:17> ({'r_t': -1146.0499, 'eps':     0.7259, 'critic_loss':   173.9118, 'actor_loss':    -5.4109, 'eps_e':     0.7259})
Step:   25000, Reward:  -125.725 [  81.982], Avg:  -219.487 (0.716) <0-00:10:42> ({'r_t': -1157.5590, 'eps':     0.7158, 'critic_loss':   142.5261, 'actor_loss':    -5.6909, 'eps_e':     0.7158})
Step:   26000, Reward:  -107.522 [  72.502], Avg:  -215.340 (0.704) <0-00:11:06> ({'r_t': -1097.6757, 'eps':     0.7044, 'critic_loss':   133.5420, 'actor_loss':    -5.8339, 'eps_e':     0.7044})
Step:   27000, Reward:   -81.846 [  36.915], Avg:  -210.572 (0.689) <0-00:11:28> ({'r_t':  -956.4991, 'eps':     0.6891, 'critic_loss':   184.2622, 'actor_loss':    -6.0035, 'eps_e':     0.6891})
Step:   28000, Reward:  -120.619 [ 106.213], Avg:  -207.471 (0.678) <0-00:11:53> ({'r_t': -1040.1664, 'eps':     0.6781, 'critic_loss':   212.3973, 'actor_loss':    -5.9060, 'eps_e':     0.6781})
Step:   29000, Reward:   -86.690 [  90.760], Avg:  -203.445 (0.666) <0-00:12:18> ({'r_t':  -966.6739, 'eps':     0.6660, 'critic_loss':   165.9035, 'actor_loss':    -5.8438, 'eps_e':     0.6660})
Step:   30000, Reward:   -85.346 [  43.221], Avg:  -199.635 (0.653) <0-00:12:41> ({'r_t':  -956.0470, 'eps':     0.6528, 'critic_loss':   157.0639, 'actor_loss':    -5.7936, 'eps_e':     0.6528})
Step:   31000, Reward:  -117.530 [  65.095], Avg:  -197.069 (0.641) <0-00:13:06> ({'r_t':  -931.0553, 'eps':     0.6412, 'critic_loss':   187.7489, 'actor_loss':    -5.9511, 'eps_e':     0.6412})
Step:   32000, Reward:   -77.294 [  34.767], Avg:  -193.440 (0.627) <0-00:13:29> ({'r_t':  -857.2000, 'eps':     0.6272, 'critic_loss':   244.1039, 'actor_loss':    -5.8292, 'eps_e':     0.6272})
Step:   33000, Reward:   -99.313 [  49.486], Avg:  -190.671 (0.615) <0-00:13:52> ({'r_t':  -797.7161, 'eps':     0.6148, 'critic_loss':   174.4413, 'actor_loss':    -6.0367, 'eps_e':     0.6148})
Step:   34000, Reward:   -84.177 [  52.229], Avg:  -187.628 (0.603) <0-00:14:15> ({'r_t':  -775.6781, 'eps':     0.6026, 'critic_loss':   157.4591, 'actor_loss':    -6.2300, 'eps_e':     0.6026})
Step:   35000, Reward:   -68.730 [  55.813], Avg:  -184.326 (0.592) <0-00:14:39> ({'r_t':  -740.8501, 'eps':     0.5918, 'critic_loss':   137.5697, 'actor_loss':    -6.5102, 'eps_e':     0.5918})
Step:   36000, Reward:   -90.429 [  65.484], Avg:  -181.788 (0.582) <0-00:15:03> ({'r_t':  -744.6604, 'eps':     0.5824, 'critic_loss':   166.3344, 'actor_loss':    -6.5088, 'eps_e':     0.5824})
Step:   37000, Reward:   -72.348 [  44.525], Avg:  -178.908 (0.570) <0-00:15:27> ({'r_t':  -689.8258, 'eps':     0.5697, 'critic_loss':   168.2913, 'actor_loss':    -6.7937, 'eps_e':     0.5697})
Step:   38000, Reward:   -53.883 [  43.509], Avg:  -175.702 (0.560) <0-00:15:50> ({'r_t':  -574.8767, 'eps':     0.5596, 'critic_loss':   123.4751, 'actor_loss':    -6.4794, 'eps_e':     0.5596})
Step:   39000, Reward:   -75.164 [  37.613], Avg:  -173.189 (0.547) <0-00:16:13> ({'r_t':  -501.1018, 'eps':     0.5474, 'critic_loss':   120.1489, 'actor_loss':    -6.4413, 'eps_e':     0.5474})
Step:   40000, Reward:   -64.374 [  41.730], Avg:  -170.535 (0.537) <0-00:16:36> ({'r_t':  -490.7868, 'eps':     0.5365, 'critic_loss':   116.7776, 'actor_loss':    -6.1479, 'eps_e':     0.5365})
Step:   41000, Reward:   -39.239 [  38.039], Avg:  -167.409 (0.526) <0-00:16:58> ({'r_t':  -535.8729, 'eps':     0.5259, 'critic_loss':   117.8242, 'actor_loss':    -5.8166, 'eps_e':     0.5259})
Step:   42000, Reward:   -50.237 [  54.809], Avg:  -164.684 (0.515) <0-00:17:22> ({'r_t':  -499.7080, 'eps':     0.5155, 'critic_loss':   109.8855, 'actor_loss':    -5.7846, 'eps_e':     0.5155})
Step:   43000, Reward:   -21.671 [  44.841], Avg:  -161.433 (0.506) <0-00:17:45> ({'r_t':  -366.5012, 'eps':     0.5063, 'critic_loss':   109.1084, 'actor_loss':    -5.8422, 'eps_e':     0.5063})
Step:   44000, Reward:   -37.526 [  39.451], Avg:  -158.680 (0.497) <0-00:18:07> ({'r_t':  -550.3015, 'eps':     0.4972, 'critic_loss':   773.7503, 'actor_loss':    -5.7797, 'eps_e':     0.4972})
Step:   45000, Reward:   -24.096 [  48.622], Avg:  -155.754 (0.488) <0-00:18:30> ({'r_t':  -300.0212, 'eps':     0.4884, 'critic_loss':  1024.7383, 'actor_loss':    -5.7340, 'eps_e':     0.4884})
Step:   46000, Reward:   -22.883 [  46.316], Avg:  -152.927 (0.479) <0-00:18:52> ({'r_t':  -242.1190, 'eps':     0.4787, 'critic_loss':   847.9115, 'actor_loss':    -5.7445, 'eps_e':     0.4787})
Step:   47000, Reward:    -2.606 [  25.044], Avg:  -149.795 (0.469) <0-00:19:16> ({'r_t':  -211.7629, 'eps':     0.4692, 'critic_loss':   918.8494, 'actor_loss':    -5.5113, 'eps_e':     0.4692})
Step:   48000, Reward:   -18.401 [  35.577], Avg:  -147.114 (0.460) <0-00:19:38> ({'r_t':  -432.3311, 'eps':     0.4599, 'critic_loss':   863.1589, 'actor_loss':    -5.3524, 'eps_e':     0.4599})
Step:   49000, Reward:    -7.290 [  33.755], Avg:  -144.317 (0.452) <0-00:20:01> ({'r_t':  -202.6478, 'eps':     0.4517, 'critic_loss':   732.4273, 'actor_loss':    -4.9939, 'eps_e':     0.4517})
Step:   50000, Reward:    -0.689 [  39.906], Avg:  -141.501 (0.442) <0-00:20:23> ({'r_t':   -68.7330, 'eps':     0.4418, 'critic_loss':   489.6282, 'actor_loss':    -4.9939, 'eps_e':     0.4418})
Step:   51000, Reward:    -8.987 [  40.724], Avg:  -138.953 (0.433) <0-00:20:45> ({'r_t':  -241.3351, 'eps':     0.4331, 'critic_loss':   192.2266, 'actor_loss':    -4.6673, 'eps_e':     0.4331})
Step:   52000, Reward:   -10.381 [  36.679], Avg:  -136.527 (0.425) <0-00:21:07> ({'r_t':  -151.5702, 'eps':     0.4253, 'critic_loss':   579.7826, 'actor_loss':    -4.7289, 'eps_e':     0.4253})
Step:   53000, Reward:    -1.703 [  43.909], Avg:  -134.030 (0.418) <0-00:21:29> ({'r_t':   -86.1098, 'eps':     0.4177, 'critic_loss':   317.8379, 'actor_loss':    -4.7952, 'eps_e':     0.4177})
Step:   54000, Reward:    -7.585 [  44.484], Avg:  -131.731 (0.409) <0-00:21:51> ({'r_t':    27.8761, 'eps':     0.4095, 'critic_loss':   978.8228, 'actor_loss':    -4.9768, 'eps_e':     0.4095})
Step:   55000, Reward:    10.900 [  50.530], Avg:  -129.184 (0.401) <0-00:22:13> ({'r_t':    60.2308, 'eps':     0.4014, 'critic_loss':   583.1852, 'actor_loss':    -4.7880, 'eps_e':     0.4014})
Step:   56000, Reward:     4.210 [  43.686], Avg:  -126.844 (0.393) <0-00:22:37> ({'r_t':    29.2646, 'eps':     0.3934, 'critic_loss':   660.9058, 'actor_loss':    -4.7239, 'eps_e':     0.3934})
Step:   57000, Reward:    10.912 [  32.229], Avg:  -124.469 (0.385) <0-00:22:59> ({'r_t':   -64.8828, 'eps':     0.3848, 'critic_loss':  1097.6791, 'actor_loss':    -4.3360, 'eps_e':     0.3848})
Step:   58000, Reward:     7.509 [  36.427], Avg:  -122.232 (0.376) <0-00:23:22> ({'r_t':   142.5734, 'eps':     0.3764, 'critic_loss':   560.7754, 'actor_loss':    -4.1151, 'eps_e':     0.3764})
Step:   59000, Reward:    12.260 [  35.350], Avg:  -119.990 (0.370) <0-00:23:43> ({'r_t':    -8.2499, 'eps':     0.3697, 'critic_loss':   556.6306, 'actor_loss':    -3.8664, 'eps_e':     0.3697})
Step:   60000, Reward:    30.460 [  32.749], Avg:  -117.524 (0.361) <0-00:24:05> ({'r_t':   186.1657, 'eps':     0.3609, 'critic_loss':   772.7286, 'actor_loss':    -3.6794, 'eps_e':     0.3609})
Step:   61000, Reward:    23.858 [  17.841], Avg:  -115.244 (0.353) <0-00:24:27> ({'r_t':   269.2378, 'eps':     0.3531, 'critic_loss':   464.4988, 'actor_loss':    -3.5291, 'eps_e':     0.3531})
Step:   62000, Reward:    26.841 [  19.515], Avg:  -112.988 (0.345) <0-00:24:48> ({'r_t':   322.9052, 'eps':     0.3454, 'critic_loss':   470.2007, 'actor_loss':    -3.4638, 'eps_e':     0.3454})
Step:   63000, Reward:    31.466 [  23.231], Avg:  -110.731 (0.338) <0-00:25:10> ({'r_t':   284.3682, 'eps':     0.3379, 'critic_loss':   726.4822, 'actor_loss':    -3.7232, 'eps_e':     0.3379})
Step:   64000, Reward:    31.900 [  19.445], Avg:  -108.537 (0.331) <0-00:25:32> ({'r_t':   329.0740, 'eps':     0.3305, 'critic_loss':   515.7661, 'actor_loss':    -3.4328, 'eps_e':     0.3305})
Step:   65000, Reward:    33.431 [  18.510], Avg:  -106.386 (0.323) <0-00:25:53> ({'r_t':   337.5899, 'eps':     0.3233, 'critic_loss':   367.6002, 'actor_loss':    -3.2924, 'eps_e':     0.3233})
Step:   66000, Reward:    40.710 [  19.811], Avg:  -104.190 (0.317) <0-00:26:15> ({'r_t':   359.8821, 'eps':     0.3169, 'critic_loss':    58.8301, 'actor_loss':    -3.0292, 'eps_e':     0.3169})
Step:   67000, Reward:    41.223 [  26.386], Avg:  -102.052 (0.309) <0-00:26:37> ({'r_t':   408.6015, 'eps':     0.3094, 'critic_loss':    52.9620, 'actor_loss':    -2.8105, 'eps_e':     0.3094})
Step:   68000, Reward:    47.937 [  13.200], Avg:   -99.878 (0.303) <0-00:26:58> ({'r_t':   448.1937, 'eps':     0.3033, 'critic_loss':    50.8387, 'actor_loss':    -2.6656, 'eps_e':     0.3033})
Step:   69000, Reward:    48.881 [  16.850], Avg:   -97.753 (0.297) <0-00:27:20> ({'r_t':   451.4155, 'eps':     0.2966, 'critic_loss':    49.8229, 'actor_loss':    -2.4892, 'eps_e':     0.2966})
Step:   70000, Reward:    38.638 [  21.928], Avg:   -95.832 (0.290) <0-00:27:41> ({'r_t':   485.8062, 'eps':     0.2902, 'critic_loss':    47.7697, 'actor_loss':    -2.5002, 'eps_e':     0.2902})
Step:   71000, Reward:    50.545 [  23.366], Avg:   -93.799 (0.284) <0-00:28:04> ({'r_t':   543.9612, 'eps':     0.2839, 'critic_loss':    49.3207, 'actor_loss':    -2.4516, 'eps_e':     0.2839})
Step:   72000, Reward:    50.040 [  20.497], Avg:   -91.829 (0.278) <0-00:28:25> ({'r_t':   593.4565, 'eps':     0.2777, 'critic_loss':    50.4749, 'actor_loss':    -2.3805, 'eps_e':     0.2777})
Step:   73000, Reward:    56.297 [  23.396], Avg:   -89.827 (0.272) <0-00:28:47> ({'r_t':   575.7480, 'eps':     0.2722, 'critic_loss':    51.9589, 'actor_loss':    -2.1832, 'eps_e':     0.2722})
Step:   74000, Reward:    56.601 [  25.329], Avg:   -87.875 (0.266) <0-00:29:09> ({'r_t':   518.5551, 'eps':     0.2662, 'critic_loss':    53.7993, 'actor_loss':    -2.2659, 'eps_e':     0.2662})
Step:   75000, Reward:    56.646 [  16.765], Avg:   -85.973 (0.261) <0-00:29:31> ({'r_t':   536.9052, 'eps':     0.2610, 'critic_loss':    53.7591, 'actor_loss':    -2.2808, 'eps_e':     0.2610})
Step:   76000, Reward:    52.731 [  26.718], Avg:   -84.172 (0.256) <0-00:29:54> ({'r_t':   585.4754, 'eps':     0.2558, 'critic_loss':    52.9878, 'actor_loss':    -2.0862, 'eps_e':     0.2558})
Step:   77000, Reward:    56.085 [  19.309], Avg:   -82.374 (0.251) <0-00:30:15> ({'r_t':   591.6060, 'eps':     0.2507, 'critic_loss':    53.7644, 'actor_loss':    -2.1760, 'eps_e':     0.2507})
Step:   78000, Reward:    68.009 [  17.269], Avg:   -80.470 (0.246) <0-00:30:37> ({'r_t':   649.2701, 'eps':     0.2458, 'critic_loss':    50.8032, 'actor_loss':    -2.0974, 'eps_e':     0.2458})
Step:   79000, Reward:    42.959 [  33.348], Avg:   -78.927 (0.240) <0-00:30:59> ({'r_t':   677.4840, 'eps':     0.2404, 'critic_loss':    51.4077, 'actor_loss':    -2.1995, 'eps_e':     0.2404})
Step:   80000, Reward:    68.035 [  16.695], Avg:   -77.113 (0.236) <0-00:31:21> ({'r_t':   666.6756, 'eps':     0.2356, 'critic_loss':    46.3052, 'actor_loss':    -2.2636, 'eps_e':     0.2356})
Step:   81000, Reward:    64.388 [  20.886], Avg:   -75.387 (0.231) <0-00:31:42> ({'r_t':   762.6473, 'eps':     0.2305, 'critic_loss':    44.5355, 'actor_loss':    -2.2257, 'eps_e':     0.2305})
Step:   82000, Reward:    66.572 [  41.107], Avg:   -73.677 (0.226) <0-00:32:04> ({'r_t':   804.6924, 'eps':     0.2259, 'critic_loss':    41.1509, 'actor_loss':    -2.1047, 'eps_e':     0.2259})
Step:   83000, Reward:    82.514 [  27.740], Avg:   -71.817 (0.221) <0-00:32:26> ({'r_t':   832.5496, 'eps':     0.2215, 'critic_loss':    37.8943, 'actor_loss':    -1.8771, 'eps_e':     0.2215})
Step:   84000, Reward:    69.933 [  18.221], Avg:   -70.150 (0.217) <0-00:32:48> ({'r_t':   861.6370, 'eps':     0.2171, 'critic_loss':    37.9480, 'actor_loss':    -1.9280, 'eps_e':     0.2171})
Step:   85000, Reward:    71.970 [  14.741], Avg:   -68.497 (0.213) <0-00:33:10> ({'r_t':   846.6633, 'eps':     0.2132, 'critic_loss':    36.5482, 'actor_loss':    -2.0556, 'eps_e':     0.2132})
Step:   86000, Reward:    78.380 [   7.338], Avg:   -66.809 (0.209) <0-00:33:31> ({'r_t':   769.2957, 'eps':     0.2090, 'critic_loss':    32.9390, 'actor_loss':    -2.3869, 'eps_e':     0.2090})
Step:   87000, Reward:    83.336 [  13.913], Avg:   -65.103 (0.205) <0-00:33:53> ({'r_t':   864.3111, 'eps':     0.2048, 'critic_loss':    29.8699, 'actor_loss':    -2.3491, 'eps_e':     0.2048})
Step:   88000, Reward:    98.033 [  23.381], Avg:   -63.270 (0.201) <0-00:34:15> ({'r_t':   992.4119, 'eps':     0.2008, 'critic_loss':    27.4152, 'actor_loss':    -2.1591, 'eps_e':     0.2008})
Step:   89000, Reward:    91.241 [  17.556], Avg:   -61.553 (0.197) <0-00:34:37> ({'r_t':   959.5302, 'eps':     0.1972, 'critic_loss':    26.3419, 'actor_loss':    -2.1534, 'eps_e':     0.1972})
Step:   90000, Reward:    89.132 [  15.839], Avg:   -59.897 (0.195) <0-00:34:59> ({'r_t':   743.3582, 'eps':     0.1948, 'critic_loss':    30.8080, 'actor_loss':    -2.2595, 'eps_e':     0.1948})
Step:   91000, Reward:    98.525 [  31.243], Avg:   -58.175 (0.191) <0-00:35:21> ({'r_t':   815.7316, 'eps':     0.1910, 'critic_loss':    39.3785, 'actor_loss':    -2.8759, 'eps_e':     0.1910})
Step:   92000, Reward:    92.662 [  23.880], Avg:   -56.553 (0.188) <0-00:35:43> ({'r_t':   822.3383, 'eps':     0.1879, 'critic_loss':    51.0658, 'actor_loss':    -3.5065, 'eps_e':     0.1879})
Step:   93000, Reward:    99.279 [  18.289], Avg:   -54.895 (0.185) <0-00:36:05> ({'r_t':   819.3332, 'eps':     0.1846, 'critic_loss':    61.8251, 'actor_loss':    -3.8728, 'eps_e':     0.1846})
Step:   94000, Reward:   104.031 [   7.132], Avg:   -53.223 (0.182) <0-00:36:27> ({'r_t':   830.7644, 'eps':     0.1816, 'critic_loss':    71.6986, 'actor_loss':    -3.8609, 'eps_e':     0.1816})
Step:   95000, Reward:    76.677 [  23.027], Avg:   -51.869 (0.178) <0-00:36:49> ({'r_t':   858.1951, 'eps':     0.1780, 'critic_loss':    82.1309, 'actor_loss':    -3.5031, 'eps_e':     0.1780})
Step:   96000, Reward:    97.450 [  12.359], Avg:   -50.330 (0.175) <0-00:37:12> ({'r_t':   882.0744, 'eps':     0.1745, 'critic_loss':    87.2949, 'actor_loss':    -2.8596, 'eps_e':     0.1745})
Step:   97000, Reward:    98.452 [   9.417], Avg:   -48.812 (0.171) <0-00:37:33> ({'r_t':   257.9467, 'eps':     0.1714, 'critic_loss':   216.8905, 'actor_loss':    -2.4047, 'eps_e':     0.1714})
Step:   98000, Reward:   106.149 [   6.371], Avg:   -47.247 (0.168) <0-00:37:55> ({'r_t':   641.3706, 'eps':     0.1683, 'critic_loss':  1648.3480, 'actor_loss':    -1.9436, 'eps_e':     0.1683})
Step:   99000, Reward:    94.022 [  24.200], Avg:   -45.834 (0.165) <0-00:38:17> ({'r_t':   756.9970, 'eps':     0.1653, 'critic_loss':  1406.7966, 'actor_loss':    -1.8891, 'eps_e':     0.1653})
Step:  100000, Reward:    88.943 [  22.818], Avg:   -44.499 (0.163) <0-00:38:39> ({'r_t':   686.3471, 'eps':     0.1627, 'critic_loss':  1455.4307, 'actor_loss':    -1.8681, 'eps_e':     0.1627})
Step:  101000, Reward:   103.748 [   9.671], Avg:   -43.046 (0.160) <0-00:39:02> ({'r_t':   808.5509, 'eps':     0.1598, 'critic_loss':  2106.2366, 'actor_loss':    -2.0241, 'eps_e':     0.1598})
Step:  102000, Reward:  -201.395 [ 666.226], Avg:   -44.583 (0.157) <0-00:39:24> ({'r_t':   746.6970, 'eps':     0.1566, 'critic_loss':  1745.6910, 'actor_loss':    -2.0584, 'eps_e':     0.1566})
Step:  103000, Reward:   100.793 [  15.722], Avg:   -43.186 (0.154) <0-00:39:46> ({'r_t':   928.1545, 'eps':     0.1535, 'critic_loss':  2835.2932, 'actor_loss':    -2.3427, 'eps_e':     0.1535})
Step:  104000, Reward:   108.643 [   3.985], Avg:   -41.740 (0.151) <0-00:40:08> ({'r_t':   905.8737, 'eps':     0.1508, 'critic_loss':  1021.7124, 'actor_loss':    -2.5068, 'eps_e':     0.1508})
Step:  105000, Reward:   104.344 [  18.723], Avg:   -40.361 (0.148) <0-00:40:30> ({'r_t':   873.3911, 'eps':     0.1481, 'critic_loss':   746.9195, 'actor_loss':    -2.5137, 'eps_e':     0.1481})
Step:  106000, Reward:    92.027 [  15.749], Avg:   -39.124 (0.145) <0-00:40:52> ({'r_t':   780.9216, 'eps':     0.1452, 'critic_loss':  1158.1740, 'actor_loss':    -2.2196, 'eps_e':     0.1452})
Step:  107000, Reward:    89.613 [  18.843], Avg:   -37.932 (0.143) <0-00:41:14> ({'r_t':  1009.3716, 'eps':     0.1426, 'critic_loss':   831.8889, 'actor_loss':    -2.1337, 'eps_e':     0.1426})
Step:  108000, Reward:   111.692 [   7.778], Avg:   -36.559 (0.140) <0-00:41:35> ({'r_t':   935.6060, 'eps':     0.1397, 'critic_loss':  1221.2684, 'actor_loss':    -2.1517, 'eps_e':     0.1397})
Step:  109000, Reward:    81.393 [  27.750], Avg:   -35.487 (0.137) <0-00:41:58> ({'r_t':  1031.9217, 'eps':     0.1372, 'critic_loss':   738.6131, 'actor_loss':    -2.2391, 'eps_e':     0.1372})
Step:  110000, Reward:   119.272 [  21.826], Avg:   -34.093 (0.135) <0-00:42:20> ({'r_t':   990.5689, 'eps':     0.1345, 'critic_loss':   500.9531, 'actor_loss':    -1.7230, 'eps_e':     0.1345})
Step:  111000, Reward:   103.362 [  12.646], Avg:   -32.866 (0.132) <0-00:42:42> ({'r_t':   996.7937, 'eps':     0.1321, 'critic_loss':   683.5922, 'actor_loss':    -1.7039, 'eps_e':     0.1321})
Step:  112000, Reward:   108.117 [   6.311], Avg:   -31.618 (0.130) <0-00:43:04> ({'r_t':   978.0018, 'eps':     0.1298, 'critic_loss':   178.6976, 'actor_loss':    -1.4101, 'eps_e':     0.1298})
Step:  113000, Reward:   123.750 [  15.349], Avg:   -30.255 (0.127) <0-00:43:26> ({'r_t':  1008.7374, 'eps':     0.1272, 'critic_loss':    23.3739, 'actor_loss':    -1.3087, 'eps_e':     0.1272})
Step:  114000, Reward:   145.352 [  10.567], Avg:   -28.728 (0.125) <0-00:43:47> ({'r_t':  1196.3574, 'eps':     0.1249, 'critic_loss':    19.8202, 'actor_loss':    -1.3676, 'eps_e':     0.1249})
Step:  115000, Reward:   129.269 [  11.350], Avg:   -27.366 (0.123) <0-00:44:09> ({'r_t':  1242.6315, 'eps':     0.1227, 'critic_loss':    16.9672, 'actor_loss':    -1.4781, 'eps_e':     0.1227})
Step:  116000, Reward:   111.769 [  17.763], Avg:   -26.177 (0.120) <0-00:44:31> ({'r_t':  1136.3477, 'eps':     0.1205, 'critic_loss':    14.7047, 'actor_loss':    -1.3706, 'eps_e':     0.1205})
Step:  117000, Reward:   134.957 [  12.560], Avg:   -24.811 (0.118) <0-00:44:53> ({'r_t':  1194.7577, 'eps':     0.1181, 'critic_loss':    16.1393, 'actor_loss':    -1.2027, 'eps_e':     0.1181})
Step:  118000, Reward:   142.208 [  12.609], Avg:   -23.408 (0.116) <0-00:45:15> ({'r_t':  1172.3409, 'eps':     0.1160, 'critic_loss':    15.5132, 'actor_loss':    -1.2530, 'eps_e':     0.1160})
Step:  119000, Reward:   146.948 [  12.286], Avg:   -21.988 (0.114) <0-00:45:36> ({'r_t':  1220.2634, 'eps':     0.1137, 'critic_loss':    17.7155, 'actor_loss':    -1.0560, 'eps_e':     0.1137})
Step:  120000, Reward:   124.336 [  28.092], Avg:   -20.779 (0.112) <0-00:45:58> ({'r_t':   467.4828, 'eps':     0.1117, 'critic_loss':   362.9295, 'actor_loss':    -1.0095, 'eps_e':     0.1117})
Step:  121000, Reward:    68.589 [   3.922], Avg:   -20.046 (0.110) <0-00:46:20> ({'r_t':   178.0483, 'eps':     0.1097, 'critic_loss':  1814.6062, 'actor_loss':    -1.6275, 'eps_e':     0.1097})
Step:  122000, Reward:    79.810 [  16.174], Avg:   -19.235 (0.108) <0-00:46:41> ({'r_t':   281.1002, 'eps':     0.1075, 'critic_loss':  4086.3201, 'actor_loss':    -2.6981, 'eps_e':     0.1075})
Step:  123000, Reward:    65.130 [  22.417], Avg:   -18.554 (0.105) <0-00:47:03> ({'r_t':   801.7671, 'eps':     0.1054, 'critic_loss':  4348.1426, 'actor_loss':    -3.7015, 'eps_e':     0.1054})
Step:  124000, Reward:   110.086 [  12.999], Avg:   -17.525 (0.103) <0-00:47:25> ({'r_t':   877.8646, 'eps':     0.1033, 'critic_loss':  3800.6609, 'actor_loss':    -3.7877, 'eps_e':     0.1033})
Step:  125000, Reward:   113.092 [  14.070], Avg:   -16.488 (0.101) <0-00:47:46> ({'r_t':   970.8097, 'eps':     0.1012, 'critic_loss':  3654.3433, 'actor_loss':    -3.5278, 'eps_e':     0.1012})
Step:  126000, Reward:   -15.021 [ 485.877], Avg:   -16.477 (0.100) <0-00:48:08> ({'r_t':   855.1820, 'eps':     0.1000, 'critic_loss':  3919.7686, 'actor_loss':    -4.1139, 'eps_e':     0.1000})
Step:  127000, Reward:    94.184 [  93.221], Avg:   -15.612 (0.100) <0-00:48:33> ({'r_t':   965.5819, 'eps':     0.1000, 'critic_loss':  2856.7927, 'actor_loss':    -3.4796, 'eps_e':     0.1000})
Step:  128000, Reward:   128.965 [  23.630], Avg:   -14.492 (0.100) <0-00:48:55> ({'r_t':  1044.3602, 'eps':     0.1000, 'critic_loss':   674.6848, 'actor_loss':    -2.1242, 'eps_e':     0.1000})
Step:  129000, Reward:   138.587 [  14.707], Avg:   -13.314 (0.100) <0-00:49:17> ({'r_t':  1095.7648, 'eps':     0.1000, 'critic_loss':   609.4754, 'actor_loss':    -1.8251, 'eps_e':     0.1000})
Step:  130000, Reward:   144.618 [   8.246], Avg:   -12.108 (0.100) <0-00:49:39> ({'r_t':   879.7034, 'eps':     0.1000, 'critic_loss':   840.3782, 'actor_loss':    -1.9389, 'eps_e':     0.1000})
Step:  131000, Reward:   127.821 [  21.557], Avg:   -11.048 (0.100) <0-00:50:01> ({'r_t':   889.6521, 'eps':     0.1000, 'critic_loss':  1541.5280, 'actor_loss':    -2.4521, 'eps_e':     0.1000})
Step:  132000, Reward:     6.522 [ 481.472], Avg:   -10.916 (0.100) <0-00:50:23> ({'r_t':   541.6966, 'eps':     0.1000, 'critic_loss':  2636.1387, 'actor_loss':    -1.9659, 'eps_e':     0.1000})
Step:  133000, Reward:    96.771 [  32.217], Avg:   -10.113 (0.100) <0-00:50:45> ({'r_t':   826.0944, 'eps':     0.1000, 'critic_loss':  2793.9680, 'actor_loss':    -1.7237, 'eps_e':     0.1000})
Step:  134000, Reward:   131.883 [  38.467], Avg:    -9.061 (0.100) <0-00:51:07> ({'r_t':   796.3491, 'eps':     0.1000, 'critic_loss':  3707.4302, 'actor_loss':    -1.7835, 'eps_e':     0.1000})
Step:  135000, Reward:    58.474 [ 481.119], Avg:    -8.564 (0.100) <0-00:51:29> ({'r_t':   821.1283, 'eps':     0.1000, 'critic_loss':  4193.1914, 'actor_loss':    -1.9242, 'eps_e':     0.1000})
Step:  136000, Reward:   170.379 [  24.460], Avg:    -7.258 (0.100) <0-00:51:51> ({'r_t':  1006.1885, 'eps':     0.1000, 'critic_loss':  3914.2180, 'actor_loss':    -1.8687, 'eps_e':     0.1000})
Step:  137000, Reward:   206.700 [   7.962], Avg:    -5.708 (0.100) <0-00:52:14> ({'r_t':  1111.9225, 'eps':     0.1000, 'critic_loss':  3942.0601, 'actor_loss':    -2.0461, 'eps_e':     0.1000})
Step:  138000, Reward:   194.924 [  70.085], Avg:    -4.264 (0.100) <0-00:52:36> ({'r_t':  1223.6271, 'eps':     0.1000, 'critic_loss':  4067.7043, 'actor_loss':    -2.3333, 'eps_e':     0.1000})
Step:  139000, Reward:    76.238 [ 483.288], Avg:    -3.689 (0.100) <0-00:52:59> ({'r_t':  1464.0713, 'eps':     0.1000, 'critic_loss':  3636.8562, 'actor_loss':    -2.4887, 'eps_e':     0.1000})
Step:  140000, Reward:   263.406 [  28.553], Avg:    -1.795 (0.100) <0-00:53:21> ({'r_t':  1726.6446, 'eps':     0.1000, 'critic_loss':  2909.6311, 'actor_loss':    -3.3737, 'eps_e':     0.1000})
Step:  141000, Reward:   196.976 [  52.381], Avg:    -0.395 (0.100) <0-00:53:43> ({'r_t':  1718.3855, 'eps':     0.1000, 'critic_loss':  2166.3904, 'actor_loss':    -4.5390, 'eps_e':     0.1000})
Step:  142000, Reward:   -39.374 [ 647.117], Avg:    -0.668 (0.100) <0-00:54:06> ({'r_t':  1721.3184, 'eps':     0.1000, 'critic_loss':  1772.0248, 'actor_loss':    -5.6538, 'eps_e':     0.1000})
Step:  143000, Reward:   163.914 [  99.652], Avg:     0.475 (0.100) <0-00:54:29> ({'r_t':  1523.9074, 'eps':     0.1000, 'critic_loss':  1491.7286, 'actor_loss':    -6.6104, 'eps_e':     0.1000})
Step:  144000, Reward:   205.211 [  88.172], Avg:     1.887 (0.100) <0-00:54:52> ({'r_t':  1470.5428, 'eps':     0.1000, 'critic_loss':   990.3945, 'actor_loss':    -5.7442, 'eps_e':     0.1000})
Step:  145000, Reward:   233.176 [  66.922], Avg:     3.471 (0.100) <0-00:55:14> ({'r_t':  1465.6296, 'eps':     0.1000, 'critic_loss':  1133.6301, 'actor_loss':    -4.6357, 'eps_e':     0.1000})
Step:  146000, Reward:   278.667 [  43.522], Avg:     5.343 (0.100) <0-00:55:37> ({'r_t':  1537.0680, 'eps':     0.1000, 'critic_loss':  1227.4674, 'actor_loss':    -3.6454, 'eps_e':     0.1000})
Step:  147000, Reward:   -22.354 [ 745.041], Avg:     5.156 (0.100) <0-00:56:00> ({'r_t':  1545.7532, 'eps':     0.1000, 'critic_loss':   614.3927, 'actor_loss':    -3.2808, 'eps_e':     0.1000})
Step:  148000, Reward:   127.275 [ 480.489], Avg:     5.976 (0.100) <0-00:56:23> ({'r_t':  1685.2610, 'eps':     0.1000, 'critic_loss':  1058.4303, 'actor_loss':    -3.1123, 'eps_e':     0.1000})
Step:  149000, Reward:   142.637 [ 483.967], Avg:     6.887 (0.100) <0-00:56:45> ({'r_t':  1346.9469, 'eps':     0.1000, 'critic_loss':  1398.9597, 'actor_loss':    -3.1344, 'eps_e':     0.1000})
Step:  150000, Reward:   201.176 [  69.211], Avg:     8.174 (0.100) <0-00:57:09> ({'r_t':  1428.3077, 'eps':     0.1000, 'critic_loss':  2562.6011, 'actor_loss':    -3.5596, 'eps_e':     0.1000})
Step:  151000, Reward:   272.937 [  35.810], Avg:     9.915 (0.100) <0-00:57:32> ({'r_t':  1690.7318, 'eps':     0.1000, 'critic_loss':  1939.1494, 'actor_loss':    -3.9409, 'eps_e':     0.1000})
Step:  152000, Reward:   257.516 [  74.952], Avg:    11.534 (0.100) <0-00:57:55> ({'r_t':  1500.5604, 'eps':     0.1000, 'critic_loss':  2315.2441, 'actor_loss':    -4.2894, 'eps_e':     0.1000})
Step:  153000, Reward:   269.902 [  58.955], Avg:    13.211 (0.100) <0-00:58:17> ({'r_t':  1490.1151, 'eps':     0.1000, 'critic_loss':  1731.1310, 'actor_loss':    -4.6409, 'eps_e':     0.1000})
Step:  154000, Reward:   263.773 [  68.248], Avg:    14.828 (0.100) <0-00:58:41> ({'r_t':  1741.4052, 'eps':     0.1000, 'critic_loss':   988.3397, 'actor_loss':    -4.1349, 'eps_e':     0.1000})
Step:  155000, Reward:   246.259 [  34.784], Avg:    16.312 (0.100) <0-00:59:05> ({'r_t':  1608.2529, 'eps':     0.1000, 'critic_loss':  2424.4629, 'actor_loss':    -3.5523, 'eps_e':     0.1000})
Step:  156000, Reward:   283.457 [  22.662], Avg:    18.013 (0.100) <0-00:59:27> ({'r_t':  1566.4891, 'eps':     0.1000, 'critic_loss':  1295.3036, 'actor_loss':    -3.3558, 'eps_e':     0.1000})
Step:  157000, Reward:   285.831 [  24.618], Avg:    19.708 (0.100) <0-00:59:50> ({'r_t':  1619.0165, 'eps':     0.1000, 'critic_loss':  1144.2192, 'actor_loss':    -3.6539, 'eps_e':     0.1000})
Step:  158000, Reward:   239.282 [  48.645], Avg:    21.089 (0.100) <0-01:00:13> ({'r_t':  1679.5986, 'eps':     0.1000, 'critic_loss':  2766.4026, 'actor_loss':    -3.5315, 'eps_e':     0.1000})
Step:  159000, Reward:   259.400 [  67.661], Avg:    22.579 (0.100) <0-01:00:37> ({'r_t':  1849.5256, 'eps':     0.1000, 'critic_loss':  1502.6932, 'actor_loss':    -3.5782, 'eps_e':     0.1000})
Step:  160000, Reward:   252.855 [  92.026], Avg:    24.009 (0.100) <0-01:01:00> ({'r_t':  1581.0585, 'eps':     0.1000, 'critic_loss':  2656.0203, 'actor_loss':    -3.4338, 'eps_e':     0.1000})
Step:  161000, Reward:   273.739 [  37.875], Avg:    25.550 (0.100) <0-01:01:23> ({'r_t':  1670.2271, 'eps':     0.1000, 'critic_loss':  2608.8574, 'actor_loss':    -3.4281, 'eps_e':     0.1000})
Step:  162000, Reward:   261.472 [  60.499], Avg:    26.998 (0.100) <0-01:01:46> ({'r_t':  1703.7449, 'eps':     0.1000, 'critic_loss':  2013.0215, 'actor_loss':    -3.2092, 'eps_e':     0.1000})
Step:  163000, Reward:   290.249 [  17.896], Avg:    28.603 (0.100) <0-01:02:09> ({'r_t':  1842.5115, 'eps':     0.1000, 'critic_loss':  1266.6631, 'actor_loss':    -3.1739, 'eps_e':     0.1000})
Step:  164000, Reward:   168.429 [ 485.937], Avg:    29.450 (0.100) <0-01:02:32> ({'r_t':  1687.9903, 'eps':     0.1000, 'critic_loss':  1160.9510, 'actor_loss':    -3.3396, 'eps_e':     0.1000})
Step:  165000, Reward:   169.261 [ 480.385], Avg:    30.293 (0.100) <0-01:02:54> ({'r_t':  1862.8046, 'eps':     0.1000, 'critic_loss':  1229.9539, 'actor_loss':    -3.5202, 'eps_e':     0.1000})
Step:  166000, Reward:   256.123 [  53.485], Avg:    31.645 (0.100) <0-01:03:17> ({'r_t':  1676.4043, 'eps':     0.1000, 'critic_loss':  1485.3546, 'actor_loss':    -3.5537, 'eps_e':     0.1000})
Step:  167000, Reward:   243.459 [  73.893], Avg:    32.906 (0.100) <0-01:03:40> ({'r_t':  1884.2756, 'eps':     0.1000, 'critic_loss':  2408.6565, 'actor_loss':    -3.2067, 'eps_e':     0.1000})
Step:  168000, Reward:   281.722 [  45.112], Avg:    34.378 (0.100) <0-01:04:03> ({'r_t':  1881.8974, 'eps':     0.1000, 'critic_loss':  1308.1256, 'actor_loss':    -3.2217, 'eps_e':     0.1000})
Step:  169000, Reward:   127.850 [ 491.157], Avg:    34.928 (0.100) <0-01:04:27> ({'r_t':  1895.5996, 'eps':     0.1000, 'critic_loss':  1479.9785, 'actor_loss':    -3.2024, 'eps_e':     0.1000})
Step:  170000, Reward:   291.832 [  18.285], Avg:    36.430 (0.100) <0-01:04:50> ({'r_t':  1618.5811, 'eps':     0.1000, 'critic_loss':  1140.0809, 'actor_loss':    -3.2029, 'eps_e':     0.1000})
Step:  171000, Reward:   238.892 [ 106.507], Avg:    37.607 (0.100) <0-01:05:20> ({'r_t':  1434.1195, 'eps':     0.1000, 'critic_loss':  1820.0038, 'actor_loss':    -3.2544, 'eps_e':     0.1000})
Step:  172000, Reward:   133.127 [ 483.661], Avg:    38.159 (0.100) <0-01:05:47> ({'r_t':  1455.8198, 'eps':     0.1000, 'critic_loss':  1977.9022, 'actor_loss':    -3.3836, 'eps_e':     0.1000})
Step:  173000, Reward:   240.757 [ 166.715], Avg:    39.324 (0.100) <0-01:06:16> ({'r_t':  1890.4068, 'eps':     0.1000, 'critic_loss':  1936.7605, 'actor_loss':    -3.1242, 'eps_e':     0.1000})
Step:  174000, Reward:   280.775 [  25.321], Avg:    40.703 (0.100) <0-01:06:39> ({'r_t':  1595.8100, 'eps':     0.1000, 'critic_loss':  2585.8345, 'actor_loss':    -3.3459, 'eps_e':     0.1000})
Step:  175000, Reward:   291.072 [   9.902], Avg:    42.126 (0.100) <0-01:07:02> ({'r_t':  1922.2606, 'eps':     0.1000, 'critic_loss':  3147.2720, 'actor_loss':    -3.6682, 'eps_e':     0.1000})
Step:  176000, Reward:   175.120 [ 484.405], Avg:    42.877 (0.100) <0-01:07:24> ({'r_t':  1710.1410, 'eps':     0.1000, 'critic_loss':  2055.9521, 'actor_loss':    -3.5364, 'eps_e':     0.1000})
Step:  177000, Reward:   304.903 [  35.045], Avg:    44.349 (0.100) <0-01:07:48> ({'r_t':  1637.2680, 'eps':     0.1000, 'critic_loss':  2842.4812, 'actor_loss':    -3.2688, 'eps_e':     0.1000})
Step:  178000, Reward:   293.437 [  15.012], Avg:    45.741 (0.100) <0-01:08:11> ({'r_t':  1876.9920, 'eps':     0.1000, 'critic_loss':  2647.9712, 'actor_loss':    -2.7270, 'eps_e':     0.1000})
Step:  179000, Reward:   300.650 [  11.536], Avg:    47.157 (0.100) <0-01:08:33> ({'r_t':  2008.7798, 'eps':     0.1000, 'critic_loss':  2111.5840, 'actor_loss':    -2.4787, 'eps_e':     0.1000})
Step:  180000, Reward:   217.713 [  98.252], Avg:    48.099 (0.100) <0-01:08:56> ({'r_t':  2039.9806, 'eps':     0.1000, 'critic_loss':  2231.8286, 'actor_loss':    -2.4072, 'eps_e':     0.1000})
Step:  181000, Reward:   292.508 [  24.414], Avg:    49.442 (0.100) <0-01:09:19> ({'r_t':  1902.9341, 'eps':     0.1000, 'critic_loss':  2354.0854, 'actor_loss':    -2.4303, 'eps_e':     0.1000})
Step:  182000, Reward:   260.061 [  49.625], Avg:    50.593 (0.100) <0-01:09:43> ({'r_t':  2026.7858, 'eps':     0.1000, 'critic_loss':  2175.9810, 'actor_loss':    -2.1924, 'eps_e':     0.1000})
Step:  183000, Reward:   292.785 [  19.862], Avg:    51.910 (0.100) <0-01:10:06> ({'r_t':  1815.8918, 'eps':     0.1000, 'critic_loss':  1856.4023, 'actor_loss':    -2.1315, 'eps_e':     0.1000})
Step:  184000, Reward:   272.163 [  77.354], Avg:    53.100 (0.100) <0-01:10:28> ({'r_t':  1723.1260, 'eps':     0.1000, 'critic_loss':  1240.7939, 'actor_loss':    -2.2042, 'eps_e':     0.1000})
Step:  185000, Reward:   305.021 [  28.587], Avg:    54.455 (0.100) <0-01:10:52> ({'r_t':  1818.3283, 'eps':     0.1000, 'critic_loss':  1338.5992, 'actor_loss':    -2.2888, 'eps_e':     0.1000})
Step:  186000, Reward:   302.226 [  42.692], Avg:    55.780 (0.100) <0-01:11:16> ({'r_t':  1682.7832, 'eps':     0.1000, 'critic_loss':  1728.1775, 'actor_loss':    -2.6331, 'eps_e':     0.1000})
Step:  187000, Reward:   267.711 [ 101.506], Avg:    56.907 (0.100) <0-01:11:41> ({'r_t':  1747.8516, 'eps':     0.1000, 'critic_loss':  1591.6904, 'actor_loss':    -2.7976, 'eps_e':     0.1000})
Step:  188000, Reward:   307.671 [  29.365], Avg:    58.234 (0.100) <0-01:12:05> ({'r_t':  1645.1602, 'eps':     0.1000, 'critic_loss':   997.7393, 'actor_loss':    -2.8574, 'eps_e':     0.1000})
Step:  189000, Reward:   148.490 [ 499.034], Avg:    58.709 (0.100) <0-01:12:32> ({'r_t':  1731.1955, 'eps':     0.1000, 'critic_loss':   799.6541, 'actor_loss':    -2.7730, 'eps_e':     0.1000})
Step:  190000, Reward:   265.361 [  93.364], Avg:    59.791 (0.100) <0-01:12:57> ({'r_t':  1759.4014, 'eps':     0.1000, 'critic_loss':  1642.1049, 'actor_loss':    -2.5218, 'eps_e':     0.1000})
Step:  191000, Reward:   272.281 [ 125.731], Avg:    60.897 (0.100) <0-01:13:22> ({'r_t':  1757.0523, 'eps':     0.1000, 'critic_loss':   957.5665, 'actor_loss':    -2.1662, 'eps_e':     0.1000})
Step:  192000, Reward:   276.107 [  97.734], Avg:    62.012 (0.100) <0-01:13:47> ({'r_t':  1955.5403, 'eps':     0.1000, 'critic_loss':   431.1886, 'actor_loss':    -2.0936, 'eps_e':     0.1000})
Step:  193000, Reward:   276.924 [  39.426], Avg:    63.120 (0.100) <0-01:14:11> ({'r_t':  1756.0568, 'eps':     0.1000, 'critic_loss':   722.2534, 'actor_loss':    -2.0342, 'eps_e':     0.1000})
Step:  194000, Reward:   -83.515 [ 780.491], Avg:    62.368 (0.100) <0-01:14:35> ({'r_t':  1786.2397, 'eps':     0.1000, 'critic_loss':   956.8427, 'actor_loss':    -1.9944, 'eps_e':     0.1000})
Step:  195000, Reward:   293.108 [  53.345], Avg:    63.545 (0.100) <0-01:14:59> ({'r_t':  1409.6244, 'eps':     0.1000, 'critic_loss':  1348.7352, 'actor_loss':    -1.9110, 'eps_e':     0.1000})
Step:  196000, Reward:   301.263 [  72.168], Avg:    64.752 (0.100) <0-01:15:22> ({'r_t':  1469.7276, 'eps':     0.1000, 'critic_loss':  1720.5432, 'actor_loss':    -2.1606, 'eps_e':     0.1000})
Step:  197000, Reward:   311.301 [  46.657], Avg:    65.997 (0.100) <0-01:15:45> ({'r_t':  1934.4936, 'eps':     0.1000, 'critic_loss':  2118.8091, 'actor_loss':    -2.7634, 'eps_e':     0.1000})
Step:  198000, Reward:   197.644 [ 477.284], Avg:    66.659 (0.100) <0-01:16:10> ({'r_t':  2071.7092, 'eps':     0.1000, 'critic_loss':  1542.7501, 'actor_loss':    -2.8165, 'eps_e':     0.1000})
Step:  199000, Reward:   318.596 [  35.423], Avg:    67.919 (0.100) <0-01:16:32> ({'r_t':  1985.0029, 'eps':     0.1000, 'critic_loss':  1793.8145, 'actor_loss':    -3.1065, 'eps_e':     0.1000})
Step:  200000, Reward:   334.795 [  35.084], Avg:    69.246 (0.100) <0-01:16:56> ({'r_t':  1626.0554, 'eps':     0.1000, 'critic_loss':  1614.9852, 'actor_loss':    -2.9510, 'eps_e':     0.1000})
Step:  201000, Reward:   320.486 [  53.233], Avg:    70.490 (0.100) <0-01:17:18> ({'r_t':  1905.6191, 'eps':     0.1000, 'critic_loss':  2424.7681, 'actor_loss':    -2.8887, 'eps_e':     0.1000})
Step:  202000, Reward:   322.541 [  40.545], Avg:    71.732 (0.100) <0-01:17:42> ({'r_t':  1953.7065, 'eps':     0.1000, 'critic_loss':  1873.8107, 'actor_loss':    -2.7279, 'eps_e':     0.1000})
Step:  203000, Reward:   294.446 [  76.403], Avg:    72.823 (0.100) <0-01:18:08> ({'r_t':  1774.2354, 'eps':     0.1000, 'critic_loss':  1203.9344, 'actor_loss':    -2.4035, 'eps_e':     0.1000})
Step:  204000, Reward:   289.535 [  50.899], Avg:    73.881 (0.100) <0-01:18:31> ({'r_t':  1563.8486, 'eps':     0.1000, 'critic_loss':  1334.1694, 'actor_loss':    -2.4408, 'eps_e':     0.1000})
Step:  205000, Reward:   198.572 [ 497.550], Avg:    74.486 (0.100) <0-01:18:54> ({'r_t':  1823.1628, 'eps':     0.1000, 'critic_loss':  2818.9272, 'actor_loss':    -2.4305, 'eps_e':     0.1000})
Step:  206000, Reward:   303.720 [  85.686], Avg:    75.593 (0.100) <0-01:19:17> ({'r_t':  1501.6298, 'eps':     0.1000, 'critic_loss':  2643.5618, 'actor_loss':    -2.4078, 'eps_e':     0.1000})
Step:  207000, Reward:   194.475 [ 478.068], Avg:    76.165 (0.100) <0-01:19:41> ({'r_t':  1901.8383, 'eps':     0.1000, 'critic_loss':  2883.3896, 'actor_loss':    -2.4030, 'eps_e':     0.1000})
Step:  208000, Reward:   338.569 [  29.717], Avg:    77.420 (0.100) <0-01:20:04> ({'r_t':  1969.9298, 'eps':     0.1000, 'critic_loss':  2146.1108, 'actor_loss':    -2.5102, 'eps_e':     0.1000})
Step:  209000, Reward:   330.292 [  33.996], Avg:    78.624 (0.100) <0-01:20:28> ({'r_t':  1836.3117, 'eps':     0.1000, 'critic_loss':  3175.1641, 'actor_loss':    -2.4554, 'eps_e':     0.1000})
Step:  210000, Reward:   350.240 [  27.832], Avg:    79.912 (0.100) <0-01:20:51> ({'r_t':  2126.0378, 'eps':     0.1000, 'critic_loss':  2447.1731, 'actor_loss':    -2.4434, 'eps_e':     0.1000})
Step:  211000, Reward:   337.729 [  30.980], Avg:    81.128 (0.100) <0-01:21:15> ({'r_t':  2083.1093, 'eps':     0.1000, 'critic_loss':  1829.2777, 'actor_loss':    -2.4301, 'eps_e':     0.1000})
Step:  212000, Reward:   312.742 [ 104.512], Avg:    82.215 (0.100) <0-01:21:38> ({'r_t':  2036.9297, 'eps':     0.1000, 'critic_loss':  1280.3464, 'actor_loss':    -2.4387, 'eps_e':     0.1000})
Step:  213000, Reward:   344.239 [  41.680], Avg:    83.440 (0.100) <0-01:22:01> ({'r_t':  2098.3225, 'eps':     0.1000, 'critic_loss':   842.8278, 'actor_loss':    -2.3827, 'eps_e':     0.1000})
Step:  214000, Reward:   349.012 [  27.418], Avg:    84.675 (0.100) <0-01:22:25> ({'r_t':  1957.4842, 'eps':     0.1000, 'critic_loss':  1264.9305, 'actor_loss':    -2.2438, 'eps_e':     0.1000})
Step:  215000, Reward:   218.221 [ 488.246], Avg:    85.293 (0.100) <0-01:22:48> ({'r_t':  1844.9517, 'eps':     0.1000, 'critic_loss':   591.7695, 'actor_loss':    -2.0942, 'eps_e':     0.1000})
Step:  216000, Reward:   333.915 [  26.341], Avg:    86.439 (0.100) <0-01:23:11> ({'r_t':  1982.1852, 'eps':     0.1000, 'critic_loss':   771.1571, 'actor_loss':    -2.1585, 'eps_e':     0.1000})
Step:  217000, Reward:   164.719 [ 506.485], Avg:    86.798 (0.100) <0-01:23:34> ({'r_t':  1874.1122, 'eps':     0.1000, 'critic_loss':  1357.2942, 'actor_loss':    -2.4418, 'eps_e':     0.1000})
Step:  218000, Reward:   194.620 [ 127.156], Avg:    87.290 (0.100) <0-01:23:57> ({'r_t':  1974.7070, 'eps':     0.1000, 'critic_loss':  1485.4790, 'actor_loss':    -2.3945, 'eps_e':     0.1000})
Step:  219000, Reward:   312.382 [  75.015], Avg:    88.313 (0.100) <0-01:24:21> ({'r_t':  1934.3019, 'eps':     0.1000, 'critic_loss':  1784.9398, 'actor_loss':    -2.5736, 'eps_e':     0.1000})
Step:  220000, Reward:   341.824 [  30.746], Avg:    89.461 (0.100) <0-01:24:45> ({'r_t':  1801.2265, 'eps':     0.1000, 'critic_loss':  1682.3706, 'actor_loss':    -2.4232, 'eps_e':     0.1000})
Step:  221000, Reward:   170.361 [ 492.967], Avg:    89.825 (0.100) <0-01:25:08> ({'r_t':  1673.9641, 'eps':     0.1000, 'critic_loss':  1949.2629, 'actor_loss':    -2.5741, 'eps_e':     0.1000})
Step:  222000, Reward:   323.228 [  35.469], Avg:    90.872 (0.100) <0-01:25:32> ({'r_t':  1991.4567, 'eps':     0.1000, 'critic_loss':  1707.4146, 'actor_loss':    -2.5277, 'eps_e':     0.1000})
Step:  223000, Reward:  -229.501 [ 792.396], Avg:    89.441 (0.100) <0-01:26:01> ({'r_t':  1445.6668, 'eps':     0.1000, 'critic_loss':  1638.5303, 'actor_loss':    -2.7894, 'eps_e':     0.1000})
Step:  224000, Reward:   342.065 [  32.899], Avg:    90.564 (0.100) <0-01:26:24> ({'r_t':  1163.2514, 'eps':     0.1000, 'critic_loss':  1672.6752, 'actor_loss':    -2.9583, 'eps_e':     0.1000})
Step:  225000, Reward:   290.337 [  59.984], Avg:    91.448 (0.100) <0-01:26:47> ({'r_t':  1880.6063, 'eps':     0.1000, 'critic_loss':  1768.9941, 'actor_loss':    -3.0718, 'eps_e':     0.1000})
Step:  226000, Reward:   348.127 [  42.655], Avg:    92.579 (0.100) <0-01:27:11> ({'r_t':  1685.5003, 'eps':     0.1000, 'critic_loss':  1961.4825, 'actor_loss':    -3.2006, 'eps_e':     0.1000})
Step:  227000, Reward:   326.783 [  44.115], Avg:    93.606 (0.100) <0-01:27:34> ({'r_t':  1864.0823, 'eps':     0.1000, 'critic_loss':  1639.6246, 'actor_loss':    -3.2876, 'eps_e':     0.1000})
Step:  228000, Reward:   340.985 [  29.560], Avg:    94.686 (0.100) <0-01:27:57> ({'r_t':  2043.6079, 'eps':     0.1000, 'critic_loss':  2223.2629, 'actor_loss':    -3.3986, 'eps_e':     0.1000})
Step:  229000, Reward:   276.881 [ 100.987], Avg:    95.478 (0.100) <0-01:28:22> ({'r_t':  1843.7954, 'eps':     0.1000, 'critic_loss':  2018.7328, 'actor_loss':    -3.5624, 'eps_e':     0.1000})
Step:  230000, Reward:   278.443 [  95.606], Avg:    96.271 (0.100) <0-01:28:45> ({'r_t':  1838.0393, 'eps':     0.1000, 'critic_loss':  2588.9380, 'actor_loss':    -3.0960, 'eps_e':     0.1000})
Step:  231000, Reward:   290.343 [  41.021], Avg:    97.107 (0.100) <0-01:29:09> ({'r_t':  1964.9986, 'eps':     0.1000, 'critic_loss':  2192.4500, 'actor_loss':    -3.1422, 'eps_e':     0.1000})
Step:  232000, Reward:   239.367 [ 158.467], Avg:    97.718 (0.100) <0-01:29:33> ({'r_t':  1905.9952, 'eps':     0.1000, 'critic_loss':  1754.4404, 'actor_loss':    -3.0438, 'eps_e':     0.1000})
Step:  233000, Reward:   333.488 [  32.532], Avg:    98.725 (0.100) <0-01:29:57> ({'r_t':  1913.5936, 'eps':     0.1000, 'critic_loss':  1510.9093, 'actor_loss':    -2.8068, 'eps_e':     0.1000})
Step:  234000, Reward:   191.929 [ 484.577], Avg:    99.122 (0.100) <0-01:30:20> ({'r_t':  1907.1598, 'eps':     0.1000, 'critic_loss':  1841.7435, 'actor_loss':    -2.7380, 'eps_e':     0.1000})
Step:  235000, Reward:   341.306 [  32.539], Avg:   100.148 (0.100) <0-01:30:43> ({'r_t':  2269.5043, 'eps':     0.1000, 'critic_loss':  1102.0334, 'actor_loss':    -2.7776, 'eps_e':     0.1000})
Step:  236000, Reward:   337.755 [  39.145], Avg:   101.151 (0.100) <0-01:31:06> ({'r_t':  2107.2271, 'eps':     0.1000, 'critic_loss':  1250.2407, 'actor_loss':    -2.7833, 'eps_e':     0.1000})
Step:  237000, Reward:   334.504 [  30.405], Avg:   102.131 (0.100) <0-01:31:29> ({'r_t':  2200.1883, 'eps':     0.1000, 'critic_loss':  1232.5465, 'actor_loss':    -2.7469, 'eps_e':     0.1000})
Step:  238000, Reward:   237.019 [ 485.690], Avg:   102.695 (0.100) <0-01:31:52> ({'r_t':  2204.6313, 'eps':     0.1000, 'critic_loss':   914.9491, 'actor_loss':    -2.6460, 'eps_e':     0.1000})
Step:  239000, Reward:   242.053 [ 489.597], Avg:   103.276 (0.100) <0-01:32:15> ({'r_t':  1957.1088, 'eps':     0.1000, 'critic_loss':  1177.8094, 'actor_loss':    -2.3690, 'eps_e':     0.1000})
Step:  240000, Reward:   341.915 [  32.252], Avg:   104.266 (0.100) <0-01:32:38> ({'r_t':  1769.1840, 'eps':     0.1000, 'critic_loss':   958.4985, 'actor_loss':    -2.4291, 'eps_e':     0.1000})
Step:  241000, Reward:   313.995 [  50.266], Avg:   105.133 (0.100) <0-01:33:01> ({'r_t':  1913.7359, 'eps':     0.1000, 'critic_loss':  1465.9325, 'actor_loss':    -2.1848, 'eps_e':     0.1000})
Step:  242000, Reward:   171.598 [ 513.430], Avg:   105.406 (0.100) <0-01:33:25> ({'r_t':  1475.1648, 'eps':     0.1000, 'critic_loss':  2434.9512, 'actor_loss':    -2.1949, 'eps_e':     0.1000})
Step:  243000, Reward:   259.840 [  74.754], Avg:   106.039 (0.100) <0-01:33:49> ({'r_t':  1499.8499, 'eps':     0.1000, 'critic_loss':  4164.1304, 'actor_loss':    -2.4822, 'eps_e':     0.1000})
Step:  244000, Reward:   312.865 [  66.912], Avg:   106.884 (0.100) <0-01:34:12> ({'r_t':  1935.1888, 'eps':     0.1000, 'critic_loss':  3943.5703, 'actor_loss':    -3.1309, 'eps_e':     0.1000})
Step:  245000, Reward:   292.262 [ 157.867], Avg:   107.637 (0.100) <0-01:34:35> ({'r_t':  1840.5108, 'eps':     0.1000, 'critic_loss':  3572.0405, 'actor_loss':    -3.0992, 'eps_e':     0.1000})
Step:  246000, Reward:   341.678 [  40.670], Avg:   108.585 (0.100) <0-01:34:59> ({'r_t':  1847.3757, 'eps':     0.1000, 'critic_loss':  3893.7095, 'actor_loss':    -3.5405, 'eps_e':     0.1000})
Step:  247000, Reward:   233.774 [ 169.345], Avg:   109.089 (0.100) <0-01:35:22> ({'r_t':  1905.7653, 'eps':     0.1000, 'critic_loss':  3092.2039, 'actor_loss':    -3.6566, 'eps_e':     0.1000})
Step:  248000, Reward:   327.001 [  60.346], Avg:   109.965 (0.100) <0-01:35:45> ({'r_t':  1896.6511, 'eps':     0.1000, 'critic_loss':  2218.8650, 'actor_loss':    -3.5743, 'eps_e':     0.1000})
Step:  249000, Reward:   315.261 [  89.110], Avg:   110.786 (0.100) <0-01:36:09> ({'r_t':  1888.3794, 'eps':     0.1000, 'critic_loss':  1031.7563, 'actor_loss':    -3.2096, 'eps_e':     0.1000})
Step:  250000, Reward:   331.984 [  47.158], Avg:   111.667 (0.100) <0-01:36:33> ({'r_t':  2142.3470, 'eps':     0.1000, 'critic_loss':   537.4980, 'actor_loss':    -2.6564, 'eps_e':     0.1000})
Step:  251000, Reward:   307.379 [  57.932], Avg:   112.444 (0.100) <0-01:36:58> ({'r_t':  1948.8116, 'eps':     0.1000, 'critic_loss':   729.3724, 'actor_loss':    -2.5683, 'eps_e':     0.1000})
Step:  252000, Reward:   321.106 [  76.749], Avg:   113.268 (0.100) <0-01:37:20> ({'r_t':  2002.5551, 'eps':     0.1000, 'critic_loss':   572.4809, 'actor_loss':    -2.3887, 'eps_e':     0.1000})
Step:  253000, Reward:   291.261 [  68.430], Avg:   113.969 (0.100) <0-01:37:43> ({'r_t':  1859.0881, 'eps':     0.1000, 'critic_loss':  1319.9579, 'actor_loss':    -2.4425, 'eps_e':     0.1000})
Step:  254000, Reward:   345.603 [  34.972], Avg:   114.878 (0.100) <0-01:38:06> ({'r_t':  2123.9880, 'eps':     0.1000, 'critic_loss':   853.3173, 'actor_loss':    -2.5685, 'eps_e':     0.1000})
Step:  255000, Reward:   323.362 [  42.277], Avg:   115.692 (0.100) <0-01:38:30> ({'r_t':  2006.6213, 'eps':     0.1000, 'critic_loss':  1134.7085, 'actor_loss':    -2.6258, 'eps_e':     0.1000})
Step:  256000, Reward:   343.006 [  41.000], Avg:   116.576 (0.100) <0-01:38:53> ({'r_t':  2133.4346, 'eps':     0.1000, 'critic_loss':  1345.1006, 'actor_loss':    -2.4936, 'eps_e':     0.1000})
Step:  257000, Reward:   345.395 [  35.529], Avg:   117.463 (0.100) <0-01:39:16> ({'r_t':  2171.3285, 'eps':     0.1000, 'critic_loss':   978.3985, 'actor_loss':    -2.2471, 'eps_e':     0.1000})
Step:  258000, Reward:   316.297 [  78.214], Avg:   118.231 (0.100) <0-01:39:39> ({'r_t':  2127.6145, 'eps':     0.1000, 'critic_loss':  1149.4712, 'actor_loss':    -2.1832, 'eps_e':     0.1000})
Step:  259000, Reward:   300.207 [  97.375], Avg:   118.931 (0.100) <0-01:40:02> ({'r_t':  2121.1305, 'eps':     0.1000, 'critic_loss':  1001.4006, 'actor_loss':    -1.9473, 'eps_e':     0.1000})
Step:  260000, Reward:   350.674 [  41.793], Avg:   119.819 (0.100) <0-01:40:25> ({'r_t':  1854.8612, 'eps':     0.1000, 'critic_loss':  1141.1505, 'actor_loss':    -1.9299, 'eps_e':     0.1000})
Step:  261000, Reward:   346.203 [  41.894], Avg:   120.683 (0.100) <0-01:40:48> ({'r_t':  2066.2995, 'eps':     0.1000, 'critic_loss':   840.8471, 'actor_loss':    -2.1364, 'eps_e':     0.1000})
Step:  262000, Reward:   359.051 [  29.228], Avg:   121.589 (0.100) <0-01:41:10> ({'r_t':  2143.3083, 'eps':     0.1000, 'critic_loss':   709.6802, 'actor_loss':    -2.0370, 'eps_e':     0.1000})
Step:  263000, Reward:   297.546 [ 157.554], Avg:   122.256 (0.100) <0-01:41:33> ({'r_t':  2173.3114, 'eps':     0.1000, 'critic_loss':   571.2017, 'actor_loss':    -2.0760, 'eps_e':     0.1000})
Step:  264000, Reward:   358.672 [  42.242], Avg:   123.148 (0.100) <0-01:41:57> ({'r_t':  1971.4620, 'eps':     0.1000, 'critic_loss':   846.0623, 'actor_loss':    -2.1337, 'eps_e':     0.1000})
Step:  265000, Reward:   330.425 [ 116.508], Avg:   123.927 (0.100) <0-01:42:24> ({'r_t':  2052.0228, 'eps':     0.1000, 'critic_loss':   601.1340, 'actor_loss':    -2.0639, 'eps_e':     0.1000})
Step:  266000, Reward:   363.226 [  30.888], Avg:   124.823 (0.100) <0-01:42:48> ({'r_t':  2123.0334, 'eps':     0.1000, 'critic_loss':  1026.1560, 'actor_loss':    -2.3416, 'eps_e':     0.1000})
Step:  267000, Reward:   335.287 [  76.150], Avg:   125.609 (0.100) <0-01:43:12> ({'r_t':  2159.4834, 'eps':     0.1000, 'critic_loss':   562.9862, 'actor_loss':    -2.1833, 'eps_e':     0.1000})
Step:  268000, Reward:   322.645 [  52.914], Avg:   126.341 (0.100) <0-01:43:35> ({'r_t':  2057.0979, 'eps':     0.1000, 'critic_loss':   420.0269, 'actor_loss':    -2.1153, 'eps_e':     0.1000})
Step:  269000, Reward:   327.775 [  97.662], Avg:   127.087 (0.100) <0-01:43:58> ({'r_t':  2126.4900, 'eps':     0.1000, 'critic_loss':   920.1585, 'actor_loss':    -2.0872, 'eps_e':     0.1000})
Step:  270000, Reward:   346.789 [  36.214], Avg:   127.898 (0.100) <0-01:44:21> ({'r_t':  2141.0785, 'eps':     0.1000, 'critic_loss':  1069.6400, 'actor_loss':    -2.0383, 'eps_e':     0.1000})
Step:  271000, Reward:   333.546 [  43.027], Avg:   128.654 (0.100) <0-01:44:44> ({'r_t':  2193.7393, 'eps':     0.1000, 'critic_loss':   411.1443, 'actor_loss':    -2.0078, 'eps_e':     0.1000})
Step:  272000, Reward:   368.274 [  24.326], Avg:   129.532 (0.100) <0-01:45:07> ({'r_t':  2090.8617, 'eps':     0.1000, 'critic_loss':   474.3157, 'actor_loss':    -1.9706, 'eps_e':     0.1000})
Step:  273000, Reward:   163.323 [ 517.480], Avg:   129.655 (0.100) <0-01:45:30> ({'r_t':  2205.0333, 'eps':     0.1000, 'critic_loss':   414.7320, 'actor_loss':    -1.8500, 'eps_e':     0.1000})
Step:  274000, Reward:   226.063 [ 487.773], Avg:   130.006 (0.100) <0-01:45:54> ({'r_t':  2055.3250, 'eps':     0.1000, 'critic_loss':   465.8701, 'actor_loss':    -1.9016, 'eps_e':     0.1000})
Step:  275000, Reward:   342.576 [  72.968], Avg:   130.776 (0.100) <0-01:46:18> ({'r_t':  1708.2985, 'eps':     0.1000, 'critic_loss':   945.1425, 'actor_loss':    -1.9322, 'eps_e':     0.1000})
Step:  276000, Reward:   338.423 [  42.694], Avg:   131.525 (0.100) <0-01:46:41> ({'r_t':  1870.8635, 'eps':     0.1000, 'critic_loss':  1191.7224, 'actor_loss':    -1.8765, 'eps_e':     0.1000})
Step:  277000, Reward:   358.679 [  27.788], Avg:   132.343 (0.100) <0-01:47:04> ({'r_t':  1956.8355, 'eps':     0.1000, 'critic_loss':  1872.1160, 'actor_loss':    -2.3131, 'eps_e':     0.1000})
Step:  278000, Reward:   203.942 [ 180.373], Avg:   132.599 (0.100) <0-01:47:33> ({'r_t':  1791.1407, 'eps':     0.1000, 'critic_loss':  1885.5220, 'actor_loss':    -2.6411, 'eps_e':     0.1000})
Step:  279000, Reward:   214.312 [ 476.420], Avg:   132.891 (0.100) <0-01:47:57> ({'r_t':  1499.5796, 'eps':     0.1000, 'critic_loss':  2142.2771, 'actor_loss':    -2.4354, 'eps_e':     0.1000})
Step:  280000, Reward:   309.298 [  38.208], Avg:   133.519 (0.100) <0-01:48:20> ({'r_t':  1868.3828, 'eps':     0.1000, 'critic_loss':  2433.8721, 'actor_loss':    -2.5405, 'eps_e':     0.1000})
Step:  281000, Reward:   297.310 [  65.497], Avg:   134.100 (0.100) <0-01:48:43> ({'r_t':  2012.7674, 'eps':     0.1000, 'critic_loss':  1907.9434, 'actor_loss':    -2.4520, 'eps_e':     0.1000})
Step:  282000, Reward:   344.186 [  36.214], Avg:   134.842 (0.100) <0-01:49:06> ({'r_t':  2090.7206, 'eps':     0.1000, 'critic_loss':  1970.4232, 'actor_loss':    -2.4969, 'eps_e':     0.1000})
Step:  283000, Reward:   340.118 [  56.263], Avg:   135.565 (0.100) <0-01:49:29> ({'r_t':  2035.0954, 'eps':     0.1000, 'critic_loss':  1588.5055, 'actor_loss':    -2.6289, 'eps_e':     0.1000})
Step:  284000, Reward:   343.263 [  70.039], Avg:   136.294 (0.100) <0-01:49:53> ({'r_t':  2013.8460, 'eps':     0.1000, 'critic_loss':  1686.5220, 'actor_loss':    -2.3902, 'eps_e':     0.1000})
Step:  285000, Reward:   344.948 [  65.229], Avg:   137.023 (0.100) <0-01:50:16> ({'r_t':  2056.5926, 'eps':     0.1000, 'critic_loss':   945.7513, 'actor_loss':    -2.3569, 'eps_e':     0.1000})
Step:  286000, Reward:   310.688 [ 116.131], Avg:   137.628 (0.100) <0-01:50:39> ({'r_t':  2164.2514, 'eps':     0.1000, 'critic_loss':   521.6124, 'actor_loss':    -2.0821, 'eps_e':     0.1000})
Step:  287000, Reward:   375.518 [  11.837], Avg:   138.454 (0.100) <0-01:51:02> ({'r_t':  2036.5755, 'eps':     0.1000, 'critic_loss':   180.6891, 'actor_loss':    -2.0083, 'eps_e':     0.1000})
Step:  288000, Reward:   349.157 [  34.727], Avg:   139.183 (0.100) <0-01:51:25> ({'r_t':  2148.8350, 'eps':     0.1000, 'critic_loss':   171.3359, 'actor_loss':    -1.9936, 'eps_e':     0.1000})
Step:  289000, Reward:   267.028 [ 161.327], Avg:   139.624 (0.100) <0-01:51:49> ({'r_t':  2028.0181, 'eps':     0.1000, 'critic_loss':   170.6837, 'actor_loss':    -1.8873, 'eps_e':     0.1000})
Step:  290000, Reward:   341.732 [  78.550], Avg:   140.319 (0.100) <0-01:52:12> ({'r_t':  2116.6600, 'eps':     0.1000, 'critic_loss':   181.3548, 'actor_loss':    -1.8022, 'eps_e':     0.1000})
Step:  291000, Reward:   365.215 [  40.700], Avg:   141.089 (0.100) <0-01:52:35> ({'r_t':  2129.9246, 'eps':     0.1000, 'critic_loss':   142.9106, 'actor_loss':    -1.7551, 'eps_e':     0.1000})
Step:  292000, Reward:   358.340 [  30.901], Avg:   141.830 (0.100) <0-01:52:58> ({'r_t':  2210.6204, 'eps':     0.1000, 'critic_loss':   151.8137, 'actor_loss':    -1.7615, 'eps_e':     0.1000})
Step:  293000, Reward:    78.640 [  56.267], Avg:   141.615 (0.100) <0-01:53:21> ({'r_t':  2121.4418, 'eps':     0.1000, 'critic_loss':   180.2895, 'actor_loss':    -1.7220, 'eps_e':     0.1000})
Step:  294000, Reward:    89.398 [ 649.837], Avg:   141.438 (0.100) <0-01:53:44> ({'r_t':  1579.3827, 'eps':     0.1000, 'critic_loss':   518.5743, 'actor_loss':    -1.8882, 'eps_e':     0.1000})
Step:  295000, Reward:   226.153 [ 485.169], Avg:   141.725 (0.100) <0-01:54:07> ({'r_t':  1500.8412, 'eps':     0.1000, 'critic_loss':  1749.4607, 'actor_loss':    -2.1512, 'eps_e':     0.1000})
Step:  296000, Reward:   331.428 [  47.320], Avg:   142.363 (0.100) <0-01:54:31> ({'r_t':  1478.0858, 'eps':     0.1000, 'critic_loss':  2672.0596, 'actor_loss':    -2.4429, 'eps_e':     0.1000})
Step:  297000, Reward:   354.275 [  29.697], Avg:   143.074 (0.100) <0-01:54:54> ({'r_t':  2076.9322, 'eps':     0.1000, 'critic_loss':  3167.5662, 'actor_loss':    -2.6140, 'eps_e':     0.1000})
Step:  298000, Reward:   350.270 [  37.345], Avg:   143.767 (0.100) <0-01:55:17> ({'r_t':  2189.1356, 'eps':     0.1000, 'critic_loss':  3617.5879, 'actor_loss':    -2.9949, 'eps_e':     0.1000})
Step:  299000, Reward:   329.732 [  84.618], Avg:   144.387 (0.100) <0-01:55:40> ({'r_t':  2144.6606, 'eps':     0.1000, 'critic_loss':  4243.4258, 'actor_loss':    -3.2667, 'eps_e':     0.1000})
Step:  300000, Reward:   361.419 [  25.038], Avg:   145.108 (0.100) <0-01:56:03> ({'r_t':  1844.2741, 'eps':     0.1000, 'critic_loss':  3791.8335, 'actor_loss':    -3.2019, 'eps_e':     0.1000})
Step:  301000, Reward:   352.481 [  42.061], Avg:   145.795 (0.100) <0-01:56:26> ({'r_t':  2192.9663, 'eps':     0.1000, 'critic_loss':  2853.9863, 'actor_loss':    -2.9480, 'eps_e':     0.1000})
Step:  302000, Reward:   355.195 [  32.800], Avg:   146.486 (0.100) <0-01:56:50> ({'r_t':  2168.4425, 'eps':     0.1000, 'critic_loss':  1552.7883, 'actor_loss':    -2.6398, 'eps_e':     0.1000})
Step:  303000, Reward:   346.072 [  39.171], Avg:   147.143 (0.100) <0-01:57:13> ({'r_t':  1907.7744, 'eps':     0.1000, 'critic_loss':   964.1382, 'actor_loss':    -2.3532, 'eps_e':     0.1000})
Step:  304000, Reward:   296.907 [  78.572], Avg:   147.634 (0.100) <0-01:57:36> ({'r_t':  2062.9507, 'eps':     0.1000, 'critic_loss':  1237.4935, 'actor_loss':    -2.3052, 'eps_e':     0.1000})
Step:  305000, Reward:   356.196 [  45.702], Avg:   148.315 (0.100) <0-01:57:59> ({'r_t':  1911.5575, 'eps':     0.1000, 'critic_loss':  1539.7079, 'actor_loss':    -2.3070, 'eps_e':     0.1000})
Step:  306000, Reward:   352.444 [  25.132], Avg:   148.980 (0.100) <0-01:58:22> ({'r_t':  2144.0753, 'eps':     0.1000, 'critic_loss':  2169.4038, 'actor_loss':    -2.3683, 'eps_e':     0.1000})
Step:  307000, Reward:   178.767 [ 141.930], Avg:   149.077 (0.100) <0-01:58:46> ({'r_t':  2034.2976, 'eps':     0.1000, 'critic_loss':  1317.2963, 'actor_loss':    -2.2606, 'eps_e':     0.1000})
Step:  308000, Reward:   357.242 [  19.795], Avg:   149.750 (0.100) <0-01:59:09> ({'r_t':  2051.7850, 'eps':     0.1000, 'critic_loss':  1997.1670, 'actor_loss':    -2.2334, 'eps_e':     0.1000})
Step:  309000, Reward:   307.449 [  98.013], Avg:   150.259 (0.100) <0-01:59:34> ({'r_t':  1677.4282, 'eps':     0.1000, 'critic_loss':  2355.6282, 'actor_loss':    -2.3056, 'eps_e':     0.1000})
Step:  310000, Reward:   335.045 [  84.531], Avg:   150.853 (0.100) <0-01:59:58> ({'r_t':  1939.4733, 'eps':     0.1000, 'critic_loss':  2463.5520, 'actor_loss':    -2.2919, 'eps_e':     0.1000})
Step:  311000, Reward:   360.414 [  33.632], Avg:   151.525 (0.100) <0-02:00:21> ({'r_t':  1982.9927, 'eps':     0.1000, 'critic_loss':  2271.1655, 'actor_loss':    -2.3490, 'eps_e':     0.1000})
Step:  312000, Reward:   344.555 [  34.779], Avg:   152.142 (0.100) <0-02:00:44> ({'r_t':  2031.6738, 'eps':     0.1000, 'critic_loss':  1510.8323, 'actor_loss':    -2.3377, 'eps_e':     0.1000})
Step:  313000, Reward:   284.760 [ 121.994], Avg:   152.564 (0.100) <0-02:01:08> ({'r_t':  2159.5416, 'eps':     0.1000, 'critic_loss':  2009.7848, 'actor_loss':    -2.4107, 'eps_e':     0.1000})
Step:  314000, Reward:    85.768 [ 480.506], Avg:   152.352 (0.100) <0-02:01:31> ({'r_t':  2128.2405, 'eps':     0.1000, 'critic_loss':  2049.1174, 'actor_loss':    -2.6045, 'eps_e':     0.1000})
Step:  315000, Reward:   349.629 [  39.061], Avg:   152.976 (0.100) <0-02:01:54> ({'r_t':  2105.8168, 'eps':     0.1000, 'critic_loss':  1643.3070, 'actor_loss':    -2.4603, 'eps_e':     0.1000})
Step:  316000, Reward:   309.118 [ 148.857], Avg:   153.469 (0.100) <0-02:02:24> ({'r_t':  2055.8322, 'eps':     0.1000, 'critic_loss':   848.3560, 'actor_loss':    -2.0924, 'eps_e':     0.1000})
Step:  317000, Reward:   365.806 [  28.155], Avg:   154.137 (0.100) <0-02:02:47> ({'r_t':  1995.9103, 'eps':     0.1000, 'critic_loss':   791.0370, 'actor_loss':    -2.0035, 'eps_e':     0.1000})
Step:  318000, Reward:   368.047 [  23.670], Avg:   154.807 (0.100) <0-02:03:10> ({'r_t':  2097.2164, 'eps':     0.1000, 'critic_loss':   461.0103, 'actor_loss':    -2.0074, 'eps_e':     0.1000})
Step:  319000, Reward:   357.764 [  36.542], Avg:   155.441 (0.100) <0-02:03:35> ({'r_t':  2046.5844, 'eps':     0.1000, 'critic_loss':   333.9851, 'actor_loss':    -1.9580, 'eps_e':     0.1000})
Step:  320000, Reward:   347.905 [  46.984], Avg:   156.041 (0.100) <0-02:03:57> ({'r_t':  2145.5630, 'eps':     0.1000, 'critic_loss':   428.3860, 'actor_loss':    -1.9732, 'eps_e':     0.1000})
Step:  321000, Reward:   370.098 [  35.361], Avg:   156.706 (0.100) <0-02:04:20> ({'r_t':  1927.8622, 'eps':     0.1000, 'critic_loss':   429.0474, 'actor_loss':    -1.7904, 'eps_e':     0.1000})
Step:  322000, Reward:   303.847 [  48.928], Avg:   157.161 (0.100) <0-02:04:43> ({'r_t':  2167.2164, 'eps':     0.1000, 'critic_loss':   336.9445, 'actor_loss':    -1.8554, 'eps_e':     0.1000})
Step:  323000, Reward:   293.366 [ 156.305], Avg:   157.582 (0.100) <0-02:05:06> ({'r_t':  2129.3918, 'eps':     0.1000, 'critic_loss':   257.5488, 'actor_loss':    -1.9054, 'eps_e':     0.1000})
Step:  324000, Reward:   239.985 [ 482.221], Avg:   157.835 (0.100) <0-02:05:29> ({'r_t':  1915.1144, 'eps':     0.1000, 'critic_loss':   335.5188, 'actor_loss':    -1.9394, 'eps_e':     0.1000})
Step:  325000, Reward:   -78.382 [ 741.968], Avg:   157.111 (0.100) <0-02:05:52> ({'r_t':  1669.5269, 'eps':     0.1000, 'critic_loss':  1759.6780, 'actor_loss':    -1.9936, 'eps_e':     0.1000})
Step:  326000, Reward:   353.638 [  79.659], Avg:   157.712 (0.100) <0-02:06:15> ({'r_t':  1090.9179, 'eps':     0.1000, 'critic_loss':  3893.0583, 'actor_loss':    -2.0203, 'eps_e':     0.1000})
Step:  327000, Reward:   358.332 [  40.677], Avg:   158.323 (0.100) <0-02:06:39> ({'r_t':  2109.6435, 'eps':     0.1000, 'critic_loss':  4246.2622, 'actor_loss':    -2.6396, 'eps_e':     0.1000})
Step:  328000, Reward:   356.872 [  38.442], Avg:   158.927 (0.100) <0-02:07:03> ({'r_t':  1941.3120, 'eps':     0.1000, 'critic_loss':  4617.7417, 'actor_loss':    -3.0192, 'eps_e':     0.1000})
Step:  329000, Reward:   355.468 [  38.619], Avg:   159.522 (0.100) <0-02:07:26> ({'r_t':  2174.5307, 'eps':     0.1000, 'critic_loss':  4727.0054, 'actor_loss':    -3.2732, 'eps_e':     0.1000})
Step:  330000, Reward:   325.226 [  27.388], Avg:   160.023 (0.100) <0-02:07:48> ({'r_t':  2177.7054, 'eps':     0.1000, 'critic_loss':  4371.6875, 'actor_loss':    -3.2763, 'eps_e':     0.1000})
Step:  331000, Reward:    68.199 [ 624.140], Avg:   159.746 (0.100) <0-02:08:12> ({'r_t':  1959.1196, 'eps':     0.1000, 'critic_loss':  3232.9431, 'actor_loss':    -3.2970, 'eps_e':     0.1000})
Step:  332000, Reward:   356.424 [  80.607], Avg:   160.337 (0.100) <0-02:08:35> ({'r_t':  2217.2530, 'eps':     0.1000, 'critic_loss':  1505.4692, 'actor_loss':    -2.9350, 'eps_e':     0.1000})
Step:  333000, Reward:   346.715 [  38.130], Avg:   160.895 (0.100) <0-02:08:58> ({'r_t':  2065.7091, 'eps':     0.1000, 'critic_loss':   576.8410, 'actor_loss':    -2.4650, 'eps_e':     0.1000})
Step:  334000, Reward:   381.353 [  12.380], Avg:   161.553 (0.100) <0-02:09:21> ({'r_t':  2302.6325, 'eps':     0.1000, 'critic_loss':   535.4697, 'actor_loss':    -2.2250, 'eps_e':     0.1000})
Step:  335000, Reward:   364.117 [  26.869], Avg:   162.156 (0.100) <0-02:09:44> ({'r_t':  2268.9230, 'eps':     0.1000, 'critic_loss':   571.2966, 'actor_loss':    -2.2331, 'eps_e':     0.1000})
Step:  336000, Reward:   365.711 [  25.600], Avg:   162.760 (0.100) <0-02:10:07> ({'r_t':  2210.3631, 'eps':     0.1000, 'critic_loss':   487.1239, 'actor_loss':    -2.0256, 'eps_e':     0.1000})
Step:  337000, Reward:   362.262 [  16.404], Avg:   163.350 (0.100) <0-02:10:30> ({'r_t':  2267.0706, 'eps':     0.1000, 'critic_loss':   607.8231, 'actor_loss':    -1.9121, 'eps_e':     0.1000})
Step:  338000, Reward:   363.714 [  36.616], Avg:   163.941 (0.100) <0-02:10:53> ({'r_t':  2092.3119, 'eps':     0.1000, 'critic_loss':   846.9207, 'actor_loss':    -1.7716, 'eps_e':     0.1000})
Step:  339000, Reward:   347.154 [  78.373], Avg:   164.480 (0.100) <0-02:11:16> ({'r_t':  2296.9794, 'eps':     0.1000, 'critic_loss':   800.3221, 'actor_loss':    -1.7753, 'eps_e':     0.1000})
Step:  340000, Reward:   358.213 [  35.063], Avg:   165.048 (0.100) <0-02:11:39> ({'r_t':  2052.0491, 'eps':     0.1000, 'critic_loss':   485.3338, 'actor_loss':    -1.7181, 'eps_e':     0.1000})
Step:  341000, Reward:   373.049 [  24.946], Avg:   165.656 (0.100) <0-02:12:02> ({'r_t':  2276.4506, 'eps':     0.1000, 'critic_loss':   459.8724, 'actor_loss':    -1.9317, 'eps_e':     0.1000})
Step:  342000, Reward:   356.283 [  24.858], Avg:   166.212 (0.100) <0-02:12:25> ({'r_t':  1942.4998, 'eps':     0.1000, 'critic_loss':   752.2067, 'actor_loss':    -1.7001, 'eps_e':     0.1000})
Step:  343000, Reward:   340.567 [  37.258], Avg:   166.719 (0.100) <0-02:12:48> ({'r_t':  1943.7424, 'eps':     0.1000, 'critic_loss':  1260.1780, 'actor_loss':    -1.7490, 'eps_e':     0.1000})
Step:  344000, Reward:   333.158 [  35.732], Avg:   167.202 (0.100) <0-02:13:11> ({'r_t':  2183.9357, 'eps':     0.1000, 'critic_loss':  1095.1624, 'actor_loss':    -1.7976, 'eps_e':     0.1000})
Step:  345000, Reward:   324.421 [  47.010], Avg:   167.656 (0.100) <0-02:13:34> ({'r_t':  1817.5166, 'eps':     0.1000, 'critic_loss':  1516.9075, 'actor_loss':    -1.9396, 'eps_e':     0.1000})
Step:  346000, Reward:   331.385 [  78.505], Avg:   168.128 (0.100) <0-02:13:58> ({'r_t':  1722.8540, 'eps':     0.1000, 'critic_loss':  1300.4951, 'actor_loss':    -1.9050, 'eps_e':     0.1000})
Step:  347000, Reward:   342.297 [  79.916], Avg:   168.628 (0.100) <0-02:14:21> ({'r_t':  1907.1132, 'eps':     0.1000, 'critic_loss':  3085.3303, 'actor_loss':    -1.9510, 'eps_e':     0.1000})
Step:  348000, Reward:   215.075 [ 162.013], Avg:   168.761 (0.100) <0-02:14:45> ({'r_t':  1448.5284, 'eps':     0.1000, 'critic_loss':  3880.1145, 'actor_loss':    -2.2024, 'eps_e':     0.1000})
Step:  349000, Reward:   358.317 [  29.059], Avg:   169.303 (0.100) <0-02:15:08> ({'r_t':  2050.8124, 'eps':     0.1000, 'critic_loss':  3312.5059, 'actor_loss':    -2.4025, 'eps_e':     0.1000})
Step:  350000, Reward:   354.789 [  44.571], Avg:   169.831 (0.100) <0-02:15:31> ({'r_t':  2207.6259, 'eps':     0.1000, 'critic_loss':  3404.4355, 'actor_loss':    -2.7231, 'eps_e':     0.1000})
Step:  351000, Reward:   371.038 [  13.713], Avg:   170.403 (0.100) <0-02:15:54> ({'r_t':  2137.3001, 'eps':     0.1000, 'critic_loss':  2933.2849, 'actor_loss':    -2.5383, 'eps_e':     0.1000})
Step:  352000, Reward:   358.280 [  24.430], Avg:   170.935 (0.100) <0-02:16:17> ({'r_t':  2168.6632, 'eps':     0.1000, 'critic_loss':  2604.7981, 'actor_loss':    -2.4052, 'eps_e':     0.1000})
Step:  353000, Reward:   111.607 [ 659.907], Avg:   170.768 (0.100) <0-02:16:40> ({'r_t':  2238.8014, 'eps':     0.1000, 'critic_loss':  1914.2023, 'actor_loss':    -2.0733, 'eps_e':     0.1000})
Step:  354000, Reward:   368.141 [  26.381], Avg:   171.324 (0.100) <0-02:17:03> ({'r_t':  2178.0891, 'eps':     0.1000, 'critic_loss':  1795.7054, 'actor_loss':    -1.9565, 'eps_e':     0.1000})
Step:  355000, Reward:   331.230 [  81.665], Avg:   171.773 (0.100) <0-02:17:27> ({'r_t':  2159.3547, 'eps':     0.1000, 'critic_loss':  1587.3829, 'actor_loss':    -1.6439, 'eps_e':     0.1000})
Step:  356000, Reward:   341.006 [  33.320], Avg:   172.247 (0.100) <0-02:17:50> ({'r_t':  1867.0146, 'eps':     0.1000, 'critic_loss':  2331.0896, 'actor_loss':    -1.5792, 'eps_e':     0.1000})
Step:  357000, Reward:   324.964 [  41.393], Avg:   172.673 (0.100) <0-02:18:14> ({'r_t':  1805.5576, 'eps':     0.1000, 'critic_loss':  2896.4929, 'actor_loss':    -1.6355, 'eps_e':     0.1000})
Step:  358000, Reward:   358.156 [  35.935], Avg:   173.190 (0.100) <0-02:18:37> ({'r_t':  1960.8634, 'eps':     0.1000, 'critic_loss':  2457.0742, 'actor_loss':    -1.8434, 'eps_e':     0.1000})
Step:  359000, Reward:   289.915 [  91.354], Avg:   173.514 (0.100) <0-02:19:00> ({'r_t':  2058.9159, 'eps':     0.1000, 'critic_loss':  2891.6155, 'actor_loss':    -1.8368, 'eps_e':     0.1000})
Step:  360000, Reward:   375.550 [  16.583], Avg:   174.074 (0.100) <0-02:19:23> ({'r_t':  2095.4625, 'eps':     0.1000, 'critic_loss':  2544.8105, 'actor_loss':    -2.0218, 'eps_e':     0.1000})
Step:  361000, Reward:   320.434 [  36.157], Avg:   174.478 (0.100) <0-02:19:47> ({'r_t':  2021.9315, 'eps':     0.1000, 'critic_loss':  2837.8291, 'actor_loss':    -1.9206, 'eps_e':     0.1000})
Step:  362000, Reward:   292.910 [ 109.697], Avg:   174.805 (0.100) <0-02:20:11> ({'r_t':  2154.0786, 'eps':     0.1000, 'critic_loss':  1952.3699, 'actor_loss':    -2.0600, 'eps_e':     0.1000})
Step:  363000, Reward:   351.519 [  36.015], Avg:   175.290 (0.100) <0-02:20:35> ({'r_t':  2181.5716, 'eps':     0.1000, 'critic_loss':  2105.5481, 'actor_loss':    -2.2502, 'eps_e':     0.1000})
Step:  364000, Reward:   361.257 [  14.481], Avg:   175.799 (0.100) <0-02:20:58> ({'r_t':  2306.5013, 'eps':     0.1000, 'critic_loss':   656.7394, 'actor_loss':    -2.0782, 'eps_e':     0.1000})
Step:  365000, Reward:   359.155 [  22.036], Avg:   176.300 (0.100) <0-02:21:20> ({'r_t':  2354.6316, 'eps':     0.1000, 'critic_loss':   329.3722, 'actor_loss':    -1.8400, 'eps_e':     0.1000})
Step:  366000, Reward:   235.718 [ 484.555], Avg:   176.462 (0.100) <0-02:21:44> ({'r_t':  2222.7189, 'eps':     0.1000, 'critic_loss':   436.9111, 'actor_loss':    -1.6573, 'eps_e':     0.1000})
Step:  367000, Reward:   369.416 [  15.403], Avg:   176.987 (0.100) <0-02:22:07> ({'r_t':  2124.7852, 'eps':     0.1000, 'critic_loss':   357.5701, 'actor_loss':    -1.4470, 'eps_e':     0.1000})
Step:  368000, Reward:   356.768 [  30.986], Avg:   177.474 (0.100) <0-02:22:30> ({'r_t':  1992.5389, 'eps':     0.1000, 'critic_loss':   245.7837, 'actor_loss':    -1.3927, 'eps_e':     0.1000})
Step:  369000, Reward:   360.088 [  30.301], Avg:   177.967 (0.100) <0-02:22:53> ({'r_t':  2149.5078, 'eps':     0.1000, 'critic_loss':   308.0116, 'actor_loss':    -1.4777, 'eps_e':     0.1000})
Step:  370000, Reward:   360.176 [  37.663], Avg:   178.459 (0.100) <0-02:23:16> ({'r_t':  2224.4932, 'eps':     0.1000, 'critic_loss':   283.7860, 'actor_loss':    -1.5972, 'eps_e':     0.1000})
Step:  371000, Reward:   378.155 [  20.982], Avg:   178.995 (0.100) <0-02:23:39> ({'r_t':  2096.1776, 'eps':     0.1000, 'critic_loss':   254.7679, 'actor_loss':    -1.7040, 'eps_e':     0.1000})
Step:  372000, Reward:   372.984 [  17.947], Avg:   179.515 (0.100) <0-02:24:02> ({'r_t':  2084.7075, 'eps':     0.1000, 'critic_loss':   869.5378, 'actor_loss':    -1.7603, 'eps_e':     0.1000})
Step:  373000, Reward:   364.301 [  24.580], Avg:   180.010 (0.100) <0-02:24:25> ({'r_t':  1977.4272, 'eps':     0.1000, 'critic_loss':  1660.1613, 'actor_loss':    -2.0233, 'eps_e':     0.1000})
Step:  374000, Reward:   275.006 [  54.584], Avg:   180.263 (0.100) <0-02:24:50> ({'r_t':  1434.5414, 'eps':     0.1000, 'critic_loss':  1625.6173, 'actor_loss':    -2.3736, 'eps_e':     0.1000})
Step:  375000, Reward:   298.178 [  64.126], Avg:   180.576 (0.100) <0-02:25:14> ({'r_t':  1281.2209, 'eps':     0.1000, 'critic_loss':  1770.6160, 'actor_loss':    -2.4105, 'eps_e':     0.1000})
Step:  376000, Reward:   341.416 [  40.414], Avg:   181.003 (0.100) <0-02:25:37> ({'r_t':  1818.5605, 'eps':     0.1000, 'critic_loss':  2571.0405, 'actor_loss':    -3.3208, 'eps_e':     0.1000})
Step:  377000, Reward:   334.455 [  40.697], Avg:   181.409 (0.100) <0-02:26:00> ({'r_t':  1653.4417, 'eps':     0.1000, 'critic_loss':  3206.6714, 'actor_loss':    -3.6509, 'eps_e':     0.1000})
Step:  378000, Reward:   341.096 [  34.482], Avg:   181.830 (0.100) <0-02:26:23> ({'r_t':  2099.5418, 'eps':     0.1000, 'critic_loss':  3976.7026, 'actor_loss':    -4.0547, 'eps_e':     0.1000})
Step:  379000, Reward:   373.016 [  14.758], Avg:   182.334 (0.100) <0-02:26:46> ({'r_t':  2043.0164, 'eps':     0.1000, 'critic_loss':  3231.5688, 'actor_loss':    -4.2597, 'eps_e':     0.1000})
Step:  380000, Reward:   234.879 [ 487.974], Avg:   182.471 (0.100) <0-02:27:09> ({'r_t':  2129.7384, 'eps':     0.1000, 'critic_loss':  3399.8420, 'actor_loss':    -5.2380, 'eps_e':     0.1000})
Step:  381000, Reward:   335.549 [ 144.484], Avg:   182.872 (0.100) <0-02:27:32> ({'r_t':  1551.5143, 'eps':     0.1000, 'critic_loss':  3731.7100, 'actor_loss':    -3.7174, 'eps_e':     0.1000})
Step:  382000, Reward:   324.364 [  46.619], Avg:   183.242 (0.100) <0-02:27:56> ({'r_t':  2110.3129, 'eps':     0.1000, 'critic_loss':  4239.8281, 'actor_loss':    -3.5961, 'eps_e':     0.1000})
Step:  383000, Reward:   375.565 [  14.493], Avg:   183.742 (0.100) <0-02:28:18> ({'r_t':  2343.1649, 'eps':     0.1000, 'critic_loss':  2548.0852, 'actor_loss':    -2.7071, 'eps_e':     0.1000})
Step:  384000, Reward:   361.991 [  29.478], Avg:   184.205 (0.100) <0-02:28:41> ({'r_t':  2155.5058, 'eps':     0.1000, 'critic_loss':  2250.9121, 'actor_loss':    -2.3920, 'eps_e':     0.1000})
Step:  385000, Reward:   362.505 [  14.482], Avg:   184.667 (0.100) <0-02:29:04> ({'r_t':  2244.6852, 'eps':     0.1000, 'critic_loss':  2211.9263, 'actor_loss':    -2.1403, 'eps_e':     0.1000})
Step:  386000, Reward:   221.744 [ 482.776], Avg:   184.763 (0.100) <0-02:29:27> ({'r_t':  2208.0148, 'eps':     0.1000, 'critic_loss':  1453.5925, 'actor_loss':    -2.1482, 'eps_e':     0.1000})
Step:  387000, Reward:   359.135 [  23.975], Avg:   185.213 (0.100) <0-02:29:50> ({'r_t':  2009.8228, 'eps':     0.1000, 'critic_loss':   811.7515, 'actor_loss':    -1.8922, 'eps_e':     0.1000})
Step:  388000, Reward:   370.162 [  11.489], Avg:   185.688 (0.100) <0-02:30:12> ({'r_t':  2229.2623, 'eps':     0.1000, 'critic_loss':   717.1623, 'actor_loss':    -2.0224, 'eps_e':     0.1000})
Step:  389000, Reward:   344.713 [  36.106], Avg:   186.096 (0.100) <0-02:30:35> ({'r_t':  2230.5143, 'eps':     0.1000, 'critic_loss':   443.9584, 'actor_loss':    -1.9498, 'eps_e':     0.1000})
Step:  390000, Reward:   345.748 [  32.140], Avg:   186.504 (0.100) <0-02:30:58> ({'r_t':  2191.1825, 'eps':     0.1000, 'critic_loss':   408.3690, 'actor_loss':    -1.9401, 'eps_e':     0.1000})
Step:  391000, Reward:   348.492 [  38.656], Avg:   186.917 (0.100) <0-02:31:21> ({'r_t':  2175.2404, 'eps':     0.1000, 'critic_loss':   776.4915, 'actor_loss':    -2.0538, 'eps_e':     0.1000})
Step:  392000, Reward:   373.396 [  19.402], Avg:   187.392 (0.100) <0-02:31:45> ({'r_t':  2051.8375, 'eps':     0.1000, 'critic_loss':   883.6354, 'actor_loss':    -2.2645, 'eps_e':     0.1000})
Step:  393000, Reward:   323.885 [ 101.684], Avg:   187.738 (0.100) <0-02:32:07> ({'r_t':  2209.1234, 'eps':     0.1000, 'critic_loss':   702.4125, 'actor_loss':    -2.3271, 'eps_e':     0.1000})
Step:  394000, Reward:   366.273 [  26.983], Avg:   188.190 (0.100) <0-02:32:31> ({'r_t':  2024.8354, 'eps':     0.1000, 'critic_loss':   790.7576, 'actor_loss':    -2.1604, 'eps_e':     0.1000})
Step:  395000, Reward:   369.973 [  31.221], Avg:   188.649 (0.100) <0-02:32:54> ({'r_t':  2168.6818, 'eps':     0.1000, 'critic_loss':   661.7122, 'actor_loss':    -2.0360, 'eps_e':     0.1000})
Step:  396000, Reward:   340.788 [ 108.571], Avg:   189.033 (0.100) <0-02:33:17> ({'r_t':  2200.6239, 'eps':     0.1000, 'critic_loss':   866.1780, 'actor_loss':    -1.9886, 'eps_e':     0.1000})
Step:  397000, Reward:   334.424 [ 146.293], Avg:   189.398 (0.100) <0-02:33:40> ({'r_t':  1914.1667, 'eps':     0.1000, 'critic_loss':   833.8637, 'actor_loss':    -2.0979, 'eps_e':     0.1000})
Step:  398000, Reward:   229.137 [ 196.407], Avg:   189.497 (0.100) <0-02:34:04> ({'r_t':  2187.6742, 'eps':     0.1000, 'critic_loss':   969.5046, 'actor_loss':    -2.0538, 'eps_e':     0.1000})
Step:  399000, Reward:   312.896 [ 136.172], Avg:   189.806 (0.100) <0-02:34:27> ({'r_t':  1941.4862, 'eps':     0.1000, 'critic_loss':   799.7937, 'actor_loss':    -2.1605, 'eps_e':     0.1000})
Step:  400000, Reward:   342.171 [ 148.998], Avg:   190.186 (0.100) <0-02:34:51> ({'r_t':  2046.1872, 'eps':     0.1000, 'critic_loss':   907.1885, 'actor_loss':    -2.0951, 'eps_e':     0.1000})
Step:  401000, Reward:   338.359 [  48.675], Avg:   190.554 (0.100) <0-02:35:14> ({'r_t':  2086.1119, 'eps':     0.1000, 'critic_loss':  1254.6780, 'actor_loss':    -2.3257, 'eps_e':     0.1000})
Step:  402000, Reward:   370.628 [  21.023], Avg:   191.001 (0.100) <0-02:35:37> ({'r_t':  2286.5115, 'eps':     0.1000, 'critic_loss':   998.2705, 'actor_loss':    -2.6890, 'eps_e':     0.1000})
Step:  403000, Reward:   365.825 [  21.686], Avg:   191.434 (0.100) <0-02:35:59> ({'r_t':  2215.6736, 'eps':     0.1000, 'critic_loss':   723.7699, 'actor_loss':    -2.5758, 'eps_e':     0.1000})
Step:  404000, Reward:   254.274 [ 482.205], Avg:   191.589 (0.100) <0-02:36:22> ({'r_t':  2038.5285, 'eps':     0.1000, 'critic_loss':  1353.4775, 'actor_loss':    -2.3369, 'eps_e':     0.1000})
Step:  405000, Reward:   175.550 [ 491.695], Avg:   191.550 (0.100) <0-02:36:47> ({'r_t':  2015.0981, 'eps':     0.1000, 'critic_loss':  1174.8242, 'actor_loss':    -2.1262, 'eps_e':     0.1000})
Step:  406000, Reward:   360.275 [  28.169], Avg:   191.964 (0.100) <0-02:37:10> ({'r_t':  2126.8452, 'eps':     0.1000, 'critic_loss':   828.6953, 'actor_loss':    -2.1318, 'eps_e':     0.1000})
Step:  407000, Reward:   324.211 [ 133.815], Avg:   192.288 (0.100) <0-02:37:33> ({'r_t':  1906.7626, 'eps':     0.1000, 'critic_loss':  1116.7117, 'actor_loss':    -1.8368, 'eps_e':     0.1000})
Step:  408000, Reward:   279.943 [ 203.571], Avg:   192.503 (0.100) <0-02:37:56> ({'r_t':  1988.5238, 'eps':     0.1000, 'critic_loss':  1200.0742, 'actor_loss':    -1.8366, 'eps_e':     0.1000})
Step:  409000, Reward:   279.874 [ 215.042], Avg:   192.716 (0.100) <0-02:38:19> ({'r_t':  2064.1743, 'eps':     0.1000, 'critic_loss':  1727.1962, 'actor_loss':    -2.0675, 'eps_e':     0.1000})
Step:  410000, Reward:   369.663 [  29.356], Avg:   193.146 (0.100) <0-02:38:42> ({'r_t':  1951.0261, 'eps':     0.1000, 'critic_loss':  1696.1852, 'actor_loss':    -2.0380, 'eps_e':     0.1000})
Step:  411000, Reward:   317.784 [ 105.423], Avg:   193.449 (0.100) <0-02:39:07> ({'r_t':  2119.1681, 'eps':     0.1000, 'critic_loss':  1645.6755, 'actor_loss':    -2.0576, 'eps_e':     0.1000})
Step:  412000, Reward:   375.613 [  21.364], Avg:   193.890 (0.100) <0-02:39:30> ({'r_t':  1959.2423, 'eps':     0.1000, 'critic_loss':  2024.2262, 'actor_loss':    -2.2125, 'eps_e':     0.1000})
Step:  413000, Reward:   345.207 [  53.599], Avg:   194.255 (0.100) <0-02:39:53> ({'r_t':  1910.8568, 'eps':     0.1000, 'critic_loss':  1453.5717, 'actor_loss':    -2.0467, 'eps_e':     0.1000})
Step:  414000, Reward:   369.722 [  28.383], Avg:   194.678 (0.100) <0-02:40:17> ({'r_t':  2134.1547, 'eps':     0.1000, 'critic_loss':  2020.8091, 'actor_loss':    -2.2030, 'eps_e':     0.1000})
Step:  415000, Reward:   358.867 [  49.454], Avg:   195.073 (0.100) <0-02:40:40> ({'r_t':  2092.5599, 'eps':     0.1000, 'critic_loss':  1543.5723, 'actor_loss':    -2.1922, 'eps_e':     0.1000})
Step:  416000, Reward:   317.888 [ 156.339], Avg:   195.367 (0.100) <0-02:41:06> ({'r_t':  2199.4537, 'eps':     0.1000, 'critic_loss':   798.3200, 'actor_loss':    -2.0016, 'eps_e':     0.1000})
Step:  417000, Reward:   372.321 [   8.825], Avg:   195.791 (0.100) <0-02:41:29> ({'r_t':  1836.8394, 'eps':     0.1000, 'critic_loss':   850.1696, 'actor_loss':    -1.9625, 'eps_e':     0.1000})
Step:  418000, Reward:   160.321 [ 505.413], Avg:   195.706 (0.100) <0-02:41:57> ({'r_t':  2080.3300, 'eps':     0.1000, 'critic_loss':  1078.1692, 'actor_loss':    -2.5482, 'eps_e':     0.1000})
Step:  419000, Reward:   368.136 [  32.230], Avg:   196.117 (0.100) <0-02:42:20> ({'r_t':  2070.1340, 'eps':     0.1000, 'critic_loss':   835.5809, 'actor_loss':    -2.2685, 'eps_e':     0.1000})
Step:  420000, Reward:   226.294 [ 499.289], Avg:   196.188 (0.100) <0-02:42:43> ({'r_t':  1938.1101, 'eps':     0.1000, 'critic_loss':   618.5617, 'actor_loss':    -2.3481, 'eps_e':     0.1000})
Step:  421000, Reward:   293.626 [  98.887], Avg:   196.419 (0.100) <0-02:43:06> ({'r_t':  2035.0596, 'eps':     0.1000, 'critic_loss':   718.0651, 'actor_loss':    -2.3817, 'eps_e':     0.1000})
Step:  422000, Reward:   316.248 [ 104.935], Avg:   196.703 (0.100) <0-02:43:29> ({'r_t':  1776.3451, 'eps':     0.1000, 'critic_loss':  1442.0110, 'actor_loss':    -2.5811, 'eps_e':     0.1000})
Step:  423000, Reward:   358.254 [  27.876], Avg:   197.084 (0.100) <0-02:43:52> ({'r_t':  2186.0617, 'eps':     0.1000, 'critic_loss':  1786.4752, 'actor_loss':    -2.5797, 'eps_e':     0.1000})
Step:  424000, Reward:   347.071 [  34.657], Avg:   197.436 (0.100) <0-02:44:15> ({'r_t':  1926.0167, 'eps':     0.1000, 'critic_loss':  1268.6946, 'actor_loss':    -2.0712, 'eps_e':     0.1000})
Step:  425000, Reward:   339.356 [  70.109], Avg:   197.770 (0.100) <0-02:44:39> ({'r_t':  2069.6376, 'eps':     0.1000, 'critic_loss':  1929.5917, 'actor_loss':    -1.8713, 'eps_e':     0.1000})
Step:  426000, Reward:   382.044 [  12.941], Avg:   198.201 (0.100) <0-02:45:02> ({'r_t':  2092.8559, 'eps':     0.1000, 'critic_loss':  1274.8282, 'actor_loss':    -1.8790, 'eps_e':     0.1000})
Step:  427000, Reward:   333.883 [  41.394], Avg:   198.518 (0.100) <0-02:45:26> ({'r_t':  1985.6136, 'eps':     0.1000, 'critic_loss':   805.2416, 'actor_loss':    -1.9088, 'eps_e':     0.1000})
Step:  428000, Reward:   304.242 [ 149.700], Avg:   198.765 (0.100) <0-02:45:49> ({'r_t':  1715.4415, 'eps':     0.1000, 'critic_loss':  1502.1719, 'actor_loss':    -2.2245, 'eps_e':     0.1000})
Step:  429000, Reward:   195.588 [ 262.153], Avg:   198.757 (0.100) <0-02:46:13> ({'r_t':  1546.5305, 'eps':     0.1000, 'critic_loss':  1556.9540, 'actor_loss':    -1.9913, 'eps_e':     0.1000})
Step:  430000, Reward:   331.697 [  34.556], Avg:   199.066 (0.100) <0-02:46:37> ({'r_t':  1857.8399, 'eps':     0.1000, 'critic_loss':  2944.3958, 'actor_loss':    -2.2033, 'eps_e':     0.1000})
Step:  431000, Reward:   278.357 [ 139.664], Avg:   199.249 (0.100) <0-02:47:00> ({'r_t':  1916.6549, 'eps':     0.1000, 'critic_loss':  2021.0199, 'actor_loss':    -2.4627, 'eps_e':     0.1000})
Step:  432000, Reward:   312.392 [ 133.376], Avg:   199.510 (0.100) <0-02:47:23> ({'r_t':  2137.6934, 'eps':     0.1000, 'critic_loss':  2031.4392, 'actor_loss':    -2.4575, 'eps_e':     0.1000})
Step:  433000, Reward:   372.626 [  31.547], Avg:   199.909 (0.100) <0-02:47:46> ({'r_t':  2209.9876, 'eps':     0.1000, 'critic_loss':  2218.1846, 'actor_loss':    -2.6135, 'eps_e':     0.1000})
Step:  434000, Reward:   377.167 [  18.019], Avg:   200.317 (0.100) <0-02:48:09> ({'r_t':  2162.5762, 'eps':     0.1000, 'critic_loss':  1982.1698, 'actor_loss':    -2.5793, 'eps_e':     0.1000})
Step:  435000, Reward:   371.419 [  20.742], Avg:   200.709 (0.100) <0-02:48:32> ({'r_t':  2114.1987, 'eps':     0.1000, 'critic_loss':  1461.6560, 'actor_loss':    -2.3878, 'eps_e':     0.1000})
Step:  436000, Reward:   349.435 [  78.336], Avg:   201.050 (0.100) <0-02:48:55> ({'r_t':  2235.5402, 'eps':     0.1000, 'critic_loss':   748.9282, 'actor_loss':    -2.0136, 'eps_e':     0.1000})
Step:  437000, Reward:   375.030 [  42.604], Avg:   201.447 (0.100) <0-02:49:20> ({'r_t':  1945.2523, 'eps':     0.1000, 'critic_loss':  1019.1751, 'actor_loss':    -1.7528, 'eps_e':     0.1000})
Step:  438000, Reward:   284.768 [ 113.340], Avg:   201.637 (0.100) <0-02:49:43> ({'r_t':  1864.3136, 'eps':     0.1000, 'critic_loss':   951.5611, 'actor_loss':    -1.6867, 'eps_e':     0.1000})
Step:  439000, Reward:   299.051 [  73.448], Avg:   201.858 (0.100) <0-02:50:07> ({'r_t':  2103.2931, 'eps':     0.1000, 'critic_loss':  1007.8645, 'actor_loss':    -1.7899, 'eps_e':     0.1000})
Step:  440000, Reward:   350.503 [  56.925], Avg:   202.195 (0.100) <0-02:50:31> ({'r_t':  2098.6926, 'eps':     0.1000, 'critic_loss':   923.8802, 'actor_loss':    -1.7628, 'eps_e':     0.1000})
Step:  441000, Reward:    76.514 [ 674.588], Avg:   201.911 (0.100) <0-02:50:55> ({'r_t':  2005.1142, 'eps':     0.1000, 'critic_loss':   917.2980, 'actor_loss':    -2.0417, 'eps_e':     0.1000})
Step:  442000, Reward:   256.730 [ 151.075], Avg:   202.035 (0.100) <0-02:51:19> ({'r_t':  1562.7111, 'eps':     0.1000, 'critic_loss':  1083.4222, 'actor_loss':    -2.4477, 'eps_e':     0.1000})
Step:  443000, Reward:   293.272 [ 173.424], Avg:   202.240 (0.100) <0-02:51:42> ({'r_t':  1882.7433, 'eps':     0.1000, 'critic_loss':  2307.1763, 'actor_loss':    -2.9971, 'eps_e':     0.1000})
Step:  444000, Reward:   323.503 [ 100.814], Avg:   202.512 (0.100) <0-02:52:05> ({'r_t':  1953.5261, 'eps':     0.1000, 'critic_loss':  2194.3171, 'actor_loss':    -3.3786, 'eps_e':     0.1000})
Step:  445000, Reward:   268.922 [  98.508], Avg:   202.661 (0.100) <0-02:52:31> ({'r_t':  1637.1064, 'eps':     0.1000, 'critic_loss':  2488.4929, 'actor_loss':    -3.1314, 'eps_e':     0.1000})
Step:  446000, Reward:   245.710 [ 105.016], Avg:   202.758 (0.100) <0-02:52:58> ({'r_t':  1327.6797, 'eps':     0.1000, 'critic_loss':  2250.7898, 'actor_loss':    -3.1051, 'eps_e':     0.1000})
Step:  447000, Reward:   284.390 [  98.432], Avg:   202.940 (0.100) <0-02:53:25> ({'r_t':   646.2020, 'eps':     0.1000, 'critic_loss':  1988.0735, 'actor_loss':    -3.0930, 'eps_e':     0.1000})
Step:  448000, Reward:    92.752 [ 668.366], Avg:   202.695 (0.100) <0-02:53:49> ({'r_t':  1861.6640, 'eps':     0.1000, 'critic_loss':  1527.9938, 'actor_loss':    -2.9930, 'eps_e':     0.1000})
Step:  449000, Reward:   373.394 [  14.969], Avg:   203.074 (0.100) <0-02:54:12> ({'r_t':  2173.3813, 'eps':     0.1000, 'critic_loss':   650.4658, 'actor_loss':    -3.0338, 'eps_e':     0.1000})
Step:  450000, Reward:   350.356 [  33.724], Avg:   203.400 (0.100) <0-02:54:35> ({'r_t':  2203.6706, 'eps':     0.1000, 'critic_loss':   490.5838, 'actor_loss':    -3.0842, 'eps_e':     0.1000})
Step:  451000, Reward:   367.643 [  23.712], Avg:   203.764 (0.100) <0-02:54:58> ({'r_t':  2086.6725, 'eps':     0.1000, 'critic_loss':   286.8525, 'actor_loss':    -3.3033, 'eps_e':     0.1000})
Step:  452000, Reward:   315.181 [ 149.781], Avg:   204.010 (0.100) <0-02:55:22> ({'r_t':  1973.1000, 'eps':     0.1000, 'critic_loss':   705.9918, 'actor_loss':    -3.3613, 'eps_e':     0.1000})
Step:  453000, Reward:   363.890 [  22.032], Avg:   204.362 (0.100) <0-02:55:45> ({'r_t':  1932.0063, 'eps':     0.1000, 'critic_loss':  1061.0317, 'actor_loss':    -3.1703, 'eps_e':     0.1000})
Step:  454000, Reward:   343.890 [  36.212], Avg:   204.669 (0.100) <0-02:56:08> ({'r_t':  2041.3353, 'eps':     0.1000, 'critic_loss':   780.0286, 'actor_loss':    -2.3044, 'eps_e':     0.1000})
Step:  455000, Reward:   353.008 [  28.799], Avg:   204.994 (0.100) <0-02:56:31> ({'r_t':  2079.6305, 'eps':     0.1000, 'critic_loss':   950.8134, 'actor_loss':    -2.1405, 'eps_e':     0.1000})
Step:  456000, Reward:   349.815 [  33.220], Avg:   205.311 (0.100) <0-02:56:54> ({'r_t':  1901.5503, 'eps':     0.1000, 'critic_loss':  1463.9365, 'actor_loss':    -2.5031, 'eps_e':     0.1000})
Step:  457000, Reward:   370.798 [  26.622], Avg:   205.672 (0.100) <0-02:57:17> ({'r_t':  2159.0992, 'eps':     0.1000, 'critic_loss':  1555.2975, 'actor_loss':    -2.5575, 'eps_e':     0.1000})
Step:  458000, Reward:   343.154 [  75.440], Avg:   205.972 (0.100) <0-02:57:41> ({'r_t':  2079.2956, 'eps':     0.1000, 'critic_loss':  1283.2538, 'actor_loss':    -2.6650, 'eps_e':     0.1000})
Step:  459000, Reward:   346.172 [  44.341], Avg:   206.276 (0.100) <0-02:58:04> ({'r_t':  2079.3062, 'eps':     0.1000, 'critic_loss':   818.5568, 'actor_loss':    -2.1125, 'eps_e':     0.1000})
Step:  460000, Reward:   360.467 [  36.404], Avg:   206.611 (0.100) <0-02:58:28> ({'r_t':  2025.7914, 'eps':     0.1000, 'critic_loss':  1421.5858, 'actor_loss':    -2.0354, 'eps_e':     0.1000})
Step:  461000, Reward:   349.876 [  88.004], Avg:   206.921 (0.100) <0-02:58:51> ({'r_t':  2108.1258, 'eps':     0.1000, 'critic_loss':  1584.2202, 'actor_loss':    -2.0045, 'eps_e':     0.1000})
Step:  462000, Reward:   333.365 [  39.413], Avg:   207.194 (0.100) <0-02:59:15> ({'r_t':  2070.5062, 'eps':     0.1000, 'critic_loss':  1717.5695, 'actor_loss':    -2.0368, 'eps_e':     0.1000})
Step:  463000, Reward:   247.472 [ 478.885], Avg:   207.281 (0.100) <0-02:59:37> ({'r_t':  2183.9674, 'eps':     0.1000, 'critic_loss':  1797.5283, 'actor_loss':    -2.0222, 'eps_e':     0.1000})
Step:  464000, Reward:   308.245 [  71.030], Avg:   207.498 (0.100) <0-03:00:01> ({'r_t':  2158.2781, 'eps':     0.1000, 'critic_loss':  1062.1414, 'actor_loss':    -1.9224, 'eps_e':     0.1000})
Step:  465000, Reward:   308.495 [ 104.832], Avg:   207.715 (0.100) <0-03:00:25> ({'r_t':  2046.0634, 'eps':     0.1000, 'critic_loss':   810.1813, 'actor_loss':    -1.6301, 'eps_e':     0.1000})
Step:  466000, Reward:   348.327 [ 102.362], Avg:   208.016 (0.100) <0-03:00:48> ({'r_t':  2143.2856, 'eps':     0.1000, 'critic_loss':   511.6994, 'actor_loss':    -1.7308, 'eps_e':     0.1000})
Step:  467000, Reward:   333.734 [  46.049], Avg:   208.284 (0.100) <0-03:01:11> ({'r_t':  2123.1654, 'eps':     0.1000, 'critic_loss':   155.8509, 'actor_loss':    -1.7228, 'eps_e':     0.1000})
Step:  468000, Reward:   237.380 [ 477.136], Avg:   208.346 (0.100) <0-03:01:34> ({'r_t':  1869.9583, 'eps':     0.1000, 'critic_loss':   280.2730, 'actor_loss':    -1.7532, 'eps_e':     0.1000})
Step:  469000, Reward:   366.377 [  29.771], Avg:   208.683 (0.100) <0-03:01:57> ({'r_t':  1979.6673, 'eps':     0.1000, 'critic_loss':  1017.7682, 'actor_loss':    -1.7473, 'eps_e':     0.1000})
Step:  470000, Reward:   329.186 [ 143.983], Avg:   208.939 (0.100) <0-03:02:21> ({'r_t':  2178.4556, 'eps':     0.1000, 'critic_loss':   690.6182, 'actor_loss':    -1.8739, 'eps_e':     0.1000})
Step:  471000, Reward:   348.685 [ 149.181], Avg:   209.235 (0.100) <0-03:02:44> ({'r_t':  2017.3412, 'eps':     0.1000, 'critic_loss':   987.0577, 'actor_loss':    -1.9784, 'eps_e':     0.1000})
Step:  472000, Reward:   245.100 [ 138.082], Avg:   209.310 (0.100) <0-03:03:07> ({'r_t':  1056.0072, 'eps':     0.1000, 'critic_loss':  3163.4468, 'actor_loss':    -2.0221, 'eps_e':     0.1000})
Step:  473000, Reward:   172.767 [ 498.619], Avg:   209.233 (0.100) <0-03:03:30> ({'r_t':  2050.5864, 'eps':     0.1000, 'critic_loss':  2787.9822, 'actor_loss':    -2.7136, 'eps_e':     0.1000})
Step:  474000, Reward:   295.031 [ 117.781], Avg:   209.414 (0.100) <0-03:03:53> ({'r_t':  2130.3126, 'eps':     0.1000, 'critic_loss':  3546.8953, 'actor_loss':    -2.9077, 'eps_e':     0.1000})
Step:  475000, Reward:   364.759 [  32.213], Avg:   209.740 (0.100) <0-03:04:17> ({'r_t':  2103.9972, 'eps':     0.1000, 'critic_loss':  3194.0193, 'actor_loss':    -3.3706, 'eps_e':     0.1000})
Step:  476000, Reward:   363.701 [  38.797], Avg:   210.063 (0.100) <0-03:04:40> ({'r_t':  1965.0434, 'eps':     0.1000, 'critic_loss':  2879.9993, 'actor_loss':    -3.3010, 'eps_e':     0.1000})
Step:  477000, Reward:   288.030 [ 114.611], Avg:   210.226 (0.100) <0-03:05:05> ({'r_t':  2064.8837, 'eps':     0.1000, 'critic_loss':  3010.6580, 'actor_loss':    -3.3124, 'eps_e':     0.1000})
Step:  478000, Reward:   364.586 [  22.913], Avg:   210.548 (0.100) <0-03:05:28> ({'r_t':  2039.6162, 'eps':     0.1000, 'critic_loss':  1781.9072, 'actor_loss':    -2.7836, 'eps_e':     0.1000})
Step:  479000, Reward:   365.587 [  25.734], Avg:   210.871 (0.100) <0-03:05:51> ({'r_t':  2132.2551, 'eps':     0.1000, 'critic_loss':   769.9678, 'actor_loss':    -2.1416, 'eps_e':     0.1000})
Step:  480000, Reward:   361.901 [  34.252], Avg:   211.185 (0.100) <0-03:06:15> ({'r_t':  2203.7886, 'eps':     0.1000, 'critic_loss':   579.0795, 'actor_loss':    -2.0790, 'eps_e':     0.1000})
Step:  481000, Reward:   349.651 [  42.677], Avg:   211.473 (0.100) <0-03:06:37> ({'r_t':  2258.4677, 'eps':     0.1000, 'critic_loss':   546.1266, 'actor_loss':    -2.0205, 'eps_e':     0.1000})
Step:  482000, Reward:   371.468 [  17.768], Avg:   211.804 (0.100) <0-03:07:01> ({'r_t':  2222.8721, 'eps':     0.1000, 'critic_loss':   444.6720, 'actor_loss':    -1.8309, 'eps_e':     0.1000})
Step:  483000, Reward:   286.261 [ 200.063], Avg:   211.958 (0.100) <0-03:07:24> ({'r_t':  1979.8700, 'eps':     0.1000, 'critic_loss':   377.2260, 'actor_loss':    -1.8063, 'eps_e':     0.1000})
Step:  484000, Reward:   370.127 [  21.864], Avg:   212.284 (0.100) <0-03:07:47> ({'r_t':  2101.7004, 'eps':     0.1000, 'critic_loss':   562.2690, 'actor_loss':    -1.5942, 'eps_e':     0.1000})
Step:  485000, Reward:     0.674 [1117.332], Avg:   211.849 (0.100) <0-03:08:10> ({'r_t':  2101.8979, 'eps':     0.1000, 'critic_loss':   341.9307, 'actor_loss':    -1.4695, 'eps_e':     0.1000})
Step:  486000, Reward:   303.215 [  93.568], Avg:   212.036 (0.100) <0-03:08:34> ({'r_t':  1774.7839, 'eps':     0.1000, 'critic_loss':   731.1805, 'actor_loss':    -1.5840, 'eps_e':     0.1000})
Step:  487000, Reward:   288.650 [  85.722], Avg:   212.193 (0.100) <0-03:08:58> ({'r_t':  1986.9559, 'eps':     0.1000, 'critic_loss':   704.9283, 'actor_loss':    -1.6507, 'eps_e':     0.1000})
Step:  488000, Reward:   350.633 [  55.196], Avg:   212.476 (0.100) <0-03:09:21> ({'r_t':  2139.0665, 'eps':     0.1000, 'critic_loss':   847.0600, 'actor_loss':    -1.8565, 'eps_e':     0.1000})
Step:  489000, Reward:   381.938 [  19.069], Avg:   212.822 (0.100) <0-03:09:44> ({'r_t':  2192.6226, 'eps':     0.1000, 'critic_loss':  1160.4528, 'actor_loss':    -2.3046, 'eps_e':     0.1000})
Step:  490000, Reward:   337.417 [  39.903], Avg:   213.076 (0.100) <0-03:10:07> ({'r_t':  2152.8747, 'eps':     0.1000, 'critic_loss':   661.1998, 'actor_loss':    -2.1976, 'eps_e':     0.1000})
Step:  491000, Reward:   359.638 [  33.899], Avg:   213.374 (0.100) <0-03:10:30> ({'r_t':  2074.2647, 'eps':     0.1000, 'critic_loss':   370.7426, 'actor_loss':    -2.1157, 'eps_e':     0.1000})
Step:  492000, Reward:   280.842 [ 149.939], Avg:   213.511 (0.100) <0-03:10:53> ({'r_t':  2080.4632, 'eps':     0.1000, 'critic_loss':   984.3427, 'actor_loss':    -1.9252, 'eps_e':     0.1000})
Step:  493000, Reward:   369.650 [  27.368], Avg:   213.827 (0.100) <0-03:11:17> ({'r_t':  2088.7745, 'eps':     0.1000, 'critic_loss':  1023.7903, 'actor_loss':    -1.7138, 'eps_e':     0.1000})
Step:  494000, Reward:  -282.787 [ 942.933], Avg:   212.823 (0.100) <0-03:11:41> ({'r_t':  1707.2180, 'eps':     0.1000, 'critic_loss':   836.0419, 'actor_loss':    -1.6246, 'eps_e':     0.1000})
Step:  495000, Reward:   339.653 [  80.030], Avg:   213.079 (0.100) <0-03:12:04> ({'r_t':  1391.5809, 'eps':     0.1000, 'critic_loss':  3090.7690, 'actor_loss':    -1.9279, 'eps_e':     0.1000})
Step:  496000, Reward:   244.068 [ 165.990], Avg:   213.141 (0.100) <0-03:12:27> ({'r_t':  1994.3736, 'eps':     0.1000, 'critic_loss':  3382.4797, 'actor_loss':    -2.8281, 'eps_e':     0.1000})
Step:  497000, Reward:   330.750 [  43.576], Avg:   213.378 (0.100) <0-03:12:51> ({'r_t':  1903.6924, 'eps':     0.1000, 'critic_loss':  3621.2493, 'actor_loss':    -2.7229, 'eps_e':     0.1000})
Step:  498000, Reward:   350.035 [  48.219], Avg:   213.651 (0.100) <0-03:13:15> ({'r_t':   873.4683, 'eps':     0.1000, 'critic_loss':  3815.2849, 'actor_loss':    -2.5469, 'eps_e':     0.1000})
Step:  499000, Reward:   310.104 [  32.389], Avg:   213.844 (0.100) <0-03:13:38> ({'r_t':  1359.4900, 'eps':     0.1000, 'critic_loss':  4944.2227, 'actor_loss':    -2.5667, 'eps_e':     0.1000})
Step:  500000, Reward:   336.162 [  72.344], Avg:   214.089 (0.100) <0-03:14:02> ({'r_t':  1759.9421, 'eps':     0.1000, 'critic_loss':  8039.3638, 'actor_loss':    -3.8915, 'eps_e':     0.1000})
