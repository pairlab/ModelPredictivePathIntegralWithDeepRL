Model: <class 'src.models.pytorch.agents.ddpg.DDPGAgent'>, Env: CarRacing-v1, Date: 18/05/2020 10:37:22
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: 1616ad8759246605a23b7de4263b52e8d0797915
Branch: master

config: 
   TRIAL_AT = 5000
   SAVE_AT = 1
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = ddpg
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
envs: <src.utils.envs.EnvManager object at 0x7fac1a645cd0> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7fac1a645fd0>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7fac1a608cb0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			pos_scale = 1
			vtarget = 20
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7fac1a613c10> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7fac1a613610> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
					Xmap = [-215.266 -214.266 -213.266 -212.266 -211.266 -210.266 -209.266 -208.266 -207.266 -206.266 -205.266 -204.266 -203.266 -202.266 -201.266 -200.266 -199.266 -198.266 -197.266 -196.266 -195.266 -194.266 -193.266 -192.266 -191.266 -190.266 -189.266 -188.266 -187.266 -186.266 -185.266 -184.266 -183.266 -182.266 -181.266 -180.266 -179.266 -178.266 -177.266 -176.266 -175.266 -174.266 -173.266 -172.266 -171.266 -170.266 -169.266 -168.266 -167.266 -166.266 -165.266 -164.266 -163.266 -162.266 -161.266 -160.266 -159.266 -158.266 -157.266 -156.266 -155.266 -154.266 -153.266 -152.266 -151.266 -150.266 -149.266 -148.266 -147.266 -146.266 -145.266 -144.266 -143.266 -142.266 -141.266 -140.266 -139.266 -138.266 -137.266 -136.266 -135.266 -134.266 -133.266 -132.266 -131.266 -130.266 -129.266 -128.266 -127.266 -126.266 -125.266 -124.266 -123.266 -122.266 -121.266 -120.266 -119.266 -118.266 -117.266 -116.266 -115.266 -114.266 -113.266 -112.266 -111.266 -110.266 -109.266 -108.266 -107.266 -106.266 -105.266 -104.266 -103.266 -102.266 -101.266 -100.266  -99.266  -98.266  -97.266  -96.266  -95.266  -94.266  -93.266  -92.266  -91.266  -90.266  -89.266  -88.266  -87.266  -86.266  -85.266  -84.266  -83.266  -82.266  -81.266  -80.266  -79.266  -78.266  -77.266  -76.266  -75.266  -74.266  -73.266  -72.266  -71.266  -70.266  -69.266  -68.266  -67.266  -66.266  -65.266  -64.266  -63.266  -62.266  -61.266  -60.266  -59.266  -58.266  -57.266  -56.266  -55.266  -54.266  -53.266  -52.266  -51.266  -50.266  -49.266  -48.266  -47.266  -46.266  -45.266  -44.266  -43.266  -42.266  -41.266  -40.266  -39.266  -38.266  -37.266  -36.266  -35.266  -34.266  -33.266  -32.266  -31.266  -30.266  -29.266  -28.266  -27.266  -26.266  -25.266  -24.266  -23.266  -22.266  -21.266  -20.266  -19.266  -18.266  -17.266  -16.266  -15.266  -14.266  -13.266  -12.266  -11.266  -10.266   -9.266   -8.266   -7.266   -6.266   -5.266   -4.266   -3.266   -2.266   -1.266   -0.266    0.734    1.734    2.734    3.734    4.734    5.734
					    6.734    7.734    8.734    9.734   10.734   11.734   12.734   13.734   14.734   15.734   16.734   17.734   18.734   19.734   20.734   21.734   22.734   23.734   24.734   25.734   26.734   27.734   28.734   29.734   30.734   31.734   32.734   33.734   34.734   35.734   36.734   37.734   38.734   39.734   40.734   41.734   42.734   43.734   44.734   45.734   46.734   47.734   48.734   49.734   50.734   51.734   52.734   53.734   54.734   55.734   56.734   57.734   58.734   59.734   60.734   61.734   62.734   63.734   64.734   65.734   66.734   67.734   68.734   69.734   70.734   71.734   72.734   73.734   74.734   75.734   76.734   77.734   78.734   79.734   80.734   81.734   82.734   83.734   84.734   85.734   86.734   87.734   88.734   89.734   90.734   91.734   92.734   93.734   94.734   95.734   96.734   97.734   98.734   99.734  100.734  101.734  102.734  103.734  104.734  105.734  106.734  107.734  108.734  109.734  110.734  111.734  112.734  113.734  114.734  115.734  116.734  117.734  118.734  119.734  120.734  121.734  122.734  123.734  124.734  125.734  126.734  127.734  128.734  129.734  130.734  131.734  132.734  133.734  134.734  135.734  136.734  137.734  138.734  139.734  140.734  141.734  142.734  143.734  144.734  145.734  146.734  147.734  148.734  149.734  150.734  151.734  152.734  153.734  154.734  155.734  156.734  157.734  158.734  159.734  160.734  161.734  162.734  163.734  164.734  165.734  166.734  167.734  168.734  169.734  170.734  171.734  172.734  173.734  174.734  175.734  176.734  177.734  178.734  179.734  180.734  181.734  182.734  183.734  184.734  185.734  186.734  187.734  188.734  189.734  190.734  191.734  192.734  193.734  194.734  195.734  196.734  197.734  198.734  199.734  200.734  201.734  202.734  203.734  204.734  205.734  206.734  207.734  208.734  209.734]
					Ymap = [-1.782e+02 -1.772e+02 -1.762e+02 -1.752e+02 -1.742e+02 -1.732e+02 -1.722e+02 -1.712e+02 -1.702e+02 -1.692e+02 -1.682e+02 -1.672e+02 -1.662e+02 -1.652e+02 -1.642e+02 -1.632e+02 -1.622e+02 -1.612e+02 -1.602e+02 -1.592e+02 -1.582e+02 -1.572e+02 -1.562e+02 -1.552e+02 -1.542e+02 -1.532e+02 -1.522e+02 -1.512e+02 -1.502e+02 -1.492e+02 -1.482e+02 -1.472e+02 -1.462e+02 -1.452e+02 -1.442e+02 -1.432e+02 -1.422e+02 -1.412e+02 -1.402e+02 -1.392e+02 -1.382e+02 -1.372e+02 -1.362e+02 -1.352e+02 -1.342e+02 -1.332e+02 -1.322e+02 -1.312e+02 -1.302e+02 -1.292e+02 -1.282e+02 -1.272e+02 -1.262e+02 -1.252e+02 -1.242e+02 -1.232e+02 -1.222e+02 -1.212e+02 -1.202e+02 -1.192e+02 -1.182e+02 -1.172e+02 -1.162e+02 -1.152e+02 -1.142e+02 -1.132e+02 -1.122e+02 -1.112e+02 -1.102e+02 -1.092e+02 -1.082e+02 -1.072e+02 -1.062e+02 -1.052e+02 -1.042e+02 -1.032e+02 -1.022e+02 -1.012e+02 -1.002e+02 -9.925e+01 -9.825e+01 -9.725e+01 -9.625e+01 -9.525e+01 -9.425e+01 -9.325e+01 -9.225e+01 -9.125e+01 -9.025e+01 -8.925e+01 -8.825e+01 -8.725e+01 -8.625e+01 -8.525e+01 -8.425e+01 -8.325e+01 -8.225e+01 -8.125e+01 -8.025e+01 -7.925e+01 -7.825e+01 -7.725e+01 -7.625e+01 -7.525e+01 -7.425e+01 -7.325e+01 -7.225e+01 -7.125e+01 -7.025e+01 -6.925e+01 -6.825e+01 -6.725e+01 -6.625e+01 -6.525e+01 -6.425e+01 -6.325e+01 -6.225e+01 -6.125e+01 -6.025e+01 -5.925e+01 -5.825e+01 -5.725e+01 -5.625e+01 -5.525e+01 -5.425e+01 -5.325e+01 -5.225e+01 -5.125e+01 -5.025e+01 -4.925e+01 -4.825e+01 -4.725e+01 -4.625e+01 -4.525e+01 -4.425e+01 -4.325e+01 -4.225e+01 -4.125e+01 -4.025e+01 -3.925e+01 -3.825e+01 -3.725e+01 -3.625e+01 -3.525e+01 -3.425e+01 -3.325e+01 -3.225e+01 -3.125e+01 -3.025e+01 -2.925e+01 -2.825e+01 -2.725e+01 -2.625e+01 -2.525e+01 -2.425e+01 -2.325e+01 -2.225e+01 -2.125e+01 -2.025e+01 -1.925e+01 -1.825e+01 -1.725e+01 -1.625e+01 -1.525e+01 -1.425e+01 -1.325e+01 -1.225e+01 -1.125e+01 -1.025e+01 -9.250e+00 -8.250e+00 -7.250e+00 -6.250e+00 -5.250e+00 -4.250e+00 -3.250e+00 -2.250e+00 -1.250e+00 -2.499e-01  7.501e-01  1.750e+00
					  2.750e+00  3.750e+00  4.750e+00  5.750e+00  6.750e+00  7.750e+00  8.750e+00  9.750e+00  1.075e+01  1.175e+01  1.275e+01  1.375e+01  1.475e+01  1.575e+01  1.675e+01  1.775e+01  1.875e+01  1.975e+01  2.075e+01  2.175e+01  2.275e+01  2.375e+01  2.475e+01  2.575e+01  2.675e+01  2.775e+01  2.875e+01  2.975e+01  3.075e+01  3.175e+01  3.275e+01  3.375e+01  3.475e+01  3.575e+01  3.675e+01  3.775e+01  3.875e+01  3.975e+01  4.075e+01  4.175e+01  4.275e+01  4.375e+01  4.475e+01  4.575e+01  4.675e+01  4.775e+01  4.875e+01  4.975e+01  5.075e+01  5.175e+01  5.275e+01  5.375e+01  5.475e+01  5.575e+01  5.675e+01  5.775e+01  5.875e+01  5.975e+01  6.075e+01  6.175e+01  6.275e+01  6.375e+01  6.475e+01  6.575e+01  6.675e+01  6.775e+01  6.875e+01  6.975e+01  7.075e+01  7.175e+01  7.275e+01  7.375e+01  7.475e+01  7.575e+01  7.675e+01  7.775e+01  7.875e+01  7.975e+01  8.075e+01  8.175e+01  8.275e+01  8.375e+01  8.475e+01  8.575e+01  8.675e+01  8.775e+01  8.875e+01  8.975e+01  9.075e+01  9.175e+01  9.275e+01  9.375e+01  9.475e+01  9.575e+01  9.675e+01  9.775e+01  9.875e+01  9.975e+01  1.008e+02  1.018e+02  1.028e+02  1.038e+02  1.048e+02  1.058e+02  1.068e+02  1.078e+02  1.088e+02  1.098e+02  1.108e+02  1.118e+02  1.128e+02  1.138e+02  1.148e+02  1.158e+02  1.168e+02  1.178e+02  1.188e+02  1.198e+02  1.208e+02  1.218e+02  1.228e+02  1.238e+02  1.248e+02  1.258e+02  1.268e+02  1.278e+02  1.288e+02  1.298e+02  1.308e+02  1.318e+02  1.328e+02  1.338e+02  1.348e+02  1.358e+02  1.368e+02  1.378e+02  1.388e+02  1.398e+02  1.408e+02  1.418e+02  1.428e+02  1.438e+02  1.448e+02  1.458e+02  1.468e+02  1.478e+02  1.488e+02  1.498e+02  1.508e+02  1.518e+02  1.528e+02  1.538e+02  1.548e+02  1.558e+02  1.568e+02  1.578e+02  1.588e+02  1.598e+02  1.608e+02  1.618e+02  1.628e+02  1.638e+02  1.648e+02  1.658e+02  1.668e+02  1.678e+02  1.688e+02  1.698e+02  1.708e+02  1.718e+02  1.728e+02  1.738e+02  1.748e+02  1.758e+02  1.768e+02  1.778e+02  1.788e+02  1.798e+02  1.808e+02  1.818e+02  1.828e+02
					  1.838e+02  1.848e+02  1.858e+02  1.868e+02  1.878e+02  1.888e+02  1.898e+02  1.908e+02  1.918e+02  1.928e+02  1.938e+02  1.948e+02  1.958e+02  1.968e+02  1.978e+02  1.988e+02  1.998e+02  2.008e+02  2.018e+02  2.028e+02  2.038e+02  2.048e+02  2.058e+02  2.068e+02  2.078e+02  2.088e+02  2.098e+02  2.108e+02  2.118e+02  2.128e+02  2.138e+02  2.148e+02  2.158e+02  2.168e+02  2.178e+02  2.188e+02  2.198e+02  2.208e+02  2.218e+02  2.228e+02  2.238e+02  2.248e+02  2.258e+02  2.268e+02  2.278e+02  2.288e+02  2.298e+02  2.308e+02  2.318e+02  2.328e+02  2.338e+02  2.348e+02  2.358e+02  2.368e+02  2.378e+02  2.388e+02  2.398e+02  2.408e+02  2.418e+02  2.428e+02  2.438e+02  2.448e+02  2.458e+02  2.468e+02  2.478e+02  2.488e+02  2.498e+02  2.508e+02  2.518e+02  2.528e+02  2.538e+02  2.548e+02  2.558e+02  2.568e+02  2.578e+02  2.588e+02  2.598e+02  2.608e+02  2.618e+02  2.628e+02]
					Zmap = [-5.894 -4.894 -3.894 -2.894 -1.894 -0.894  0.106  1.106  2.106  3.106  4.106  5.106  6.106  7.106  8.106  9.106 10.106 11.106 12.106 13.106]
					point_map = [[[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]]
					
					 [[291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  [291 291 291 ... 291 291 291]
					  ...
					  [161 161 161 ... 161 161 161]
					  [161 161 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 [[291 291 291 ... 292 292 292]
					  [291 291 291 ... 291 292 292]
					  [291 291 291 ... 291 291 291]
					  ...
					  [162 162 161 ... 161 161 161]
					  [162 162 162 ... 161 161 161]
					  [162 162 162 ... 161 161 161]]
					
					 ...
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]
					
					 [[395 395 395 ... 395 395 395]
					  [395 395 395 ... 395 395 395]
					  [394 394 394 ... 394 394 394]
					  ...
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]
					  [210 210 210 ... 210 210 210]]]
					res = 1
					min_point = [-215.266 -178.250   -5.894]
					max_point = [ 209.734  262.750   13.106]
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				cost_map = [[ 214.381  214.299  214.217 ...  112.184  112.264  112.344]
				 [ 214.324  214.242  214.160 ...  112.124  112.204  112.284]
				 [ 214.267  214.185  214.103 ...  112.064  112.144  112.224]
				 ...
				 [  96.764   96.690   96.616 ...  242.661  242.689  242.717]
				 [  96.831   96.757   96.683 ...  242.757  242.785  242.813]
				 [  96.898   96.824   96.750 ...  242.852  242.881  242.909]]
				res = 0.1
				min_point = [-215.266 -178.250    0.000]
				max_point = [ 210.234  262.950    0.000]
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			max_time = 500
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7fac9a3cce60>
					get_reward = <function CarRacing.get_reward at 0x7fac9a3d3950>
					step = <function CarRacing.step at 0x7fac9a3d70e0>
					render = <function CarRacing.render at 0x7fac9a3d7170>
					observation = <function CarRacing.observation at 0x7fac9a3d7200>
					close = <function CarRacing.close at 0x7fac9a3d7290>
					id = 1
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(60,) 
			dtype = float32
			shape = (60,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7fac2603be50> 
			observation_space = Box(60,) 
				dtype = float32
				shape = (60,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (60,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7fac1a613b50> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=198, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59566), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=199, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54092), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=200, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36460), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=201, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38280), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=202, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49018), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=203, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38886), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=204, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 44796), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=208, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48566), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=209, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36142), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=210, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 33456), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=211, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47418), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=212, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 38276), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=213, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 42130), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=214, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53912), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=215, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49794), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=216, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 36498), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 5000,
agent: <src.models.wrappers.ParallelAgent object at 0x7fac1a613810> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7fac1a5c2450> 
		state_size = (60,)
	agent = <src.models.pytorch.agents.ddpg.DDPGAgent object at 0x7fac1a5c2a50> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7fac1a5c2d50> 
			size = (3,)
			dt = 0.2
			action = [ 0.803 -0.194  0.111]
			daction_dt = [-0.719 -0.119 -0.116]
		discrete = False
		action_size = (3,)
		state_size = (60,)
		config = <src.models.Config object at 0x7fac25ffcfd0> 
			TRIAL_AT = 5000
			SAVE_AT = 1
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = ddpg
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7fac1a5c2e10> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = DDPGNetwork(
			  (actor_local): DDPGActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): DDPGActor(
			    (layer1): Linear(in_features=60, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): DDPGCritic(
			    (net_state): Linear(in_features=60, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): DDPGCritic(
			    (net_state): Linear(in_features=60, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = ddpg
			stats = <src.utils.logger.Stats object at 0x7fac1a5c2f10> 
				mean_dict = {}
				sum_dict = {}
			config = <src.models.Config object at 0x7fac25ffcfd0> 
				TRIAL_AT = 5000
				SAVE_AT = 1
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.1
				EPS_DECAY = 0.998
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = ddpg
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class DDPGActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, sample=True):\n\t\tstate = self.layer1(state).relu() \n\t\tstate = self.layer2(state).relu() \n\t\tstate = self.layer3(state).relu() \n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).exp()\n\t\tepsilon = torch.randn_like(action_sig)\n\t\taction = action_mu + epsilon.mul(action_sig) if sample else action_mu\n\t\treturn action.tanh() if not self.discrete else gsoftmax(action)\n', 'class DDPGCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7fac1a5c25d0> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7fac1a5c2bd0> 
		size = (3,)
		dt = 0.2
		action = [ 0.174 -1.000  1.000]
		daction_dt = [ 0.399  0.781 -0.371]
	discrete = False
	action_size = (3,)
	state_size = (60,)
	config = <src.models.Config object at 0x7fac25ffcfd0> 
		TRIAL_AT = 5000
		SAVE_AT = 1
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = ddpg
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7fac1a5c2850> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import torch
import random
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax, one_hot
from src.utils.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh() if not self.discrete else gsoftmax(action)
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=DDPGActor, critic=DDPGCritic, gpu=True, load=None, name="ddpg"): 
		self.discrete = type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)

	def get_action(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			q_value = q_value.gather(-1, action.argmax(-1, keepdim=True)) if self.discrete and not probs else q_value
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, q_targets):
		actions = one_hot(actions) if self.actor_local.discrete else actions
		q_values = self.get_q_value(states, actions, grad=True, probs=False)
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True, probs=True)
		q_actions = (actor_action*q_actions).sum(-1) if self.discrete else q_actions
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = -(q_actions - q_baseline.detach()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		self.soft_copy(self.actor_local, self.actor_target)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)
		
class DDPGAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, DDPGNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if self.discrete and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), numpy=True, sample=sample)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			actions = torch.cat([actions, self.network.get_action(states[-1], use_target=True).unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets)
			if np.any(done[0]): self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward:  -264.076 [ 182.249], Avg:  -264.076 (1.000) <0-00:00:00> ({'r_t':    -0.2083, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    5000, Reward:  -264.847 [ 122.208], Avg:  -264.462 (0.929) <0-00:01:49> ({'r_t': -7284.0342, 'eps':     0.9286, 'critic_loss':    44.0027, 'actor_loss':    -1.9893, 'eps_e':     0.9286})
Step:   10000, Reward:  -262.415 [ 155.543], Avg:  -263.779 (0.876) <0-00:03:37> ({'r_t': -7357.1048, 'eps':     0.8762, 'critic_loss':    66.2015, 'actor_loss':    -1.6897, 'eps_e':     0.8762})
Step:   15000, Reward:  -205.573 [ 117.221], Avg:  -249.228 (0.823) <0-00:05:24> ({'r_t': -7071.1214, 'eps':     0.8235, 'critic_loss':    72.3713, 'actor_loss':    -1.9701, 'eps_e':     0.8235})
Step:   20000, Reward:  -256.255 [ 198.812], Avg:  -250.633 (0.769) <0-00:07:13> ({'r_t': -6597.7689, 'eps':     0.7693, 'critic_loss':    78.1698, 'actor_loss':    -2.6892, 'eps_e':     0.7693})
Step:   25000, Reward:  -218.824 [  87.783], Avg:  -245.332 (0.723) <0-00:08:58> ({'r_t': -6208.7856, 'eps':     0.7230, 'critic_loss':    85.5243, 'actor_loss':    -3.2006, 'eps_e':     0.7230})
Step:   30000, Reward:  -124.774 [  55.710], Avg:  -228.109 (0.673) <0-00:10:44> ({'r_t': -5479.1663, 'eps':     0.6727, 'critic_loss':    90.1336, 'actor_loss':    -4.5191, 'eps_e':     0.6727})
Step:   35000, Reward:  -106.885 [  67.773], Avg:  -212.956 (0.617) <0-00:12:29> ({'r_t': -4793.7947, 'eps':     0.6172, 'critic_loss':    72.6448, 'actor_loss':    -5.5651, 'eps_e':     0.6172})
Step:   40000, Reward:   -69.366 [  29.150], Avg:  -197.002 (0.575) <0-00:14:12> ({'r_t': -3930.8204, 'eps':     0.5755, 'critic_loss':    59.0868, 'actor_loss':    -5.3477, 'eps_e':     0.5755})
Step:   45000, Reward:  -108.663 [  58.253], Avg:  -188.168 (0.535) <0-00:15:57> ({'r_t': -3303.4041, 'eps':     0.5355, 'critic_loss':    46.1707, 'actor_loss':    -4.5700, 'eps_e':     0.5355})
Step:   50000, Reward:   -88.339 [  41.998], Avg:  -179.092 (0.505) <0-00:17:44> ({'r_t': -2499.1073, 'eps':     0.5053, 'critic_loss':    43.0748, 'actor_loss':    -4.0352, 'eps_e':     0.5053})
Step:   55000, Reward:   -64.781 [  25.041], Avg:  -169.566 (0.478) <0-00:19:30> ({'r_t': -1738.2220, 'eps':     0.4777, 'critic_loss':    33.6451, 'actor_loss':    -3.4177, 'eps_e':     0.4777})
Step:   60000, Reward:   -63.611 [  33.449], Avg:  -161.416 (0.454) <0-00:21:16> ({'r_t': -1411.8794, 'eps':     0.4544, 'critic_loss':    25.8623, 'actor_loss':    -2.8442, 'eps_e':     0.4544})
Step:   65000, Reward:   -42.190 [  39.262], Avg:  -152.900 (0.436) <0-00:23:02> ({'r_t': -1240.8007, 'eps':     0.4357, 'critic_loss':    28.1409, 'actor_loss':    -2.7221, 'eps_e':     0.4357})
Step:   70000, Reward:   -30.030 [  45.259], Avg:  -144.709 (0.418) <0-00:24:48> ({'r_t': -1025.5390, 'eps':     0.4177, 'critic_loss':    29.6469, 'actor_loss':    -2.3363, 'eps_e':     0.4177})
Step:   75000, Reward:    -5.938 [  27.610], Avg:  -136.035 (0.403) <0-00:26:34> ({'r_t':  -493.6734, 'eps':     0.4030, 'critic_loss':    26.0770, 'actor_loss':    -2.5821, 'eps_e':     0.4030})
Step:   80000, Reward:     4.376 [  17.233], Avg:  -127.776 (0.391) <0-00:28:21> ({'r_t':  -246.7480, 'eps':     0.3910, 'critic_loss':    21.9104, 'actor_loss':    -2.3482, 'eps_e':     0.3910})
Step:   85000, Reward:   -25.178 [  32.521], Avg:  -122.076 (0.376) <0-00:30:05> ({'r_t':  -367.2773, 'eps':     0.3757, 'critic_loss':    15.7684, 'actor_loss':    -1.9377, 'eps_e':     0.3757})
Step:   90000, Reward:   -13.076 [  16.146], Avg:  -116.339 (0.360) <0-00:31:51> ({'r_t':  -467.0709, 'eps':     0.3602, 'critic_loss':    18.7593, 'actor_loss':    -1.8670, 'eps_e':     0.3602})
Step:   95000, Reward:    59.425 [  24.274], Avg:  -107.551 (0.350) <0-00:33:41> ({'r_t':   136.1795, 'eps':     0.3503, 'critic_loss':    16.3225, 'actor_loss':    -2.3135, 'eps_e':     0.3503})
Step:  100000, Reward:    33.056 [  15.003], Avg:  -100.855 (0.341) <0-00:35:26> ({'r_t':   463.2314, 'eps':     0.3413, 'critic_loss':    11.1576, 'actor_loss':    -2.1201, 'eps_e':     0.3413})
Step:  105000, Reward:    26.607 [  15.977], Avg:   -95.062 (0.329) <0-00:37:12> ({'r_t':   424.1922, 'eps':     0.3292, 'critic_loss':     7.3293, 'actor_loss':    -1.6076, 'eps_e':     0.3292})
Step:  110000, Reward:    28.948 [  12.627], Avg:   -89.670 (0.317) <0-00:38:58> ({'r_t':   467.5662, 'eps':     0.3169, 'critic_loss':     8.2659, 'actor_loss':    -1.4940, 'eps_e':     0.3169})
Step:  115000, Reward:   -10.222 [  21.193], Avg:   -86.360 (0.306) <0-00:40:46> ({'r_t':   398.1472, 'eps':     0.3057, 'critic_loss':     8.4571, 'actor_loss':    -1.2884, 'eps_e':     0.3057})
Step:  120000, Reward:    40.644 [  16.574], Avg:   -81.279 (0.298) <0-00:42:36> ({'r_t':   471.3559, 'eps':     0.2984, 'critic_loss':     9.3029, 'actor_loss':    -2.0375, 'eps_e':     0.2984})
Step:  125000, Reward:    67.891 [   7.305], Avg:   -75.542 (0.290) <0-00:44:21> ({'r_t':   750.4250, 'eps':     0.2896, 'critic_loss':    14.4857, 'actor_loss':    -1.8537, 'eps_e':     0.2896})
Step:  130000, Reward:    56.125 [  10.762], Avg:   -70.666 (0.280) <0-00:46:07> ({'r_t':   966.0875, 'eps':     0.2799, 'critic_loss':     6.7384, 'actor_loss':    -1.1705, 'eps_e':     0.2799})
Step:  135000, Reward:    46.313 [   9.802], Avg:   -66.488 (0.271) <0-00:47:53> ({'r_t':   820.0861, 'eps':     0.2705, 'critic_loss':     4.2217, 'actor_loss':    -1.0302, 'eps_e':     0.2705})
Step:  140000, Reward:    54.202 [  16.493], Avg:   -62.326 (0.261) <0-00:49:40> ({'r_t':   911.3949, 'eps':     0.2615, 'critic_loss':     4.0286, 'actor_loss':    -1.0358, 'eps_e':     0.2615})
Step:  145000, Reward:    61.555 [   6.561], Avg:   -58.197 (0.253) <0-00:51:26> ({'r_t':   888.7381, 'eps':     0.2533, 'critic_loss':     4.1095, 'actor_loss':    -0.9466, 'eps_e':     0.2533})
Step:  150000, Reward:    90.520 [   4.941], Avg:   -53.399 (0.246) <0-00:53:12> ({'r_t':  1114.3782, 'eps':     0.2458, 'critic_loss':     3.2697, 'actor_loss':    -1.2244, 'eps_e':     0.2458})
Step:  155000, Reward:    67.939 [   6.181], Avg:   -49.607 (0.238) <0-00:54:58> ({'r_t':  1260.8316, 'eps':     0.2375, 'critic_loss':     2.5042, 'actor_loss':    -1.0466, 'eps_e':     0.2375})
Step:  160000, Reward:    70.641 [  20.155], Avg:   -45.964 (0.231) <0-00:56:44> ({'r_t':  1053.8182, 'eps':     0.2305, 'critic_loss':     2.4747, 'actor_loss':    -0.7781, 'eps_e':     0.2305})
Step:  165000, Reward:    69.220 [   9.368], Avg:   -42.576 (0.223) <0-00:58:31> ({'r_t':  1038.8128, 'eps':     0.2232, 'critic_loss':     2.8544, 'actor_loss':    -0.7162, 'eps_e':     0.2232})
Step:  170000, Reward:    93.626 [   8.811], Avg:   -38.684 (0.217) <0-01:00:19> ({'r_t':  1019.7111, 'eps':     0.2166, 'critic_loss':     4.2964, 'actor_loss':    -0.8039, 'eps_e':     0.2166})
Step:  175000, Reward:    -5.880 [  14.059], Avg:   -37.773 (0.211) <0-01:02:08> ({'r_t':   657.4829, 'eps':     0.2115, 'critic_loss':     3.8538, 'actor_loss':    -0.8002, 'eps_e':     0.2115})
Step:  180000, Reward:    69.813 [  17.868], Avg:   -34.865 (0.207) <0-01:03:56> ({'r_t':   212.9282, 'eps':     0.2073, 'critic_loss':     9.3288, 'actor_loss':    -0.8139, 'eps_e':     0.2073})
Step:  185000, Reward:    88.761 [   5.408], Avg:   -31.612 (0.202) <0-01:05:45> ({'r_t':   928.6261, 'eps':     0.2020, 'critic_loss':     9.4848, 'actor_loss':    -1.0788, 'eps_e':     0.2020})
Step:  190000, Reward:    77.919 [  20.727], Avg:   -28.804 (0.197) <0-01:07:35> ({'r_t':   796.0609, 'eps':     0.1972, 'critic_loss':     6.7972, 'actor_loss':    -1.0822, 'eps_e':     0.1972})
Step:  195000, Reward:   157.944 [   7.882], Avg:   -24.135 (0.193) <0-01:09:25> ({'r_t':   866.5456, 'eps':     0.1933, 'critic_loss':     9.4446, 'actor_loss':    -1.2730, 'eps_e':     0.1933})
Step:  200000, Reward:   147.924 [  11.646], Avg:   -19.938 (0.189) <0-01:11:14> ({'r_t':  1460.0997, 'eps':     0.1894, 'critic_loss':     7.6750, 'actor_loss':    -1.4770, 'eps_e':     0.1894})
Step:  205000, Reward:   119.445 [  43.377], Avg:   -16.620 (0.186) <0-01:13:04> ({'r_t':  1602.2899, 'eps':     0.1857, 'critic_loss':     7.7435, 'actor_loss':    -1.7553, 'eps_e':     0.1857})
Step:  210000, Reward:    78.994 [  21.640], Avg:   -14.396 (0.182) <0-01:14:55> ({'r_t':  1204.8353, 'eps':     0.1820, 'critic_loss':    16.1650, 'actor_loss':    -1.6344, 'eps_e':     0.1820})
Step:  215000, Reward:   126.709 [  64.386], Avg:   -11.189 (0.178) <0-01:16:44> ({'r_t':   889.4394, 'eps':     0.1780, 'critic_loss':    21.8418, 'actor_loss':    -1.0423, 'eps_e':     0.1780})
Step:  220000, Reward:   215.845 [  18.537], Avg:    -6.144 (0.175) <0-01:18:34> ({'r_t':  1861.1345, 'eps':     0.1745, 'critic_loss':    19.6730, 'actor_loss':    -1.2453, 'eps_e':     0.1745})
Step:  225000, Reward:   173.487 [  35.850], Avg:    -2.239 (0.171) <0-01:20:23> ({'r_t':  1695.3858, 'eps':     0.1711, 'critic_loss':    13.9012, 'actor_loss':    -1.1839, 'eps_e':     0.1711})
Step:  230000, Reward:   208.383 [  16.274], Avg:     2.242 (0.167) <0-01:22:13> ({'r_t':  1790.9989, 'eps':     0.1673, 'critic_loss':    20.3078, 'actor_loss':    -1.1768, 'eps_e':     0.1673})
Step:  235000, Reward:   229.573 [  16.518], Avg:     6.978 (0.164) <0-01:24:03> ({'r_t':  1996.8164, 'eps':     0.1640, 'critic_loss':    15.0996, 'actor_loss':    -1.1019, 'eps_e':     0.1640})
Step:  240000, Reward:   149.649 [  38.353], Avg:     9.890 (0.161) <0-01:25:52> ({'r_t':  1800.5967, 'eps':     0.1608, 'critic_loss':    16.7812, 'actor_loss':    -1.1208, 'eps_e':     0.1608})
Step:  245000, Reward:   216.684 [  32.918], Avg:    14.026 (0.158) <0-01:27:42> ({'r_t':  1818.6488, 'eps':     0.1576, 'critic_loss':    17.3682, 'actor_loss':    -1.1335, 'eps_e':     0.1576})
Step:  250000, Reward:   194.619 [  96.175], Avg:    17.567 (0.154) <0-01:29:32> ({'r_t':  2413.7732, 'eps':     0.1545, 'critic_loss':    14.1607, 'actor_loss':    -1.2047, 'eps_e':     0.1545})
Step:  255000, Reward:   273.093 [  17.685], Avg:    22.481 (0.151) <0-01:31:21> ({'r_t':  2247.5459, 'eps':     0.1514, 'critic_loss':    11.7092, 'actor_loss':    -1.1536, 'eps_e':     0.1514})
Step:  260000, Reward:   214.055 [  28.359], Avg:    26.096 (0.148) <0-01:33:11> ({'r_t':  2057.9114, 'eps':     0.1484, 'critic_loss':    16.3890, 'actor_loss':    -0.9940, 'eps_e':     0.1484})
Step:  265000, Reward:   230.420 [  37.844], Avg:    29.879 (0.145) <0-01:35:00> ({'r_t':  2137.1199, 'eps':     0.1454, 'critic_loss':    16.4671, 'actor_loss':    -0.8790, 'eps_e':     0.1454})
Step:  270000, Reward:   157.211 [  34.535], Avg:    32.194 (0.143) <0-01:36:50> ({'r_t':  1669.0585, 'eps':     0.1426, 'critic_loss':    21.6790, 'actor_loss':    -1.0388, 'eps_e':     0.1426})
Step:  275000, Reward:   227.206 [  88.697], Avg:    35.677 (0.140) <0-01:38:40> ({'r_t':  1620.7827, 'eps':     0.1397, 'critic_loss':    27.0692, 'actor_loss':    -0.9622, 'eps_e':     0.1397})
Step:  280000, Reward:   276.613 [  16.438], Avg:    39.904 (0.137) <0-01:40:29> ({'r_t':  2403.2579, 'eps':     0.1370, 'critic_loss':    25.2953, 'actor_loss':    -1.2188, 'eps_e':     0.1370})
Step:  285000, Reward:   298.812 [  14.916], Avg:    44.368 (0.134) <0-01:42:19> ({'r_t':  2663.6086, 'eps':     0.1343, 'critic_loss':    12.7908, 'actor_loss':    -1.2062, 'eps_e':     0.1343})
Step:  290000, Reward:   262.138 [  28.086], Avg:    48.059 (0.132) <0-01:44:08> ({'r_t':  2594.2739, 'eps':     0.1316, 'critic_loss':     9.1567, 'actor_loss':    -1.1003, 'eps_e':     0.1316})
Step:  295000, Reward:   274.596 [  16.714], Avg:    51.834 (0.129) <0-01:45:58> ({'r_t':  2540.1636, 'eps':     0.1290, 'critic_loss':    11.4425, 'actor_loss':    -1.1010, 'eps_e':     0.1290})
Step:  300000, Reward:   313.260 [  16.689], Avg:    56.120 (0.126) <0-01:47:47> ({'r_t':  2743.0795, 'eps':     0.1264, 'critic_loss':    11.0935, 'actor_loss':    -0.9827, 'eps_e':     0.1264})
Step:  305000, Reward:   299.618 [  21.388], Avg:    60.047 (0.124) <0-01:49:37> ({'r_t':  2982.0549, 'eps':     0.1239, 'critic_loss':     9.3610, 'actor_loss':    -1.0129, 'eps_e':     0.1239})
Step:  310000, Reward:   305.062 [  26.430], Avg:    63.937 (0.121) <0-01:51:26> ({'r_t':  3058.1262, 'eps':     0.1215, 'critic_loss':     8.6078, 'actor_loss':    -0.8940, 'eps_e':     0.1215})
Step:  315000, Reward:   325.506 [  16.137], Avg:    68.024 (0.119) <0-01:53:16> ({'r_t':  2962.6803, 'eps':     0.1191, 'critic_loss':     9.7478, 'actor_loss':    -0.8368, 'eps_e':     0.1191})
Step:  320000, Reward:   322.635 [  25.960], Avg:    71.941 (0.117) <0-01:55:06> ({'r_t':  3116.0677, 'eps':     0.1167, 'critic_loss':     9.2569, 'actor_loss':    -1.0628, 'eps_e':     0.1167})
Step:  325000, Reward:   352.038 [  14.952], Avg:    76.185 (0.114) <0-01:56:55> ({'r_t':  3275.9737, 'eps':     0.1144, 'critic_loss':     7.2052, 'actor_loss':    -1.1431, 'eps_e':     0.1144})
Step:  330000, Reward:   343.742 [  15.159], Avg:    80.178 (0.112) <0-01:58:45> ({'r_t':  3277.1779, 'eps':     0.1121, 'critic_loss':     7.0891, 'actor_loss':    -0.8291, 'eps_e':     0.1121})
Step:  335000, Reward:   343.989 [  19.083], Avg:    84.057 (0.110) <0-02:00:34> ({'r_t':  3410.1861, 'eps':     0.1099, 'critic_loss':     6.3003, 'actor_loss':    -0.8204, 'eps_e':     0.1099})
Step:  340000, Reward:   313.399 [  26.821], Avg:    87.381 (0.108) <0-02:02:24> ({'r_t':  3336.7332, 'eps':     0.1077, 'critic_loss':     5.6227, 'actor_loss':    -0.7704, 'eps_e':     0.1077})
Step:  345000, Reward:   353.019 [  13.393], Avg:    91.176 (0.106) <0-02:04:13> ({'r_t':  3406.1661, 'eps':     0.1056, 'critic_loss':     5.4593, 'actor_loss':    -0.6833, 'eps_e':     0.1056})
Step:  350000, Reward:   367.741 [  15.895], Avg:    95.071 (0.103) <0-02:06:03> ({'r_t':  3463.9451, 'eps':     0.1035, 'critic_loss':     5.2842, 'actor_loss':    -0.6539, 'eps_e':     0.1035})
Step:  355000, Reward:   353.856 [  16.378], Avg:    98.666 (0.101) <0-02:07:53> ({'r_t':  3533.2598, 'eps':     0.1014, 'critic_loss':     5.5620, 'actor_loss':    -0.6058, 'eps_e':     0.1014})
Step:  360000, Reward:   364.885 [  11.476], Avg:   102.312 (0.100) <0-02:09:42> ({'r_t':  3501.5880, 'eps':     0.1000, 'critic_loss':     7.0590, 'actor_loss':    -0.6064, 'eps_e':     0.1000})
Step:  365000, Reward:   365.087 [  15.906], Avg:   105.863 (0.100) <0-02:11:32> ({'r_t':  3544.4829, 'eps':     0.1000, 'critic_loss':     7.1284, 'actor_loss':    -0.6391, 'eps_e':     0.1000})
Step:  370000, Reward:   352.876 [  13.021], Avg:   109.157 (0.100) <0-02:13:21> ({'r_t':  3386.8920, 'eps':     0.1000, 'critic_loss':     8.1996, 'actor_loss':    -0.6464, 'eps_e':     0.1000})
Step:  375000, Reward:   355.255 [  12.296], Avg:   112.395 (0.100) <0-02:15:11> ({'r_t':  3584.5264, 'eps':     0.1000, 'critic_loss':     8.5190, 'actor_loss':    -0.6405, 'eps_e':     0.1000})
Step:  380000, Reward:   358.593 [  10.939], Avg:   115.592 (0.100) <0-02:17:01> ({'r_t':  3499.2117, 'eps':     0.1000, 'critic_loss':     6.8968, 'actor_loss':    -0.5697, 'eps_e':     0.1000})
Step:  385000, Reward:   365.499 [  12.312], Avg:   118.796 (0.100) <0-02:18:51> ({'r_t':  3507.6261, 'eps':     0.1000, 'critic_loss':     6.8213, 'actor_loss':    -0.5677, 'eps_e':     0.1000})
Step:  390000, Reward:   359.778 [  19.161], Avg:   121.847 (0.100) <0-02:20:40> ({'r_t':  3582.2711, 'eps':     0.1000, 'critic_loss':     5.5160, 'actor_loss':    -0.6827, 'eps_e':     0.1000})
Step:  395000, Reward:   371.343 [  15.731], Avg:   124.965 (0.100) <0-02:22:29> ({'r_t':  3652.1275, 'eps':     0.1000, 'critic_loss':     5.0324, 'actor_loss':    -0.5535, 'eps_e':     0.1000})
Step:  400000, Reward:   378.103 [  10.596], Avg:   128.091 (0.100) <0-02:24:19> ({'r_t':  3583.3765, 'eps':     0.1000, 'critic_loss':     4.3499, 'actor_loss':    -0.5375, 'eps_e':     0.1000})
Step:  405000, Reward:   373.140 [  12.962], Avg:   131.079 (0.100) <0-02:26:08> ({'r_t':  3568.8301, 'eps':     0.1000, 'critic_loss':     5.6653, 'actor_loss':    -0.5524, 'eps_e':     0.1000})
Step:  410000, Reward:   376.797 [   8.927], Avg:   134.040 (0.100) <0-02:27:58> ({'r_t':  3520.3146, 'eps':     0.1000, 'critic_loss':     5.7938, 'actor_loss':    -0.5579, 'eps_e':     0.1000})
Step:  415000, Reward:   360.544 [  18.098], Avg:   136.736 (0.100) <0-02:29:47> ({'r_t':  3573.3598, 'eps':     0.1000, 'critic_loss':     6.1083, 'actor_loss':    -0.5673, 'eps_e':     0.1000})
Step:  420000, Reward:   385.447 [  14.459], Avg:   139.662 (0.100) <0-02:31:37> ({'r_t':  3534.0224, 'eps':     0.1000, 'critic_loss':     5.6122, 'actor_loss':    -0.5971, 'eps_e':     0.1000})
Step:  425000, Reward:   386.559 [  12.180], Avg:   142.533 (0.100) <0-02:33:26> ({'r_t':  3674.7502, 'eps':     0.1000, 'critic_loss':     4.2652, 'actor_loss':    -0.5504, 'eps_e':     0.1000})
Step:  430000, Reward:   378.780 [  11.333], Avg:   145.248 (0.100) <0-02:35:16> ({'r_t':  3719.0247, 'eps':     0.1000, 'critic_loss':     3.6316, 'actor_loss':    -0.5447, 'eps_e':     0.1000})
Step:  435000, Reward:   382.143 [  14.333], Avg:   147.940 (0.100) <0-02:37:05> ({'r_t':  3731.7130, 'eps':     0.1000, 'critic_loss':     3.5543, 'actor_loss':    -0.5523, 'eps_e':     0.1000})
Step:  440000, Reward:   383.097 [  12.210], Avg:   150.583 (0.100) <0-02:38:55> ({'r_t':  3772.0426, 'eps':     0.1000, 'critic_loss':     3.4464, 'actor_loss':    -0.6038, 'eps_e':     0.1000})
Step:  445000, Reward:   380.612 [   9.999], Avg:   153.138 (0.100) <0-02:40:44> ({'r_t':  3798.5415, 'eps':     0.1000, 'critic_loss':     3.8296, 'actor_loss':    -0.5053, 'eps_e':     0.1000})
Step:  450000, Reward:   400.932 [   9.073], Avg:   155.861 (0.100) <0-02:42:33> ({'r_t':  3792.7559, 'eps':     0.1000, 'critic_loss':     3.6926, 'actor_loss':    -0.5038, 'eps_e':     0.1000})
Step:  455000, Reward:   388.178 [  13.888], Avg:   158.387 (0.100) <0-02:44:23> ({'r_t':  3844.1470, 'eps':     0.1000, 'critic_loss':     3.3351, 'actor_loss':    -0.5095, 'eps_e':     0.1000})
Step:  460000, Reward:   378.327 [   9.346], Avg:   160.752 (0.100) <0-02:46:12> ({'r_t':  3831.3337, 'eps':     0.1000, 'critic_loss':     3.2327, 'actor_loss':    -0.4525, 'eps_e':     0.1000})
Step:  465000, Reward:   374.980 [  11.749], Avg:   163.031 (0.100) <0-02:48:02> ({'r_t':  3821.1394, 'eps':     0.1000, 'critic_loss':     3.1881, 'actor_loss':    -0.4593, 'eps_e':     0.1000})
Step:  470000, Reward:   381.397 [   9.926], Avg:   165.329 (0.100) <0-02:49:51> ({'r_t':  3862.1589, 'eps':     0.1000, 'critic_loss':     3.1614, 'actor_loss':    -0.4577, 'eps_e':     0.1000})
Step:  475000, Reward:   408.124 [   7.646], Avg:   167.858 (0.100) <0-02:51:43> ({'r_t':  3893.8919, 'eps':     0.1000, 'critic_loss':     3.0420, 'actor_loss':    -0.4785, 'eps_e':     0.1000})
Step:  480000, Reward:   402.738 [  10.573], Avg:   170.280 (0.100) <0-02:53:32> ({'r_t':  3919.0853, 'eps':     0.1000, 'critic_loss':     2.7983, 'actor_loss':    -0.4788, 'eps_e':     0.1000})
Step:  485000, Reward:   405.106 [  10.957], Avg:   172.676 (0.100) <0-02:55:22> ({'r_t':  3970.8561, 'eps':     0.1000, 'critic_loss':     2.7293, 'actor_loss':    -0.4429, 'eps_e':     0.1000})
Step:  490000, Reward:   409.891 [   9.163], Avg:   175.072 (0.100) <0-02:57:11> ({'r_t':  3984.3098, 'eps':     0.1000, 'critic_loss':     2.8416, 'actor_loss':    -0.4230, 'eps_e':     0.1000})
Step:  495000, Reward:   409.514 [   7.815], Avg:   177.416 (0.100) <0-02:59:01> ({'r_t':  4007.5951, 'eps':     0.1000, 'critic_loss':     2.6732, 'actor_loss':    -0.4403, 'eps_e':     0.1000})
Step:  500000, Reward:   407.907 [   8.788], Avg:   179.699 (0.100) <0-03:00:51> ({'r_t':  3982.2987, 'eps':     0.1000, 'critic_loss':     2.3045, 'actor_loss':    -0.3961, 'eps_e':     0.1000})
