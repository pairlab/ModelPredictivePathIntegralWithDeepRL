Model: <class 'src.models.pytorch.agents.ddpg.DDPGAgent'>, Env: CarRacing-v1, Date: 12/05/2020 18:55:58
CPU: 8 Core, 5.0GHz, 62.66 GB, Linux-5.3.0-51-generic-x86_64-with-debian-buster-sid
GPU 0: GeForce RTX 2070, 7.98 GB (Driver: 440.64.00)
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: c93c07c172568b5588d78b5be23a7c477c097f38
Branch: master

envs: <src.utils.envs.EnvManager object at 0x7f80b88bc650> 
	env = <GymEnv<CarRacing<CarRacing-v1>>> 
		env = <CarRacing<CarRacing-v1>> 
			channel = <mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel object at 0x7f80b88bc690>
			scale_sim = <function CarRacing.__init__.<locals>.<lambda> at 0x7f80b88773b0>
			env = <UnityToGymWrapper instance> 
				visual_obs = None
				game_over = False
				name = CarBehavior?team=0
				group_spec = BehaviorSpec(observation_shapes=[(30,)], action_type=<ActionType.CONTINUOUS: 1>, action_shape=3)
				use_visual = False
				uint8_visual = False
			action_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -1.000]
				high = [ 1.000  1.000  1.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			observation_space = Box(30,) 
				dtype = float32
				shape = (30,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
			cost_model = <src.envs.CarRacing.objective.cost.CostModel object at 0x7f80b8876d50> 
				track = <src.envs.CarRacing.objective.track.Track object at 0x7f80b8896150> 
					track = <list len=500>
					X = (1.540585208684206, 1.5814536064863205, 1.6016383588314056, 1.6350171357393264, 1.6559478223323822, 1.6717498254776002, 1.709812204837799, 1.7354034245014192, 1.7725858569145203, 1.8077154874801635, 1.958074402809143, 2.0178433418273927, 2.1851138830184937, 2.258661150932312, 2.3439700841903686, 2.452700424194336, 2.586679172515869, 2.782884216308594, 3.047244071960449, 3.4783129692077637, 3.9734771251678467, 4.596014499664307, 5.29957389831543, 6.05716609954834, 6.824328422546387, 7.646727561950684, 8.59219741821289, 9.675070762634277, 10.77119255065918, 11.868535041809082, 12.83842658996582, 13.727555274963379, 14.569844245910645, 15.391722679138184, 16.204023361206055, 17.02372169494629, 17.626384735107422, 18.072078704833984, 18.462026596069336, 18.803436279296875, 19.08125877380371, 19.200590133666992, 19.074377059936523, 18.833162307739258, 18.582487106323242, 18.339160919189453, 17.97744369506836, 17.59515380859375, 17.09140968322754, 16.50218391418457, 15.817791938781738, 14.983868598937988, 13.986822128295898, 12.817933082580566, 11.528505325317383, 10.241579055786133, 8.946599960327148, 7.588953971862793, 6.2032341957092285, 4.799948692321777, 3.3720505237579346, 1.9454675912857056, 0.4815756678581238, -0.9242660999298096, -2.3082480430603027, -3.7190709114074707, -5.090760231018066, -6.490819931030273, -7.933252811431885, -9.48039722442627, -11.141877174377441, -12.927711486816406, -14.796602249145508, -16.603300094604492, -18.390233993530273, -20.1385498046875, -21.805997848510742, -23.41408920288086, -25.02754783630371, -26.801597595214844, -28.776451110839844, -30.972705841064453, -33.385520935058594, -35.90762710571289, -38.527618408203125, -41.362369537353516, -44.435585021972656, -47.831398010253906, -51.587188720703125, -55.642662048339844, -59.980804443359375, -64.55036163330078, -69.1060562133789, -73.4732666015625, -77.65788269042969, -81.6474380493164, -85.45370483398438, -89.12055206298828, -92.67816925048828, -96.15220642089844, -99.54827117919922, -102.86875915527344, -106.01786804199219, -109.03597259521484, -111.96282958984375, -114.75870513916016, -117.48453521728516, -120.2335205078125, -123.01750946044922, -125.81232452392578, -128.56246948242188, -131.20936584472656, -133.767333984375, -136.21359252929688, -138.6573486328125, -141.0603485107422, -143.3613739013672, -145.4899444580078, -147.5723114013672, -149.41514587402344, -150.9908905029297, -152.32089233398438, -153.6006622314453, -154.83030700683594, -156.0063018798828, -157.14691162109375, -158.23680114746094, -159.30880737304688, -160.30152893066406, -161.2411651611328, -162.03582763671875, -162.72186279296875, -163.28753662109375, -163.81460571289062, -164.31549072265625, -164.78814697265625, -165.1201171875, -165.26596069335938, -165.24961853027344, -165.20376586914062, -165.07931518554688, -165.0469512939453, -165.03262329101562, -164.86660766601562, -164.62220764160156, -164.3842315673828, -164.145263671875, -163.90011596679688, -163.64981079101562, -163.3218231201172, -162.726318359375, -161.83493041992188, -160.71856689453125, -159.4139862060547, -157.9736328125, -156.54212951660156, -155.10464477539062, -153.63636779785156, -152.13641357421875, -150.6412811279297, -149.1659698486328, -147.64437866210938, -146.01336669921875, -144.21286010742188, -142.3518829345703, -140.49502563476562, -138.6591796875, -136.8135986328125, -134.9413604736328, -132.9547882080078, -130.7132110595703, -128.1597137451172, -125.3279037475586, -122.26266479492188, -118.97386932373047, -115.49871826171875, -111.90750122070312, -108.16539764404297, -104.34297180175781, -100.58757781982422, -96.96247863769531, -93.51396942138672, -90.1981201171875, -86.93607330322266, -83.70171356201172, -80.58210754394531, -77.49177551269531, -74.4620132446289, -71.53809356689453, -68.60317993164062, -65.52932739257812, -62.46957778930664, -59.48895263671875, -56.56187057495117, -53.813289642333984, -51.1711311340332, -48.648197174072266, -46.242332458496094, -43.94118118286133, -41.766075134277344, -39.70472717285156, -37.813140869140625, -36.01365280151367, -34.269657135009766, -32.50520706176758, -30.680166244506836, -28.837051391601562, -27.001256942749023, -25.25333023071289, -23.701873779296875, -22.668081283569336, -22.199195861816406, -22.169893264770508, -22.46630859375, -23.134033203125, -24.32797622680664, -26.001781463623047, -27.869766235351562, -29.80392074584961, -31.775949478149414, -33.793365478515625, -35.771907806396484, -37.70563888549805, -39.61886215209961, -41.516029357910156, -43.41127014160156, -45.27768325805664, -47.11109924316406, -48.94091796875, -50.77583694458008, -52.619163513183594, -54.48332977294922, -56.314815521240234, -58.103755950927734, -59.823333740234375, -61.56585693359375, -63.30061340332031, -64.97642517089844, -66.51130676269531, -67.94270324707031, -69.3357925415039, -70.66708374023438, -71.93402099609375, -73.18978118896484, -74.31753540039062, -75.23255920410156, -75.95966339111328, -76.61920166015625, -77.26768493652344, -77.9359130859375, -78.5946273803711, -79.26289367675781, -79.79534912109375, -80.2015380859375, -80.60335540771484, -81.02714538574219, -81.53772735595703, -82.04193878173828, -82.53047180175781, -83.04158020019531, -83.56088256835938, -84.14714813232422, -84.81393432617188, -85.55133056640625, -86.36656188964844, -87.24837493896484, -88.13751983642578, -88.99240112304688, -89.81124877929688, -90.60415649414062, -91.33631896972656, -92.02133178710938, -92.65229034423828, -93.23121643066406, -93.7853012084961, -94.3372573852539, -94.88070678710938, -95.41710662841797, -95.84803771972656, -96.24778747558594, -96.6568374633789, -97.0496826171875, -97.41992950439453, -97.77052307128906, -97.91485595703125, -97.96147155761719, -97.87026977539062, -97.53227233886719, -96.85386657714844, -95.81302642822266, -94.54135131835938, -93.15739440917969, -91.603271484375, -89.95466613769531, -88.35015106201172, -86.80291748046875, -85.39144134521484, -84.07344055175781, -82.86149597167969, -81.5972671508789, -80.11182403564453, -78.36345672607422, -76.40621948242188, -74.32894134521484, -72.0761489868164, -69.69659423828125, -67.17849731445312, -64.48152160644531, -61.61235046386719, -58.499427795410156, -55.10073471069336, -51.55522918701172, -47.74736785888672, -43.832923889160156, -39.801971435546875, -35.743858337402344, -31.80649757385254, -28.028738021850586, -24.38759994506836, -20.836519241333008, -17.374597549438477, -14.002902030944824, -10.617079734802246, -7.34421443939209, -4.187110424041748, -1.115414023399353, 2.037353277206421, 5.401520252227783, 8.870983123779297, 12.423381805419922, 16.180818557739258, 20.157392501831055, 24.33769989013672, 28.77823829650879, 33.3828010559082, 38.12346267700195, 42.767642974853516, 47.21396255493164, 51.497074127197266, 55.640106201171875, 59.61445999145508, 63.45794677734375, 67.16992950439453, 70.71627044677734, 74.12809753417969, 77.53622436523438, 80.97876739501953, 84.45626068115234, 87.9986572265625, 91.61026000976562, 95.1865234375, 98.68260192871094, 102.08172607421875, 105.37554168701172, 108.5978012084961, 111.72406005859375, 114.72969818115234, 117.6103515625, 120.28418731689453, 122.77039337158203, 125.10813903808594, 127.35991668701172, 129.5707550048828, 131.73577880859375, 133.8451385498047, 135.88076782226562, 137.81361389160156, 139.69195556640625, 141.56494140625, 143.51321411132812, 145.43582153320312, 147.37954711914062, 149.30592346191406, 151.1349334716797, 152.76832580566406, 154.18382263183594, 155.40008544921875, 156.48155212402344, 157.39840698242188, 158.19866943359375, 158.91281127929688, 159.4974822998047, 160.02337646484375, 160.31883239746094, 160.23129272460938, 159.7694854736328, 159.0675506591797, 158.11312866210938, 157.08311462402344, 155.8784942626953, 154.47816467285156, 152.8489990234375, 151.00660705566406, 149.11109924316406, 147.24368286132812, 145.35427856445312, 143.4554443359375, 141.39073181152344, 139.07090759277344, 136.57705688476562, 134.08177185058594, 131.63348388671875, 129.23263549804688, 126.91446685791016, 124.63007354736328, 122.27965545654297, 119.90943145751953, 117.51732635498047, 115.1493148803711, 112.83964538574219, 110.53994750976562, 108.22462463378906, 105.85285949707031, 103.4562759399414, 101.13794708251953, 98.82323455810547, 96.44384765625, 93.94629669189453, 91.3570556640625, 88.73168182373047, 86.05917358398438, 83.26211547851562, 80.25263214111328, 77.10718536376953, 73.97905731201172, 70.96484375, 68.1133804321289, 65.44701385498047, 62.890159606933594, 60.41355514526367, 57.95263671875, 55.59248352050781, 53.20044708251953, 50.7462272644043, 48.28958511352539, 45.88505935668945, 43.5562744140625, 41.31084442138672, 39.171634674072266, 37.183380126953125, 35.43268966674805, 33.800804138183594, 32.20466613769531, 30.66669273376465, 29.13826560974121, 27.552635192871094, 25.97852325439453, 24.294662475585938, 22.565439224243164, 20.874217987060547, 19.30082893371582, 17.831933975219727, 16.408084869384766, 15.044317245483398, 13.766607284545898, 12.577005386352539, 11.475253105163574, 10.496495246887207, 9.622332572937012, 8.769275665283203, 7.927954196929932, 7.112521648406982, 6.322704315185547, 5.563619136810303, 4.829586982727051, 4.113427639007568, 3.3697121143341064, 2.5567243099212646, 1.7977246046066284, 1.0246542692184448, 0.2572939395904541, -0.4480553865432739, -1.1242897510528564, -1.6556841135025024, -2.0525705814361572, -2.214649200439453, -2.169621467590332, -2.035892963409424, -1.9102517366409302, -1.7909443378448486, -1.7162281274795532, -1.651557445526123, -1.5775796175003052, -1.5097243785858154, -1.4451829195022583, -1.3808107376098633, -1.3076838254928589, -1.1195673942565918, -0.8252816200256348, -0.5349398255348206, -0.2580118477344513, 0.009828831069171429, 0.2716897428035736, 0.5349469780921936, 0.7902784943580627, 1.052398443222046, 1.31592857837677, 1.570581078529358, 1.6137370109558105, 1.6365979194641114)
					Z = (-0.8819639682769775, -0.8812801241874695, -0.8804802298545837, -0.8791921734809875, -0.8777425289154053, -0.8758563995361328, -0.873963475227356, -0.8539403676986694, -0.7802032232284546, -0.761174201965332, -0.7716957926750183, -0.8395041823387146, -0.8772552609443665, -0.8344407081604004, -0.788372814655304, -0.80742347240448, -0.8527643084526062, -0.8346409797668457, -0.824370265007019, -0.8134136199951172, -0.7967275381088257, -0.7752544283866882, -0.7417746782302856, -0.6927484273910522, -0.633834719657898, -0.5747796297073364, -0.5113369226455688, -0.4433113932609558, -0.3737497925758362, -0.3008161187171936, -0.2312106341123581, -0.16523221135139465, -0.09990986436605453, -0.033577218651771545, 0.03842548280954361, 0.11881522089242935, 0.1981208622455597, 0.28177762031555176, 0.38250869512557983, 0.5017393231391907, 0.625041127204895, 0.7394312620162964, 0.8367793560028076, 0.9279725551605225, 1.0242633819580078, 1.1258037090301514, 1.2272775173187256, 1.3421326875686646, 1.4506069421768188, 1.561546802520752, 1.6706804037094116, 1.7743912935256958, 1.8515067100524902, 1.9097793102264404, 1.948763370513916, 1.9814872741699219, 2.0233898162841797, 2.07637095451355, 2.132861375808716, 2.17509126663208, 2.2180161476135254, 2.274773597717285, 2.3546767234802246, 2.4420950412750244, 2.5328733921051025, 2.6344215869903564, 2.7358694076538086, 2.8366494178771973, 2.9418249130249023, 3.0620920658111572, 3.1827614307403564, 3.30625581741333, 3.427833080291748, 3.5489587783813477, 3.675954818725586, 3.79117488861084, 3.901960849761963, 4.005653381347656, 4.107993125915527, 4.2158284187316895, 4.328779220581055, 4.445080280303955, 4.569532871246338, 4.690032005310059, 4.799752712249756, 4.872299671173096, 4.92843770980835, 4.985036849975586, 5.057000637054443, 5.13352108001709, 5.213327884674072, 5.295718193054199, 5.3766703605651855, 5.451817512512207, 5.519579887390137, 5.582165718078613, 5.639312267303467, 5.692175388336182, 5.7414727210998535, 5.787367820739746, 5.830183506011963, 5.869744300842285, 5.905086994171143, 5.936120986938477, 5.963281154632568, 5.987318992614746, 6.008669376373291, 6.027542591094971, 6.044310569763184, 6.057828903198242, 6.067286968231201, 6.074985504150391, 6.081448554992676, 6.086737155914307, 6.091536998748779, 6.096595764160156, 6.1012773513793945, 6.104137420654297, 6.10720682144165, 6.105283260345459, 6.09289026260376, 6.069871425628662, 6.042582988739014, 6.011574745178223, 5.977062702178955, 5.945542812347412, 5.9195661544799805, 5.900696277618408, 5.875031471252441, 5.850343227386475, 5.822032451629639, 5.787215232849121, 5.749323844909668, 5.708043575286865, 5.672667503356934, 5.640613079071045, 5.58774995803833, 5.510519504547119, 5.4132280349731445, 5.318352222442627, 5.21757173538208, 5.129578113555908, 5.049224376678467, 4.955892086029053, 4.855170726776123, 4.759181022644043, 4.6699957847595215, 4.590251922607422, 4.507761478424072, 4.420248508453369, 4.298507213592529, 4.1367998123168945, 3.954977035522461, 3.7536673545837402, 3.5393548011779785, 3.336235761642456, 3.13871431350708, 2.941469192504883, 2.743802785873413, 2.5500059127807617, 2.362222671508789, 2.172161817550659, 1.9712504148483276, 1.7527763843536377, 1.5335578918457031, 1.3216581344604492, 1.11974036693573, 0.924856424331665, 0.7362942099571228, 0.548167884349823, 0.3510936498641968, 0.14911779761314392, -0.04503828287124634, -0.22794248163700104, -0.3905165493488312, -0.5209499597549438, -0.6174218654632568, -0.6916936039924622, -0.7458155751228333, -0.7768694162368774, -0.7899942994117737, -0.7893635630607605, -0.7789414525032043, -0.7635725736618042, -0.7461717128753662, -0.7283236980438232, -0.704211413860321, -0.6622856855392456, -0.5993924140930176, -0.5216199159622192, -0.426088809967041, -0.3150973916053772, -0.1974087506532669, -0.07835512608289719, 0.03133012354373932, 0.13556505739688873, 0.24022513628005981, 0.3493971824645996, 0.45991453528404236, 0.5715771317481995, 0.6827750205993652, 0.7940959930419922, 0.907843291759491, 1.025125503540039, 1.148614764213562, 1.2811535596847534, 1.417541265487671, 1.5532535314559937, 1.6824359893798828, 1.7986339330673218, 1.8819316625595093, 1.9304401874542236, 1.9543043375015259, 1.9636659622192383, 1.9588732719421387, 1.916387915611267, 1.8345577716827393, 1.7349056005477905, 1.6296110153198242, 1.5208213329315186, 1.405418872833252, 1.2866981029510498, 1.16438889503479, 1.0394600629806519, 0.9107307195663452, 0.7798608541488647, 0.6512886881828308, 0.5262399315834045, 0.4030036926269531, 0.2815271019935608, 0.16398224234580994, 0.05072043836116791, -0.05590145289897919, -0.15327762067317963, -0.24135041236877441, -0.3243723213672638, -0.3988741636276245, -0.4620799124240875, -0.542617678642273, -0.646656334400177, -0.7287228107452393, -0.7844877243041992, -0.806078314781189, -0.8148013949394226, -0.8116025924682617, -0.8039451837539673, -0.7978506088256836, -0.8006065487861633, -0.8066939115524292, -0.8129818439483643, -0.8215823173522949, -0.8290983438491821, -0.8362972736358643, -0.8428731560707092, -0.8489797711372375, -0.8558133840560913, -0.8626493811607361, -0.8682581186294556, -0.8741699457168579, -0.879978597164154, -0.8859436511993408, -0.8909560441970825, -0.8937748670578003, -0.8939367532730103, -0.8897822499275208, -0.8787690997123718, -0.8593403697013855, -0.8307321667671204, -0.8021003603935242, -0.7821503281593323, -0.7700151801109314, -0.7592963576316833, -0.7492351531982422, -0.7390634417533875, -0.7314242720603943, -0.7212424278259277, -0.7080341577529907, -0.6888165473937988, -0.66937655210495, -0.6463529467582703, -0.6128187775611877, -0.5654257535934448, -0.5037499666213989, -0.42715343832969666, -0.34471648931503296, -0.25006303191185, -0.14578062295913696, -0.03818090260028839, 0.0759134441614151, 0.21288788318634033, 0.35622480511665344, 0.515775203704834, 0.6532223224639893, 0.7738814949989319, 0.8932506442070007, 1.0421302318572998, 1.2146294116973877, 1.385721206665039, 1.5515326261520386, 1.7406084537506104, 1.9566478729248047, 2.214561700820923, 2.5135207176208496, 2.8274102210998535, 3.160696268081665, 3.501220941543579, 3.8431997299194336, 4.200472354888916, 4.574350357055664, 4.894090175628662, 5.0936360359191895, 5.216364860534668, 5.390469074249268, 5.586197853088379, 5.784314155578613, 5.985593795776367, 6.1828765869140625, 6.373883247375488, 6.556783199310303, 6.733740329742432, 6.906088829040527, 7.071183204650879, 7.233142852783203, 7.3868231773376465, 7.530625343322754, 7.665377616882324, 7.797634124755859, 7.930730819702148, 8.059279441833496, 8.180848121643066, 8.296680450439453, 8.406368255615234, 8.505520820617676, 8.589674949645996, 8.655287742614746, 8.70052719116211, 8.722027778625488, 8.70865249633789, 8.652679443359375, 8.560135841369629, 8.443024635314941, 8.307100296020508, 8.149582862854004, 7.971302032470703, 7.780361175537109, 7.575259685516357, 7.355491638183594, 7.124767303466797, 6.885737419128418, 6.638427257537842, 6.395895481109619, 6.166090488433838, 5.953654766082764, 5.738729953765869, 5.529703140258789, 5.342148303985596, 5.179572105407715, 5.024766445159912, 4.851255416870117, 4.646117210388184, 4.430662155151367, 4.217848777770996, 4.0131144523620605, 3.7878849506378174, 3.559556245803833, 3.3353841304779053, 3.1190574169158936, 2.9180359840393066, 2.7267343997955322, 2.5381720066070557, 2.3227102756500244, 2.0959630012512207, 1.8809078931808472, 1.6847819089889526, 1.495663046836853, 1.3055880069732666, 1.1171165704727173, 0.9520562887191772, 0.8042331337928772, 0.681337833404541, 0.5795820951461792, 0.5025584101676941, 0.46133852005004883, 0.4328932762145996, 0.3858243227005005, 0.3234015107154846, 0.2624247372150421, 0.19709435105323792, 0.15313704311847687, 0.11826862394809723, 0.08544927090406418, 0.04712279140949249, 0.0015682056546211243, -0.026410788297653198, -0.03486667573451996, -0.027389593422412872, -0.0065015703439712524, 0.0059362053871154785, 0.002570606768131256, -0.006264716386795044, -0.013282939791679382, -0.018584154546260834, -0.022372961044311523, -0.0232115238904953, -0.02133723348379135, -0.030498042702674866, -0.057736508548259735, -0.09805164486169815, -0.13833804428577423, -0.17615404725074768, -0.21290594339370728, -0.24737012386322021, -0.26589956879615784, -0.2773838937282562, -0.2822290062904358, -0.2861996591091156, -0.2940981388092041, -0.2990141808986664, -0.3035801351070404, -0.3050832152366638, -0.3049992024898529, -0.30373987555503845, -0.3003387153148651, -0.29614898562431335, -0.2985635995864868, -0.31389492750167847, -0.34401920437812805, -0.3844596743583679, -0.4300534129142761, -0.4741150140762329, -0.5105020999908447, -0.5354415774345398, -0.552415132522583, -0.5600359439849854, -0.5654557943344116, -0.5681073665618896, -0.5666967630386353, -0.5622239112854004, -0.5597591996192932, -0.5650179386138916, -0.579081654548645, -0.5969113707542419, -0.6101321578025818, -0.622231125831604, -0.6340838074684143, -0.6458472609519958, -0.657522976398468, -0.6685013771057129, -0.6801296472549438, -0.6912583708763123, -0.7032382488250732, -0.7155491709709167, -0.7265709042549133, -0.7348979115486145, -0.7445682287216187, -0.7536845207214355, -0.761847198009491, -0.7706142067909241, -0.7806366682052612, -0.7898868322372437, -0.7978246212005615, -0.8051745295524597, -0.8114349842071533, -0.8171375393867493, -0.821597158908844, -0.8264663219451904, -0.8312869071960449, -0.8363567590713501, -0.8399266004562378, -0.8434712290763855, -0.8482410907745361, -0.8517320156097412, -0.8557907342910767, -0.8605977296829224, -0.864855170249939, -0.8680832982063293, -0.869952917098999, -0.8720065951347351, -0.8741781711578369, -0.8759156465530396, -0.8775535821914673, -0.8793764710426331, -0.8817098140716553, -0.8832718729972839, -0.8847836852073669, -0.8870889544487, -0.8891378045082092, -0.8896875977516174, -0.8895387649536133, -0.8889559507369995, -0.8881706595420837, -0.8874912261962891, -0.8865614533424377, -0.8851791024208069, -0.8832001686096191, -0.8809881806373596, -0.8781297206878662, -0.8746054172515869, -0.8718098402023315, -0.8688086271286011)
					Y = (0.24426956474781036, 0.4990326166152954, 0.819128692150116, 1.153626799583435, 1.5026447772979736, 1.8859440088272095, 2.373248815536499, 2.968236207962036, 3.61586332321167, 4.355114459991455, 5.173743724822998, 6.038478374481201, 6.951005458831787, 7.899267673492432, 8.918261528015137, 10.051026344299316, 11.312947273254395, 12.90755558013916, 14.871548652648926, 17.198680877685547, 19.908754348754883, 22.898487091064453, 26.10063934326172, 29.397844314575195, 32.636375427246094, 35.74137878417969, 38.707183837890625, 41.484439849853516, 44.07951736450195, 46.60736846923828, 49.15201187133789, 51.65317916870117, 54.06341552734375, 56.4561882019043, 58.852813720703125, 61.29132080078125, 63.84211730957031, 66.49172973632812, 69.07376861572266, 71.62057495117188, 74.08918762207031, 76.49169158935547, 78.78299713134766, 80.95753479003906, 83.06936645507812, 85.1029281616211, 87.12429809570312, 89.12969970703125, 91.03314971923828, 92.87902069091797, 94.55635070800781, 96.09061431884766, 97.33863830566406, 98.26770782470703, 98.91900634765625, 99.34143829345703, 99.79500579833984, 100.22048950195312, 100.46652221679688, 100.50714111328125, 100.43055725097656, 100.3218765258789, 100.27439880371094, 100.24840545654297, 100.22171020507812, 100.19712829589844, 100.16851043701172, 100.09687042236328, 100.02641296386719, 99.95970153808594, 99.8285140991211, 99.58265686035156, 99.25724792480469, 98.94861602783203, 98.7610855102539, 98.6032943725586, 98.43841552734375, 98.27819061279297, 98.11662292480469, 97.93367004394531, 97.72758483886719, 97.4378662109375, 97.10028839111328, 96.74153900146484, 96.36189270019531, 95.95005798339844, 95.50723266601562, 95.01679229736328, 94.47090911865234, 93.8803482055664, 93.24833679199219, 92.5796127319336, 91.90768432617188, 91.14244079589844, 90.31917572021484, 89.48597717285156, 88.64861297607422, 87.82418823242188, 87.01628875732422, 86.22871398925781, 85.56230163574219, 84.96900177001953, 84.57625579833984, 84.36016082763672, 84.20700073242188, 84.08193969726562, 83.97764587402344, 83.87611389160156, 83.92423248291016, 84.14193725585938, 84.41809844970703, 84.70330810546875, 85.00025939941406, 85.29436492919922, 85.68895721435547, 86.27693176269531, 87.06804656982422, 88.0323715209961, 89.15747833251953, 90.61774444580078, 92.43035125732422, 94.46464538574219, 96.57106018066406, 98.82080078125, 101.0973129272461, 103.33666229248047, 105.50848388671875, 107.6570053100586, 109.891357421875, 112.15137481689453, 114.42011260986328, 116.68489074707031, 118.90473175048828, 121.11170959472656, 123.25049591064453, 125.32403564453125, 127.53121185302734, 129.89825439453125, 132.2855987548828, 134.6158905029297, 136.92697143554688, 139.15802001953125, 141.3134002685547, 143.4351806640625, 145.5569305419922, 147.65158081054688, 149.7096405029297, 151.71261596679688, 153.65261840820312, 155.51608276367188, 157.31924438476562, 159.11117553710938, 160.7533416748047, 162.2732696533203, 163.74002075195312, 165.19287109375, 166.6624298095703, 168.05679321289062, 169.36721801757812, 170.6645965576172, 171.94862365722656, 173.23680114746094, 174.46946716308594, 175.60227966308594, 176.68606567382812, 177.7667236328125, 178.8304901123047, 179.89537048339844, 180.9698944091797, 182.1023712158203, 183.38099670410156, 184.83396911621094, 186.4405059814453, 188.17733764648438, 190.03277587890625, 191.99041748046875, 193.9769287109375, 195.76626586914062, 197.2998809814453, 198.64427185058594, 199.84442138671875, 201.0236358642578, 202.19769287109375, 203.31591796875, 204.40118408203125, 205.4407196044922, 206.46392822265625, 207.45944213867188, 208.4150848388672, 209.36993408203125, 210.36520385742188, 211.35165405273438, 212.19497680664062, 212.80360412597656, 212.99081420898438, 212.8595428466797, 212.59893798828125, 212.30372619628906, 211.88113403320312, 211.2249298095703, 210.27505493164062, 209.16802978515625, 207.95042419433594, 206.6737060546875, 205.3536376953125, 203.98805236816406, 202.4827117919922, 200.79603576660156, 198.84075927734375, 196.52613830566406, 193.94662475585938, 191.1892852783203, 188.33187866210938, 185.4967803955078, 182.7758331298828, 180.3319091796875, 178.08534240722656, 175.87472534179688, 173.57350158691406, 171.1052703857422, 168.51658630371094, 165.9554443359375, 163.4188995361328, 160.97314453125, 158.5869903564453, 156.26071166992188, 154.0010223388672, 151.86273193359375, 149.84214782714844, 147.8561553955078, 145.87100219726562, 143.8812255859375, 141.9394073486328, 140.04071044921875, 138.22088623046875, 136.38259887695312, 134.54953002929688, 132.78271484375, 130.9574737548828, 129.08750915527344, 127.25975799560547, 125.4315185546875, 123.64933013916016, 121.882080078125, 120.05531311035156, 118.18463134765625, 116.25498962402344, 114.34269714355469, 112.4908447265625, 110.6985092163086, 108.94164276123047, 107.16153717041016, 105.32911682128906, 103.44462585449219, 101.6138916015625, 99.76459503173828, 97.91300964355469, 96.16510772705078, 94.41311645507812, 92.58258056640625, 90.4946517944336, 88.02781677246094, 85.19628143310547, 82.00907135009766, 78.48986053466797, 74.69635772705078, 70.86166381835938, 67.15168762207031, 63.572113037109375, 60.10674285888672, 56.803375244140625, 53.6189079284668, 50.549373626708984, 47.61164474487305, 44.77302932739258, 41.92876434326172, 39.06986999511719, 36.2219352722168, 33.32758331298828, 30.242610931396484, 26.973918914794922, 23.662368774414062, 20.41046714782715, 17.231449127197266, 14.126823425292969, 11.168815612792969, 8.347853660583496, 5.706920623779297, 3.3018741607666016, 1.2335699796676636, -0.5328974723815918, -2.043576717376709, -3.110535144805908, -3.740983486175537, -4.098943710327148, -4.4906511306762695, -4.8972249031066895, -5.2530198097229, -5.577995777130127, -5.934023857116699, -6.255759239196777, -6.630918025970459, -7.013139724731445, -7.412384033203125, -7.725191116333008, -8.017799377441406, -8.335323333740234, -8.662646293640137, -9.008383750915527, -9.383427619934082, -9.718378067016602, -10.013775825500488, -10.301630973815918, -10.562592506408691, -10.815587997436523, -11.065951347351074, -11.301687240600586, -11.448249816894531, -11.537090301513672, -11.524465560913086, -11.443005561828613, -11.383244514465332, -11.339241981506348, -11.295818328857422, -11.257658004760742, -11.223909378051758, -11.219079971313477, -11.304905891418457, -11.446738243103027, -11.616390228271484, -11.812542915344238, -12.02774429321289, -12.266841888427734, -12.534515380859375, -12.815123558044434, -13.006359100341797, -13.117430686950684, -13.182148933410645, -13.210461616516113, -13.223767280578613, -13.236565589904785, -13.257308006286621, -13.364906311035156, -13.60283374786377, -13.906349182128906, -14.247852325439453, -14.630463600158691, -15.034890174865723, -15.458684921264648, -15.909191131591797, -16.372478485107422, -16.83634376525879, -17.298728942871094, -17.954330444335938, -18.74985694885254, -19.579227447509766, -20.42566680908203, -21.43193817138672, -22.800357818603516, -24.44293212890625, -26.13048553466797, -27.82823944091797, -29.55722427368164, -31.477741241455078, -33.487709045410156, -35.511478424072266, -37.493263244628906, -39.456016540527344, -41.433685302734375, -43.504295349121094, -45.86669158935547, -48.45779037475586, -51.14822006225586, -53.83092498779297, -56.52829360961914, -59.291015625, -62.107452392578125, -64.86852264404297, -67.60960388183594, -70.36067199707031, -73.03939819335938, -75.66210174560547, -78.23661041259766, -80.80587005615234, -83.38500213623047, -85.95026397705078, -88.392578125, -90.68785095214844, -92.96864318847656, -95.2093505859375, -97.35236358642578, -99.36150360107422, -101.18042755126953, -102.92134857177734, -104.60369110107422, -106.27859497070312, -107.93692779541016, -109.50454711914062, -110.95790100097656, -112.26480102539062, -113.4476318359375, -114.55032348632812, -115.59841918945312, -116.59353637695312, -117.56787872314453, -118.43424987792969, -119.07018280029297, -119.529541015625, -119.9432144165039, -120.33118438720703, -120.70291137695312, -121.06876373291016, -121.57264709472656, -122.14915466308594, -122.72602844238281, -123.31329345703125, -123.84371948242188, -124.38484191894531, -124.94699096679688, -125.50639343261719, -126.06773376464844, -126.62725067138672, -127.21639251708984, -127.76771545410156, -128.14712524414062, -128.24986267089844, -128.0001220703125, -127.45743560791016, -126.70941925048828, -125.85266876220703, -124.98062133789062, -124.1561508178711, -123.36287689208984, -122.56819915771484, -121.65084838867188, -120.66740417480469, -119.70370483398438, -118.76301574707031, -117.76809692382812, -116.55887603759766, -115.09596252441406, -113.52935028076172, -111.99527740478516, -110.50000762939453, -108.9967041015625, -107.39553833007812, -105.7052001953125, -103.86796569824219, -101.89085388183594, -99.83897399902344, -97.75530242919922, -95.71993255615234, -93.73746490478516, -91.82310485839844, -89.95047760009766, -88.10604858398438, -86.26592254638672, -84.39051818847656, -82.42990112304688, -80.4601821899414, -78.54206085205078, -76.67953491210938, -74.87965393066406, -73.13782501220703, -71.447998046875, -69.79700469970703, -68.07174682617188, -66.20356750488281, -64.17756652832031, -62.02452850341797, -59.78955841064453, -57.599979400634766, -55.49079895019531, -53.38170623779297, -51.32799530029297, -49.24906539916992, -47.25999069213867, -45.2713508605957, -43.23389434814453, -41.17817687988281, -39.17205047607422, -37.22850799560547, -35.21967697143555, -33.25495910644531, -31.328039169311523, -29.30510902404785, -27.14748191833496, -24.93663215637207, -22.68917465209961, -20.511201858520508, -18.440406799316406, -16.442750930786133, -14.476696014404297, -12.49740982055664, -10.538829803466797, -8.549440383911133, -6.5612688064575195, -4.653802394866943, -2.830416679382324, -1.0931862592697144)
				X = [-215.266 -215.166 -215.066 ...  210.034  210.134  210.234]
				Y = [-178.250 -178.150 -178.050 ...  262.750  262.850  262.950]
				cost_map = [[ 214.381  214.299  214.217 ...  112.184  112.264  112.344]
				 [ 214.324  214.242  214.160 ...  112.124  112.204  112.284]
				 [ 214.267  214.185  214.103 ...  112.064  112.144  112.224]
				 ...
				 [  96.764   96.690   96.616 ...  242.661  242.689  242.717]
				 [  96.831   96.757   96.683 ...  242.757  242.785  242.813]
				 [  96.898   96.824   96.750 ...  242.852  242.881  242.909]]
				res = 0.1
				min_point = [-215.266 -178.250    0.000]
			max_time = 1000
			time = 0
			idle_timeout = 10
			spec = EnvSpec(CarRacing-v1) 
				id = CarRacing-v1
				entry_point = <class 'src.envs.CarRacing.car_racing.CarRacing'> 
					reset = <function CarRacing.reset at 0x7f8138868f80>
					get_reward = <function CarRacing.get_reward at 0x7f8138868ef0>
					step = <function CarRacing.step at 0x7f81388739e0>
					render = <function CarRacing.render at 0x7f8138873a70>
					close = <function CarRacing.close at 0x7f8138873b00>
					id = 1
				reward_threshold = None
				nondeterministic = False
				max_episode_steps = None
			verbose = 0
		action_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -1.000]
			high = [ 1.000  1.000  1.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		observation_space = Box(30,) 
			dtype = float32
			shape = (30,)
			low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
			high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
			bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': []}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x7f80b8c53bd0> 
			observation_space = Box(30,) 
				dtype = float32
				shape = (30,)
				low = [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]
				high = [ inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf  inf]
				bounded_below = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				bounded_above = [False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False]
				np_random = RandomState(MT19937)
	state_size = (30,)
	action_size = (3,)
	action_space = Box(3,) 
		dtype = float32
		shape = (3,)
		low = [-1.000 -1.000 -1.000]
		high = [ 1.000  1.000  1.000]
		bounded_below = [ True  True  True]
		bounded_above = [ True  True  True]
		np_random = RandomState(MT19937)
	server_ports = <list len=16>
	conn = <src.utils.multiprocess.TCPClient object at 0x7f80c44cc950> 
		num_clients = 16
		client_ranks = <list len=16>
		client_ports = <list len=16>
		client_sockets = {9001: <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51636), raddr=('127.0.0.1', 9001)>, 9002: <socket.socket fd=77, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 44408), raddr=('127.0.0.1', 9002)>, 9003: <socket.socket fd=78, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 46750), raddr=('127.0.0.1', 9003)>, 9004: <socket.socket fd=79, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 49790), raddr=('127.0.0.1', 9004)>, 9005: <socket.socket fd=86, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41614), raddr=('127.0.0.1', 9005)>, 9006: <socket.socket fd=88, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41674), raddr=('127.0.0.1', 9006)>, 9007: <socket.socket fd=89, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 46536), raddr=('127.0.0.1', 9007)>, 9008: <socket.socket fd=90, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 47498), raddr=('127.0.0.1', 9008)>, 9009: <socket.socket fd=91, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 48294), raddr=('127.0.0.1', 9009)>, 9010: <socket.socket fd=92, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 40752), raddr=('127.0.0.1', 9010)>, 9011: <socket.socket fd=93, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 53006), raddr=('127.0.0.1', 9011)>, 9012: <socket.socket fd=94, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 35996), raddr=('127.0.0.1', 9012)>, 9013: <socket.socket fd=172, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 59034), raddr=('127.0.0.1', 9013)>, 9014: <socket.socket fd=173, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 41656), raddr=('127.0.0.1', 9014)>, 9015: <socket.socket fd=174, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 35446), raddr=('127.0.0.1', 9015)>, 9016: <socket.socket fd=177, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 54922), raddr=('127.0.0.1', 9016)>}
	num_envs = 16
	max_steps = 1000,
agent: <src.models.wrappers.ParallelAgent object at 0x7f80b8bf2490> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x7f80b88961d0> 
		state_size = (30,)
	agent = <src.models.pytorch.agents.ddpg.DDPGAgent object at 0x7f80b8896310> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x7f80b8896350> 
			size = (3,)
			dt = 0.2
			action = [-0.215 -1.000  1.000]
			daction_dt = [ 0.589  0.033 -0.233]
		discrete = False
		action_size = (3,)
		state_size = (30,)
		config = <src.models.Config object at 0x7f80c3291d10> 
			TRIAL_AT = 1000
			SAVE_AT = 10
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.02
			EPS_DECAY = 0.99
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 100000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			env_name = CarRacing-v1
			rank = 0
			size = 17
			split = 17
			model = ddpg
			framework = pt
			train_prop = 1.0
			tcp_ports = <list len=17>
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x7f80b8896650> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
		network = DDPGNetwork(
			  (actor_local): DDPGActor(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (actor_target): DDPGActor(
			    (layer1): Linear(in_features=30, out_features=512, bias=True)
			    (layer2): Linear(in_features=512, out_features=256, bias=True)
			    (layer3): Linear(in_features=256, out_features=256, bias=True)
			    (action_mu): Linear(in_features=256, out_features=3, bias=True)
			    (action_sig): Linear(in_features=256, out_features=3, bias=True)
			  )
			  (critic_local): DDPGCritic(
			    (net_state): Linear(in_features=30, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			  (critic_target): DDPGCritic(
			    (net_state): Linear(in_features=30, out_features=512, bias=True)
			    (net_action): Linear(in_features=3, out_features=512, bias=True)
			    (net_layer1): Linear(in_features=1024, out_features=1024, bias=True)
			    (net_layer2): Linear(in_features=1024, out_features=1024, bias=True)
			    (q_value): Linear(in_features=1024, out_features=1, bias=True)
			  )
			) 
			discrete = False
			training = True
			tau = 0.0004
			name = ddpg
			stats = <src.utils.logger.Stats object at 0x7f80b8d090d0> 
				mean_dict = {}
				sum_dict = {}
			config = <src.models.Config object at 0x7f80c3291d10> 
				TRIAL_AT = 1000
				SAVE_AT = 10
				REG_LAMBDA = 1e-06
				LEARN_RATE = 0.0001
				DISCOUNT_RATE = 0.99
				ADVANTAGE_DECAY = 0.95
				INPUT_LAYER = 512
				ACTOR_HIDDEN = 256
				CRITIC_HIDDEN = 1024
				EPS_MAX = 1.0
				EPS_MIN = 0.02
				EPS_DECAY = 0.99
				NUM_STEPS = 500
				MAX_BUFFER_SIZE = 100000
				REPLAY_BATCH_SIZE = 32
				TARGET_UPDATE_RATE = 0.0004
				env_name = CarRacing-v1
				rank = 0
				size = 17
				split = 17
				model = ddpg
				framework = pt
				train_prop = 1.0
				tcp_ports = <list len=17>
				tcp_rank = 0
				num_envs = 1
				nsteps = 500000
				render = False
				trial = False
				icm = False
				rs = False
			device = cuda
			src = ['class DDPGActor(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN\n\t\tself.discrete = type(action_size) != tuple\n\t\tself.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.layer2 = torch.nn.Linear(input_layer, actor_hidden)\n\t\tself.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)\n\t\tself.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, sample=True):\n\t\tstate = self.layer1(state).relu() \n\t\tstate = self.layer2(state).relu() \n\t\tstate = self.layer3(state).relu() \n\t\taction_mu = self.action_mu(state)\n\t\taction_sig = self.action_sig(state).exp()\n\t\tepsilon = torch.randn_like(action_sig)\n\t\taction = action_mu + epsilon.mul(action_sig) if sample else action_mu\n\t\treturn action.tanh() if not self.discrete else gsoftmax(action)\n', 'class DDPGCritic(torch.nn.Module):\n\tdef __init__(self, state_size, action_size, config):\n\t\tsuper().__init__()\n\t\tinput_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN\n\t\tself.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)\n\t\tself.net_action = torch.nn.Linear(action_size[-1], input_layer)\n\t\tself.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)\n\t\tself.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)\n\t\tself.q_value = torch.nn.Linear(critic_hidden, 1)\n\t\tself.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)\n\n\tdef forward(self, state, action):\n\t\tstate = self.net_state(state).relu()\n\t\tnet_action = self.net_action(action).relu()\n\t\tnet_layer = torch.cat([state, net_action], dim=-1)\n\t\tnet_layer = self.net_layer1(net_layer).relu()\n\t\tnet_layer = self.net_layer2(net_layer).relu()\n\t\tq_value = self.q_value(net_layer)\n\t\treturn q_value\n']
			actor_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
			critic_optimizer = Adam (
			Parameter Group 0
			    amsgrad: False
			    betas: (0.9, 0.999)
			    eps: 1e-08
			    lr: 0.0001
			    weight_decay: 1e-06
			)
		replay_buffer = <src.utils.rand.ReplayBuffer object at 0x7f80b885e110> 
			buffer = deque([], maxlen=100000)
		buffer = []
	noise_process = <src.utils.rand.BrownianNoise object at 0x7f80b885e090> 
		size = (3,)
		dt = 0.2
		action = [-0.414 -0.139 -1.000]
		daction_dt = [ 1.011  0.192 -1.705]
	discrete = False
	action_size = (3,)
	state_size = (30,)
	config = <src.models.Config object at 0x7f80c3291d10> 
		TRIAL_AT = 1000
		SAVE_AT = 10
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.02
		EPS_DECAY = 0.99
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 100000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		env_name = CarRacing-v1
		rank = 0
		size = 17
		split = 17
		model = ddpg
		framework = pt
		train_prop = 1.0
		tcp_ports = <list len=17>
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x7f80b885e190> 
		mean_dict = {}
		sum_dict = {},
config: 
   TRIAL_AT = 1000
   SAVE_AT = 10
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.02
   EPS_DECAY = 0.99
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 100000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   env_name = CarRacing-v1
   rank = 0
   size = 17
   split = 17
   model = ddpg
   framework = pt
   train_prop = 1.0
   tcp_ports = [9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016]
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 16,
conn: None,

import torch
import random
import numpy as np
from .base import PTACNetwork, PTAgent, PTCritic, Conv, gsoftmax, one_hot
from src.utils.rand import RandomAgent, PrioritizedReplayBuffer, ReplayBuffer

class DDPGActor(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, actor_hidden = config.INPUT_LAYER, config.ACTOR_HIDDEN
		self.discrete = type(action_size) != tuple
		self.layer1 = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.layer2 = torch.nn.Linear(input_layer, actor_hidden)
		self.layer3 = torch.nn.Linear(actor_hidden, actor_hidden)
		self.action_mu = torch.nn.Linear(actor_hidden, action_size[-1])
		self.action_sig = torch.nn.Linear(actor_hidden, action_size[-1])
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, sample=True):
		state = self.layer1(state).relu() 
		state = self.layer2(state).relu() 
		state = self.layer3(state).relu() 
		action_mu = self.action_mu(state)
		action_sig = self.action_sig(state).exp()
		epsilon = torch.randn_like(action_sig)
		action = action_mu + epsilon.mul(action_sig) if sample else action_mu
		return action.tanh() if not self.discrete else gsoftmax(action)
	
class DDPGCritic(torch.nn.Module):
	def __init__(self, state_size, action_size, config):
		super().__init__()
		input_layer, critic_hidden = config.INPUT_LAYER, config.CRITIC_HIDDEN
		self.net_state = torch.nn.Linear(state_size[-1], input_layer) if len(state_size)!=3 else Conv(state_size, input_layer)
		self.net_action = torch.nn.Linear(action_size[-1], input_layer)
		self.net_layer1 = torch.nn.Linear(2*input_layer, critic_hidden)
		self.net_layer2 = torch.nn.Linear(critic_hidden, critic_hidden)
		self.q_value = torch.nn.Linear(critic_hidden, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state, action):
		state = self.net_state(state).relu()
		net_action = self.net_action(action).relu()
		net_layer = torch.cat([state, net_action], dim=-1)
		net_layer = self.net_layer1(net_layer).relu()
		net_layer = self.net_layer2(net_layer).relu()
		q_value = self.q_value(net_layer)
		return q_value

class DDPGNetwork(PTACNetwork):
	def __init__(self, state_size, action_size, config, actor=DDPGActor, critic=DDPGCritic, gpu=True, load=None, name="ddpg"): 
		self.discrete = type(action_size)!=tuple
		super().__init__(state_size, action_size, config, actor, critic if not self.discrete else lambda s,a,c: PTCritic(s,a,c), gpu=gpu, load=load, name=name)

	def get_action(self, state, use_target=False, grad=False, numpy=False, sample=True):
		with torch.enable_grad() if grad else torch.no_grad():
			actor = self.actor_local if not use_target else self.actor_target
			return actor(state, sample).cpu().numpy() if numpy else actor(state, sample)

	def get_q_value(self, state, action, use_target=False, grad=False, numpy=False, probs=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			q_value = critic(state) if self.discrete else critic(state, action)
			q_value = q_value.gather(-1, action.argmax(-1, keepdim=True)) if self.discrete and not probs else q_value
			return q_value.cpu().numpy() if numpy else q_value
	
	def optimize(self, states, actions, q_targets):
		actions = one_hot(actions) if self.actor_local.discrete else actions
		q_values = self.get_q_value(states, actions, grad=True, probs=False)
		critic_loss = (q_values - q_targets.detach()).pow(2).mean()
		self.step(self.critic_optimizer, critic_loss)
		self.soft_copy(self.critic_local, self.critic_target)

		actor_action = self.actor_local(states)
		q_actions = self.get_q_value(states, actor_action, grad=True, probs=True)
		q_actions = (actor_action*q_actions).sum(-1) if self.discrete else q_actions
		q_baseline = q_targets if self.discrete else q_values
		actor_loss = -(q_actions - q_baseline.detach()).mean()
		self.step(self.actor_optimizer, actor_loss, self.actor_local.parameters())
		self.soft_copy(self.actor_local, self.actor_target)
		self.stats.mean(critic_loss=critic_loss, actor_loss=actor_loss)
		
class DDPGAgent(PTAgent):
	def __init__(self, state_size, action_size, config, gpu=True, load=None):
		super().__init__(state_size, action_size, config, DDPGNetwork, gpu=gpu, load=load)

	def get_action(self, state, eps=None, sample=True):
		eps = self.eps if eps is None else eps
		action_random = super().get_action(state, eps)
		if self.discrete and random.random() < eps: return action_random
		action_greedy = self.network.get_action(self.to_tensor(state), numpy=True, sample=sample)
		action = np.clip((1-eps)*action_greedy + eps*action_random, -1, 1)
		return action
		
	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, action, reward, done))
		if np.any(done[0]) or len(self.buffer) >= self.config.NUM_STEPS:
			states, actions, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()	
			states = torch.cat([states, self.to_tensor(next_state).unsqueeze(0)], dim=0)
			actions = torch.cat([actions, self.network.get_action(states[-1], use_target=True).unsqueeze(0)], dim=0)
			values = self.network.get_q_value(states, actions, use_target=True)
			targets = self.compute_gae(values[-1], rewards.unsqueeze(-1), dones.unsqueeze(-1), values[:-1])[0]
			states, actions, targets = [x.view(x.size(0)*x.size(1), *x.size()[2:]).cpu().numpy() for x in (states[:-1], actions[:-1], targets)]
			self.replay_buffer.extend(list(zip(states, actions, targets)), shuffle=False)	
		if len(self.replay_buffer) > self.config.REPLAY_BATCH_SIZE:
			states, actions, targets = self.replay_buffer.sample(self.config.REPLAY_BATCH_SIZE, dtype=self.to_tensor)[0]
			self.network.optimize(states, actions, targets)
			if np.any(done[0]): self.eps = max(self.eps * self.config.EPS_DECAY, self.config.EPS_MIN)


Step:       0, Reward:   -30.338 [  27.661], Avg:   -30.338 (1.000) <0-00:00:00> ({'r_t':  -7.00e-05, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward:   -29.131 [  26.146], Avg:   -29.734 (0.932) <0-00:00:44> ({'r_t':  -201.4465, 'eps':     0.9321, 'critic_loss':     4.3528, 'actor_loss':    -0.1965, 'eps_e':     0.9321})
Step:    2000, Reward:   -19.156 [  22.964], Avg:   -26.208 (0.878) <0-00:01:34> ({'r_t':  -199.0331, 'eps':     0.8775, 'critic_loss':     4.9866, 'actor_loss':    -0.3323, 'eps_e':     0.8775})
Step:    3000, Reward:   -25.035 [  21.687], Avg:   -25.915 (0.826) <0-00:02:17> ({'r_t':  -183.0299, 'eps':     0.8262, 'critic_loss':     4.8012, 'actor_loss':    -0.5212, 'eps_e':     0.8262})
Step:    4000, Reward:   -17.347 [  23.069], Avg:   -24.201 (0.762) <0-00:02:59> ({'r_t':  -139.9999, 'eps':     0.7623, 'critic_loss':     5.0002, 'actor_loss':    -0.6797, 'eps_e':     0.7623})
Step:    5000, Reward:   -17.481 [  26.854], Avg:   -23.081 (0.703) <0-00:03:41> ({'r_t':  -137.1977, 'eps':     0.7034, 'critic_loss':     5.8626, 'actor_loss':    -0.8710, 'eps_e':     0.7034})
Step:    6000, Reward:    -3.190 [  22.704], Avg:   -20.240 (0.662) <0-00:04:21> ({'r_t':   -95.8597, 'eps':     0.6623, 'critic_loss':     6.3878, 'actor_loss':    -1.0627, 'eps_e':     0.6623})
Step:    7000, Reward:    -5.764 [  28.470], Avg:   -18.430 (0.617) <0-00:05:01> ({'r_t':   -76.2471, 'eps':     0.6173, 'critic_loss':     7.5886, 'actor_loss':    -1.2690, 'eps_e':     0.6173})
Step:    8000, Reward:    -5.624 [  21.906], Avg:   -17.007 (0.575) <0-00:05:39> ({'r_t':     2.9377, 'eps':     0.5754, 'critic_loss':     9.2513, 'actor_loss':    -1.4855, 'eps_e':     0.5754})
Step:    9000, Reward:     5.576 [  33.228], Avg:   -14.749 (0.536) <0-00:06:19> ({'r_t':    90.2815, 'eps':     0.5363, 'critic_loss':    11.3549, 'actor_loss':    -1.7050, 'eps_e':     0.5363})
Step:   10000, Reward:     8.314 [  23.960], Avg:   -12.652 (0.495) <0-00:06:56> ({'r_t':    15.1887, 'eps':     0.4948, 'critic_loss':    13.6783, 'actor_loss':    -2.1118, 'eps_e':     0.4948})
Step:   11000, Reward:    38.589 [  33.248], Avg:    -8.382 (0.457) <0-00:07:34> ({'r_t':    92.1839, 'eps':     0.4566, 'critic_loss':    15.8876, 'actor_loss':    -2.3254, 'eps_e':     0.4566})
Step:   12000, Reward:    40.524 [  27.757], Avg:    -4.620 (0.417) <0-00:08:40> ({'r_t':   314.2848, 'eps':     0.4171, 'critic_loss':    18.4433, 'actor_loss':    -2.4221, 'eps_e':     0.4171})
Step:   13000, Reward:    45.132 [  29.973], Avg:    -1.067 (0.381) <0-00:09:18> ({'r_t':   450.0773, 'eps':     0.3810, 'critic_loss':    20.3937, 'actor_loss':    -2.5673, 'eps_e':     0.3810})
Step:   14000, Reward:    56.680 [  30.059], Avg:     2.783 (0.366) <0-00:09:55> ({'r_t':   512.2096, 'eps':     0.3660, 'critic_loss':    21.0034, 'actor_loss':    -2.5998, 'eps_e':     0.3660})
Step:   15000, Reward:    65.515 [  28.281], Avg:     6.704 (0.341) <0-00:10:32> ({'r_t':   525.1139, 'eps':     0.3412, 'critic_loss':    23.2883, 'actor_loss':    -2.4146, 'eps_e':     0.3412})
Step:   16000, Reward:    52.989 [  32.675], Avg:     9.427 (0.305) <0-00:11:08> ({'r_t':   560.4540, 'eps':     0.3055, 'critic_loss':    23.6764, 'actor_loss':    -2.2651, 'eps_e':     0.3055})
Step:   17000, Reward:    76.902 [  24.547], Avg:    13.175 (0.276) <0-00:11:45> ({'r_t':   679.7891, 'eps':     0.2763, 'critic_loss':    23.8423, 'actor_loss':    -2.1611, 'eps_e':     0.2763})
Step:   18000, Reward:    78.495 [  33.093], Avg:    16.613 (0.250) <0-00:12:23> ({'r_t':   716.6078, 'eps':     0.2498, 'critic_loss':    24.2739, 'actor_loss':    -2.0840, 'eps_e':     0.2498})
Step:   19000, Reward:    67.548 [  35.146], Avg:    19.160 (0.226) <0-00:13:00> ({'r_t':   744.2604, 'eps':     0.2259, 'critic_loss':    24.6540, 'actor_loss':    -1.9259, 'eps_e':     0.2259})
Step:   20000, Reward:    92.110 [  32.279], Avg:    22.634 (0.204) <0-00:13:39> ({'r_t':   812.2817, 'eps':     0.2043, 'critic_loss':    24.1914, 'actor_loss':    -1.7458, 'eps_e':     0.2043})
Step:   21000, Reward:    99.084 [  35.159], Avg:    26.109 (0.187) <0-00:14:16> ({'r_t':   816.5022, 'eps':     0.1867, 'critic_loss':    23.1403, 'actor_loss':    -1.6890, 'eps_e':     0.1867})
Step:   22000, Reward:    85.346 [  29.502], Avg:    28.684 (0.169) <0-00:14:53> ({'r_t':   859.8485, 'eps':     0.1688, 'critic_loss':    24.4577, 'actor_loss':    -1.5861, 'eps_e':     0.1688})
Step:   23000, Reward:    88.774 [  41.783], Avg:    31.188 (0.153) <0-00:15:29> ({'r_t':   881.2567, 'eps':     0.1527, 'critic_loss':    23.7024, 'actor_loss':    -1.4491, 'eps_e':     0.1527})
Step:   24000, Reward:   109.369 [  24.681], Avg:    34.315 (0.145) <0-00:16:06> ({'r_t':   850.8032, 'eps':     0.1452, 'critic_loss':    24.5178, 'actor_loss':    -1.3902, 'eps_e':     0.1452})
Step:   25000, Reward:   113.573 [   9.304], Avg:    37.364 (0.131) <0-00:16:43> ({'r_t':   918.1142, 'eps':     0.1313, 'critic_loss':    25.1230, 'actor_loss':    -1.2751, 'eps_e':     0.1313})
Step:   26000, Reward:   113.440 [  10.916], Avg:    40.181 (0.119) <0-00:17:21> ({'r_t':   872.0276, 'eps':     0.1188, 'critic_loss':    26.3081, 'actor_loss':    -1.1120, 'eps_e':     0.1188})
Step:   27000, Reward:   100.078 [  32.731], Avg:    42.320 (0.107) <0-00:17:58> ({'r_t':   874.6306, 'eps':     0.1074, 'critic_loss':    49.3248, 'actor_loss':    -1.0614, 'eps_e':     0.1074})
Step:   28000, Reward:   101.603 [  24.678], Avg:    44.365 (0.097) <0-00:18:36> ({'r_t':   630.3927, 'eps':     0.0971, 'critic_loss':  2295.3052, 'actor_loss':    -1.0260, 'eps_e':     0.0971})
Step:   29000, Reward:    89.488 [  39.712], Avg:    45.869 (0.088) <0-00:19:13> ({'r_t':   903.1849, 'eps':     0.0878, 'critic_loss': 13156.0010, 'actor_loss':    -0.9554, 'eps_e':     0.0878})
Step:   30000, Reward:   109.906 [  12.760], Avg:    47.934 (0.079) <0-00:19:50> ({'r_t':   923.9873, 'eps':     0.0794, 'critic_loss':  5710.5703, 'actor_loss':    -0.8404, 'eps_e':     0.0794})
Step:   31000, Reward:   -21.014 [ 537.456], Avg:    45.780 (0.072) <0-00:20:56> ({'r_t':   978.7190, 'eps':     0.0718, 'critic_loss':  6529.8159, 'actor_loss':    -0.8335, 'eps_e':     0.0718})
Step:   32000, Reward:   104.226 [  27.640], Avg:    47.551 (0.066) <0-00:21:32> ({'r_t':   970.3173, 'eps':     0.0656, 'critic_loss':  7033.0991, 'actor_loss':    -0.8041, 'eps_e':     0.0656})
Step:   33000, Reward:   111.565 [  15.325], Avg:    49.434 (0.060) <0-00:22:08> ({'r_t':  1017.1897, 'eps':     0.0600, 'critic_loss':  3855.9453, 'actor_loss':    -0.8354, 'eps_e':     0.0600})
Step:   34000, Reward:   114.378 [  19.106], Avg:    51.289 (0.054) <0-00:22:45> ({'r_t':   922.3024, 'eps':     0.0542, 'critic_loss':  6095.9595, 'actor_loss':    -0.7522, 'eps_e':     0.0542})
Step:   35000, Reward:   114.555 [   5.370], Avg:    53.047 (0.049) <0-00:23:21> ({'r_t':  1027.6985, 'eps':     0.0490, 'critic_loss':    23.3450, 'actor_loss':    -0.7268, 'eps_e':     0.0490})
Step:   36000, Reward:   100.751 [  15.297], Avg:    54.336 (0.044) <0-00:23:59> ({'r_t':  1005.1084, 'eps':     0.0444, 'critic_loss':    19.8331, 'actor_loss':    -0.7194, 'eps_e':     0.0444})
Step:   37000, Reward:   100.376 [  25.243], Avg:    55.547 (0.041) <0-00:24:35> ({'r_t':   998.4684, 'eps':     0.0405, 'critic_loss':    19.4054, 'actor_loss':    -0.6839, 'eps_e':     0.0405})
Step:   38000, Reward:   100.338 [  27.038], Avg:    56.696 (0.040) <0-00:25:12> ({'r_t':   706.8920, 'eps':     0.0397, 'critic_loss':   848.0018, 'actor_loss':    -0.5601, 'eps_e':     0.0397})
Step:   39000, Reward:    99.572 [  35.870], Avg:    57.768 (0.036) <0-00:25:48> ({'r_t':   927.9868, 'eps':     0.0363, 'critic_loss':  4490.3042, 'actor_loss':    -0.5333, 'eps_e':     0.0363})
Step:   40000, Reward:    91.396 [  21.117], Avg:    58.588 (0.033) <0-00:26:38> ({'r_t':   940.0509, 'eps':     0.0331, 'critic_loss':  6339.0273, 'actor_loss':    -0.5616, 'eps_e':     0.0331})
Step:   41000, Reward:   111.799 [   4.620], Avg:    59.855 (0.030) <0-00:27:15> ({'r_t':   998.7209, 'eps':     0.0300, 'critic_loss':  2289.9475, 'actor_loss':    -0.5388, 'eps_e':     0.0300})
Step:   42000, Reward:    83.660 [  14.143], Avg:    60.409 (0.027) <0-00:27:55> ({'r_t':   984.9918, 'eps':     0.0271, 'critic_loss':  2762.5708, 'actor_loss':    -0.5785, 'eps_e':     0.0271})
Step:   43000, Reward:   109.751 [  13.039], Avg:    61.530 (0.025) <0-00:28:35> ({'r_t':   577.3802, 'eps':     0.0245, 'critic_loss':  6712.2222, 'actor_loss':    -0.5021, 'eps_e':     0.0245})
Step:   44000, Reward:    94.240 [   6.666], Avg:    62.257 (0.022) <0-00:29:12> ({'r_t':   976.4211, 'eps':     0.0222, 'critic_loss':  7458.6255, 'actor_loss':    -0.4987, 'eps_e':     0.0222})
Step:   45000, Reward:    82.080 [  19.030], Avg:    62.688 (0.020) <0-00:29:50> ({'r_t':  1009.3587, 'eps':     0.0200, 'critic_loss':  3527.6643, 'actor_loss':    -0.5543, 'eps_e':     0.0200})
Step:   46000, Reward:   105.591 [  20.704], Avg:    63.601 (0.020) <0-00:30:27> ({'r_t':  1009.8273, 'eps':     0.0200, 'critic_loss':  2183.4893, 'actor_loss':    -0.4057, 'eps_e':     0.0200})
Step:   47000, Reward:   108.118 [  16.794], Avg:    64.528 (0.020) <0-00:31:03> ({'r_t':   995.0939, 'eps':     0.0200, 'critic_loss':  1530.4196, 'actor_loss':    -0.4543, 'eps_e':     0.0200})
Step:   48000, Reward:    99.102 [  27.015], Avg:    65.234 (0.020) <0-00:31:39> ({'r_t':   981.6062, 'eps':     0.0200, 'critic_loss':  1249.8917, 'actor_loss':    -0.4096, 'eps_e':     0.0200})
Step:   49000, Reward:    86.774 [   9.991], Avg:    65.665 (0.020) <0-00:32:16> ({'r_t':   941.4153, 'eps':     0.0200, 'critic_loss':  2603.1970, 'actor_loss':    -0.3954, 'eps_e':     0.0200})
Step:   50000, Reward:   106.754 [   2.506], Avg:    66.470 (0.020) <0-00:32:52> ({'r_t':   988.0762, 'eps':     0.0200, 'critic_loss':    26.2054, 'actor_loss':    -0.3250, 'eps_e':     0.0200})
Step:   51000, Reward:   120.337 [   8.416], Avg:    67.506 (0.020) <0-00:33:30> ({'r_t':   995.3337, 'eps':     0.0200, 'critic_loss':    24.8551, 'actor_loss':    -0.3265, 'eps_e':     0.0200})
Step:   52000, Reward:   114.360 [   5.205], Avg:    68.390 (0.020) <0-00:34:06> ({'r_t':  1029.7686, 'eps':     0.0200, 'critic_loss':    25.0180, 'actor_loss':    -0.4049, 'eps_e':     0.0200})
Step:   53000, Reward:   111.574 [   2.959], Avg:    69.190 (0.020) <0-00:34:42> ({'r_t':   923.2069, 'eps':     0.0200, 'critic_loss':    22.5824, 'actor_loss':    -0.3925, 'eps_e':     0.0200})
Step:   54000, Reward:   117.032 [   1.587], Avg:    70.060 (0.020) <0-00:35:18> ({'r_t':   746.2052, 'eps':     0.0200, 'critic_loss':    26.8281, 'actor_loss':    -0.3531, 'eps_e':     0.0200})
Step:   55000, Reward:   118.100 [   5.151], Avg:    70.918 (0.020) <0-00:35:55> ({'r_t':   875.0588, 'eps':     0.0200, 'critic_loss':    22.3998, 'actor_loss':    -0.3443, 'eps_e':     0.0200})
Step:   56000, Reward:   113.664 [   4.837], Avg:    71.667 (0.020) <0-00:36:34> ({'r_t':   804.0969, 'eps':     0.0200, 'critic_loss':    17.8742, 'actor_loss':    -0.3454, 'eps_e':     0.0200})
Step:   57000, Reward:   103.193 [  26.988], Avg:    72.211 (0.020) <0-00:37:32> ({'r_t':   749.8531, 'eps':     0.0200, 'critic_loss':    16.9366, 'actor_loss':    -0.3573, 'eps_e':     0.0200})
Step:   58000, Reward:   111.158 [  21.828], Avg:    72.871 (0.020) <0-00:38:25> ({'r_t':   911.0935, 'eps':     0.0200, 'critic_loss':    15.8210, 'actor_loss':    -0.3790, 'eps_e':     0.0200})
Step:   59000, Reward:    75.429 [  57.201], Avg:    72.914 (0.020) <0-00:39:03> ({'r_t':   867.9485, 'eps':     0.0200, 'critic_loss':    14.9494, 'actor_loss':    -0.4006, 'eps_e':     0.0200})
Step:   60000, Reward:    98.421 [  24.117], Avg:    73.332 (0.020) <0-00:39:41> ({'r_t':   422.3061, 'eps':     0.0200, 'critic_loss':   138.2867, 'actor_loss':    -0.3820, 'eps_e':     0.0200})
Step:   61000, Reward:    54.348 [ 140.136], Avg:    73.026 (0.020) <0-00:40:47> ({'r_t':   786.7082, 'eps':     0.0200, 'critic_loss':   309.9614, 'actor_loss':    -0.3395, 'eps_e':     0.0200})
Step:   62000, Reward:    62.035 [  67.401], Avg:    72.851 (0.020) <0-00:41:33> ({'r_t':   874.8608, 'eps':     0.0200, 'critic_loss':  1378.5017, 'actor_loss':    -0.2871, 'eps_e':     0.0200})
Step:   63000, Reward:    88.584 [  49.778], Avg:    73.097 (0.020) <0-00:42:32> ({'r_t':   813.0498, 'eps':     0.0200, 'critic_loss':  1881.0579, 'actor_loss':    -0.3700, 'eps_e':     0.0200})
Step:   64000, Reward:   104.415 [  25.271], Avg:    73.579 (0.020) <0-00:43:09> ({'r_t':   840.7187, 'eps':     0.0200, 'critic_loss':  2693.0461, 'actor_loss':    -0.3525, 'eps_e':     0.0200})
Step:   65000, Reward:    98.058 [  26.576], Avg:    73.950 (0.020) <0-00:43:46> ({'r_t':  1020.7220, 'eps':     0.0200, 'critic_loss':  1106.8230, 'actor_loss':    -0.4177, 'eps_e':     0.0200})
Step:   66000, Reward:   101.860 [  14.517], Avg:    74.366 (0.020) <0-00:44:23> ({'r_t':  1017.6427, 'eps':     0.0200, 'critic_loss':   958.5140, 'actor_loss':    -0.3964, 'eps_e':     0.0200})
Step:   67000, Reward:   107.803 [  15.802], Avg:    74.858 (0.020) <0-00:45:13> ({'r_t':  1059.2659, 'eps':     0.0200, 'critic_loss':   216.7860, 'actor_loss':    -0.3583, 'eps_e':     0.0200})
Step:   68000, Reward:   102.946 [  24.511], Avg:    75.265 (0.020) <0-00:45:51> ({'r_t':  1079.6593, 'eps':     0.0200, 'critic_loss':    14.3214, 'actor_loss':    -0.3655, 'eps_e':     0.0200})
Step:   69000, Reward:   109.970 [  18.420], Avg:    75.761 (0.020) <0-00:46:27> ({'r_t':  1109.4090, 'eps':     0.0200, 'critic_loss':    11.4907, 'actor_loss':    -0.3783, 'eps_e':     0.0200})
Step:   70000, Reward:   108.537 [  24.416], Avg:    76.223 (0.020) <0-00:47:04> ({'r_t':   999.5728, 'eps':     0.0200, 'critic_loss':    10.3776, 'actor_loss':    -0.3396, 'eps_e':     0.0200})
Step:   71000, Reward:   114.082 [  21.618], Avg:    76.748 (0.020) <0-00:47:40> ({'r_t':  1026.4561, 'eps':     0.0200, 'critic_loss':     8.8358, 'actor_loss':    -0.3285, 'eps_e':     0.0200})
Step:   72000, Reward:   114.736 [   3.226], Avg:    77.269 (0.020) <0-00:48:18> ({'r_t':   902.4849, 'eps':     0.0200, 'critic_loss':     7.6435, 'actor_loss':    -0.3112, 'eps_e':     0.0200})
Step:   73000, Reward:   102.613 [  16.520], Avg:    77.611 (0.020) <0-00:49:00> ({'r_t':   970.0958, 'eps':     0.0200, 'critic_loss':     9.2250, 'actor_loss':    -0.2654, 'eps_e':     0.0200})
Step:   74000, Reward:    62.267 [  40.336], Avg:    77.407 (0.020) <0-00:49:41> ({'r_t':   991.6924, 'eps':     0.0200, 'critic_loss':    10.3161, 'actor_loss':    -0.2461, 'eps_e':     0.0200})
Step:   75000, Reward:    38.504 [  97.803], Avg:    76.895 (0.020) <0-00:50:28> ({'r_t':   905.1430, 'eps':     0.0200, 'critic_loss':    11.1079, 'actor_loss':    -0.2298, 'eps_e':     0.0200})
Step:   76000, Reward:    71.861 [  33.141], Avg:    76.829 (0.020) <0-00:51:04> ({'r_t':   933.2908, 'eps':     0.0200, 'critic_loss':    12.7654, 'actor_loss':    -0.2673, 'eps_e':     0.0200})
Step:   77000, Reward:    77.538 [  24.972], Avg:    76.839 (0.020) <0-00:51:41> ({'r_t':   950.2152, 'eps':     0.0200, 'critic_loss':    13.8243, 'actor_loss':    -0.2570, 'eps_e':     0.0200})
Step:   78000, Reward:   103.434 [  20.749], Avg:    77.175 (0.020) <0-00:52:47> ({'r_t':   793.4618, 'eps':     0.0200, 'critic_loss':    13.2923, 'actor_loss':    -0.2581, 'eps_e':     0.0200})
Step:   79000, Reward:    77.391 [  35.893], Avg:    77.178 (0.020) <0-00:53:25> ({'r_t':   797.8830, 'eps':     0.0200, 'critic_loss':    14.1426, 'actor_loss':    -0.2770, 'eps_e':     0.0200})
Step:   80000, Reward:    45.853 [  14.918], Avg:    76.791 (0.020) <0-00:54:07> ({'r_t':   755.5850, 'eps':     0.0200, 'critic_loss':    13.6559, 'actor_loss':    -0.2635, 'eps_e':     0.0200})
Step:   81000, Reward:    89.853 [  35.335], Avg:    76.950 (0.020) <0-00:54:44> ({'r_t':   851.9259, 'eps':     0.0200, 'critic_loss':    13.8808, 'actor_loss':    -0.2505, 'eps_e':     0.0200})
Step:   82000, Reward:   115.851 [  16.174], Avg:    77.419 (0.020) <0-00:55:34> ({'r_t':   835.7293, 'eps':     0.0200, 'critic_loss':    13.6282, 'actor_loss':    -0.3272, 'eps_e':     0.0200})
Step:   83000, Reward:    85.880 [  32.281], Avg:    77.520 (0.020) <0-00:56:13> ({'r_t':   976.4954, 'eps':     0.0200, 'critic_loss':    15.4567, 'actor_loss':    -0.3017, 'eps_e':     0.0200})
Step:   84000, Reward:   105.055 [  33.765], Avg:    77.844 (0.020) <0-00:56:50> ({'r_t':  1038.7270, 'eps':     0.0200, 'critic_loss':    15.1763, 'actor_loss':    -0.3197, 'eps_e':     0.0200})
Step:   85000, Reward:   114.208 [  10.662], Avg:    78.267 (0.020) <0-00:57:26> ({'r_t':  1021.8777, 'eps':     0.0200, 'critic_loss':    13.2282, 'actor_loss':    -0.3422, 'eps_e':     0.0200})
Step:   86000, Reward:   120.847 [   0.842], Avg:    78.756 (0.020) <0-00:58:03> ({'r_t':   845.8523, 'eps':     0.0200, 'critic_loss':    14.4337, 'actor_loss':    -0.3025, 'eps_e':     0.0200})
Step:   87000, Reward:   107.268 [  14.086], Avg:    79.080 (0.020) <0-00:58:39> ({'r_t':  1043.7342, 'eps':     0.0200, 'critic_loss':    10.4874, 'actor_loss':    -0.2885, 'eps_e':     0.0200})
Step:   88000, Reward:   114.596 [  10.044], Avg:    79.479 (0.020) <0-00:59:16> ({'r_t':  1037.9371, 'eps':     0.0200, 'critic_loss':     8.5681, 'actor_loss':    -0.2540, 'eps_e':     0.0200})
Step:   89000, Reward:   104.108 [  23.098], Avg:    79.753 (0.020) <0-00:59:53> ({'r_t':   920.0133, 'eps':     0.0200, 'critic_loss':     6.2989, 'actor_loss':    -0.2525, 'eps_e':     0.0200})
Step:   90000, Reward:   114.265 [   5.155], Avg:    80.132 (0.020) <0-01:00:33> ({'r_t':   776.8382, 'eps':     0.0200, 'critic_loss':     8.1754, 'actor_loss':    -0.2217, 'eps_e':     0.0200})
Step:   91000, Reward:    91.351 [  26.420], Avg:    80.254 (0.020) <0-01:01:09> ({'r_t':   606.9467, 'eps':     0.0200, 'critic_loss':   149.2108, 'actor_loss':    -0.2527, 'eps_e':     0.0200})
Step:   92000, Reward:   103.096 [  27.779], Avg:    80.500 (0.020) <0-01:01:46> ({'r_t':   880.7681, 'eps':     0.0200, 'critic_loss':   828.2126, 'actor_loss':    -0.3539, 'eps_e':     0.0200})
Step:   93000, Reward:   112.551 [  25.363], Avg:    80.841 (0.020) <0-01:02:52> ({'r_t':   822.6746, 'eps':     0.0200, 'critic_loss':   203.8703, 'actor_loss':    -0.3908, 'eps_e':     0.0200})
Step:   94000, Reward:    49.250 [  41.312], Avg:    80.508 (0.020) <0-01:03:41> ({'r_t':   940.7755, 'eps':     0.0200, 'critic_loss':   733.4656, 'actor_loss':    -0.4101, 'eps_e':     0.0200})
Step:   95000, Reward:    84.198 [  30.436], Avg:    80.546 (0.020) <0-01:04:19> ({'r_t':   908.7739, 'eps':     0.0200, 'critic_loss':  1601.4265, 'actor_loss':    -0.4087, 'eps_e':     0.0200})
Step:   96000, Reward:    66.455 [  52.218], Avg:    80.401 (0.020) <0-01:05:25> ({'r_t':   937.8988, 'eps':     0.0200, 'critic_loss':   785.5430, 'actor_loss':    -0.3858, 'eps_e':     0.0200})
Step:   97000, Reward:   118.836 [   1.421], Avg:    80.793 (0.020) <0-01:06:01> ({'r_t':   939.9388, 'eps':     0.0200, 'critic_loss':   713.2023, 'actor_loss':    -0.3547, 'eps_e':     0.0200})
Step:   98000, Reward:   119.778 [   1.552], Avg:    81.187 (0.020) <0-01:06:39> ({'r_t':   965.5909, 'eps':     0.0200, 'critic_loss':   767.1929, 'actor_loss':    -0.3327, 'eps_e':     0.0200})
Step:   99000, Reward:   113.494 [  15.870], Avg:    81.510 (0.020) <0-01:07:15> ({'r_t':   924.7462, 'eps':     0.0200, 'critic_loss':   753.9325, 'actor_loss':    -0.3555, 'eps_e':     0.0200})
Step:  100000, Reward:   109.442 [  19.473], Avg:    81.787 (0.020) <0-01:07:52> ({'r_t':  1075.0132, 'eps':     0.0200, 'critic_loss':   238.1887, 'actor_loss':    -0.3452, 'eps_e':     0.0200})
Step:  101000, Reward:   106.607 [  15.469], Avg:    82.030 (0.020) <0-01:08:28> ({'r_t':  1060.3742, 'eps':     0.0200, 'critic_loss':    10.0635, 'actor_loss':    -0.3368, 'eps_e':     0.0200})
Step:  102000, Reward:   120.307 [   1.212], Avg:    82.402 (0.020) <0-01:09:05> ({'r_t':  1087.3280, 'eps':     0.0200, 'critic_loss':     7.9017, 'actor_loss':    -0.3615, 'eps_e':     0.0200})
Step:  103000, Reward:   115.169 [   2.930], Avg:    82.717 (0.020) <0-01:09:41> ({'r_t':   992.8841, 'eps':     0.0200, 'critic_loss':     9.5813, 'actor_loss':    -0.3210, 'eps_e':     0.0200})
Step:  104000, Reward:   113.186 [   6.536], Avg:    83.007 (0.020) <0-01:10:18> ({'r_t':  1032.2200, 'eps':     0.0200, 'critic_loss':    10.2451, 'actor_loss':    -0.3596, 'eps_e':     0.0200})
Step:  105000, Reward:    98.548 [  27.096], Avg:    83.154 (0.020) <0-01:11:11> ({'r_t':  1083.5869, 'eps':     0.0200, 'critic_loss':     9.2489, 'actor_loss':    -0.3463, 'eps_e':     0.0200})
Step:  106000, Reward:   110.298 [  22.059], Avg:    83.407 (0.020) <0-01:11:47> ({'r_t':  1010.7145, 'eps':     0.0200, 'critic_loss':     8.6438, 'actor_loss':    -0.3179, 'eps_e':     0.0200})
Step:  107000, Reward:   119.525 [   3.180], Avg:    83.742 (0.020) <0-01:12:24> ({'r_t':  1070.0185, 'eps':     0.0200, 'critic_loss':     8.1260, 'actor_loss':    -0.3137, 'eps_e':     0.0200})
Step:  108000, Reward:   101.350 [  14.444], Avg:    83.903 (0.020) <0-01:13:00> ({'r_t':  1090.9354, 'eps':     0.0200, 'critic_loss':     9.3732, 'actor_loss':    -0.3207, 'eps_e':     0.0200})
Step:  109000, Reward:   101.575 [  30.682], Avg:    84.064 (0.020) <0-01:13:36> ({'r_t':  1039.2437, 'eps':     0.0200, 'critic_loss':     7.9008, 'actor_loss':    -0.3182, 'eps_e':     0.0200})
Step:  110000, Reward:   100.385 [  32.172], Avg:    84.211 (0.020) <0-01:14:14> ({'r_t':  1063.0797, 'eps':     0.0200, 'critic_loss':     5.5162, 'actor_loss':    -0.3139, 'eps_e':     0.0200})
Step:  111000, Reward:   120.024 [   6.011], Avg:    84.531 (0.020) <0-01:14:50> ({'r_t':   969.9525, 'eps':     0.0200, 'critic_loss':     5.2914, 'actor_loss':    -0.3092, 'eps_e':     0.0200})
Step:  112000, Reward:   120.765 [   0.811], Avg:    84.851 (0.020) <0-01:15:27> ({'r_t':  1021.9566, 'eps':     0.0200, 'critic_loss':     7.1099, 'actor_loss':    -0.2882, 'eps_e':     0.0200})
Step:  113000, Reward:   119.510 [   1.151], Avg:    85.155 (0.020) <0-01:16:03> ({'r_t':  1046.4484, 'eps':     0.0200, 'critic_loss':     8.8238, 'actor_loss':    -0.2916, 'eps_e':     0.0200})
Step:  114000, Reward:   115.154 [   6.003], Avg:    85.416 (0.020) <0-01:16:41> ({'r_t':  1035.8614, 'eps':     0.0200, 'critic_loss':     9.6361, 'actor_loss':    -0.2972, 'eps_e':     0.0200})
Step:  115000, Reward:    96.612 [  75.797], Avg:    85.513 (0.020) <0-01:17:47> ({'r_t':  1033.6702, 'eps':     0.0200, 'critic_loss':     8.1100, 'actor_loss':    -0.2991, 'eps_e':     0.0200})
Step:  116000, Reward:    95.343 [  10.683], Avg:    85.597 (0.020) <0-01:18:24> ({'r_t':   985.0331, 'eps':     0.0200, 'critic_loss':     9.9980, 'actor_loss':    -0.3026, 'eps_e':     0.0200})
Step:  117000, Reward:    66.197 [  44.136], Avg:    85.432 (0.020) <0-01:19:05> ({'r_t':   929.2400, 'eps':     0.0200, 'critic_loss':    10.5735, 'actor_loss':    -0.3320, 'eps_e':     0.0200})
Step:  118000, Reward:   105.911 [  31.370], Avg:    85.604 (0.020) <0-01:20:11> ({'r_t':   578.8738, 'eps':     0.0200, 'critic_loss':     9.0232, 'actor_loss':    -0.3160, 'eps_e':     0.0200})
Step:  119000, Reward:   118.124 [   1.182], Avg:    85.875 (0.020) <0-01:20:48> ({'r_t':   773.9097, 'eps':     0.0200, 'critic_loss':     8.6765, 'actor_loss':    -0.3586, 'eps_e':     0.0200})
Step:  120000, Reward:   119.382 [   2.291], Avg:    86.152 (0.020) <0-01:21:24> ({'r_t':   987.0163, 'eps':     0.0200, 'critic_loss':     8.4739, 'actor_loss':    -0.4215, 'eps_e':     0.0200})
Step:  121000, Reward:   115.943 [   4.679], Avg:    86.397 (0.020) <0-01:22:02> ({'r_t':  1103.3193, 'eps':     0.0200, 'critic_loss':     7.9383, 'actor_loss':    -0.4356, 'eps_e':     0.0200})
Step:  122000, Reward:   119.959 [   2.230], Avg:    86.669 (0.020) <0-01:22:40> ({'r_t':  1088.2620, 'eps':     0.0200, 'critic_loss':     7.3416, 'actor_loss':    -0.4501, 'eps_e':     0.0200})
Step:  123000, Reward:   112.901 [   4.294], Avg:    86.881 (0.020) <0-01:23:16> ({'r_t':  1111.0032, 'eps':     0.0200, 'critic_loss':     6.2271, 'actor_loss':    -0.4828, 'eps_e':     0.0200})
Step:  124000, Reward:    67.246 [  18.525], Avg:    86.724 (0.020) <0-01:23:53> ({'r_t':  1121.1570, 'eps':     0.0200, 'critic_loss':     5.9482, 'actor_loss':    -0.5176, 'eps_e':     0.0200})
Step:  125000, Reward:   110.539 [  24.933], Avg:    86.913 (0.020) <0-01:24:31> ({'r_t':  1044.5952, 'eps':     0.0200, 'critic_loss':     5.9453, 'actor_loss':    -0.3759, 'eps_e':     0.0200})
Step:  126000, Reward:   121.201 [   1.213], Avg:    87.183 (0.020) <0-01:25:07> ({'r_t':  1111.1068, 'eps':     0.0200, 'critic_loss':     5.3831, 'actor_loss':    -0.3297, 'eps_e':     0.0200})
Step:  127000, Reward:   118.297 [   5.221], Avg:    87.426 (0.020) <0-01:25:44> ({'r_t':  1064.4582, 'eps':     0.0200, 'critic_loss':     4.9930, 'actor_loss':    -0.3265, 'eps_e':     0.0200})
Step:  128000, Reward:   115.170 [  16.138], Avg:    87.641 (0.020) <0-01:26:22> ({'r_t':  1064.6347, 'eps':     0.0200, 'critic_loss':     5.1794, 'actor_loss':    -0.2980, 'eps_e':     0.0200})
Step:  129000, Reward:   117.401 [   5.357], Avg:    87.870 (0.020) <0-01:27:00> ({'r_t':  1096.4429, 'eps':     0.0200, 'critic_loss':     5.6661, 'actor_loss':    -0.3104, 'eps_e':     0.0200})
Step:  130000, Reward:   118.408 [   5.878], Avg:    88.103 (0.020) <0-01:27:36> ({'r_t':  1061.5410, 'eps':     0.0200, 'critic_loss':     4.8724, 'actor_loss':    -0.3059, 'eps_e':     0.0200})
Step:  131000, Reward:    79.197 [  19.110], Avg:    88.036 (0.020) <0-01:28:12> ({'r_t':  1144.5474, 'eps':     0.0200, 'critic_loss':     3.8017, 'actor_loss':    -0.3035, 'eps_e':     0.0200})
Step:  132000, Reward:   119.879 [   2.274], Avg:    88.275 (0.020) <0-01:28:49> ({'r_t':  1102.1235, 'eps':     0.0200, 'critic_loss':     4.1028, 'actor_loss':    -0.2824, 'eps_e':     0.0200})
Step:  133000, Reward:   118.766 [   6.497], Avg:    88.503 (0.020) <0-01:29:25> ({'r_t':  1087.5025, 'eps':     0.0200, 'critic_loss':     5.1477, 'actor_loss':    -0.2950, 'eps_e':     0.0200})
Step:  134000, Reward:   108.248 [  22.902], Avg:    88.649 (0.020) <0-01:30:03> ({'r_t':  1094.2295, 'eps':     0.0200, 'critic_loss':     5.4687, 'actor_loss':    -0.2573, 'eps_e':     0.0200})
Step:  135000, Reward:   111.217 [  17.724], Avg:    88.815 (0.020) <0-01:30:40> ({'r_t':  1015.9538, 'eps':     0.0200, 'critic_loss':     6.6887, 'actor_loss':    -0.2658, 'eps_e':     0.0200})
Step:  136000, Reward:   109.100 [  21.470], Avg:    88.963 (0.020) <0-01:31:16> ({'r_t':   859.3709, 'eps':     0.0200, 'critic_loss':   205.8862, 'actor_loss':    -0.2782, 'eps_e':     0.0200})
Step:  137000, Reward:   121.605 [   1.260], Avg:    89.199 (0.020) <0-01:31:52> ({'r_t':  1081.1609, 'eps':     0.0200, 'critic_loss':   139.1343, 'actor_loss':    -0.2816, 'eps_e':     0.0200})
Step:  138000, Reward:   101.138 [  20.722], Avg:    89.285 (0.020) <0-01:32:42> ({'r_t':  1026.3375, 'eps':     0.0200, 'critic_loss':   240.6811, 'actor_loss':    -0.2800, 'eps_e':     0.0200})
Step:  139000, Reward:   120.176 [   5.553], Avg:    89.506 (0.020) <0-01:33:19> ({'r_t':  1128.1269, 'eps':     0.0200, 'critic_loss':   187.0637, 'actor_loss':    -0.2871, 'eps_e':     0.0200})
Step:  140000, Reward:   117.784 [   4.332], Avg:    89.706 (0.020) <0-01:33:55> ({'r_t':  1112.3570, 'eps':     0.0200, 'critic_loss':   119.3516, 'actor_loss':    -0.3110, 'eps_e':     0.0200})
Step:  141000, Reward:   119.959 [   1.034], Avg:    89.920 (0.020) <0-01:34:31> ({'r_t':  1115.2248, 'eps':     0.0200, 'critic_loss':   221.9509, 'actor_loss':    -0.2992, 'eps_e':     0.0200})
Step:  142000, Reward:   121.113 [   1.289], Avg:    90.138 (0.020) <0-01:35:08> ({'r_t':  1051.9239, 'eps':     0.0200, 'critic_loss':   237.0590, 'actor_loss':    -0.3149, 'eps_e':     0.0200})
Step:  143000, Reward:   120.499 [   1.687], Avg:    90.349 (0.020) <0-01:35:44> ({'r_t':  1119.0667, 'eps':     0.0200, 'critic_loss':     4.6744, 'actor_loss':    -0.3198, 'eps_e':     0.0200})
Step:  144000, Reward:   121.428 [   0.926], Avg:    90.563 (0.020) <0-01:36:20> ({'r_t':  1126.0287, 'eps':     0.0200, 'critic_loss':     3.9332, 'actor_loss':    -0.3014, 'eps_e':     0.0200})
Step:  145000, Reward:   119.046 [   8.414], Avg:    90.758 (0.020) <0-01:36:57> ({'r_t':  1125.9228, 'eps':     0.0200, 'critic_loss':     3.3575, 'actor_loss':    -0.2580, 'eps_e':     0.0200})
Step:  146000, Reward:   116.034 [   6.593], Avg:    90.930 (0.020) <0-01:37:33> ({'r_t':  1108.6727, 'eps':     0.0200, 'critic_loss':     4.2503, 'actor_loss':    -0.2337, 'eps_e':     0.0200})
Step:  147000, Reward:   119.268 [   2.556], Avg:    91.121 (0.020) <0-01:38:09> ({'r_t':  1137.9928, 'eps':     0.0200, 'critic_loss':     3.6107, 'actor_loss':    -0.2455, 'eps_e':     0.0200})
Step:  148000, Reward:   120.641 [   3.919], Avg:    91.319 (0.020) <0-01:38:48> ({'r_t':  1114.5783, 'eps':     0.0200, 'critic_loss':     3.4062, 'actor_loss':    -0.2411, 'eps_e':     0.0200})
Step:  149000, Reward:   121.913 [   1.206], Avg:    91.523 (0.020) <0-01:39:24> ({'r_t':  1173.3430, 'eps':     0.0200, 'critic_loss':     2.6659, 'actor_loss':    -0.2476, 'eps_e':     0.0200})
Step:  150000, Reward:   119.505 [   5.119], Avg:    91.709 (0.020) <0-01:40:00> ({'r_t':  1101.2676, 'eps':     0.0200, 'critic_loss':     2.7237, 'actor_loss':    -0.2371, 'eps_e':     0.0200})
Step:  151000, Reward:   122.126 [   0.932], Avg:    91.909 (0.020) <0-01:40:36> ({'r_t':  1108.8498, 'eps':     0.0200, 'critic_loss':     3.1530, 'actor_loss':    -0.2428, 'eps_e':     0.0200})
Step:  152000, Reward:   121.783 [   1.134], Avg:    92.104 (0.020) <0-01:41:13> ({'r_t':  1059.7901, 'eps':     0.0200, 'critic_loss':     3.9012, 'actor_loss':    -0.2486, 'eps_e':     0.0200})
Step:  153000, Reward:   119.395 [   1.103], Avg:    92.281 (0.020) <0-01:41:49> ({'r_t':  1066.2028, 'eps':     0.0200, 'critic_loss':     4.3341, 'actor_loss':    -0.2591, 'eps_e':     0.0200})
Step:  154000, Reward:   121.197 [   1.506], Avg:    92.468 (0.020) <0-01:42:25> ({'r_t':  1111.3711, 'eps':     0.0200, 'critic_loss':     4.2902, 'actor_loss':    -0.2512, 'eps_e':     0.0200})
Step:  155000, Reward:   123.745 [   5.383], Avg:    92.668 (0.020) <0-01:43:02> ({'r_t':   949.6561, 'eps':     0.0200, 'critic_loss':     6.3044, 'actor_loss':    -0.2684, 'eps_e':     0.0200})
Step:  156000, Reward:   117.656 [   2.328], Avg:    92.828 (0.020) <0-01:43:38> ({'r_t':  1015.6774, 'eps':     0.0200, 'critic_loss':     9.7738, 'actor_loss':    -0.2622, 'eps_e':     0.0200})
Step:  157000, Reward:   120.817 [   3.994], Avg:    93.005 (0.020) <0-01:44:15> ({'r_t':  1108.1515, 'eps':     0.0200, 'critic_loss':     8.3130, 'actor_loss':    -0.2883, 'eps_e':     0.0200})
Step:  158000, Reward:   119.442 [   4.721], Avg:    93.171 (0.020) <0-01:44:51> ({'r_t':  1089.6367, 'eps':     0.0200, 'critic_loss':     8.5977, 'actor_loss':    -0.3033, 'eps_e':     0.0200})
Step:  159000, Reward:   118.747 [   5.043], Avg:    93.331 (0.020) <0-01:45:28> ({'r_t':  1154.9093, 'eps':     0.0200, 'critic_loss':     7.8394, 'actor_loss':    -0.2817, 'eps_e':     0.0200})
Step:  160000, Reward:   118.823 [   4.577], Avg:    93.489 (0.020) <0-01:46:05> ({'r_t':  1125.7204, 'eps':     0.0200, 'critic_loss':     6.5717, 'actor_loss':    -0.2367, 'eps_e':     0.0200})
Step:  161000, Reward:   119.732 [  10.779], Avg:    93.651 (0.020) <0-01:46:43> ({'r_t':  1155.1512, 'eps':     0.0200, 'critic_loss':     6.5908, 'actor_loss':    -0.2383, 'eps_e':     0.0200})
Step:  162000, Reward:   115.687 [  13.602], Avg:    93.786 (0.020) <0-01:47:34> ({'r_t':  1132.4263, 'eps':     0.0200, 'critic_loss':     3.3907, 'actor_loss':    -0.2410, 'eps_e':     0.0200})
Step:  163000, Reward:   123.245 [   1.531], Avg:    93.966 (0.020) <0-01:48:12> ({'r_t':  1150.2402, 'eps':     0.0200, 'critic_loss':     2.4665, 'actor_loss':    -0.2375, 'eps_e':     0.0200})
Step:  164000, Reward:   122.691 [   2.484], Avg:    94.140 (0.020) <0-01:48:48> ({'r_t':  1150.4267, 'eps':     0.0200, 'critic_loss':     2.1082, 'actor_loss':    -0.2304, 'eps_e':     0.0200})
Step:  165000, Reward:   120.282 [   2.301], Avg:    94.298 (0.020) <0-01:49:24> ({'r_t':  1113.0841, 'eps':     0.0200, 'critic_loss':     1.6692, 'actor_loss':    -0.2185, 'eps_e':     0.0200})
Step:  166000, Reward:   119.607 [   1.642], Avg:    94.449 (0.020) <0-01:50:01> ({'r_t':  1142.6591, 'eps':     0.0200, 'critic_loss':     1.3762, 'actor_loss':    -0.2324, 'eps_e':     0.0200})
Step:  167000, Reward:   120.158 [   1.902], Avg:    94.602 (0.020) <0-01:50:37> ({'r_t':  1127.9182, 'eps':     0.0200, 'critic_loss':     1.5835, 'actor_loss':    -0.2099, 'eps_e':     0.0200})
Step:  168000, Reward:   119.188 [   1.242], Avg:    94.748 (0.020) <0-01:51:13> ({'r_t':   830.4344, 'eps':     0.0200, 'critic_loss':    20.0033, 'actor_loss':    -0.1951, 'eps_e':     0.0200})
Step:  169000, Reward:   122.885 [   1.233], Avg:    94.913 (0.020) <0-01:51:50> ({'r_t':  1074.3886, 'eps':     0.0200, 'critic_loss':    97.0891, 'actor_loss':    -0.2360, 'eps_e':     0.0200})
Step:  170000, Reward:    85.042 [  18.827], Avg:    94.855 (0.020) <0-01:52:26> ({'r_t':  1124.7340, 'eps':     0.0200, 'critic_loss':   187.4009, 'actor_loss':    -0.2524, 'eps_e':     0.0200})
Step:  171000, Reward:   116.750 [  21.100], Avg:    94.983 (0.020) <0-01:53:02> ({'r_t':  1152.7274, 'eps':     0.0200, 'critic_loss':    83.2338, 'actor_loss':    -0.2443, 'eps_e':     0.0200})
Step:  172000, Reward:   122.093 [   1.070], Avg:    95.139 (0.020) <0-01:53:39> ({'r_t':  1116.4334, 'eps':     0.0200, 'critic_loss':   189.0030, 'actor_loss':    -0.2340, 'eps_e':     0.0200})
Step:  173000, Reward:   114.289 [  12.002], Avg:    95.249 (0.020) <0-01:54:16> ({'r_t':  1104.6559, 'eps':     0.0200, 'critic_loss':   106.4306, 'actor_loss':    -0.2340, 'eps_e':     0.0200})
Step:  174000, Reward:   119.597 [   2.031], Avg:    95.389 (0.020) <0-01:54:53> ({'r_t':  1129.6006, 'eps':     0.0200, 'critic_loss':   102.6077, 'actor_loss':    -0.2279, 'eps_e':     0.0200})
Step:  175000, Reward:   121.334 [   0.993], Avg:    95.536 (0.020) <0-01:55:29> ({'r_t':  1109.7916, 'eps':     0.0200, 'critic_loss':    24.5805, 'actor_loss':    -0.2239, 'eps_e':     0.0200})
Step:  176000, Reward:   122.081 [   0.714], Avg:    95.686 (0.020) <0-01:56:05> ({'r_t':  1084.1341, 'eps':     0.0200, 'critic_loss':     2.1536, 'actor_loss':    -0.2265, 'eps_e':     0.0200})
Step:  177000, Reward:   122.429 [   1.018], Avg:    95.836 (0.020) <0-01:56:42> ({'r_t':  1150.6038, 'eps':     0.0200, 'critic_loss':     2.4249, 'actor_loss':    -0.2058, 'eps_e':     0.0200})
Step:  178000, Reward:   116.325 [   2.777], Avg:    95.951 (0.020) <0-01:57:19> ({'r_t':  1115.9954, 'eps':     0.0200, 'critic_loss':     2.2411, 'actor_loss':    -0.1979, 'eps_e':     0.0200})
Step:  179000, Reward:   118.594 [   2.122], Avg:    96.076 (0.020) <0-01:57:55> ({'r_t':  1137.7266, 'eps':     0.0200, 'critic_loss':     2.2215, 'actor_loss':    -0.2095, 'eps_e':     0.0200})
Step:  180000, Reward:   118.441 [   5.462], Avg:    96.200 (0.020) <0-01:58:33> ({'r_t':  1128.4418, 'eps':     0.0200, 'critic_loss':     2.1000, 'actor_loss':    -0.1989, 'eps_e':     0.0200})
Step:  181000, Reward:   118.274 [  15.472], Avg:    96.321 (0.020) <0-01:59:09> ({'r_t':  1175.0140, 'eps':     0.0200, 'critic_loss':     1.3359, 'actor_loss':    -0.2073, 'eps_e':     0.0200})
Step:  182000, Reward:   117.394 [  20.285], Avg:    96.436 (0.020) <0-01:59:45> ({'r_t':  1105.2289, 'eps':     0.0200, 'critic_loss':     1.6573, 'actor_loss':    -0.1940, 'eps_e':     0.0200})
Step:  183000, Reward:   122.049 [   2.249], Avg:    96.576 (0.020) <0-02:00:22> ({'r_t':  1121.0994, 'eps':     0.0200, 'critic_loss':     1.8464, 'actor_loss':    -0.2042, 'eps_e':     0.0200})
Step:  184000, Reward:   122.330 [   1.294], Avg:    96.715 (0.020) <0-02:00:58> ({'r_t':  1124.3663, 'eps':     0.0200, 'critic_loss':     2.2879, 'actor_loss':    -0.1956, 'eps_e':     0.0200})
Step:  185000, Reward:   116.233 [   5.809], Avg:    96.820 (0.020) <0-02:01:35> ({'r_t':  1054.6107, 'eps':     0.0200, 'critic_loss':     2.3774, 'actor_loss':    -0.1945, 'eps_e':     0.0200})
Step:  186000, Reward:   119.045 [   4.129], Avg:    96.939 (0.020) <0-02:02:11> ({'r_t':  1133.2830, 'eps':     0.0200, 'critic_loss':     2.7012, 'actor_loss':    -0.2069, 'eps_e':     0.0200})
Step:  187000, Reward:   120.927 [   0.897], Avg:    97.066 (0.020) <0-02:02:47> ({'r_t':  1135.9999, 'eps':     0.0200, 'critic_loss':     2.9908, 'actor_loss':    -0.2196, 'eps_e':     0.0200})
Step:  188000, Reward:   121.300 [   4.490], Avg:    97.194 (0.020) <0-02:03:25> ({'r_t':  1105.8416, 'eps':     0.0200, 'critic_loss':     2.7386, 'actor_loss':    -0.2280, 'eps_e':     0.0200})
Step:  189000, Reward:   119.728 [   4.644], Avg:    97.313 (0.020) <0-02:04:01> ({'r_t':  1139.6391, 'eps':     0.0200, 'critic_loss':     2.2710, 'actor_loss':    -0.2281, 'eps_e':     0.0200})
Step:  190000, Reward:   121.206 [   4.534], Avg:    97.438 (0.020) <0-02:04:38> ({'r_t':  1144.3469, 'eps':     0.0200, 'critic_loss':     1.8570, 'actor_loss':    -0.2172, 'eps_e':     0.0200})
Step:  191000, Reward:   119.859 [   3.057], Avg:    97.555 (0.020) <0-02:05:14> ({'r_t':  1155.8277, 'eps':     0.0200, 'critic_loss':     1.5871, 'actor_loss':    -0.2174, 'eps_e':     0.0200})
Step:  192000, Reward:   120.243 [   1.166], Avg:    97.672 (0.020) <0-02:05:50> ({'r_t':  1163.8400, 'eps':     0.0200, 'critic_loss':     1.0168, 'actor_loss':    -0.2057, 'eps_e':     0.0200})
Step:  193000, Reward:   120.982 [   2.875], Avg:    97.793 (0.020) <0-02:06:27> ({'r_t':  1169.6514, 'eps':     0.0200, 'critic_loss':     0.6781, 'actor_loss':    -0.1941, 'eps_e':     0.0200})
Step:  194000, Reward:   121.975 [   1.238], Avg:    97.917 (0.020) <0-02:07:03> ({'r_t':  1171.8794, 'eps':     0.0200, 'critic_loss':     0.5032, 'actor_loss':    -0.1904, 'eps_e':     0.0200})
Step:  195000, Reward:   122.880 [   0.627], Avg:    98.044 (0.020) <0-02:07:39> ({'r_t':  1194.3180, 'eps':     0.0200, 'critic_loss':     0.3975, 'actor_loss':    -0.1763, 'eps_e':     0.0200})
Step:  196000, Reward:   122.516 [   1.310], Avg:    98.168 (0.020) <0-02:08:15> ({'r_t':  1186.6470, 'eps':     0.0200, 'critic_loss':     0.2799, 'actor_loss':    -0.1706, 'eps_e':     0.0200})
Step:  197000, Reward:   124.115 [   0.693], Avg:    98.299 (0.020) <0-02:08:52> ({'r_t':  1145.0726, 'eps':     0.0200, 'critic_loss':     0.2046, 'actor_loss':    -0.1582, 'eps_e':     0.0200})
Step:  198000, Reward:    97.288 [  31.880], Avg:    98.294 (0.020) <0-02:09:29> ({'r_t':  1102.3363, 'eps':     0.0200, 'critic_loss':     0.2374, 'actor_loss':    -0.1522, 'eps_e':     0.0200})
Step:  199000, Reward:    92.424 [  38.722], Avg:    98.265 (0.020) <0-02:10:05> ({'r_t':  1081.6501, 'eps':     0.0200, 'critic_loss':     0.7191, 'actor_loss':    -0.1535, 'eps_e':     0.0200})
Step:  200000, Reward:   110.786 [  25.291], Avg:    98.327 (0.020) <0-02:10:42> ({'r_t':   953.8999, 'eps':     0.0200, 'critic_loss':     3.9917, 'actor_loss':    -0.1733, 'eps_e':     0.0200})
Step:  201000, Reward:   118.023 [   4.529], Avg:    98.425 (0.020) <0-02:11:18> ({'r_t':   994.4940, 'eps':     0.0200, 'critic_loss':     8.2201, 'actor_loss':    -0.2474, 'eps_e':     0.0200})
Step:  202000, Reward:   114.004 [   8.496], Avg:    98.501 (0.020) <0-02:11:54> ({'r_t':  1137.0488, 'eps':     0.0200, 'critic_loss':     9.1251, 'actor_loss':    -0.3212, 'eps_e':     0.0200})
Step:  203000, Reward:   120.200 [   7.143], Avg:    98.608 (0.020) <0-02:12:31> ({'r_t':  1115.8175, 'eps':     0.0200, 'critic_loss':     9.6205, 'actor_loss':    -0.3379, 'eps_e':     0.0200})
Step:  204000, Reward:   110.712 [   8.009], Avg:    98.667 (0.020) <0-02:13:07> ({'r_t':  1140.0692, 'eps':     0.0200, 'critic_loss':     9.9218, 'actor_loss':    -0.4177, 'eps_e':     0.0200})
Step:  205000, Reward:   123.290 [   1.540], Avg:    98.786 (0.020) <0-02:13:44> ({'r_t':  1105.5980, 'eps':     0.0200, 'critic_loss':     9.3425, 'actor_loss':    -0.3809, 'eps_e':     0.0200})
Step:  206000, Reward:   121.270 [   3.434], Avg:    98.895 (0.020) <0-02:14:20> ({'r_t':  1157.8521, 'eps':     0.0200, 'critic_loss':     7.7629, 'actor_loss':    -0.3550, 'eps_e':     0.0200})
Step:  207000, Reward:   118.682 [   3.103], Avg:    98.990 (0.020) <0-02:14:56> ({'r_t':  1138.8681, 'eps':     0.0200, 'critic_loss':     4.4276, 'actor_loss':    -0.2743, 'eps_e':     0.0200})
Step:  208000, Reward:   120.947 [   5.993], Avg:    99.095 (0.020) <0-02:15:33> ({'r_t':  1146.6939, 'eps':     0.0200, 'critic_loss':     2.0139, 'actor_loss':    -0.2155, 'eps_e':     0.0200})
Step:  209000, Reward:   120.785 [   6.168], Avg:    99.198 (0.020) <0-02:16:10> ({'r_t':  1169.8838, 'eps':     0.0200, 'critic_loss':     1.2678, 'actor_loss':    -0.2187, 'eps_e':     0.0200})
Step:  210000, Reward:   119.593 [   7.030], Avg:    99.295 (0.020) <0-02:16:47> ({'r_t':  1190.5503, 'eps':     0.0200, 'critic_loss':     0.8532, 'actor_loss':    -0.2083, 'eps_e':     0.0200})
Step:  211000, Reward:   113.692 [  19.198], Avg:    99.363 (0.020) <0-02:17:25> ({'r_t':  1113.0271, 'eps':     0.0200, 'critic_loss':     0.7282, 'actor_loss':    -0.1886, 'eps_e':     0.0200})
Step:  212000, Reward:   111.353 [  33.946], Avg:    99.419 (0.020) <0-02:18:02> ({'r_t':  1110.5979, 'eps':     0.0200, 'critic_loss':     0.7658, 'actor_loss':    -0.1818, 'eps_e':     0.0200})
Step:  213000, Reward:   121.422 [   1.917], Avg:    99.522 (0.020) <0-02:18:41> ({'r_t':  1159.9466, 'eps':     0.0200, 'critic_loss':     0.6983, 'actor_loss':    -0.1662, 'eps_e':     0.0200})
Step:  214000, Reward:   122.298 [   1.263], Avg:    99.628 (0.020) <0-02:19:17> ({'r_t':  1101.5299, 'eps':     0.0200, 'critic_loss':     0.7442, 'actor_loss':    -0.1545, 'eps_e':     0.0200})
Step:  215000, Reward:   122.446 [   1.667], Avg:    99.734 (0.020) <0-02:19:53> ({'r_t':  1159.7409, 'eps':     0.0200, 'critic_loss':     0.9870, 'actor_loss':    -0.1593, 'eps_e':     0.0200})
Step:  216000, Reward:   114.092 [   4.299], Avg:    99.800 (0.020) <0-02:20:31> ({'r_t':  1119.0430, 'eps':     0.0200, 'critic_loss':     1.5974, 'actor_loss':    -0.1535, 'eps_e':     0.0200})
Step:  217000, Reward:   113.774 [   6.765], Avg:    99.864 (0.020) <0-02:21:07> ({'r_t':  1083.1547, 'eps':     0.0200, 'critic_loss':     2.5910, 'actor_loss':    -0.1619, 'eps_e':     0.0200})
Step:  218000, Reward:   121.264 [   1.280], Avg:    99.962 (0.020) <0-02:21:44> ({'r_t':  1073.8497, 'eps':     0.0200, 'critic_loss':     2.8289, 'actor_loss':    -0.1632, 'eps_e':     0.0200})
Step:  219000, Reward:   121.081 [   2.497], Avg:   100.058 (0.020) <0-02:22:20> ({'r_t':  1094.4510, 'eps':     0.0200, 'critic_loss':     2.4854, 'actor_loss':    -0.1814, 'eps_e':     0.0200})
Step:  220000, Reward:   118.656 [   7.193], Avg:   100.142 (0.020) <0-02:22:58> ({'r_t':  1052.2118, 'eps':     0.0200, 'critic_loss':     3.4495, 'actor_loss':    -0.1828, 'eps_e':     0.0200})
Step:  221000, Reward:   106.439 [  22.969], Avg:   100.170 (0.020) <0-02:23:36> ({'r_t':  1077.4714, 'eps':     0.0200, 'critic_loss':     3.3828, 'actor_loss':    -0.1810, 'eps_e':     0.0200})
Step:  222000, Reward:   119.283 [   6.218], Avg:   100.256 (0.020) <0-02:24:14> ({'r_t':  1121.0559, 'eps':     0.0200, 'critic_loss':     3.1595, 'actor_loss':    -0.1967, 'eps_e':     0.0200})
Step:  223000, Reward:   -64.228 [  69.964], Avg:    99.522 (0.020) <0-02:25:20> ({'r_t':  1098.3393, 'eps':     0.0200, 'critic_loss':     2.3685, 'actor_loss':    -0.2074, 'eps_e':     0.0200})
Step:  224000, Reward:   115.167 [   4.626], Avg:    99.591 (0.020) <0-02:25:59> ({'r_t':   180.6207, 'eps':     0.0200, 'critic_loss':     2.5112, 'actor_loss':    -0.3059, 'eps_e':     0.0200})
Step:  225000, Reward:   114.511 [   7.650], Avg:    99.657 (0.020) <0-02:26:38> ({'r_t':   505.5122, 'eps':     0.0200, 'critic_loss':     3.1387, 'actor_loss':    -0.2617, 'eps_e':     0.0200})
Step:  226000, Reward:   121.116 [   0.579], Avg:    99.752 (0.020) <0-02:27:14> ({'r_t':   919.4176, 'eps':     0.0200, 'critic_loss':     4.0806, 'actor_loss':    -0.2506, 'eps_e':     0.0200})
Step:  227000, Reward:   122.138 [   1.046], Avg:    99.850 (0.020) <0-02:27:50> ({'r_t':  1150.6305, 'eps':     0.0200, 'critic_loss':     3.6827, 'actor_loss':    -0.2886, 'eps_e':     0.0200})
Step:  228000, Reward:   121.363 [   0.868], Avg:    99.944 (0.020) <0-02:28:26> ({'r_t':  1126.4723, 'eps':     0.0200, 'critic_loss':     4.1481, 'actor_loss':    -0.2887, 'eps_e':     0.0200})
Step:  229000, Reward:   120.899 [   3.261], Avg:   100.035 (0.020) <0-02:29:03> ({'r_t':   897.9764, 'eps':     0.0200, 'critic_loss':     5.7137, 'actor_loss':    -0.3295, 'eps_e':     0.0200})
Step:  230000, Reward:   119.119 [   2.760], Avg:   100.118 (0.020) <0-02:29:39> ({'r_t':  1091.8266, 'eps':     0.0200, 'critic_loss':     6.9354, 'actor_loss':    -0.3286, 'eps_e':     0.0200})
Step:  231000, Reward:   106.538 [  27.179], Avg:   100.145 (0.020) <0-02:30:17> ({'r_t':  1115.9504, 'eps':     0.0200, 'critic_loss':     6.9030, 'actor_loss':    -0.2874, 'eps_e':     0.0200})
Step:  232000, Reward:   121.812 [   1.392], Avg:   100.238 (0.020) <0-02:30:53> ({'r_t':  1067.0496, 'eps':     0.0200, 'critic_loss':     6.8000, 'actor_loss':    -0.2381, 'eps_e':     0.0200})
Step:  233000, Reward:   120.987 [   1.271], Avg:   100.327 (0.020) <0-02:31:29> ({'r_t':  1153.9343, 'eps':     0.0200, 'critic_loss':     6.1052, 'actor_loss':    -0.2411, 'eps_e':     0.0200})
Step:  234000, Reward:   121.024 [   1.698], Avg:   100.415 (0.020) <0-02:32:06> ({'r_t':   973.0168, 'eps':     0.0200, 'critic_loss':     6.5167, 'actor_loss':    -0.2506, 'eps_e':     0.0200})
Step:  235000, Reward:   122.126 [   0.933], Avg:   100.507 (0.020) <0-02:32:42> ({'r_t':  1081.2425, 'eps':     0.0200, 'critic_loss':     6.0067, 'actor_loss':    -0.2290, 'eps_e':     0.0200})
Step:  236000, Reward:   118.388 [   3.174], Avg:   100.582 (0.020) <0-02:33:21> ({'r_t':  1162.5178, 'eps':     0.0200, 'critic_loss':     4.5960, 'actor_loss':    -0.2161, 'eps_e':     0.0200})
Step:  237000, Reward:   122.093 [   0.562], Avg:   100.673 (0.020) <0-02:33:57> ({'r_t':  1157.9308, 'eps':     0.0200, 'critic_loss':     3.9760, 'actor_loss':    -0.2533, 'eps_e':     0.0200})
Step:  238000, Reward:   121.060 [   1.138], Avg:   100.758 (0.020) <0-02:34:33> ({'r_t':  1141.6232, 'eps':     0.0200, 'critic_loss':     3.1731, 'actor_loss':    -0.2468, 'eps_e':     0.0200})
Step:  239000, Reward:   121.574 [   0.666], Avg:   100.845 (0.020) <0-02:35:09> ({'r_t':  1174.1701, 'eps':     0.0200, 'critic_loss':     2.7519, 'actor_loss':    -0.2513, 'eps_e':     0.0200})
Step:  240000, Reward:   121.901 [   1.412], Avg:   100.932 (0.020) <0-02:35:45> ({'r_t':  1195.7016, 'eps':     0.0200, 'critic_loss':     2.9677, 'actor_loss':    -0.2359, 'eps_e':     0.0200})
Step:  241000, Reward:   121.247 [   1.580], Avg:   101.016 (0.020) <0-02:36:22> ({'r_t':  1196.0926, 'eps':     0.0200, 'critic_loss':     1.3442, 'actor_loss':    -0.2004, 'eps_e':     0.0200})
Step:  242000, Reward:   120.393 [   1.386], Avg:   101.096 (0.020) <0-02:36:58> ({'r_t':  1178.2822, 'eps':     0.0200, 'critic_loss':     1.4883, 'actor_loss':    -0.1743, 'eps_e':     0.0200})
Step:  243000, Reward:   108.248 [   3.591], Avg:   101.125 (0.020) <0-02:37:36> ({'r_t':  1162.6587, 'eps':     0.0200, 'critic_loss':     1.5060, 'actor_loss':    -0.1716, 'eps_e':     0.0200})
Step:  244000, Reward:   115.361 [  10.923], Avg:   101.183 (0.020) <0-02:38:12> ({'r_t':  1021.4328, 'eps':     0.0200, 'critic_loss':     4.8969, 'actor_loss':    -0.1894, 'eps_e':     0.0200})
Step:  245000, Reward:   117.867 [   3.140], Avg:   101.251 (0.020) <0-02:38:48> ({'r_t':  1099.6395, 'eps':     0.0200, 'critic_loss':     5.0780, 'actor_loss':    -0.1979, 'eps_e':     0.0200})
Step:  246000, Reward:   119.377 [   1.775], Avg:   101.324 (0.020) <0-02:39:25> ({'r_t':  1037.3772, 'eps':     0.0200, 'critic_loss':     6.4198, 'actor_loss':    -0.2553, 'eps_e':     0.0200})
Step:  247000, Reward:   117.640 [   2.517], Avg:   101.390 (0.020) <0-02:40:01> ({'r_t':  1125.2343, 'eps':     0.0200, 'critic_loss':     6.5980, 'actor_loss':    -0.2878, 'eps_e':     0.0200})
Step:  248000, Reward:   121.904 [   0.811], Avg:   101.473 (0.020) <0-02:40:39> ({'r_t':  1127.2979, 'eps':     0.0200, 'critic_loss':     7.2917, 'actor_loss':    -0.2876, 'eps_e':     0.0200})
Step:  249000, Reward:   115.409 [   6.838], Avg:   101.528 (0.020) <0-02:41:16> ({'r_t':  1139.2899, 'eps':     0.0200, 'critic_loss':     7.6457, 'actor_loss':    -0.3088, 'eps_e':     0.0200})
Step:  250000, Reward:   109.983 [   8.124], Avg:   101.562 (0.020) <0-02:41:53> ({'r_t':  1119.3675, 'eps':     0.0200, 'critic_loss':     5.7154, 'actor_loss':    -0.2949, 'eps_e':     0.0200})
Step:  251000, Reward:   120.695 [   3.181], Avg:   101.638 (0.020) <0-02:42:29> ({'r_t':  1108.1937, 'eps':     0.0200, 'critic_loss':     4.2359, 'actor_loss':    -0.2692, 'eps_e':     0.0200})
Step:  252000, Reward:   108.898 [  12.000], Avg:   101.667 (0.020) <0-02:43:07> ({'r_t':  1158.5515, 'eps':     0.0200, 'critic_loss':     3.2397, 'actor_loss':    -0.2490, 'eps_e':     0.0200})
Step:  253000, Reward:   114.545 [  16.568], Avg:   101.717 (0.020) <0-02:43:44> ({'r_t':  1182.5365, 'eps':     0.0200, 'critic_loss':     2.6018, 'actor_loss':    -0.2162, 'eps_e':     0.0200})
Step:  254000, Reward:   121.035 [   2.503], Avg:   101.793 (0.020) <0-02:44:20> ({'r_t':  1194.6046, 'eps':     0.0200, 'critic_loss':     1.9689, 'actor_loss':    -0.2022, 'eps_e':     0.0200})
Step:  255000, Reward:   120.950 [   0.733], Avg:   101.868 (0.020) <0-02:44:56> ({'r_t':  1193.4620, 'eps':     0.0200, 'critic_loss':     1.7995, 'actor_loss':    -0.1977, 'eps_e':     0.0200})
Step:  256000, Reward:   122.418 [   2.691], Avg:   101.948 (0.020) <0-02:45:32> ({'r_t':  1199.9226, 'eps':     0.0200, 'critic_loss':     1.3237, 'actor_loss':    -0.1908, 'eps_e':     0.0200})
Step:  257000, Reward:   122.205 [   1.483], Avg:   102.026 (0.020) <0-02:46:08> ({'r_t':  1173.2438, 'eps':     0.0200, 'critic_loss':     0.6774, 'actor_loss':    -0.1678, 'eps_e':     0.0200})
Step:  258000, Reward:   116.326 [   6.840], Avg:   102.082 (0.020) <0-02:46:45> ({'r_t':  1077.6808, 'eps':     0.0200, 'critic_loss':     1.3312, 'actor_loss':    -0.1670, 'eps_e':     0.0200})
Step:  259000, Reward:   120.252 [   1.528], Avg:   102.152 (0.020) <0-02:47:21> ({'r_t':  1055.7349, 'eps':     0.0200, 'critic_loss':     3.1008, 'actor_loss':    -0.1821, 'eps_e':     0.0200})
Step:  260000, Reward:   121.398 [   0.618], Avg:   102.225 (0.020) <0-02:47:58> ({'r_t':  1091.2969, 'eps':     0.0200, 'critic_loss':     3.4765, 'actor_loss':    -0.2046, 'eps_e':     0.0200})
Step:  261000, Reward:   121.108 [   2.444], Avg:   102.297 (0.020) <0-02:48:34> ({'r_t':  1064.6159, 'eps':     0.0200, 'critic_loss':     4.4602, 'actor_loss':    -0.2156, 'eps_e':     0.0200})
Step:  262000, Reward:   104.033 [  17.629], Avg:   102.304 (0.020) <0-02:49:11> ({'r_t':  1054.7725, 'eps':     0.0200, 'critic_loss':     6.2491, 'actor_loss':    -0.2539, 'eps_e':     0.0200})
Step:  263000, Reward:   120.567 [   1.536], Avg:   102.373 (0.020) <0-02:49:47> ({'r_t':  1113.6886, 'eps':     0.0200, 'critic_loss':     6.6149, 'actor_loss':    -0.2748, 'eps_e':     0.0200})
Step:  264000, Reward:   119.486 [   1.251], Avg:   102.438 (0.020) <0-02:50:23> ({'r_t':  1179.1618, 'eps':     0.0200, 'critic_loss':     6.5313, 'actor_loss':    -0.2992, 'eps_e':     0.0200})
Step:  265000, Reward:   121.849 [   0.614], Avg:   102.511 (0.020) <0-02:51:00> ({'r_t':  1134.5579, 'eps':     0.0200, 'critic_loss':     4.5326, 'actor_loss':    -0.2410, 'eps_e':     0.0200})
Step:  266000, Reward:   118.947 [   6.307], Avg:   102.572 (0.020) <0-02:51:36> ({'r_t':  1159.9606, 'eps':     0.0200, 'critic_loss':     4.6797, 'actor_loss':    -0.2429, 'eps_e':     0.0200})
Step:  267000, Reward:   115.096 [   4.045], Avg:   102.619 (0.020) <0-02:52:13> ({'r_t':  1122.1795, 'eps':     0.0200, 'critic_loss':     3.4014, 'actor_loss':    -0.2169, 'eps_e':     0.0200})
Step:  268000, Reward:   116.989 [   7.220], Avg:   102.672 (0.020) <0-02:52:49> ({'r_t':  1179.8615, 'eps':     0.0200, 'critic_loss':     1.9874, 'actor_loss':    -0.2056, 'eps_e':     0.0200})
Step:  269000, Reward:   113.538 [  17.794], Avg:   102.713 (0.020) <0-02:53:26> ({'r_t':  1154.8374, 'eps':     0.0200, 'critic_loss':     1.3714, 'actor_loss':    -0.1966, 'eps_e':     0.0200})
Step:  270000, Reward:   123.111 [   0.554], Avg:   102.788 (0.020) <0-02:54:02> ({'r_t':  1154.8223, 'eps':     0.0200, 'critic_loss':     1.5120, 'actor_loss':    -0.1948, 'eps_e':     0.0200})
Step:  271000, Reward:   120.581 [   1.767], Avg:   102.853 (0.020) <0-02:54:38> ({'r_t':  1123.1722, 'eps':     0.0200, 'critic_loss':     2.1998, 'actor_loss':    -0.1827, 'eps_e':     0.0200})
Step:  272000, Reward:   116.889 [   5.251], Avg:   102.905 (0.020) <0-02:55:15> ({'r_t':  1116.4388, 'eps':     0.0200, 'critic_loss':     2.2498, 'actor_loss':    -0.1905, 'eps_e':     0.0200})
Step:  273000, Reward:   113.609 [  30.079], Avg:   102.944 (0.020) <0-02:55:51> ({'r_t':  1110.0222, 'eps':     0.0200, 'critic_loss':     2.2010, 'actor_loss':    -0.2054, 'eps_e':     0.0200})
Step:  274000, Reward:   120.159 [   1.510], Avg:   103.006 (0.020) <0-02:56:28> ({'r_t':  1107.6504, 'eps':     0.0200, 'critic_loss':     2.4445, 'actor_loss':    -0.2021, 'eps_e':     0.0200})
Step:  275000, Reward:   121.090 [   1.072], Avg:   103.072 (0.020) <0-02:57:04> ({'r_t':  1128.5966, 'eps':     0.0200, 'critic_loss':     3.2334, 'actor_loss':    -0.2050, 'eps_e':     0.0200})
Step:  276000, Reward:   122.571 [   0.934], Avg:   103.142 (0.020) <0-02:57:40> ({'r_t':  1112.3583, 'eps':     0.0200, 'critic_loss':     2.7427, 'actor_loss':    -0.2185, 'eps_e':     0.0200})
Step:  277000, Reward:   122.514 [   1.159], Avg:   103.212 (0.020) <0-02:58:16> ({'r_t':  1172.8784, 'eps':     0.0200, 'critic_loss':     2.1096, 'actor_loss':    -0.2190, 'eps_e':     0.0200})
Step:  278000, Reward:   122.085 [   0.867], Avg:   103.280 (0.020) <0-02:58:53> ({'r_t':  1186.5953, 'eps':     0.0200, 'critic_loss':     1.3258, 'actor_loss':    -0.2144, 'eps_e':     0.0200})
Step:  279000, Reward:   119.120 [   6.042], Avg:   103.336 (0.020) <0-02:59:29> ({'r_t':  1147.5344, 'eps':     0.0200, 'critic_loss':     1.5987, 'actor_loss':    -0.1952, 'eps_e':     0.0200})
Step:  280000, Reward:   115.747 [  12.207], Avg:   103.380 (0.020) <0-03:00:18> ({'r_t':  1174.6041, 'eps':     0.0200, 'critic_loss':     1.9952, 'actor_loss':    -0.1826, 'eps_e':     0.0200})
Step:  281000, Reward:    96.921 [  38.974], Avg:   103.357 (0.020) <0-03:00:54> ({'r_t':  1109.1933, 'eps':     0.0200, 'critic_loss':     1.6870, 'actor_loss':    -0.1884, 'eps_e':     0.0200})
Step:  282000, Reward:   121.341 [   1.021], Avg:   103.421 (0.020) <0-03:01:30> ({'r_t':  1091.0165, 'eps':     0.0200, 'critic_loss':     1.8295, 'actor_loss':    -0.1743, 'eps_e':     0.0200})
Step:  283000, Reward:   122.270 [   1.765], Avg:   103.487 (0.020) <0-03:02:06> ({'r_t':  1077.0025, 'eps':     0.0200, 'critic_loss':     2.1120, 'actor_loss':    -0.1694, 'eps_e':     0.0200})
Step:  284000, Reward:   121.430 [   3.417], Avg:   103.550 (0.020) <0-03:02:43> ({'r_t':  1184.0253, 'eps':     0.0200, 'critic_loss':     2.2070, 'actor_loss':    -0.1797, 'eps_e':     0.0200})
Step:  285000, Reward:   117.601 [   1.220], Avg:   103.599 (0.020) <0-03:03:19> ({'r_t':  1169.0087, 'eps':     0.0200, 'critic_loss':     1.8278, 'actor_loss':    -0.1876, 'eps_e':     0.0200})
Step:  286000, Reward:   116.850 [   2.410], Avg:   103.646 (0.020) <0-03:03:55> ({'r_t':  1182.8043, 'eps':     0.0200, 'critic_loss':     1.5857, 'actor_loss':    -0.1854, 'eps_e':     0.0200})
Step:  287000, Reward:   123.672 [   0.642], Avg:   103.715 (0.020) <0-03:04:32> ({'r_t':  1195.5947, 'eps':     0.0200, 'critic_loss':     1.1410, 'actor_loss':    -0.1820, 'eps_e':     0.0200})
Step:  288000, Reward:   122.174 [   1.074], Avg:   103.779 (0.020) <0-03:05:08> ({'r_t':  1191.9634, 'eps':     0.0200, 'critic_loss':     0.9321, 'actor_loss':    -0.1926, 'eps_e':     0.0200})
Step:  289000, Reward:   121.435 [   1.265], Avg:   103.840 (0.020) <0-03:05:44> ({'r_t':  1183.5449, 'eps':     0.0200, 'critic_loss':     0.5298, 'actor_loss':    -0.1783, 'eps_e':     0.0200})
Step:  290000, Reward:   121.726 [   1.082], Avg:   103.901 (0.020) <0-03:06:20> ({'r_t':  1175.2949, 'eps':     0.0200, 'critic_loss':     0.3378, 'actor_loss':    -0.1678, 'eps_e':     0.0200})
Step:  291000, Reward:   122.722 [   0.862], Avg:   103.966 (0.020) <0-03:06:57> ({'r_t':  1190.7838, 'eps':     0.0200, 'critic_loss':     0.2926, 'actor_loss':    -0.1605, 'eps_e':     0.0200})
Step:  292000, Reward:   123.431 [   0.595], Avg:   104.032 (0.020) <0-03:07:33> ({'r_t':  1196.3119, 'eps':     0.0200, 'critic_loss':     0.2534, 'actor_loss':    -0.1468, 'eps_e':     0.0200})
Step:  293000, Reward:   123.029 [   0.666], Avg:   104.097 (0.020) <0-03:08:09> ({'r_t':  1165.7808, 'eps':     0.0200, 'critic_loss':     0.2393, 'actor_loss':    -0.1396, 'eps_e':     0.0200})
Step:  294000, Reward:   114.636 [   2.584], Avg:   104.133 (0.020) <0-03:09:00> ({'r_t':   993.6323, 'eps':     0.0200, 'critic_loss':     0.5956, 'actor_loss':    -0.2088, 'eps_e':     0.0200})
Step:  295000, Reward:   112.191 [   6.137], Avg:   104.160 (0.020) <0-03:09:44> ({'r_t':   539.7842, 'eps':     0.0200, 'critic_loss':     0.8823, 'actor_loss':    -0.3196, 'eps_e':     0.0200})
Step:  296000, Reward:   108.010 [  21.723], Avg:   104.173 (0.020) <0-03:10:27> ({'r_t':   371.4859, 'eps':     0.0200, 'critic_loss':     1.3088, 'actor_loss':    -0.2459, 'eps_e':     0.0200})
Step:  297000, Reward:    95.705 [  48.550], Avg:   104.144 (0.020) <0-03:11:03> ({'r_t':   996.9953, 'eps':     0.0200, 'critic_loss':     2.0264, 'actor_loss':    -0.3034, 'eps_e':     0.0200})
Step:  298000, Reward:   117.886 [  11.276], Avg:   104.190 (0.020) <0-03:11:44> ({'r_t':  1174.4748, 'eps':     0.0200, 'critic_loss':     2.0972, 'actor_loss':    -0.3367, 'eps_e':     0.0200})
Step:  299000, Reward:   121.174 [   4.362], Avg:   104.247 (0.020) <0-03:12:20> ({'r_t':  1138.1056, 'eps':     0.0200, 'critic_loss':     2.1212, 'actor_loss':    -0.3588, 'eps_e':     0.0200})
Step:  300000, Reward:   121.726 [   0.849], Avg:   104.305 (0.020) <0-03:12:56> ({'r_t':  1116.6575, 'eps':     0.0200, 'critic_loss':     2.3319, 'actor_loss':    -0.3764, 'eps_e':     0.0200})
Step:  301000, Reward:   121.371 [   1.324], Avg:   104.362 (0.020) <0-03:13:33> ({'r_t':  1145.3011, 'eps':     0.0200, 'critic_loss':     2.9318, 'actor_loss':    -0.3407, 'eps_e':     0.0200})
Step:  302000, Reward:   122.328 [   0.873], Avg:   104.421 (0.020) <0-03:14:09> ({'r_t':  1173.7795, 'eps':     0.0200, 'critic_loss':     2.5359, 'actor_loss':    -0.2690, 'eps_e':     0.0200})
Step:  303000, Reward:   120.181 [   4.192], Avg:   104.473 (0.020) <0-03:14:45> ({'r_t':  1172.4922, 'eps':     0.0200, 'critic_loss':     2.1335, 'actor_loss':    -0.1975, 'eps_e':     0.0200})
Step:  304000, Reward:   122.162 [   2.390], Avg:   104.531 (0.020) <0-03:15:22> ({'r_t':  1156.0650, 'eps':     0.0200, 'critic_loss':     1.8794, 'actor_loss':    -0.1758, 'eps_e':     0.0200})
Step:  305000, Reward:   122.714 [   1.326], Avg:   104.590 (0.020) <0-03:15:58> ({'r_t':  1164.6734, 'eps':     0.0200, 'critic_loss':     1.8162, 'actor_loss':    -0.1713, 'eps_e':     0.0200})
Step:  306000, Reward:   122.282 [   1.415], Avg:   104.648 (0.020) <0-03:16:34> ({'r_t':  1173.7936, 'eps':     0.0200, 'critic_loss':     1.4921, 'actor_loss':    -0.1797, 'eps_e':     0.0200})
Step:  307000, Reward:   121.879 [   1.088], Avg:   104.704 (0.020) <0-03:17:10> ({'r_t':  1183.2601, 'eps':     0.0200, 'critic_loss':     1.0157, 'actor_loss':    -0.1615, 'eps_e':     0.0200})
Step:  308000, Reward:   122.298 [   0.939], Avg:   104.761 (0.020) <0-03:17:47> ({'r_t':  1178.4228, 'eps':     0.0200, 'critic_loss':     0.7970, 'actor_loss':    -0.1543, 'eps_e':     0.0200})
Step:  309000, Reward:   123.571 [   0.539], Avg:   104.821 (0.020) <0-03:18:23> ({'r_t':  1189.7986, 'eps':     0.0200, 'critic_loss':     0.8951, 'actor_loss':    -0.1525, 'eps_e':     0.0200})
Step:  310000, Reward:   123.054 [   0.713], Avg:   104.880 (0.020) <0-03:18:59> ({'r_t':  1053.2729, 'eps':     0.0200, 'critic_loss':     0.7106, 'actor_loss':    -0.1497, 'eps_e':     0.0200})
Step:  311000, Reward:   123.013 [   5.467], Avg:   104.938 (0.020) <0-03:19:35> ({'r_t':  1160.1386, 'eps':     0.0200, 'critic_loss':     0.7074, 'actor_loss':    -0.1562, 'eps_e':     0.0200})
Step:  312000, Reward:   124.240 [   0.625], Avg:   105.000 (0.020) <0-03:20:12> ({'r_t':  1175.3897, 'eps':     0.0200, 'critic_loss':     0.6991, 'actor_loss':    -0.1899, 'eps_e':     0.0200})
Step:  313000, Reward:   123.903 [   0.701], Avg:   105.060 (0.020) <0-03:20:48> ({'r_t':  1188.1968, 'eps':     0.0200, 'critic_loss':     0.4309, 'actor_loss':    -0.1737, 'eps_e':     0.0200})
Step:  314000, Reward:   123.886 [   0.755], Avg:   105.120 (0.020) <0-03:21:24> ({'r_t':  1149.7540, 'eps':     0.0200, 'critic_loss':     0.6076, 'actor_loss':    -0.1758, 'eps_e':     0.0200})
Step:  315000, Reward:   122.605 [   2.733], Avg:   105.175 (0.020) <0-03:22:01> ({'r_t':  1174.5666, 'eps':     0.0200, 'critic_loss':     0.3132, 'actor_loss':    -0.1828, 'eps_e':     0.0200})
Step:  316000, Reward:   123.447 [   0.577], Avg:   105.233 (0.020) <0-03:22:37> ({'r_t':  1174.6515, 'eps':     0.0200, 'critic_loss':     0.2185, 'actor_loss':    -0.1702, 'eps_e':     0.0200})
Step:  317000, Reward:   121.474 [   1.898], Avg:   105.284 (0.020) <0-03:23:13> ({'r_t':  1190.0191, 'eps':     0.0200, 'critic_loss':     0.2060, 'actor_loss':    -0.1341, 'eps_e':     0.0200})
Step:  318000, Reward:   124.215 [   0.574], Avg:   105.343 (0.020) <0-03:23:50> ({'r_t':  1189.1440, 'eps':     0.0200, 'critic_loss':     0.2707, 'actor_loss':    -0.1228, 'eps_e':     0.0200})
Step:  319000, Reward:   123.304 [   0.868], Avg:   105.399 (0.020) <0-03:24:26> ({'r_t':  1167.2566, 'eps':     0.0200, 'critic_loss':     0.3172, 'actor_loss':    -0.1239, 'eps_e':     0.0200})
Step:  320000, Reward:   123.564 [   0.686], Avg:   105.456 (0.020) <0-03:25:02> ({'r_t':  1194.8476, 'eps':     0.0200, 'critic_loss':     0.2537, 'actor_loss':    -0.1230, 'eps_e':     0.0200})
Step:  321000, Reward:   119.337 [   1.794], Avg:   105.499 (0.020) <0-03:25:38> ({'r_t':  1201.6557, 'eps':     0.0200, 'critic_loss':     0.2382, 'actor_loss':    -0.1241, 'eps_e':     0.0200})
Step:  322000, Reward:   121.480 [   1.622], Avg:   105.548 (0.020) <0-03:26:15> ({'r_t':  1179.1541, 'eps':     0.0200, 'critic_loss':     0.2852, 'actor_loss':    -0.1165, 'eps_e':     0.0200})
Step:  323000, Reward:   123.301 [   2.871], Avg:   105.603 (0.020) <0-03:26:51> ({'r_t':  1149.2285, 'eps':     0.0200, 'critic_loss':     0.5649, 'actor_loss':    -0.1220, 'eps_e':     0.0200})
Step:  324000, Reward:   122.569 [   1.429], Avg:   105.655 (0.020) <0-03:27:27> ({'r_t':  1188.9499, 'eps':     0.0200, 'critic_loss':     0.6868, 'actor_loss':    -0.1269, 'eps_e':     0.0200})
Step:  325000, Reward:   122.102 [   1.071], Avg:   105.706 (0.020) <0-03:28:04> ({'r_t':  1192.3150, 'eps':     0.0200, 'critic_loss':     0.8375, 'actor_loss':    -0.1303, 'eps_e':     0.0200})
Step:  326000, Reward:   120.967 [   5.506], Avg:   105.752 (0.020) <0-03:28:40> ({'r_t':  1187.0895, 'eps':     0.0200, 'critic_loss':     0.7758, 'actor_loss':    -0.1198, 'eps_e':     0.0200})
Step:  327000, Reward:   122.746 [   2.270], Avg:   105.804 (0.020) <0-03:29:16> ({'r_t':  1186.3908, 'eps':     0.0200, 'critic_loss':     0.8286, 'actor_loss':    -0.1296, 'eps_e':     0.0200})
Step:  328000, Reward:   124.335 [   1.032], Avg:   105.861 (0.020) <0-03:29:52> ({'r_t':  1183.6963, 'eps':     0.0200, 'critic_loss':     0.9263, 'actor_loss':    -0.1215, 'eps_e':     0.0200})
Step:  329000, Reward:   124.468 [   0.585], Avg:   105.917 (0.020) <0-03:30:29> ({'r_t':  1189.4985, 'eps':     0.0200, 'critic_loss':     0.7337, 'actor_loss':    -0.1143, 'eps_e':     0.0200})
Step:  330000, Reward:   123.845 [   0.999], Avg:   105.971 (0.020) <0-03:31:05> ({'r_t':  1192.1840, 'eps':     0.0200, 'critic_loss':     0.3649, 'actor_loss':    -0.1069, 'eps_e':     0.0200})
Step:  331000, Reward:   120.334 [   5.175], Avg:   106.014 (0.020) <0-03:31:41> ({'r_t':  1180.2057, 'eps':     0.0200, 'critic_loss':     0.2679, 'actor_loss':    -0.0999, 'eps_e':     0.0200})
Step:  332000, Reward:   124.213 [   1.284], Avg:   106.069 (0.020) <0-03:32:18> ({'r_t':  1198.3167, 'eps':     0.0200, 'critic_loss':     0.2703, 'actor_loss':    -0.1045, 'eps_e':     0.0200})
Step:  333000, Reward:   123.432 [   1.733], Avg:   106.121 (0.020) <0-03:32:54> ({'r_t':  1187.6774, 'eps':     0.0200, 'critic_loss':     0.2639, 'actor_loss':    -0.1006, 'eps_e':     0.0200})
Step:  334000, Reward:   123.665 [   1.144], Avg:   106.173 (0.020) <0-03:33:30> ({'r_t':  1148.9857, 'eps':     0.0200, 'critic_loss':     0.6625, 'actor_loss':    -0.0947, 'eps_e':     0.0200})
Step:  335000, Reward:   104.105 [   6.124], Avg:   106.167 (0.020) <0-03:34:36> ({'r_t':  1017.6426, 'eps':     0.0200, 'critic_loss':     2.0508, 'actor_loss':    -0.1100, 'eps_e':     0.0200})
Step:  336000, Reward:   100.942 [  12.203], Avg:   106.152 (0.020) <0-03:35:42> ({'r_t':   284.4313, 'eps':     0.0200, 'critic_loss':     3.2220, 'actor_loss':    -0.1889, 'eps_e':     0.0200})
Step:  337000, Reward:   121.665 [   2.126], Avg:   106.198 (0.020) <0-03:36:19> ({'r_t':   710.2368, 'eps':     0.0200, 'critic_loss':     2.7689, 'actor_loss':    -0.1717, 'eps_e':     0.0200})
Step:  338000, Reward:   118.646 [   4.007], Avg:   106.234 (0.020) <0-03:36:59> ({'r_t':  1149.6204, 'eps':     0.0200, 'critic_loss':     2.7214, 'actor_loss':    -0.1790, 'eps_e':     0.0200})
Step:  339000, Reward:   121.610 [   3.802], Avg:   106.280 (0.020) <0-03:37:35> ({'r_t':  1150.1167, 'eps':     0.0200, 'critic_loss':     3.3657, 'actor_loss':    -0.2101, 'eps_e':     0.0200})
Step:  340000, Reward:   122.174 [   1.104], Avg:   106.326 (0.020) <0-03:38:11> ({'r_t':  1164.8256, 'eps':     0.0200, 'critic_loss':     2.8992, 'actor_loss':    -0.2126, 'eps_e':     0.0200})
Step:  341000, Reward:   124.430 [   2.576], Avg:   106.379 (0.020) <0-03:38:48> ({'r_t':  1200.5693, 'eps':     0.0200, 'critic_loss':     2.3676, 'actor_loss':    -0.2200, 'eps_e':     0.0200})
Step:  342000, Reward:   123.902 [   3.121], Avg:   106.430 (0.020) <0-03:39:24> ({'r_t':  1205.8097, 'eps':     0.0200, 'critic_loss':     0.8841, 'actor_loss':    -0.1841, 'eps_e':     0.0200})
Step:  343000, Reward:   124.410 [   0.790], Avg:   106.483 (0.020) <0-03:40:00> ({'r_t':  1185.7839, 'eps':     0.0200, 'critic_loss':     1.0540, 'actor_loss':    -0.1662, 'eps_e':     0.0200})
Step:  344000, Reward:   123.823 [   0.659], Avg:   106.533 (0.020) <0-03:40:36> ({'r_t':  1190.9880, 'eps':     0.0200, 'critic_loss':     0.6711, 'actor_loss':    -0.1634, 'eps_e':     0.0200})
Step:  345000, Reward:   123.318 [   0.888], Avg:   106.581 (0.020) <0-03:41:13> ({'r_t':  1161.3178, 'eps':     0.0200, 'critic_loss':     0.7424, 'actor_loss':    -0.1379, 'eps_e':     0.0200})
Step:  346000, Reward:   121.618 [   1.321], Avg:   106.625 (0.020) <0-03:41:49> ({'r_t':  1134.7952, 'eps':     0.0200, 'critic_loss':     0.8444, 'actor_loss':    -0.1222, 'eps_e':     0.0200})
Step:  347000, Reward:   124.477 [   0.550], Avg:   106.676 (0.020) <0-03:42:25> ({'r_t':  1140.0474, 'eps':     0.0200, 'critic_loss':     1.5256, 'actor_loss':    -0.1371, 'eps_e':     0.0200})
Step:  348000, Reward:   121.459 [   1.608], Avg:   106.718 (0.020) <0-03:43:01> ({'r_t':  1109.0981, 'eps':     0.0200, 'critic_loss':     1.7269, 'actor_loss':    -0.1338, 'eps_e':     0.0200})
Step:  349000, Reward:   117.387 [   5.033], Avg:   106.749 (0.020) <0-03:43:42> ({'r_t':  1091.3991, 'eps':     0.0200, 'critic_loss':     1.8119, 'actor_loss':    -0.1362, 'eps_e':     0.0200})
Step:  350000, Reward:   121.748 [   1.410], Avg:   106.792 (0.020) <0-03:44:19> ({'r_t':  1179.5767, 'eps':     0.0200, 'critic_loss':     1.9827, 'actor_loss':    -0.1454, 'eps_e':     0.0200})
Step:  351000, Reward:   122.485 [   2.025], Avg:   106.836 (0.020) <0-03:44:55> ({'r_t':  1170.1202, 'eps':     0.0200, 'critic_loss':     1.6336, 'actor_loss':    -0.1496, 'eps_e':     0.0200})
Step:  352000, Reward:   122.541 [   1.265], Avg:   106.881 (0.020) <0-03:45:31> ({'r_t':  1178.6677, 'eps':     0.0200, 'critic_loss':     1.5168, 'actor_loss':    -0.1593, 'eps_e':     0.0200})
Step:  353000, Reward:   121.929 [   1.516], Avg:   106.923 (0.020) <0-03:46:07> ({'r_t':  1182.4172, 'eps':     0.0200, 'critic_loss':     1.3290, 'actor_loss':    -0.1458, 'eps_e':     0.0200})
Step:  354000, Reward:   122.389 [   1.045], Avg:   106.967 (0.020) <0-03:46:43> ({'r_t':  1185.7890, 'eps':     0.0200, 'critic_loss':     1.0673, 'actor_loss':    -0.1393, 'eps_e':     0.0200})
Step:  355000, Reward:   122.175 [   1.238], Avg:   107.009 (0.020) <0-03:47:20> ({'r_t':  1177.2873, 'eps':     0.0200, 'critic_loss':     0.8754, 'actor_loss':    -0.1336, 'eps_e':     0.0200})
Step:  356000, Reward:   107.782 [   7.107], Avg:   107.012 (0.020) <0-03:47:57> ({'r_t':  1179.4718, 'eps':     0.0200, 'critic_loss':     1.0093, 'actor_loss':    -0.1206, 'eps_e':     0.0200})
Step:  357000, Reward:   101.552 [  38.827], Avg:   106.996 (0.020) <0-03:48:37> ({'r_t':  1152.1427, 'eps':     0.0200, 'critic_loss':     0.6453, 'actor_loss':    -0.1170, 'eps_e':     0.0200})
Step:  358000, Reward:   122.417 [   1.510], Avg:   107.039 (0.020) <0-03:49:13> ({'r_t':  1160.2792, 'eps':     0.0200, 'critic_loss':     1.7956, 'actor_loss':    -0.1339, 'eps_e':     0.0200})
Step:  359000, Reward:   121.581 [   2.088], Avg:   107.080 (0.020) <0-03:49:49> ({'r_t':  1167.9449, 'eps':     0.0200, 'critic_loss':     2.1370, 'actor_loss':    -0.1395, 'eps_e':     0.0200})
Step:  360000, Reward:   120.654 [   3.278], Avg:   107.117 (0.020) <0-03:50:26> ({'r_t':  1168.8235, 'eps':     0.0200, 'critic_loss':     1.8660, 'actor_loss':    -0.1519, 'eps_e':     0.0200})
Step:  361000, Reward:   123.746 [   0.831], Avg:   107.163 (0.020) <0-03:51:02> ({'r_t':  1185.8568, 'eps':     0.0200, 'critic_loss':     2.0718, 'actor_loss':    -0.1678, 'eps_e':     0.0200})
Step:  362000, Reward:   123.807 [   0.792], Avg:   107.209 (0.020) <0-03:51:38> ({'r_t':  1157.7191, 'eps':     0.0200, 'critic_loss':     2.1837, 'actor_loss':    -0.1598, 'eps_e':     0.0200})
Step:  363000, Reward:   122.140 [   1.377], Avg:   107.250 (0.020) <0-03:52:14> ({'r_t':  1163.5248, 'eps':     0.0200, 'critic_loss':     1.6982, 'actor_loss':    -0.1860, 'eps_e':     0.0200})
Step:  364000, Reward:   121.079 [   0.966], Avg:   107.288 (0.020) <0-03:52:51> ({'r_t':  1174.9923, 'eps':     0.0200, 'critic_loss':     1.0785, 'actor_loss':    -0.1707, 'eps_e':     0.0200})
Step:  365000, Reward:   121.098 [   1.881], Avg:   107.326 (0.020) <0-03:53:27> ({'r_t':  1162.6154, 'eps':     0.0200, 'critic_loss':     0.8971, 'actor_loss':    -0.1558, 'eps_e':     0.0200})
Step:  366000, Reward:   117.485 [   3.654], Avg:   107.353 (0.020) <0-03:54:03> ({'r_t':  1128.6953, 'eps':     0.0200, 'critic_loss':     1.6058, 'actor_loss':    -0.1479, 'eps_e':     0.0200})
Step:  367000, Reward:   106.665 [  24.856], Avg:   107.351 (0.020) <0-03:54:39> ({'r_t':  1142.8149, 'eps':     0.0200, 'critic_loss':     1.9105, 'actor_loss':    -0.1692, 'eps_e':     0.0200})
Step:  368000, Reward:   121.900 [   0.761], Avg:   107.391 (0.020) <0-03:55:16> ({'r_t':  1163.6796, 'eps':     0.0200, 'critic_loss':     2.1925, 'actor_loss':    -0.1604, 'eps_e':     0.0200})
Step:  369000, Reward:   121.314 [   1.051], Avg:   107.429 (0.020) <0-03:55:52> ({'r_t':  1150.7427, 'eps':     0.0200, 'critic_loss':     2.1084, 'actor_loss':    -0.1607, 'eps_e':     0.0200})
Step:  370000, Reward:   123.183 [   0.564], Avg:   107.471 (0.020) <0-03:56:28> ({'r_t':  1166.9896, 'eps':     0.0200, 'critic_loss':     2.2143, 'actor_loss':    -0.1671, 'eps_e':     0.0200})
Step:  371000, Reward:   120.375 [   4.247], Avg:   107.506 (0.020) <0-03:57:04> ({'r_t':  1145.3272, 'eps':     0.0200, 'critic_loss':     2.0279, 'actor_loss':    -0.1700, 'eps_e':     0.0200})
Step:  372000, Reward:   115.308 [   4.501], Avg:   107.527 (0.020) <0-03:57:41> ({'r_t':  1188.8250, 'eps':     0.0200, 'critic_loss':     2.0545, 'actor_loss':    -0.1817, 'eps_e':     0.0200})
Step:  373000, Reward:   122.095 [   5.966], Avg:   107.566 (0.020) <0-03:58:17> ({'r_t':  1167.2873, 'eps':     0.0200, 'critic_loss':     1.2678, 'actor_loss':    -0.1574, 'eps_e':     0.0200})
Step:  374000, Reward:   120.652 [   7.246], Avg:   107.600 (0.020) <0-03:58:58> ({'r_t':  1186.8074, 'eps':     0.0200, 'critic_loss':     1.2505, 'actor_loss':    -0.1479, 'eps_e':     0.0200})
Step:  375000, Reward:   123.476 [   0.646], Avg:   107.643 (0.020) <0-03:59:34> ({'r_t':  1181.0822, 'eps':     0.0200, 'critic_loss':     1.0972, 'actor_loss':    -0.1406, 'eps_e':     0.0200})
Step:  376000, Reward:   117.885 [   1.972], Avg:   107.670 (0.020) <0-04:00:11> ({'r_t':  1163.9890, 'eps':     0.0200, 'critic_loss':     0.8094, 'actor_loss':    -0.1486, 'eps_e':     0.0200})
Step:  377000, Reward:   122.411 [   0.865], Avg:   107.709 (0.020) <0-04:00:47> ({'r_t':  1128.9749, 'eps':     0.0200, 'critic_loss':     0.8021, 'actor_loss':    -0.1392, 'eps_e':     0.0200})
Step:  378000, Reward:   117.847 [   4.371], Avg:   107.736 (0.020) <0-04:01:23> ({'r_t':  1192.1170, 'eps':     0.0200, 'critic_loss':     0.9231, 'actor_loss':    -0.1517, 'eps_e':     0.0200})
Step:  379000, Reward:   120.123 [   1.154], Avg:   107.768 (0.020) <0-04:02:00> ({'r_t':  1072.2570, 'eps':     0.0200, 'critic_loss':     1.9996, 'actor_loss':    -0.1342, 'eps_e':     0.0200})
Step:  380000, Reward:   112.621 [   9.328], Avg:   107.781 (0.020) <0-04:02:37> ({'r_t':  1157.2613, 'eps':     0.0200, 'critic_loss':     2.5676, 'actor_loss':    -0.1713, 'eps_e':     0.0200})
Step:  381000, Reward:   118.888 [   3.987], Avg:   107.810 (0.020) <0-04:03:14> ({'r_t':  1164.6057, 'eps':     0.0200, 'critic_loss':     2.3466, 'actor_loss':    -0.1663, 'eps_e':     0.0200})
Step:  382000, Reward:   123.157 [   1.197], Avg:   107.850 (0.020) <0-04:03:50> ({'r_t':  1168.0801, 'eps':     0.0200, 'critic_loss':     2.4980, 'actor_loss':    -0.1771, 'eps_e':     0.0200})
Step:  383000, Reward:   121.190 [   1.296], Avg:   107.885 (0.020) <0-04:04:26> ({'r_t':  1174.6201, 'eps':     0.0200, 'critic_loss':     2.0910, 'actor_loss':    -0.1823, 'eps_e':     0.0200})
Step:  384000, Reward:   119.843 [   1.238], Avg:   107.916 (0.020) <0-04:05:02> ({'r_t':  1106.3279, 'eps':     0.0200, 'critic_loss':     2.4455, 'actor_loss':    -0.1924, 'eps_e':     0.0200})
Step:  385000, Reward:   115.706 [   5.050], Avg:   107.936 (0.020) <0-04:05:39> ({'r_t':  1165.0300, 'eps':     0.0200, 'critic_loss':     2.1106, 'actor_loss':    -0.1989, 'eps_e':     0.0200})
Step:  386000, Reward:   122.529 [   3.355], Avg:   107.974 (0.020) <0-04:06:15> ({'r_t':  1198.2528, 'eps':     0.0200, 'critic_loss':     1.1006, 'actor_loss':    -0.1620, 'eps_e':     0.0200})
Step:  387000, Reward:   118.800 [   3.836], Avg:   108.002 (0.020) <0-04:06:51> ({'r_t':  1178.8876, 'eps':     0.0200, 'critic_loss':     0.7845, 'actor_loss':    -0.1561, 'eps_e':     0.0200})
Step:  388000, Reward:   117.719 [  24.187], Avg:   108.027 (0.020) <0-04:07:27> ({'r_t':  1174.8492, 'eps':     0.0200, 'critic_loss':     0.8165, 'actor_loss':    -0.1564, 'eps_e':     0.0200})
Step:  389000, Reward:   123.126 [   1.002], Avg:   108.065 (0.020) <0-04:08:04> ({'r_t':  1199.8280, 'eps':     0.0200, 'critic_loss':     0.5827, 'actor_loss':    -0.1647, 'eps_e':     0.0200})
Step:  390000, Reward:   122.767 [   1.834], Avg:   108.103 (0.020) <0-04:08:40> ({'r_t':  1184.5324, 'eps':     0.0200, 'critic_loss':     0.4040, 'actor_loss':    -0.1509, 'eps_e':     0.0200})
Step:  391000, Reward:   124.011 [   0.995], Avg:   108.144 (0.020) <0-04:09:16> ({'r_t':  1149.0150, 'eps':     0.0200, 'critic_loss':     0.3032, 'actor_loss':    -0.1375, 'eps_e':     0.0200})
Step:  392000, Reward:   122.950 [   1.091], Avg:   108.181 (0.020) <0-04:09:53> ({'r_t':  1198.1890, 'eps':     0.0200, 'critic_loss':     0.3064, 'actor_loss':    -0.1274, 'eps_e':     0.0200})
Step:  393000, Reward:   123.443 [   0.634], Avg:   108.220 (0.020) <0-04:10:29> ({'r_t':  1182.0570, 'eps':     0.0200, 'critic_loss':     0.2889, 'actor_loss':    -0.1230, 'eps_e':     0.0200})
Step:  394000, Reward:   120.503 [   0.969], Avg:   108.251 (0.020) <0-04:11:05> ({'r_t':  1194.9129, 'eps':     0.0200, 'critic_loss':     0.2780, 'actor_loss':    -0.1163, 'eps_e':     0.0200})
Step:  395000, Reward:   121.809 [   1.133], Avg:   108.285 (0.020) <0-04:11:41> ({'r_t':  1196.2015, 'eps':     0.0200, 'critic_loss':     0.2498, 'actor_loss':    -0.1083, 'eps_e':     0.0200})
Step:  396000, Reward:   122.845 [   1.251], Avg:   108.322 (0.020) <0-04:12:18> ({'r_t':  1206.2816, 'eps':     0.0200, 'critic_loss':     0.2296, 'actor_loss':    -0.1024, 'eps_e':     0.0200})
Step:  397000, Reward:   123.451 [   1.300], Avg:   108.360 (0.020) <0-04:12:54> ({'r_t':  1215.8467, 'eps':     0.0200, 'critic_loss':     0.2210, 'actor_loss':    -0.1072, 'eps_e':     0.0200})
Step:  398000, Reward:   123.320 [   0.600], Avg:   108.397 (0.020) <0-04:13:30> ({'r_t':  1199.8016, 'eps':     0.0200, 'critic_loss':     0.1809, 'actor_loss':    -0.0945, 'eps_e':     0.0200})
Step:  399000, Reward:   124.038 [   0.586], Avg:   108.437 (0.020) <0-04:14:06> ({'r_t':  1179.6843, 'eps':     0.0200, 'critic_loss':     0.2245, 'actor_loss':    -0.0880, 'eps_e':     0.0200})
Step:  400000, Reward:    87.483 [  13.277], Avg:   108.384 (0.020) <0-04:15:12> ({'r_t':   591.1668, 'eps':     0.0200, 'critic_loss':     0.2094, 'actor_loss':    -0.1190, 'eps_e':     0.0200})
Step:  401000, Reward:   122.703 [   1.067], Avg:   108.420 (0.020) <0-04:15:49> ({'r_t':   722.9220, 'eps':     0.0200, 'critic_loss':     0.2722, 'actor_loss':    -0.1519, 'eps_e':     0.0200})
Step:  402000, Reward:   123.094 [   0.876], Avg:   108.456 (0.020) <0-04:16:25> ({'r_t':  1118.8891, 'eps':     0.0200, 'critic_loss':     0.5846, 'actor_loss':    -0.3655, 'eps_e':     0.0200})
Step:  403000, Reward:   121.046 [   1.678], Avg:   108.488 (0.020) <0-04:17:01> ({'r_t':  1040.2744, 'eps':     0.0200, 'critic_loss':     2.3273, 'actor_loss':    -0.3990, 'eps_e':     0.0200})
Step:  404000, Reward:   120.150 [   3.316], Avg:   108.516 (0.020) <0-04:17:37> ({'r_t':  1148.9558, 'eps':     0.0200, 'critic_loss':     3.6276, 'actor_loss':    -0.4184, 'eps_e':     0.0200})
Step:  405000, Reward:   119.170 [   6.247], Avg:   108.543 (0.020) <0-04:18:14> ({'r_t':  1155.1277, 'eps':     0.0200, 'critic_loss':     4.3306, 'actor_loss':    -0.4653, 'eps_e':     0.0200})
Step:  406000, Reward:   122.484 [   1.048], Avg:   108.577 (0.020) <0-04:18:50> ({'r_t':  1187.1327, 'eps':     0.0200, 'critic_loss':     3.8573, 'actor_loss':    -0.4939, 'eps_e':     0.0200})
Step:  407000, Reward:   117.927 [   4.208], Avg:   108.600 (0.020) <0-04:19:26> ({'r_t':  1201.4496, 'eps':     0.0200, 'critic_loss':     4.0988, 'actor_loss':    -0.3159, 'eps_e':     0.0200})
Step:  408000, Reward:   121.362 [   1.168], Avg:   108.631 (0.020) <0-04:20:02> ({'r_t':  1169.3814, 'eps':     0.0200, 'critic_loss':     3.8143, 'actor_loss':    -0.2692, 'eps_e':     0.0200})
Step:  409000, Reward:   122.549 [   2.275], Avg:   108.665 (0.020) <0-04:20:40> ({'r_t':  1153.2394, 'eps':     0.0200, 'critic_loss':     2.9279, 'actor_loss':    -0.2166, 'eps_e':     0.0200})
Step:  410000, Reward:   121.424 [   1.898], Avg:   108.696 (0.020) <0-04:21:17> ({'r_t':  1184.5360, 'eps':     0.0200, 'critic_loss':     1.6444, 'actor_loss':    -0.1783, 'eps_e':     0.0200})
Step:  411000, Reward:   123.834 [   0.588], Avg:   108.733 (0.020) <0-04:21:53> ({'r_t':  1198.1820, 'eps':     0.0200, 'critic_loss':     0.9302, 'actor_loss':    -0.1539, 'eps_e':     0.0200})
Step:  412000, Reward:   123.828 [   1.336], Avg:   108.769 (0.020) <0-04:22:29> ({'r_t':  1187.8210, 'eps':     0.0200, 'critic_loss':     0.6036, 'actor_loss':    -0.1527, 'eps_e':     0.0200})
Step:  413000, Reward:   122.836 [   2.251], Avg:   108.803 (0.020) <0-04:23:05> ({'r_t':  1182.8893, 'eps':     0.0200, 'critic_loss':     0.4316, 'actor_loss':    -0.1396, 'eps_e':     0.0200})
Step:  414000, Reward:   124.160 [   0.495], Avg:   108.840 (0.020) <0-04:23:42> ({'r_t':  1205.2953, 'eps':     0.0200, 'critic_loss':     0.3889, 'actor_loss':    -0.1282, 'eps_e':     0.0200})
Step:  415000, Reward:   124.049 [   0.476], Avg:   108.877 (0.020) <0-04:24:18> ({'r_t':  1153.4423, 'eps':     0.0200, 'critic_loss':     0.4301, 'actor_loss':    -0.1178, 'eps_e':     0.0200})
Step:  416000, Reward:   119.699 [   1.299], Avg:   108.903 (0.020) <0-04:24:54> ({'r_t':  1137.0032, 'eps':     0.0200, 'critic_loss':     0.3250, 'actor_loss':    -0.1151, 'eps_e':     0.0200})
Step:  417000, Reward:   122.119 [   1.321], Avg:   108.934 (0.020) <0-04:25:30> ({'r_t':  1166.2992, 'eps':     0.0200, 'critic_loss':     0.3188, 'actor_loss':    -0.1139, 'eps_e':     0.0200})
Step:  418000, Reward:   121.801 [   1.324], Avg:   108.965 (0.020) <0-04:26:07> ({'r_t':  1194.6443, 'eps':     0.0200, 'critic_loss':     0.2819, 'actor_loss':    -0.1118, 'eps_e':     0.0200})
Step:  419000, Reward:   123.556 [   0.723], Avg:   109.000 (0.020) <0-04:26:43> ({'r_t':  1204.8102, 'eps':     0.0200, 'critic_loss':     0.2638, 'actor_loss':    -0.1057, 'eps_e':     0.0200})
Step:  420000, Reward:   123.522 [   0.680], Avg:   109.034 (0.020) <0-04:27:19> ({'r_t':  1190.2390, 'eps':     0.0200, 'critic_loss':     0.2617, 'actor_loss':    -0.1046, 'eps_e':     0.0200})
Step:  421000, Reward:   122.253 [   0.823], Avg:   109.066 (0.020) <0-04:27:55> ({'r_t':  1182.7050, 'eps':     0.0200, 'critic_loss':     0.2806, 'actor_loss':    -0.1028, 'eps_e':     0.0200})
Step:  422000, Reward:   122.086 [   1.476], Avg:   109.096 (0.020) <0-04:28:31> ({'r_t':  1193.9523, 'eps':     0.0200, 'critic_loss':     0.2520, 'actor_loss':    -0.0984, 'eps_e':     0.0200})
Step:  423000, Reward:   124.121 [   0.625], Avg:   109.132 (0.020) <0-04:29:08> ({'r_t':  1197.9195, 'eps':     0.0200, 'critic_loss':     0.1924, 'actor_loss':    -0.0939, 'eps_e':     0.0200})
Step:  424000, Reward:   116.323 [   2.425], Avg:   109.149 (0.020) <0-04:29:45> ({'r_t':  1127.4723, 'eps':     0.0200, 'critic_loss':     0.1784, 'actor_loss':    -0.0975, 'eps_e':     0.0200})
Step:  425000, Reward:    95.437 [  13.595], Avg:   109.117 (0.020) <0-04:30:22> ({'r_t':   495.1397, 'eps':     0.0200, 'critic_loss':     0.4358, 'actor_loss':    -0.0974, 'eps_e':     0.0200})
Step:  426000, Reward:    99.450 [  33.527], Avg:   109.094 (0.020) <0-04:30:58> ({'r_t':  1073.8847, 'eps':     0.0200, 'critic_loss':     1.0955, 'actor_loss':    -0.1820, 'eps_e':     0.0200})
Step:  427000, Reward:   120.328 [  16.232], Avg:   109.120 (0.020) <0-04:31:35> ({'r_t':  1180.7807, 'eps':     0.0200, 'critic_loss':     0.9466, 'actor_loss':    -0.2028, 'eps_e':     0.0200})
Step:  428000, Reward:   123.882 [   0.838], Avg:   109.155 (0.020) <0-04:32:11> ({'r_t':  1205.7468, 'eps':     0.0200, 'critic_loss':     0.8924, 'actor_loss':    -0.2507, 'eps_e':     0.0200})
Step:  429000, Reward:   123.027 [   0.802], Avg:   109.187 (0.020) <0-04:32:47> ({'r_t':  1199.0185, 'eps':     0.0200, 'critic_loss':     0.8663, 'actor_loss':    -0.2914, 'eps_e':     0.0200})
Step:  430000, Reward:   122.941 [   1.377], Avg:   109.219 (0.020) <0-04:33:23> ({'r_t':  1194.1157, 'eps':     0.0200, 'critic_loss':     0.8535, 'actor_loss':    -0.3161, 'eps_e':     0.0200})
Step:  431000, Reward:   124.757 [   0.824], Avg:   109.255 (0.020) <0-04:33:59> ({'r_t':  1205.4291, 'eps':     0.0200, 'critic_loss':     0.7339, 'actor_loss':    -0.2661, 'eps_e':     0.0200})
Step:  432000, Reward:   124.034 [   0.699], Avg:   109.289 (0.020) <0-04:34:36> ({'r_t':  1200.4453, 'eps':     0.0200, 'critic_loss':     0.4124, 'actor_loss':    -0.1553, 'eps_e':     0.0200})
Step:  433000, Reward:   124.523 [   1.706], Avg:   109.324 (0.020) <0-04:35:13> ({'r_t':  1210.1719, 'eps':     0.0200, 'critic_loss':     0.2120, 'actor_loss':    -0.1319, 'eps_e':     0.0200})
Step:  434000, Reward:   124.284 [   0.403], Avg:   109.358 (0.020) <0-04:35:50> ({'r_t':  1213.2381, 'eps':     0.0200, 'critic_loss':     0.1955, 'actor_loss':    -0.1181, 'eps_e':     0.0200})
Step:  435000, Reward:   124.839 [   0.690], Avg:   109.394 (0.020) <0-04:36:26> ({'r_t':  1218.7583, 'eps':     0.0200, 'critic_loss':     0.1249, 'actor_loss':    -0.1119, 'eps_e':     0.0200})
Step:  436000, Reward:   124.394 [   0.751], Avg:   109.428 (0.020) <0-04:37:02> ({'r_t':  1208.0340, 'eps':     0.0200, 'critic_loss':     0.1041, 'actor_loss':    -0.0992, 'eps_e':     0.0200})
Step:  437000, Reward:   122.478 [   1.203], Avg:   109.458 (0.020) <0-04:37:38> ({'r_t':  1209.4600, 'eps':     0.0200, 'critic_loss':     0.0980, 'actor_loss':    -0.0932, 'eps_e':     0.0200})
Step:  438000, Reward:   124.726 [   0.580], Avg:   109.493 (0.020) <0-04:38:14> ({'r_t':  1212.6627, 'eps':     0.0200, 'critic_loss':     0.0813, 'actor_loss':    -0.0849, 'eps_e':     0.0200})
Step:  439000, Reward:   123.810 [   0.857], Avg:   109.525 (0.020) <0-04:38:51> ({'r_t':  1219.1486, 'eps':     0.0200, 'critic_loss':     0.0683, 'actor_loss':    -0.0782, 'eps_e':     0.0200})
Step:  440000, Reward:   120.208 [   0.967], Avg:   109.549 (0.020) <0-04:39:27> ({'r_t':  1197.2688, 'eps':     0.0200, 'critic_loss':     0.0831, 'actor_loss':    -0.0727, 'eps_e':     0.0200})
Step:  441000, Reward:   124.488 [   0.675], Avg:   109.583 (0.020) <0-04:40:03> ({'r_t':  1194.6289, 'eps':     0.0200, 'critic_loss':     0.1178, 'actor_loss':    -0.0680, 'eps_e':     0.0200})
Step:  442000, Reward:   124.404 [   0.620], Avg:   109.617 (0.020) <0-04:40:39> ({'r_t':  1209.2319, 'eps':     0.0200, 'critic_loss':     0.1372, 'actor_loss':    -0.0706, 'eps_e':     0.0200})
Step:  443000, Reward:   124.736 [   0.581], Avg:   109.651 (0.020) <0-04:41:16> ({'r_t':  1211.8342, 'eps':     0.0200, 'critic_loss':     0.1505, 'actor_loss':    -0.0745, 'eps_e':     0.0200})
Step:  444000, Reward:   125.256 [   0.544], Avg:   109.686 (0.020) <0-04:41:52> ({'r_t':  1204.8785, 'eps':     0.0200, 'critic_loss':     0.1646, 'actor_loss':    -0.0735, 'eps_e':     0.0200})
Step:  445000, Reward:   122.750 [   1.344], Avg:   109.715 (0.020) <0-04:42:28> ({'r_t':  1201.2332, 'eps':     0.0200, 'critic_loss':     0.1753, 'actor_loss':    -0.0750, 'eps_e':     0.0200})
Step:  446000, Reward:   124.599 [   0.742], Avg:   109.748 (0.020) <0-04:43:04> ({'r_t':  1209.6759, 'eps':     0.0200, 'critic_loss':     0.2288, 'actor_loss':    -0.0790, 'eps_e':     0.0200})
Step:  447000, Reward:   123.863 [   0.525], Avg:   109.780 (0.020) <0-04:43:41> ({'r_t':  1211.4677, 'eps':     0.0200, 'critic_loss':     0.2456, 'actor_loss':    -0.0806, 'eps_e':     0.0200})
Step:  448000, Reward:   124.695 [   0.918], Avg:   109.813 (0.020) <0-04:44:17> ({'r_t':  1200.5889, 'eps':     0.0200, 'critic_loss':     0.1956, 'actor_loss':    -0.0821, 'eps_e':     0.0200})
Step:  449000, Reward:   123.034 [   0.795], Avg:   109.843 (0.020) <0-04:44:53> ({'r_t':  1212.9098, 'eps':     0.0200, 'critic_loss':     0.1890, 'actor_loss':    -0.0785, 'eps_e':     0.0200})
Step:  450000, Reward:   124.408 [   1.036], Avg:   109.875 (0.020) <0-04:45:29> ({'r_t':  1211.3052, 'eps':     0.0200, 'critic_loss':     0.2413, 'actor_loss':    -0.0781, 'eps_e':     0.0200})
Step:  451000, Reward:   124.596 [   0.609], Avg:   109.907 (0.020) <0-04:46:06> ({'r_t':  1210.4389, 'eps':     0.0200, 'critic_loss':     0.1570, 'actor_loss':    -0.0755, 'eps_e':     0.0200})
Step:  452000, Reward:   124.604 [   0.841], Avg:   109.940 (0.020) <0-04:46:42> ({'r_t':  1204.9736, 'eps':     0.0200, 'critic_loss':     0.0986, 'actor_loss':    -0.0793, 'eps_e':     0.0200})
Step:  453000, Reward:   124.955 [   0.516], Avg:   109.973 (0.020) <0-04:47:18> ({'r_t':  1209.6744, 'eps':     0.0200, 'critic_loss':     0.0772, 'actor_loss':    -0.0688, 'eps_e':     0.0200})
Step:  454000, Reward:   124.378 [   0.723], Avg:   110.005 (0.020) <0-04:47:54> ({'r_t':  1228.3831, 'eps':     0.0200, 'critic_loss':     0.0753, 'actor_loss':    -0.0678, 'eps_e':     0.0200})
Step:  455000, Reward:   124.689 [   0.854], Avg:   110.037 (0.020) <0-04:48:31> ({'r_t':  1207.4388, 'eps':     0.0200, 'critic_loss':     0.0791, 'actor_loss':    -0.0637, 'eps_e':     0.0200})
Step:  456000, Reward:   123.928 [   1.119], Avg:   110.067 (0.020) <0-04:49:07> ({'r_t':  1199.4736, 'eps':     0.0200, 'critic_loss':     0.0748, 'actor_loss':    -0.0624, 'eps_e':     0.0200})
Step:  457000, Reward:   125.025 [   0.657], Avg:   110.100 (0.020) <0-04:49:43> ({'r_t':  1218.8573, 'eps':     0.0200, 'critic_loss':     0.0631, 'actor_loss':    -0.0592, 'eps_e':     0.0200})
Step:  458000, Reward:   124.881 [   0.720], Avg:   110.132 (0.020) <0-04:50:19> ({'r_t':  1221.0206, 'eps':     0.0200, 'critic_loss':     0.0620, 'actor_loss':    -0.0540, 'eps_e':     0.0200})
Step:  459000, Reward:   124.759 [   0.650], Avg:   110.164 (0.020) <0-04:50:55> ({'r_t':  1204.0814, 'eps':     0.0200, 'critic_loss':     0.0723, 'actor_loss':    -0.0545, 'eps_e':     0.0200})
Step:  460000, Reward:   124.857 [   0.710], Avg:   110.196 (0.020) <0-04:51:32> ({'r_t':  1196.1887, 'eps':     0.0200, 'critic_loss':     0.0726, 'actor_loss':    -0.0538, 'eps_e':     0.0200})
Step:  461000, Reward:   123.772 [   0.733], Avg:   110.225 (0.020) <0-04:52:08> ({'r_t':  1221.7146, 'eps':     0.0200, 'critic_loss':     0.0695, 'actor_loss':    -0.0549, 'eps_e':     0.0200})
Step:  462000, Reward:   125.177 [   0.455], Avg:   110.257 (0.020) <0-04:52:44> ({'r_t':  1210.6781, 'eps':     0.0200, 'critic_loss':     0.0725, 'actor_loss':    -0.0569, 'eps_e':     0.0200})
Step:  463000, Reward:   125.078 [   0.610], Avg:   110.289 (0.020) <0-04:53:20> ({'r_t':  1194.9027, 'eps':     0.0200, 'critic_loss':     0.0701, 'actor_loss':    -0.0547, 'eps_e':     0.0200})
Step:  464000, Reward:   125.338 [   0.619], Avg:   110.322 (0.020) <0-04:53:57> ({'r_t':  1215.4320, 'eps':     0.0200, 'critic_loss':     0.0730, 'actor_loss':    -0.0556, 'eps_e':     0.0200})
Step:  465000, Reward:   124.301 [   0.627], Avg:   110.352 (0.020) <0-04:54:33> ({'r_t':  1224.2129, 'eps':     0.0200, 'critic_loss':     0.0720, 'actor_loss':    -0.0521, 'eps_e':     0.0200})
Step:  466000, Reward:   125.435 [   0.724], Avg:   110.384 (0.020) <0-04:55:09> ({'r_t':  1204.8943, 'eps':     0.0200, 'critic_loss':     0.0687, 'actor_loss':    -0.0552, 'eps_e':     0.0200})
Step:  467000, Reward:   124.774 [   0.446], Avg:   110.415 (0.020) <0-04:55:45> ({'r_t':  1200.0743, 'eps':     0.0200, 'critic_loss':     0.0653, 'actor_loss':    -0.0534, 'eps_e':     0.0200})
Step:  468000, Reward:   125.069 [   0.441], Avg:   110.446 (0.020) <0-04:56:22> ({'r_t':  1223.7321, 'eps':     0.0200, 'critic_loss':     0.0586, 'actor_loss':    -0.0494, 'eps_e':     0.0200})
Step:  469000, Reward:   124.148 [   0.959], Avg:   110.475 (0.020) <0-04:56:58> ({'r_t':  1221.1590, 'eps':     0.0200, 'critic_loss':     0.0563, 'actor_loss':    -0.0494, 'eps_e':     0.0200})
Step:  470000, Reward:   124.902 [   0.717], Avg:   110.506 (0.020) <0-04:57:34> ({'r_t':  1186.3989, 'eps':     0.0200, 'critic_loss':     0.0564, 'actor_loss':    -0.0436, 'eps_e':     0.0200})
Step:  471000, Reward:   124.781 [   0.568], Avg:   110.536 (0.020) <0-04:58:10> ({'r_t':  1215.6345, 'eps':     0.0200, 'critic_loss':     0.0731, 'actor_loss':    -0.0442, 'eps_e':     0.0200})
Step:  472000, Reward:   124.712 [   0.518], Avg:   110.566 (0.020) <0-04:58:47> ({'r_t':  1199.4281, 'eps':     0.0200, 'critic_loss':     0.1191, 'actor_loss':    -0.0466, 'eps_e':     0.0200})
Step:  473000, Reward:   124.410 [   1.121], Avg:   110.595 (0.020) <0-04:59:23> ({'r_t':  1182.3943, 'eps':     0.0200, 'critic_loss':     0.1536, 'actor_loss':    -0.0529, 'eps_e':     0.0200})
Step:  474000, Reward:   122.345 [   2.388], Avg:   110.620 (0.020) <0-04:59:59> ({'r_t':  1198.1101, 'eps':     0.0200, 'critic_loss':     0.1587, 'actor_loss':    -0.0549, 'eps_e':     0.0200})
Step:  475000, Reward:   124.447 [   1.124], Avg:   110.649 (0.020) <0-05:00:37> ({'r_t':  1216.7670, 'eps':     0.0200, 'critic_loss':     0.1645, 'actor_loss':    -0.0705, 'eps_e':     0.0200})
Step:  476000, Reward:   123.959 [   1.140], Avg:   110.677 (0.020) <0-05:01:13> ({'r_t':  1223.8406, 'eps':     0.0200, 'critic_loss':     0.1440, 'actor_loss':    -0.0727, 'eps_e':     0.0200})
Step:  477000, Reward:   125.309 [   0.510], Avg:   110.708 (0.020) <0-05:01:49> ({'r_t':  1202.7315, 'eps':     0.0200, 'critic_loss':     0.1763, 'actor_loss':    -0.0676, 'eps_e':     0.0200})
Step:  478000, Reward:   125.114 [   0.713], Avg:   110.738 (0.020) <0-05:02:26> ({'r_t':  1219.9084, 'eps':     0.0200, 'critic_loss':     0.1343, 'actor_loss':    -0.0716, 'eps_e':     0.0200})
Step:  479000, Reward:   124.200 [   0.949], Avg:   110.766 (0.020) <0-05:03:02> ({'r_t':  1218.0625, 'eps':     0.0200, 'critic_loss':     0.0927, 'actor_loss':    -0.0643, 'eps_e':     0.0200})
Step:  480000, Reward:   124.480 [   0.523], Avg:   110.794 (0.020) <0-05:03:38> ({'r_t':  1213.5466, 'eps':     0.0200, 'critic_loss':     0.0789, 'actor_loss':    -0.0600, 'eps_e':     0.0200})
Step:  481000, Reward:   124.132 [   0.766], Avg:   110.822 (0.020) <0-05:04:14> ({'r_t':  1206.0845, 'eps':     0.0200, 'critic_loss':     0.0622, 'actor_loss':    -0.0579, 'eps_e':     0.0200})
Step:  482000, Reward:   123.253 [   1.212], Avg:   110.848 (0.020) <0-05:04:51> ({'r_t':  1217.8612, 'eps':     0.0200, 'critic_loss':     0.0620, 'actor_loss':    -0.0534, 'eps_e':     0.0200})
Step:  483000, Reward:   125.168 [   0.598], Avg:   110.877 (0.020) <0-05:05:27> ({'r_t':  1225.1002, 'eps':     0.0200, 'critic_loss':     0.0529, 'actor_loss':    -0.0484, 'eps_e':     0.0200})
Step:  484000, Reward:   125.018 [   0.564], Avg:   110.906 (0.020) <0-05:06:03> ({'r_t':  1214.4406, 'eps':     0.0200, 'critic_loss':     0.0552, 'actor_loss':    -0.0466, 'eps_e':     0.0200})
Step:  485000, Reward:   124.816 [   0.481], Avg:   110.935 (0.020) <0-05:06:39> ({'r_t':  1209.7238, 'eps':     0.0200, 'critic_loss':     0.0687, 'actor_loss':    -0.0434, 'eps_e':     0.0200})
Step:  486000, Reward:   124.529 [   0.784], Avg:   110.963 (0.020) <0-05:07:15> ({'r_t':  1214.3321, 'eps':     0.0200, 'critic_loss':     0.0738, 'actor_loss':    -0.0429, 'eps_e':     0.0200})
Step:  487000, Reward:   123.043 [   1.244], Avg:   110.988 (0.020) <0-05:07:52> ({'r_t':  1212.0879, 'eps':     0.0200, 'critic_loss':     0.0782, 'actor_loss':    -0.0437, 'eps_e':     0.0200})
Step:  488000, Reward:   125.126 [   0.471], Avg:   111.016 (0.020) <0-05:08:28> ({'r_t':  1212.1220, 'eps':     0.0200, 'critic_loss':     0.0899, 'actor_loss':    -0.0452, 'eps_e':     0.0200})
Step:  489000, Reward:   125.124 [   0.947], Avg:   111.045 (0.020) <0-05:09:04> ({'r_t':  1217.4055, 'eps':     0.0200, 'critic_loss':     0.0947, 'actor_loss':    -0.0487, 'eps_e':     0.0200})
Step:  490000, Reward:   121.444 [   1.081], Avg:   111.066 (0.020) <0-05:09:40> ({'r_t':  1204.8751, 'eps':     0.0200, 'critic_loss':     0.0978, 'actor_loss':    -0.0473, 'eps_e':     0.0200})
Step:  491000, Reward:   125.268 [   0.467], Avg:   111.095 (0.020) <0-05:10:17> ({'r_t':  1219.7823, 'eps':     0.0200, 'critic_loss':     0.1078, 'actor_loss':    -0.0485, 'eps_e':     0.0200})
Step:  492000, Reward:   124.250 [   1.282], Avg:   111.122 (0.020) <0-05:10:53> ({'r_t':  1199.2492, 'eps':     0.0200, 'critic_loss':     0.1834, 'actor_loss':    -0.0484, 'eps_e':     0.0200})
Step:  493000, Reward:   123.645 [   1.083], Avg:   111.147 (0.020) <0-05:11:29> ({'r_t':  1207.1926, 'eps':     0.0200, 'critic_loss':     0.2110, 'actor_loss':    -0.0520, 'eps_e':     0.0200})
Step:  494000, Reward:   124.848 [   0.599], Avg:   111.175 (0.020) <0-05:12:05> ({'r_t':  1192.6501, 'eps':     0.0200, 'critic_loss':     0.2524, 'actor_loss':    -0.0555, 'eps_e':     0.0200})
Step:  495000, Reward:   124.692 [   0.557], Avg:   111.202 (0.020) <0-05:12:41> ({'r_t':  1215.8032, 'eps':     0.0200, 'critic_loss':     0.2788, 'actor_loss':    -0.0679, 'eps_e':     0.0200})
Step:  496000, Reward:   123.996 [   0.779], Avg:   111.228 (0.020) <0-05:13:18> ({'r_t':  1191.5495, 'eps':     0.0200, 'critic_loss':     0.3748, 'actor_loss':    -0.0650, 'eps_e':     0.0200})
Step:  497000, Reward:   124.407 [   0.473], Avg:   111.255 (0.020) <0-05:13:54> ({'r_t':  1206.2442, 'eps':     0.0200, 'critic_loss':     0.6223, 'actor_loss':    -0.0774, 'eps_e':     0.0200})
Step:  498000, Reward:   121.956 [   0.574], Avg:   111.276 (0.020) <0-05:14:30> ({'r_t':  1203.0661, 'eps':     0.0200, 'critic_loss':     0.7096, 'actor_loss':    -0.0853, 'eps_e':     0.0200})
Step:  499000, Reward:   123.781 [   0.697], Avg:   111.301 (0.020) <0-05:15:06> ({'r_t':  1205.4194, 'eps':     0.0200, 'critic_loss':     0.6062, 'actor_loss':    -0.0982, 'eps_e':     0.0200})
Step:  500000, Reward:   123.852 [   0.804], Avg:   111.326 (0.020) <0-05:15:43> ({'r_t':  1200.7668, 'eps':     0.0200, 'critic_loss':     0.7339, 'actor_loss':    -0.0976, 'eps_e':     0.0200})
