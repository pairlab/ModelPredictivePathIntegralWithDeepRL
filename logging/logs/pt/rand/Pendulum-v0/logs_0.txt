Model: <class 'src.utils.rand.RandomAgent'>, Env: Pendulum-v0, Date: 06/06/2020 22:23:28
CPU: 4 Core, 2.2GHz, 16.0 GB, Darwin-18.7.0-x86_64-i386-64bit
Git URL: git@github.com:shawnmanuel000/ModelPredictivePathIntegralWithDeepRL.git
Hash: df05964fa4262840095e5c93d6ca54a9f32dc498
Branch: master

config: 
   TRIAL_AT = 1000
   SAVE_AT = 1
   SEED = 0
   REG_LAMBDA = 1e-06
   LEARN_RATE = 0.0001
   DISCOUNT_RATE = 0.99
   ADVANTAGE_DECAY = 0.95
   INPUT_LAYER = 512
   ACTOR_HIDDEN = 256
   CRITIC_HIDDEN = 1024
   EPS_MAX = 1.0
   EPS_MIN = 0.1
   EPS_DECAY = 0.998
   NUM_STEPS = 500
   MAX_BUFFER_SIZE = 1000000
   REPLAY_BATCH_SIZE = 32
   TARGET_UPDATE_RATE = 0.0004
   dynamics_size = 3
   state_size = (3,)
   action_size = (1,)
   env_name = Pendulum-v0
   rank = 0
   size = 1
   split = 1
   model = rand
   framework = pt
   train_prop = 1.0
   tcp_ports = []
   tcp_rank = 0
   num_envs = 1
   nsteps = 500000
   render = False
   trial = False
   icm = False
   rs = False,
num_envs: 0,
envs: <src.utils.envs.EnsembleEnv object at 0x13b135650> 
	num_envs = 1
	env = <GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>> 
		env = <TimeLimit<PendulumEnv<Pendulum-v0>>> 
			env = <PendulumEnv<Pendulum-v0>> 
				max_speed = 8
				max_torque = 2.0
				dt = 0.05
				g = 10.0
				m = 1.0
				l = 1.0
				viewer = None
				action_space = Box(1,) 
					dtype = float32
					shape = (1,)
					low = [-2.000]
					high = [ 2.000]
					bounded_below = [ True]
					bounded_above = [ True]
					np_random = RandomState(MT19937)
				observation_space = Box(3,) 
					dtype = float32
					shape = (3,)
					low = [-1.000 -1.000 -8.000]
					high = [ 1.000  1.000  8.000]
					bounded_below = [ True  True  True]
					bounded_above = [ True  True  True]
					np_random = RandomState(MT19937)
				np_random = RandomState(MT19937)
				spec = EnvSpec(Pendulum-v0) 
					id = Pendulum-v0
					entry_point = gym.envs.classic_control:PendulumEnv
					reward_threshold = None
					nondeterministic = False
					max_episode_steps = 200
				verbose = 0
			action_space = Box(1,) 
				dtype = float32
				shape = (1,)
				low = [-2.000]
				high = [ 2.000]
				bounded_below = [ True]
				bounded_above = [ True]
				np_random = RandomState(MT19937)
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
			reward_range = (-inf, inf)
			metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		action_space = Box(1,) 
			dtype = float32
			shape = (1,)
			low = [-2.000]
			high = [ 2.000]
			bounded_below = [ True]
			bounded_above = [ True]
			np_random = RandomState(MT19937)
		observation_space = Box(3,) 
			dtype = float32
			shape = (3,)
			low = [-1.000 -1.000 -8.000]
			high = [ 1.000  1.000  8.000]
			bounded_below = [ True  True  True]
			bounded_above = [ True  True  True]
			np_random = RandomState(MT19937)
		reward_range = (-inf, inf)
		metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}
		preprocess = <src.envs.wrappers.RawPreprocess object at 0x13b428790> 
			observation_space = Box(3,) 
				dtype = float32
				shape = (3,)
				low = [-1.000 -1.000 -8.000]
				high = [ 1.000  1.000  8.000]
				bounded_below = [ True  True  True]
				bounded_above = [ True  True  True]
				np_random = RandomState(MT19937)
	envs = [<GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>>]
	test_envs = [<GymEnv<TimeLimit<PendulumEnv<Pendulum-v0>>>>]
	state_size = (3,)
	action_size = (1,)
	action_space = Box(1,) 
		dtype = float32
		shape = (1,)
		low = [-2.000]
		high = [ 2.000]
		bounded_below = [ True]
		bounded_above = [ True]
		np_random = RandomState(MT19937)
	max_steps = 200,
agent: <src.models.wrappers.ParallelAgent object at 0x13b0728d0> 
	icm = None
	stack = <src.models.wrappers.RawState object at 0x13b467dd0> 
		state_size = (3,)
	agent = <src.utils.rand.RandomAgent object at 0x13b467e10> 
		noise_process = <src.utils.rand.BrownianNoise object at 0x13b467e50> 
			size = (1,)
			dt = 0.2
			action = [ 0.359]
			daction_dt = [ 1.927]
		discrete = False
		action_size = (1,)
		state_size = (3,)
		config = <src.utils.config.Config object at 0x13ae8fc50> 
			TRIAL_AT = 1000
			SAVE_AT = 1
			SEED = 0
			REG_LAMBDA = 1e-06
			LEARN_RATE = 0.0001
			DISCOUNT_RATE = 0.99
			ADVANTAGE_DECAY = 0.95
			INPUT_LAYER = 512
			ACTOR_HIDDEN = 256
			CRITIC_HIDDEN = 1024
			EPS_MAX = 1.0
			EPS_MIN = 0.1
			EPS_DECAY = 0.998
			NUM_STEPS = 500
			MAX_BUFFER_SIZE = 1000000
			REPLAY_BATCH_SIZE = 32
			TARGET_UPDATE_RATE = 0.0004
			dynamics_size = 3
			state_size = (3,)
			action_size = (1,)
			env_name = Pendulum-v0
			rank = 0
			size = 1
			split = 1
			model = rand
			framework = pt
			train_prop = 1.0
			tcp_ports = []
			tcp_rank = 0
			num_envs = 1
			nsteps = 500000
			render = False
			trial = False
			icm = False
			rs = False
		stats = <src.utils.logger.Stats object at 0x13b467e90> 
			mean_dict = {}
			sum_dict = {}
		eps = 1.0
	noise_process = <src.utils.rand.BrownianNoise object at 0x13b467ed0> 
		size = (1,)
		dt = 0.2
		action = [-0.337]
		daction_dt = [-0.747]
	discrete = False
	action_size = (1,)
	state_size = (3,)
	config = <src.utils.config.Config object at 0x13ae8fc50> 
		TRIAL_AT = 1000
		SAVE_AT = 1
		SEED = 0
		REG_LAMBDA = 1e-06
		LEARN_RATE = 0.0001
		DISCOUNT_RATE = 0.99
		ADVANTAGE_DECAY = 0.95
		INPUT_LAYER = 512
		ACTOR_HIDDEN = 256
		CRITIC_HIDDEN = 1024
		EPS_MAX = 1.0
		EPS_MIN = 0.1
		EPS_DECAY = 0.998
		NUM_STEPS = 500
		MAX_BUFFER_SIZE = 1000000
		REPLAY_BATCH_SIZE = 32
		TARGET_UPDATE_RATE = 0.0004
		dynamics_size = 3
		state_size = (3,)
		action_size = (1,)
		env_name = Pendulum-v0
		rank = 0
		size = 1
		split = 1
		model = rand
		framework = pt
		train_prop = 1.0
		tcp_ports = []
		tcp_rank = 0
		num_envs = 1
		nsteps = 500000
		render = False
		trial = False
		icm = False
		rs = False
	stats = <src.utils.logger.Stats object at 0x13b467f10> 
		mean_dict = {}
		sum_dict = {},
conn: None,

import math
import random
import numpy as np
from collections import deque
from operator import itemgetter
from src.utils.logger import Stats
from src.envs.Gym.gym.spaces import Discrete, MultiDiscrete

class Noise():
	def __init__(self, size):
		self.size = size

	def reset(self):
		pass

	def sample(self, shape=[], scale=1):
		return scale * np.random.randn(*shape, *self.size)

class OUNoise(Noise):
	def __init__(self, size, scale=0.1, mu=0, theta=0.15, sigma=0.2):
		self.size = size
		self.scale = scale
		self.mu = mu
		self.theta = theta
		self.sigma = sigma
		self.state = np.ones(*self.size) * self.mu
		self.reset()

	def reset(self, shape=[]):
		self.state = np.ones(*shape, *self.size) * self.mu

	def sample(self, shape=[], scale=1):
		delta = self.sigma * np.random.randn(*self.state.shape)
		if self.state.shape != delta.shape: self.reset(shape)
		x = self.state
		dx = self.theta * (self.mu - x) + delta
		self.state = x + dx
		return self.state * self.scale

class BrownianNoise(Noise):
	def __init__(self, size, dt=0.2):
		self.size = size
		self.dt = dt
		self.reset()

	def reset(self):
		self.action = np.clip(np.random.randn(*self.size), -1, 1)
		self.daction_dt = np.random.randn(*self.size)

	def sample(self, shape=[], scale=1):
		self.daction_dt = np.random.randn(*shape, *self.size)
		self.action = np.zeros_like(self.daction_dt) if self.action.shape != self.daction_dt.shape else self.action
		self.action = np.clip(self.action + math.sqrt(self.dt) * self.daction_dt, -1, 1)
		return self.action * scale

class RandomAgent():
	def __init__(self, state_size, action_size, config=None, eps=1.0, **kwargs):
		self.noise_process = BrownianNoise(action_size)
		self.discrete = type(action_size) != tuple
		self.action_size = action_size
		self.state_size = state_size
		self.config = config
		self.stats = Stats()
		self.eps = config.EPS_MAX if config else eps

	def get_action(self, state, eps=None, sample=True):
		return self.noise_process.sample(state.shape[:-len(self.state_size)])

	def get_env_action(self, env, state=None, eps=None, sample=True, **kwargs):
		action = self.get_action(state, eps, sample, **kwargs)
		env_action = self.to_env_action(env.action_space, action)
		return env_action, action

	@staticmethod
	def to_env_action(action_space, action):
		if type(action_space) == list: return [RandomAgent.to_env_action(a_space, a) for a_space,a in zip(action_space, action)]
		if type(action_space) in [Discrete, MultiDiscrete]: return np.argmax(action, -1)
		return action_space.low + np.multiply((1+action)/2, action_space.high - action_space.low)

	def train(self, state, action, next_state, reward, done):
		if np.any(done): self.noise_process.reset()

	def get_stats(self):
		return {**self.stats.get_stats(), "eps": self.eps}

class ReplayBuffer():
	def __init__(self, maxlen=None):
		self.buffer = deque(maxlen=int(maxlen))
		
	def add(self, experience):
		self.buffer.append(experience)
		return self

	def extend(self, experiences, shuffle=False):
		if shuffle: random.shuffle(experiences)
		for exp in experiences:
			self.add(exp)
		return self

	def clear(self):
		self.buffer.clear()
		return self
		
	def sample(self, batch_size, dtype=np.array, weights=None):
		sample_size = min(len(self.buffer), batch_size)
		sample_indices = random.choices(range(len(self.buffer)), k=sample_size, weights=weights)
		samples = itemgetter(*sample_indices)(self.buffer)
		sample_arrays = samples if dtype is None else map(dtype, zip(*samples))
		return sample_arrays, sample_indices, np.array([1])

	def next_batch(self, batch_size=1, dtype=np.array):
		if not hasattr(self, "i_batch"): self.i_batch = 0
		sample_indices = [i%len(self.buffer) for i in range(self.i_batch, self.i_batch+batch_size)]
		samples = itemgetter(*sample_indices)(self.buffer)
		self.i_batch = (self.i_batch+batch_size) % len(self.buffer)
		sample_arrays = samples if dtype is None else map(dtype, zip(*samples))
		return sample_arrays, sample_indices, np.array([1])

	def update_priorities(self, indices, errors, offset=0.1):
		pass

	def reset_priorities(self):
		pass

	def __len__(self):
		return len(self.buffer)

class PrioritizedReplayBuffer(ReplayBuffer):
	def __init__(self, maxlen=None):
		super().__init__(maxlen)
		self.priorities = deque(maxlen=maxlen)
		
	def add(self, experience):
		super().add(experience)
		self.priorities.append(max(self.priorities, default=1))
		return self

	def clear(self):
		super().clear()
		self.priorities.clear()
		return self
		
	def get_probabilities(self, priority_scale):
		scaled_priorities = np.array(self.priorities) ** priority_scale
		sample_probabilities = scaled_priorities / sum(scaled_priorities)
		return sample_probabilities
	
	def get_importance(self, probabilities):
		importance = 1/len(self.buffer) * 1/probabilities
		importance_normalized = importance / max(importance)
		return importance_normalized[:,np.newaxis]
		
	def sample(self, batch_size, dtype=np.array, priority_scale=0.5):
		sample_probs = self.get_probabilities(priority_scale)
		samples, sample_indices, _ = super().sample(batch_size, None, sample_probs)
		importance = self.get_importance(sample_probs[sample_indices])
		return map(dtype, zip(*samples)), sample_indices, np.array(importance)
						
	def update_priorities(self, indices, errors, offset=0.1):
		for i,e in zip(indices, errors):
			self.priorities[i] = abs(e) + offset

	def reset_priorities(self):
		for i in range(len(self.priorities)):
			self.priorities[i] = 1


Step:       0, Reward:  -985.048 [   0.000], Avg:  -985.048 (1.000) <0-00:00:00> ({'r_t':    -9.3591, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    1000, Reward: -1280.500 [   0.000], Avg: -1132.774 (1.000) <0-00:00:00> ({'r_t': -6962.0945, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    2000, Reward: -1221.440 [   0.000], Avg: -1162.329 (1.000) <0-00:00:00> ({'r_t': -6573.3311, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    3000, Reward: -1572.633 [   0.000], Avg: -1264.905 (1.000) <0-00:00:01> ({'r_t': -5842.4521, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    4000, Reward: -1136.336 [   0.000], Avg: -1239.191 (1.000) <0-00:00:01> ({'r_t': -6185.9720, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    5000, Reward: -1116.108 [   0.000], Avg: -1218.677 (1.000) <0-00:00:01> ({'r_t': -6635.0523, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    6000, Reward:  -920.413 [   0.000], Avg: -1176.068 (1.000) <0-00:00:02> ({'r_t': -6561.1607, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    7000, Reward: -1305.637 [   0.000], Avg: -1192.264 (1.000) <0-00:00:02> ({'r_t': -5943.8451, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    8000, Reward: -1316.376 [   0.000], Avg: -1206.054 (1.000) <0-00:00:03> ({'r_t': -5505.2721, 'eps':     1.0000, 'eps_e':     1.0000})
Step:    9000, Reward: -1110.378 [   0.000], Avg: -1196.487 (1.000) <0-00:00:03> ({'r_t': -5779.6127, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   10000, Reward: -1157.424 [   0.000], Avg: -1192.936 (1.000) <0-00:00:03> ({'r_t': -6448.6665, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   11000, Reward: -1452.903 [   0.000], Avg: -1214.600 (1.000) <0-00:00:04> ({'r_t': -6301.0467, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   12000, Reward: -1339.891 [   0.000], Avg: -1224.237 (1.000) <0-00:00:04> ({'r_t': -5640.1888, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   13000, Reward: -1208.432 [   0.000], Avg: -1223.108 (1.000) <0-00:00:05> ({'r_t': -5762.4222, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   14000, Reward: -1407.689 [   0.000], Avg: -1235.414 (1.000) <0-00:00:05> ({'r_t': -6459.1550, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   15000, Reward: -1017.042 [   0.000], Avg: -1221.766 (1.000) <0-00:00:05> ({'r_t': -5603.0978, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   16000, Reward: -1101.985 [   0.000], Avg: -1214.720 (1.000) <0-00:00:06> ({'r_t': -5887.7227, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   17000, Reward: -1206.728 [   0.000], Avg: -1214.276 (1.000) <0-00:00:06> ({'r_t': -6031.2256, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   18000, Reward: -1033.936 [   0.000], Avg: -1204.784 (1.000) <0-00:00:07> ({'r_t': -6237.4167, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   19000, Reward: -1134.832 [   0.000], Avg: -1201.286 (1.000) <0-00:00:07> ({'r_t': -6480.6864, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   20000, Reward: -1212.023 [   0.000], Avg: -1201.798 (1.000) <0-00:00:07> ({'r_t': -5930.0427, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   21000, Reward: -1211.495 [   0.000], Avg: -1202.239 (1.000) <0-00:00:08> ({'r_t': -5899.3407, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   22000, Reward: -1223.963 [   0.000], Avg: -1203.183 (1.000) <0-00:00:08> ({'r_t': -6711.6674, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   23000, Reward: -1206.274 [   0.000], Avg: -1203.312 (1.000) <0-00:00:08> ({'r_t': -6137.6678, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   24000, Reward: -1360.336 [   0.000], Avg: -1209.593 (1.000) <0-00:00:09> ({'r_t': -6047.7338, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   25000, Reward: -1317.357 [   0.000], Avg: -1213.738 (1.000) <0-00:00:09> ({'r_t': -5857.5766, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   26000, Reward:  -949.204 [   0.000], Avg: -1203.940 (1.000) <0-00:00:10> ({'r_t': -6379.8392, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   27000, Reward: -1042.594 [   0.000], Avg: -1198.178 (1.000) <0-00:00:10> ({'r_t': -6448.9593, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   28000, Reward: -1074.067 [   0.000], Avg: -1193.898 (1.000) <0-00:00:10> ({'r_t': -6301.7169, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   29000, Reward: -1340.600 [   0.000], Avg: -1198.788 (1.000) <0-00:00:11> ({'r_t': -6232.4665, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   30000, Reward: -1274.822 [   0.000], Avg: -1201.241 (1.000) <0-00:00:11> ({'r_t': -5918.6512, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   31000, Reward: -1139.587 [   0.000], Avg: -1199.314 (1.000) <0-00:00:12> ({'r_t': -6405.2711, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   32000, Reward: -1389.677 [   0.000], Avg: -1205.083 (1.000) <0-00:00:12> ({'r_t': -6607.0081, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   33000, Reward: -1635.292 [   0.000], Avg: -1217.736 (1.000) <0-00:00:12> ({'r_t': -6082.1119, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   34000, Reward: -1389.513 [   0.000], Avg: -1222.644 (1.000) <0-00:00:13> ({'r_t': -5892.5050, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   35000, Reward: -1488.150 [   0.000], Avg: -1230.019 (1.000) <0-00:00:13> ({'r_t': -6082.3902, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   36000, Reward: -1149.829 [   0.000], Avg: -1227.852 (1.000) <0-00:00:13> ({'r_t': -5949.5708, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   37000, Reward: -1109.888 [   0.000], Avg: -1224.747 (1.000) <0-00:00:14> ({'r_t': -6125.6865, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   38000, Reward: -1094.035 [   0.000], Avg: -1221.396 (1.000) <0-00:00:14> ({'r_t': -5959.8219, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   39000, Reward: -1368.046 [   0.000], Avg: -1225.062 (1.000) <0-00:00:15> ({'r_t': -5594.4476, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   40000, Reward: -1175.714 [   0.000], Avg: -1223.858 (1.000) <0-00:00:15> ({'r_t': -6458.0280, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   41000, Reward: -1685.903 [   0.000], Avg: -1234.859 (1.000) <0-00:00:15> ({'r_t': -6342.4694, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   42000, Reward: -1362.131 [   0.000], Avg: -1237.819 (1.000) <0-00:00:16> ({'r_t': -6321.2876, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   43000, Reward: -1093.407 [   0.000], Avg: -1234.537 (1.000) <0-00:00:16> ({'r_t': -5898.7060, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   44000, Reward: -1160.158 [   0.000], Avg: -1232.884 (1.000) <0-00:00:16> ({'r_t': -6166.8228, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   45000, Reward: -1406.318 [   0.000], Avg: -1236.655 (1.000) <0-00:00:17> ({'r_t': -6826.6268, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   46000, Reward: -1209.224 [   0.000], Avg: -1236.071 (1.000) <0-00:00:17> ({'r_t': -6304.1931, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   47000, Reward: -1087.207 [   0.000], Avg: -1232.970 (1.000) <0-00:00:18> ({'r_t': -5502.0480, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   48000, Reward: -1376.753 [   0.000], Avg: -1235.904 (1.000) <0-00:00:18> ({'r_t': -6352.2106, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   49000, Reward: -1270.829 [   0.000], Avg: -1236.602 (1.000) <0-00:00:18> ({'r_t': -6044.2608, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   50000, Reward: -1139.620 [   0.000], Avg: -1234.701 (1.000) <0-00:00:19> ({'r_t': -6718.6185, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   51000, Reward: -1175.350 [   0.000], Avg: -1233.559 (1.000) <0-00:00:19> ({'r_t': -6085.7212, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   52000, Reward: -1330.924 [   0.000], Avg: -1235.397 (1.000) <0-00:00:20> ({'r_t': -6065.0796, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   53000, Reward:  -956.081 [   0.000], Avg: -1230.224 (1.000) <0-00:00:20> ({'r_t': -6434.5582, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   54000, Reward: -1191.559 [   0.000], Avg: -1229.521 (1.000) <0-00:00:21> ({'r_t': -6209.3742, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   55000, Reward: -1283.459 [   0.000], Avg: -1230.484 (1.000) <0-00:00:21> ({'r_t': -5991.5378, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   56000, Reward: -1283.508 [   0.000], Avg: -1231.414 (1.000) <0-00:00:21> ({'r_t': -6045.0614, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   57000, Reward: -1019.442 [   0.000], Avg: -1227.760 (1.000) <0-00:00:22> ({'r_t': -6074.8678, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   58000, Reward: -1664.469 [   0.000], Avg: -1235.162 (1.000) <0-00:00:22> ({'r_t': -6619.9300, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   59000, Reward: -1420.562 [   0.000], Avg: -1238.252 (1.000) <0-00:00:23> ({'r_t': -5893.6364, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   60000, Reward: -1371.106 [   0.000], Avg: -1240.430 (1.000) <0-00:00:23> ({'r_t': -5925.2113, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   61000, Reward: -1383.977 [   0.000], Avg: -1242.745 (1.000) <0-00:00:23> ({'r_t': -5999.1482, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   62000, Reward: -1322.687 [   0.000], Avg: -1244.014 (1.000) <0-00:00:24> ({'r_t': -6036.7206, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   63000, Reward: -1557.371 [   0.000], Avg: -1248.910 (1.000) <0-00:00:24> ({'r_t': -6645.2262, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   64000, Reward: -1061.535 [   0.000], Avg: -1246.027 (1.000) <0-00:00:25> ({'r_t': -6513.0061, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   65000, Reward: -1252.109 [   0.000], Avg: -1246.119 (1.000) <0-00:00:25> ({'r_t': -6599.4802, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   66000, Reward: -1080.918 [   0.000], Avg: -1243.654 (1.000) <0-00:00:25> ({'r_t': -4959.5180, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   67000, Reward: -1069.455 [   0.000], Avg: -1241.092 (1.000) <0-00:00:26> ({'r_t': -6687.9988, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   68000, Reward: -1400.032 [   0.000], Avg: -1243.395 (1.000) <0-00:00:26> ({'r_t': -6918.8858, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   69000, Reward: -1374.751 [   0.000], Avg: -1245.272 (1.000) <0-00:00:26> ({'r_t': -6418.9450, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   70000, Reward: -1168.886 [   0.000], Avg: -1244.196 (1.000) <0-00:00:27> ({'r_t': -6190.6252, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   71000, Reward: -1190.828 [   0.000], Avg: -1243.455 (1.000) <0-00:00:27> ({'r_t': -6019.2467, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   72000, Reward: -1215.211 [   0.000], Avg: -1243.068 (1.000) <0-00:00:28> ({'r_t': -6176.9781, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   73000, Reward: -1263.492 [   0.000], Avg: -1243.344 (1.000) <0-00:00:28> ({'r_t': -6275.7380, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   74000, Reward: -1401.451 [   0.000], Avg: -1245.452 (1.000) <0-00:00:28> ({'r_t': -5790.1507, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   75000, Reward: -1202.883 [   0.000], Avg: -1244.892 (1.000) <0-00:00:29> ({'r_t': -6086.0870, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   76000, Reward: -1161.064 [   0.000], Avg: -1243.803 (1.000) <0-00:00:29> ({'r_t': -6036.4939, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   77000, Reward: -1124.399 [   0.000], Avg: -1242.272 (1.000) <0-00:00:30> ({'r_t': -6406.2213, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   78000, Reward: -1197.386 [   0.000], Avg: -1241.704 (1.000) <0-00:00:30> ({'r_t': -6016.6088, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   79000, Reward: -1117.695 [   0.000], Avg: -1240.154 (1.000) <0-00:00:30> ({'r_t': -6533.6231, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   80000, Reward: -1293.658 [   0.000], Avg: -1240.815 (1.000) <0-00:00:31> ({'r_t': -6589.3324, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   81000, Reward: -1141.817 [   0.000], Avg: -1239.607 (1.000) <0-00:00:31> ({'r_t': -6249.9709, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   82000, Reward: -1253.306 [   0.000], Avg: -1239.772 (1.000) <0-00:00:31> ({'r_t': -6170.5478, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   83000, Reward: -1160.280 [   0.000], Avg: -1238.826 (1.000) <0-00:00:32> ({'r_t': -6125.3921, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   84000, Reward: -1259.835 [   0.000], Avg: -1239.073 (1.000) <0-00:00:32> ({'r_t': -5917.3652, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   85000, Reward: -1484.885 [   0.000], Avg: -1241.932 (1.000) <0-00:00:33> ({'r_t': -6482.9558, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   86000, Reward: -1102.284 [   0.000], Avg: -1240.326 (1.000) <0-00:00:33> ({'r_t': -6904.4655, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   87000, Reward: -1222.695 [   0.000], Avg: -1240.126 (1.000) <0-00:00:33> ({'r_t': -5576.7042, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   88000, Reward: -1158.837 [   0.000], Avg: -1239.213 (1.000) <0-00:00:34> ({'r_t': -5773.8174, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   89000, Reward:  -895.795 [   0.000], Avg: -1235.397 (1.000) <0-00:00:34> ({'r_t': -6642.3466, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   90000, Reward: -1026.574 [   0.000], Avg: -1233.102 (1.000) <0-00:00:34> ({'r_t': -6451.8845, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   91000, Reward: -1084.149 [   0.000], Avg: -1231.483 (1.000) <0-00:00:35> ({'r_t': -6193.6946, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   92000, Reward: -1124.580 [   0.000], Avg: -1230.334 (1.000) <0-00:00:35> ({'r_t': -5859.3333, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   93000, Reward: -1293.585 [   0.000], Avg: -1231.007 (1.000) <0-00:00:36> ({'r_t': -6316.8090, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   94000, Reward: -1284.949 [   0.000], Avg: -1231.574 (1.000) <0-00:00:36> ({'r_t': -6194.4290, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   95000, Reward: -1399.303 [   0.000], Avg: -1233.322 (1.000) <0-00:00:36> ({'r_t': -5400.6915, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   96000, Reward: -1267.844 [   0.000], Avg: -1233.677 (1.000) <0-00:00:37> ({'r_t': -6181.9447, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   97000, Reward: -1144.670 [   0.000], Avg: -1232.769 (1.000) <0-00:00:37> ({'r_t': -6145.2344, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   98000, Reward: -1427.029 [   0.000], Avg: -1234.731 (1.000) <0-00:00:38> ({'r_t': -6447.9783, 'eps':     1.0000, 'eps_e':     1.0000})
Step:   99000, Reward: -1216.344 [   0.000], Avg: -1234.548 (1.000) <0-00:00:38> ({'r_t': -5842.6214, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  100000, Reward: -1396.265 [   0.000], Avg: -1236.149 (1.000) <0-00:00:38> ({'r_t': -6320.9002, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  101000, Reward: -1380.056 [   0.000], Avg: -1237.560 (1.000) <0-00:00:39> ({'r_t': -6272.6151, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  102000, Reward: -1262.827 [   0.000], Avg: -1237.805 (1.000) <0-00:00:39> ({'r_t': -6899.7991, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  103000, Reward: -1154.152 [   0.000], Avg: -1237.001 (1.000) <0-00:00:39> ({'r_t': -6209.5827, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  104000, Reward: -1133.310 [   0.000], Avg: -1236.013 (1.000) <0-00:00:40> ({'r_t': -6820.3656, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  105000, Reward: -1690.215 [   0.000], Avg: -1240.298 (1.000) <0-00:00:40> ({'r_t': -5750.9747, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  106000, Reward: -1193.795 [   0.000], Avg: -1239.863 (1.000) <0-00:00:41> ({'r_t': -5724.6815, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  107000, Reward: -1312.722 [   0.000], Avg: -1240.538 (1.000) <0-00:00:41> ({'r_t': -6440.9701, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  108000, Reward: -1111.092 [   0.000], Avg: -1239.350 (1.000) <0-00:00:41> ({'r_t': -5794.5433, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  109000, Reward: -1143.730 [   0.000], Avg: -1238.481 (1.000) <0-00:00:42> ({'r_t': -6327.0030, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  110000, Reward: -1198.395 [   0.000], Avg: -1238.120 (1.000) <0-00:00:42> ({'r_t': -6198.3352, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  111000, Reward: -1124.881 [   0.000], Avg: -1237.109 (1.000) <0-00:00:42> ({'r_t': -6173.3731, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  112000, Reward: -1211.571 [   0.000], Avg: -1236.883 (1.000) <0-00:00:43> ({'r_t': -6214.6685, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  113000, Reward: -1190.333 [   0.000], Avg: -1236.475 (1.000) <0-00:00:43> ({'r_t': -6543.3119, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  114000, Reward: -1055.088 [   0.000], Avg: -1234.897 (1.000) <0-00:00:44> ({'r_t': -6339.4071, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  115000, Reward: -1273.111 [   0.000], Avg: -1235.227 (1.000) <0-00:00:44> ({'r_t': -6091.1136, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  116000, Reward:  -917.661 [   0.000], Avg: -1232.512 (1.000) <0-00:00:44> ({'r_t': -6450.6191, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  117000, Reward: -1197.856 [   0.000], Avg: -1232.219 (1.000) <0-00:00:45> ({'r_t': -6285.8809, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  118000, Reward: -1521.069 [   0.000], Avg: -1234.646 (1.000) <0-00:00:45> ({'r_t': -6200.4343, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  119000, Reward: -1135.441 [   0.000], Avg: -1233.819 (1.000) <0-00:00:46> ({'r_t': -6061.3363, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  120000, Reward: -1088.094 [   0.000], Avg: -1232.615 (1.000) <0-00:00:46> ({'r_t': -5980.7701, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  121000, Reward: -1221.137 [   0.000], Avg: -1232.521 (1.000) <0-00:00:46> ({'r_t': -6438.4931, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  122000, Reward: -1254.873 [   0.000], Avg: -1232.703 (1.000) <0-00:00:47> ({'r_t': -5940.0094, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  123000, Reward: -1217.915 [   0.000], Avg: -1232.583 (1.000) <0-00:00:47> ({'r_t': -5744.5507, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  124000, Reward: -1093.840 [   0.000], Avg: -1231.473 (1.000) <0-00:00:47> ({'r_t': -6188.6079, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  125000, Reward: -1403.534 [   0.000], Avg: -1232.839 (1.000) <0-00:00:48> ({'r_t': -6485.7738, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  126000, Reward: -1056.059 [   0.000], Avg: -1231.447 (1.000) <0-00:00:48> ({'r_t': -5749.7953, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  127000, Reward: -1342.508 [   0.000], Avg: -1232.315 (1.000) <0-00:00:49> ({'r_t': -6395.1813, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  128000, Reward: -1263.641 [   0.000], Avg: -1232.558 (1.000) <0-00:00:49> ({'r_t': -6111.2914, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  129000, Reward: -1315.509 [   0.000], Avg: -1233.196 (1.000) <0-00:00:49> ({'r_t': -6899.0692, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  130000, Reward:  -999.212 [   0.000], Avg: -1231.410 (1.000) <0-00:00:50> ({'r_t': -6533.8489, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  131000, Reward: -1271.201 [   0.000], Avg: -1231.711 (1.000) <0-00:00:50> ({'r_t': -6298.8312, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  132000, Reward: -1159.042 [   0.000], Avg: -1231.165 (1.000) <0-00:00:50> ({'r_t': -6274.2423, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  133000, Reward: -1163.255 [   0.000], Avg: -1230.658 (1.000) <0-00:00:51> ({'r_t': -6365.6856, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  134000, Reward: -1149.883 [   0.000], Avg: -1230.059 (1.000) <0-00:00:51> ({'r_t': -5458.5325, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  135000, Reward: -1496.747 [   0.000], Avg: -1232.020 (1.000) <0-00:00:52> ({'r_t': -6826.5929, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  136000, Reward: -1229.635 [   0.000], Avg: -1232.003 (1.000) <0-00:00:52> ({'r_t': -6680.1213, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  137000, Reward: -1453.903 [   0.000], Avg: -1233.611 (1.000) <0-00:00:52> ({'r_t': -5883.7040, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  138000, Reward:  -976.329 [   0.000], Avg: -1231.760 (1.000) <0-00:00:53> ({'r_t': -5553.9526, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  139000, Reward: -1297.332 [   0.000], Avg: -1232.228 (1.000) <0-00:00:53> ({'r_t': -6291.1028, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  140000, Reward: -1410.438 [   0.000], Avg: -1233.492 (1.000) <0-00:00:54> ({'r_t': -6075.7195, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  141000, Reward: -1247.390 [   0.000], Avg: -1233.590 (1.000) <0-00:00:54> ({'r_t': -5651.7728, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  142000, Reward: -1150.846 [   0.000], Avg: -1233.012 (1.000) <0-00:00:54> ({'r_t': -5995.1578, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  143000, Reward: -1186.335 [   0.000], Avg: -1232.687 (1.000) <0-00:00:55> ({'r_t': -6221.0801, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  144000, Reward: -1207.290 [   0.000], Avg: -1232.512 (1.000) <0-00:00:55> ({'r_t': -6348.5039, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  145000, Reward: -1052.587 [   0.000], Avg: -1231.280 (1.000) <0-00:00:55> ({'r_t': -5943.6428, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  146000, Reward: -1155.792 [   0.000], Avg: -1230.766 (1.000) <0-00:00:56> ({'r_t': -5832.6064, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  147000, Reward: -1096.257 [   0.000], Avg: -1229.858 (1.000) <0-00:00:56> ({'r_t': -5983.1442, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  148000, Reward: -1208.615 [   0.000], Avg: -1229.715 (1.000) <0-00:00:57> ({'r_t': -6050.7289, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  149000, Reward: -1229.178 [   0.000], Avg: -1229.711 (1.000) <0-00:00:57> ({'r_t': -5974.4261, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  150000, Reward: -1241.216 [   0.000], Avg: -1229.788 (1.000) <0-00:00:57> ({'r_t': -6886.2074, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  151000, Reward: -1339.255 [   0.000], Avg: -1230.508 (1.000) <0-00:00:58> ({'r_t': -6422.6576, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  152000, Reward: -1504.415 [   0.000], Avg: -1232.298 (1.000) <0-00:00:58> ({'r_t': -5903.5345, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  153000, Reward: -1146.006 [   0.000], Avg: -1231.738 (1.000) <0-00:00:59> ({'r_t': -6465.3578, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  154000, Reward: -1107.739 [   0.000], Avg: -1230.938 (1.000) <0-00:00:59> ({'r_t': -6108.4950, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  155000, Reward: -1451.915 [   0.000], Avg: -1232.354 (1.000) <0-00:00:59> ({'r_t': -5858.4690, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  156000, Reward: -1319.074 [   0.000], Avg: -1232.907 (1.000) <0-00:01:00> ({'r_t': -6358.3973, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  157000, Reward: -1164.223 [   0.000], Avg: -1232.472 (1.000) <0-00:01:00> ({'r_t': -5670.0609, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  158000, Reward: -1503.294 [   0.000], Avg: -1234.175 (1.000) <0-00:01:00> ({'r_t': -6414.4369, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  159000, Reward:  -979.384 [   0.000], Avg: -1232.583 (1.000) <0-00:01:01> ({'r_t': -5940.3236, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  160000, Reward: -1328.924 [   0.000], Avg: -1233.181 (1.000) <0-00:01:01> ({'r_t': -6556.4319, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  161000, Reward:  -992.379 [   0.000], Avg: -1231.695 (1.000) <0-00:01:02> ({'r_t': -6697.3308, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  162000, Reward: -1126.378 [   0.000], Avg: -1231.049 (1.000) <0-00:01:02> ({'r_t': -6199.5935, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  163000, Reward: -1250.315 [   0.000], Avg: -1231.166 (1.000) <0-00:01:02> ({'r_t': -6013.1456, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  164000, Reward: -1130.755 [   0.000], Avg: -1230.557 (1.000) <0-00:01:03> ({'r_t': -6552.9153, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  165000, Reward: -1299.372 [   0.000], Avg: -1230.972 (1.000) <0-00:01:03> ({'r_t': -6155.1495, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  166000, Reward: -1528.589 [   0.000], Avg: -1232.754 (1.000) <0-00:01:03> ({'r_t': -6309.1298, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  167000, Reward: -1313.335 [   0.000], Avg: -1233.234 (1.000) <0-00:01:04> ({'r_t': -6163.3496, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  168000, Reward: -1232.328 [   0.000], Avg: -1233.228 (1.000) <0-00:01:04> ({'r_t': -6068.3516, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  169000, Reward: -1340.831 [   0.000], Avg: -1233.861 (1.000) <0-00:01:05> ({'r_t': -6480.6130, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  170000, Reward: -1020.565 [   0.000], Avg: -1232.614 (1.000) <0-00:01:05> ({'r_t': -6094.8358, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  171000, Reward: -1136.558 [   0.000], Avg: -1232.056 (1.000) <0-00:01:05> ({'r_t': -6295.7194, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  172000, Reward: -1026.555 [   0.000], Avg: -1230.868 (1.000) <0-00:01:06> ({'r_t': -6134.5981, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  173000, Reward: -1183.493 [   0.000], Avg: -1230.595 (1.000) <0-00:01:06> ({'r_t': -5825.9551, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  174000, Reward: -1190.414 [   0.000], Avg: -1230.366 (1.000) <0-00:01:06> ({'r_t': -6448.7796, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  175000, Reward: -1219.762 [   0.000], Avg: -1230.306 (1.000) <0-00:01:07> ({'r_t': -6002.7851, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  176000, Reward: -1284.085 [   0.000], Avg: -1230.609 (1.000) <0-00:01:07> ({'r_t': -6435.3054, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  177000, Reward: -1225.560 [   0.000], Avg: -1230.581 (1.000) <0-00:01:08> ({'r_t': -5684.0409, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  178000, Reward: -1130.236 [   0.000], Avg: -1230.020 (1.000) <0-00:01:08> ({'r_t': -5901.8654, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  179000, Reward: -1393.081 [   0.000], Avg: -1230.926 (1.000) <0-00:01:08> ({'r_t': -5819.2497, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  180000, Reward: -1227.210 [   0.000], Avg: -1230.906 (1.000) <0-00:01:09> ({'r_t': -6756.0274, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  181000, Reward: -1342.346 [   0.000], Avg: -1231.518 (1.000) <0-00:01:09> ({'r_t': -5853.0107, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  182000, Reward: -1245.333 [   0.000], Avg: -1231.594 (1.000) <0-00:01:09> ({'r_t': -6499.7621, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  183000, Reward: -1055.684 [   0.000], Avg: -1230.638 (1.000) <0-00:01:10> ({'r_t': -6096.5067, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  184000, Reward: -1276.638 [   0.000], Avg: -1230.886 (1.000) <0-00:01:10> ({'r_t': -6373.8464, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  185000, Reward: -1197.663 [   0.000], Avg: -1230.708 (1.000) <0-00:01:11> ({'r_t': -6345.2400, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  186000, Reward: -1102.145 [   0.000], Avg: -1230.020 (1.000) <0-00:01:11> ({'r_t': -5947.3785, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  187000, Reward: -1282.922 [   0.000], Avg: -1230.301 (1.000) <0-00:01:11> ({'r_t': -5901.0895, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  188000, Reward: -1100.564 [   0.000], Avg: -1229.615 (1.000) <0-00:01:12> ({'r_t': -6185.8337, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  189000, Reward: -1209.054 [   0.000], Avg: -1229.507 (1.000) <0-00:01:12> ({'r_t': -6377.1367, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  190000, Reward: -1253.033 [   0.000], Avg: -1229.630 (1.000) <0-00:01:13> ({'r_t': -6233.2577, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  191000, Reward: -1313.358 [   0.000], Avg: -1230.066 (1.000) <0-00:01:13> ({'r_t': -5435.1867, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  192000, Reward: -1304.911 [   0.000], Avg: -1230.454 (1.000) <0-00:01:13> ({'r_t': -6192.7262, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  193000, Reward: -1118.801 [   0.000], Avg: -1229.878 (1.000) <0-00:01:14> ({'r_t': -6575.3100, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  194000, Reward: -1180.735 [   0.000], Avg: -1229.626 (1.000) <0-00:01:14> ({'r_t': -6726.7046, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  195000, Reward: -1129.987 [   0.000], Avg: -1229.118 (1.000) <0-00:01:15> ({'r_t': -6235.9906, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  196000, Reward: -1269.813 [   0.000], Avg: -1229.325 (1.000) <0-00:01:15> ({'r_t': -5895.6696, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  197000, Reward:  -894.156 [   0.000], Avg: -1227.632 (1.000) <0-00:01:15> ({'r_t': -6197.5342, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  198000, Reward: -1197.094 [   0.000], Avg: -1227.478 (1.000) <0-00:01:16> ({'r_t': -6087.3901, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  199000, Reward: -1189.548 [   0.000], Avg: -1227.289 (1.000) <0-00:01:16> ({'r_t': -6438.2529, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  200000, Reward: -1638.741 [   0.000], Avg: -1229.336 (1.000) <0-00:01:16> ({'r_t': -6448.3490, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  201000, Reward: -1418.632 [   0.000], Avg: -1230.273 (1.000) <0-00:01:17> ({'r_t': -6365.0874, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  202000, Reward: -1196.725 [   0.000], Avg: -1230.108 (1.000) <0-00:01:17> ({'r_t': -6039.0244, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  203000, Reward: -1162.025 [   0.000], Avg: -1229.774 (1.000) <0-00:01:18> ({'r_t': -6706.7821, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  204000, Reward: -1149.796 [   0.000], Avg: -1229.384 (1.000) <0-00:01:18> ({'r_t': -6092.9687, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  205000, Reward: -1228.224 [   0.000], Avg: -1229.378 (1.000) <0-00:01:18> ({'r_t': -6340.6827, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  206000, Reward: -1258.749 [   0.000], Avg: -1229.520 (1.000) <0-00:01:19> ({'r_t': -6438.3094, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  207000, Reward: -1088.238 [   0.000], Avg: -1228.841 (1.000) <0-00:01:19> ({'r_t': -5800.6484, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  208000, Reward: -1146.232 [   0.000], Avg: -1228.445 (1.000) <0-00:01:20> ({'r_t': -6273.4879, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  209000, Reward: -1234.905 [   0.000], Avg: -1228.476 (1.000) <0-00:01:20> ({'r_t': -6284.0479, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  210000, Reward: -1304.658 [   0.000], Avg: -1228.837 (1.000) <0-00:01:20> ({'r_t': -6291.0164, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  211000, Reward: -1338.703 [   0.000], Avg: -1229.355 (1.000) <0-00:01:21> ({'r_t': -6801.6593, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  212000, Reward: -1613.736 [   0.000], Avg: -1231.160 (1.000) <0-00:01:21> ({'r_t': -6631.6122, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  213000, Reward: -1336.404 [   0.000], Avg: -1231.652 (1.000) <0-00:01:21> ({'r_t': -6447.9640, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  214000, Reward: -1428.344 [   0.000], Avg: -1232.567 (1.000) <0-00:01:22> ({'r_t': -6718.7634, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  215000, Reward: -1118.588 [   0.000], Avg: -1232.039 (1.000) <0-00:01:22> ({'r_t': -5552.7353, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  216000, Reward: -1340.550 [   0.000], Avg: -1232.539 (1.000) <0-00:01:23> ({'r_t': -5909.7801, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  217000, Reward: -1309.348 [   0.000], Avg: -1232.891 (1.000) <0-00:01:23> ({'r_t': -5677.9949, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  218000, Reward: -1173.236 [   0.000], Avg: -1232.619 (1.000) <0-00:01:23> ({'r_t': -5843.7121, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  219000, Reward:  -954.828 [   0.000], Avg: -1231.356 (1.000) <0-00:01:24> ({'r_t': -5693.2475, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  220000, Reward: -1438.288 [   0.000], Avg: -1232.293 (1.000) <0-00:01:24> ({'r_t': -5968.3257, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  221000, Reward: -1445.316 [   0.000], Avg: -1233.252 (1.000) <0-00:01:24> ({'r_t': -6252.8897, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  222000, Reward: -1064.658 [   0.000], Avg: -1232.496 (1.000) <0-00:01:25> ({'r_t': -6605.4810, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  223000, Reward: -1154.558 [   0.000], Avg: -1232.148 (1.000) <0-00:01:25> ({'r_t': -5853.3992, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  224000, Reward: -1146.182 [   0.000], Avg: -1231.766 (1.000) <0-00:01:26> ({'r_t': -5904.5671, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  225000, Reward: -1357.205 [   0.000], Avg: -1232.321 (1.000) <0-00:01:26> ({'r_t': -6440.0901, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  226000, Reward: -1392.508 [   0.000], Avg: -1233.027 (1.000) <0-00:01:26> ({'r_t': -6153.0819, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  227000, Reward: -1125.916 [   0.000], Avg: -1232.557 (1.000) <0-00:01:27> ({'r_t': -6079.2110, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  228000, Reward: -1260.490 [   0.000], Avg: -1232.679 (1.000) <0-00:01:27> ({'r_t': -5978.1970, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  229000, Reward: -1289.685 [   0.000], Avg: -1232.927 (1.000) <0-00:01:28> ({'r_t': -6062.7476, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  230000, Reward: -1535.740 [   0.000], Avg: -1234.238 (1.000) <0-00:01:28> ({'r_t': -6113.5898, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  231000, Reward: -1097.083 [   0.000], Avg: -1233.647 (1.000) <0-00:01:28> ({'r_t': -6734.2552, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  232000, Reward: -1215.588 [   0.000], Avg: -1233.569 (1.000) <0-00:01:29> ({'r_t': -6167.7810, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  233000, Reward: -1121.325 [   0.000], Avg: -1233.089 (1.000) <0-00:01:29> ({'r_t': -5955.4408, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  234000, Reward: -1023.224 [   0.000], Avg: -1232.196 (1.000) <0-00:01:29> ({'r_t': -5965.4078, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  235000, Reward: -1086.391 [   0.000], Avg: -1231.579 (1.000) <0-00:01:30> ({'r_t': -6268.7743, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  236000, Reward: -1070.307 [   0.000], Avg: -1230.898 (1.000) <0-00:01:30> ({'r_t': -6036.8886, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  237000, Reward: -1115.677 [   0.000], Avg: -1230.414 (1.000) <0-00:01:31> ({'r_t': -5886.0866, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  238000, Reward: -1193.594 [   0.000], Avg: -1230.260 (1.000) <0-00:01:31> ({'r_t': -6162.5583, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  239000, Reward: -1080.254 [   0.000], Avg: -1229.635 (1.000) <0-00:01:31> ({'r_t': -6022.1335, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  240000, Reward: -1168.294 [   0.000], Avg: -1229.380 (1.000) <0-00:01:32> ({'r_t': -5890.8416, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  241000, Reward: -1454.594 [   0.000], Avg: -1230.311 (1.000) <0-00:01:32> ({'r_t': -6548.4854, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  242000, Reward: -1163.269 [   0.000], Avg: -1230.035 (1.000) <0-00:01:32> ({'r_t': -6338.0112, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  243000, Reward: -1199.797 [   0.000], Avg: -1229.911 (1.000) <0-00:01:33> ({'r_t': -6328.4795, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  244000, Reward: -1240.340 [   0.000], Avg: -1229.954 (1.000) <0-00:01:33> ({'r_t': -6415.4209, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  245000, Reward: -1338.823 [   0.000], Avg: -1230.396 (1.000) <0-00:01:34> ({'r_t': -6029.9286, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  246000, Reward: -1266.693 [   0.000], Avg: -1230.543 (1.000) <0-00:01:34> ({'r_t': -5971.9736, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  247000, Reward: -1222.437 [   0.000], Avg: -1230.511 (1.000) <0-00:01:34> ({'r_t': -6541.1166, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  248000, Reward: -1047.838 [   0.000], Avg: -1229.777 (1.000) <0-00:01:35> ({'r_t': -6997.0692, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  249000, Reward: -1106.978 [   0.000], Avg: -1229.286 (1.000) <0-00:01:35> ({'r_t': -6616.5842, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  250000, Reward: -1164.665 [   0.000], Avg: -1229.028 (1.000) <0-00:01:35> ({'r_t': -6501.9749, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  251000, Reward: -1172.826 [   0.000], Avg: -1228.805 (1.000) <0-00:01:36> ({'r_t': -6228.7478, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  252000, Reward: -1177.358 [   0.000], Avg: -1228.602 (1.000) <0-00:01:36> ({'r_t': -6112.3071, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  253000, Reward: -1091.849 [   0.000], Avg: -1228.064 (1.000) <0-00:01:37> ({'r_t': -5986.8789, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  254000, Reward: -1143.846 [   0.000], Avg: -1227.733 (1.000) <0-00:01:37> ({'r_t': -6260.9135, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  255000, Reward: -1066.237 [   0.000], Avg: -1227.102 (1.000) <0-00:01:37> ({'r_t': -6088.7510, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  256000, Reward: -1479.970 [   0.000], Avg: -1228.086 (1.000) <0-00:01:38> ({'r_t': -6037.0290, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  257000, Reward: -1037.221 [   0.000], Avg: -1227.347 (1.000) <0-00:01:38> ({'r_t': -6156.8582, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  258000, Reward: -1316.545 [   0.000], Avg: -1227.691 (1.000) <0-00:01:39> ({'r_t': -5962.1935, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  259000, Reward: -1607.694 [   0.000], Avg: -1229.153 (1.000) <0-00:01:39> ({'r_t': -6590.8462, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  260000, Reward: -1570.335 [   0.000], Avg: -1230.460 (1.000) <0-00:01:39> ({'r_t': -6320.3410, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  261000, Reward: -1216.885 [   0.000], Avg: -1230.408 (1.000) <0-00:01:40> ({'r_t': -6440.1858, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  262000, Reward:  -977.307 [   0.000], Avg: -1229.446 (1.000) <0-00:01:40> ({'r_t': -6433.8055, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  263000, Reward: -1328.898 [   0.000], Avg: -1229.822 (1.000) <0-00:01:40> ({'r_t': -6201.1823, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  264000, Reward: -1362.714 [   0.000], Avg: -1230.324 (1.000) <0-00:01:41> ({'r_t': -5961.1673, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  265000, Reward: -1065.700 [   0.000], Avg: -1229.705 (1.000) <0-00:01:41> ({'r_t': -6396.5636, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  266000, Reward: -1180.668 [   0.000], Avg: -1229.521 (1.000) <0-00:01:42> ({'r_t': -5663.8917, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  267000, Reward: -1484.730 [   0.000], Avg: -1230.473 (1.000) <0-00:01:42> ({'r_t': -5794.6676, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  268000, Reward: -1283.621 [   0.000], Avg: -1230.671 (1.000) <0-00:01:42> ({'r_t': -6175.1398, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  269000, Reward: -1250.550 [   0.000], Avg: -1230.745 (1.000) <0-00:01:43> ({'r_t': -6687.7190, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  270000, Reward: -1494.100 [   0.000], Avg: -1231.716 (1.000) <0-00:01:43> ({'r_t': -6238.0330, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  271000, Reward: -1108.839 [   0.000], Avg: -1231.265 (1.000) <0-00:01:44> ({'r_t': -6137.5679, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  272000, Reward: -1202.147 [   0.000], Avg: -1231.158 (1.000) <0-00:01:44> ({'r_t': -6311.2162, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  273000, Reward: -1637.057 [   0.000], Avg: -1232.639 (1.000) <0-00:01:44> ({'r_t': -5892.0876, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  274000, Reward: -1109.650 [   0.000], Avg: -1232.192 (1.000) <0-00:01:45> ({'r_t': -5946.3390, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  275000, Reward: -1235.325 [   0.000], Avg: -1232.204 (1.000) <0-00:01:45> ({'r_t': -5737.3156, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  276000, Reward: -1353.611 [   0.000], Avg: -1232.642 (1.000) <0-00:01:45> ({'r_t': -6021.7088, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  277000, Reward: -1214.915 [   0.000], Avg: -1232.578 (1.000) <0-00:01:46> ({'r_t': -5930.3353, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  278000, Reward: -1135.379 [   0.000], Avg: -1232.230 (1.000) <0-00:01:46> ({'r_t': -5737.0436, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  279000, Reward: -1377.263 [   0.000], Avg: -1232.748 (1.000) <0-00:01:47> ({'r_t': -5818.0205, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  280000, Reward: -1147.094 [   0.000], Avg: -1232.443 (1.000) <0-00:01:47> ({'r_t': -6677.5838, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  281000, Reward: -1379.455 [   0.000], Avg: -1232.964 (1.000) <0-00:01:47> ({'r_t': -6291.2438, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  282000, Reward: -1348.879 [   0.000], Avg: -1233.374 (1.000) <0-00:01:48> ({'r_t': -6604.8302, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  283000, Reward: -1148.218 [   0.000], Avg: -1233.074 (1.000) <0-00:01:48> ({'r_t': -6210.3340, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  284000, Reward: -1269.532 [   0.000], Avg: -1233.202 (1.000) <0-00:01:49> ({'r_t': -5778.4217, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  285000, Reward: -1088.151 [   0.000], Avg: -1232.695 (1.000) <0-00:01:49> ({'r_t': -5954.5764, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  286000, Reward: -1093.973 [   0.000], Avg: -1232.211 (1.000) <0-00:01:49> ({'r_t': -5931.3896, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  287000, Reward: -1044.088 [   0.000], Avg: -1231.558 (1.000) <0-00:01:50> ({'r_t': -6448.9221, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  288000, Reward: -1399.393 [   0.000], Avg: -1232.139 (1.000) <0-00:01:50> ({'r_t': -6054.8886, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  289000, Reward: -1251.385 [   0.000], Avg: -1232.205 (1.000) <0-00:01:50> ({'r_t': -5952.3794, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  290000, Reward: -1245.207 [   0.000], Avg: -1232.250 (1.000) <0-00:01:51> ({'r_t': -6399.7090, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  291000, Reward: -1356.847 [   0.000], Avg: -1232.677 (1.000) <0-00:01:51> ({'r_t': -6314.6691, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  292000, Reward: -1102.446 [   0.000], Avg: -1232.232 (1.000) <0-00:01:52> ({'r_t': -6828.3240, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  293000, Reward: -1144.962 [   0.000], Avg: -1231.935 (1.000) <0-00:01:52> ({'r_t': -6123.8923, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  294000, Reward: -1177.333 [   0.000], Avg: -1231.750 (1.000) <0-00:01:53> ({'r_t': -6089.3628, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  295000, Reward: -1274.135 [   0.000], Avg: -1231.893 (1.000) <0-00:01:53> ({'r_t': -6493.6668, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  296000, Reward: -1124.938 [   0.000], Avg: -1231.533 (1.000) <0-00:01:53> ({'r_t': -6433.3111, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  297000, Reward: -1103.852 [   0.000], Avg: -1231.105 (1.000) <0-00:01:54> ({'r_t': -6618.9078, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  298000, Reward: -1228.059 [   0.000], Avg: -1231.095 (1.000) <0-00:01:54> ({'r_t': -6225.3908, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  299000, Reward: -1171.817 [   0.000], Avg: -1230.897 (1.000) <0-00:01:55> ({'r_t': -6222.6495, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  300000, Reward: -1286.349 [   0.000], Avg: -1231.081 (1.000) <0-00:01:55> ({'r_t': -5742.7374, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  301000, Reward:  -988.967 [   0.000], Avg: -1230.280 (1.000) <0-00:01:55> ({'r_t': -5686.6388, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  302000, Reward: -1620.548 [   0.000], Avg: -1231.568 (1.000) <0-00:01:56> ({'r_t': -6509.7116, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  303000, Reward: -1529.971 [   0.000], Avg: -1232.549 (1.000) <0-00:01:56> ({'r_t': -6090.4449, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  304000, Reward: -1084.166 [   0.000], Avg: -1232.063 (1.000) <0-00:01:56> ({'r_t': -5758.4506, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  305000, Reward: -1201.856 [   0.000], Avg: -1231.964 (1.000) <0-00:01:57> ({'r_t': -5825.3056, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  306000, Reward: -1164.148 [   0.000], Avg: -1231.743 (1.000) <0-00:01:57> ({'r_t': -6384.2209, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  307000, Reward: -1069.606 [   0.000], Avg: -1231.217 (1.000) <0-00:01:58> ({'r_t': -5769.7449, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  308000, Reward: -1066.979 [   0.000], Avg: -1230.685 (1.000) <0-00:01:58> ({'r_t': -5910.2814, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  309000, Reward: -1174.140 [   0.000], Avg: -1230.503 (1.000) <0-00:01:58> ({'r_t': -5925.5495, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  310000, Reward: -1307.320 [   0.000], Avg: -1230.750 (1.000) <0-00:01:59> ({'r_t': -6659.3188, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  311000, Reward: -1122.897 [   0.000], Avg: -1230.404 (1.000) <0-00:01:59> ({'r_t': -5930.9578, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  312000, Reward: -1152.568 [   0.000], Avg: -1230.155 (1.000) <0-00:02:00> ({'r_t': -6160.0451, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  313000, Reward: -1166.658 [   0.000], Avg: -1229.953 (1.000) <0-00:02:00> ({'r_t': -6566.2731, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  314000, Reward: -1087.143 [   0.000], Avg: -1229.500 (1.000) <0-00:02:01> ({'r_t': -5769.9350, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  315000, Reward: -1213.948 [   0.000], Avg: -1229.451 (1.000) <0-00:02:01> ({'r_t': -5708.9870, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  316000, Reward: -1312.682 [   0.000], Avg: -1229.713 (1.000) <0-00:02:02> ({'r_t': -6404.3039, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  317000, Reward: -1023.052 [   0.000], Avg: -1229.063 (1.000) <0-00:02:02> ({'r_t': -6366.4256, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  318000, Reward: -1568.245 [   0.000], Avg: -1230.127 (1.000) <0-00:02:02> ({'r_t': -6302.6864, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  319000, Reward: -1019.506 [   0.000], Avg: -1229.468 (1.000) <0-00:02:03> ({'r_t': -6804.5264, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  320000, Reward: -1529.331 [   0.000], Avg: -1230.402 (1.000) <0-00:02:03> ({'r_t': -6500.4964, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  321000, Reward: -1141.664 [   0.000], Avg: -1230.127 (1.000) <0-00:02:03> ({'r_t': -5568.3355, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  322000, Reward: -1369.540 [   0.000], Avg: -1230.559 (1.000) <0-00:02:04> ({'r_t': -6755.5427, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  323000, Reward: -1337.580 [   0.000], Avg: -1230.889 (1.000) <0-00:02:04> ({'r_t': -6545.5843, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  324000, Reward: -1450.281 [   0.000], Avg: -1231.564 (1.000) <0-00:02:05> ({'r_t': -5910.4243, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  325000, Reward:  -998.608 [   0.000], Avg: -1230.849 (1.000) <0-00:02:05> ({'r_t': -6222.4610, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  326000, Reward: -1158.692 [   0.000], Avg: -1230.629 (1.000) <0-00:02:05> ({'r_t': -6189.2163, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  327000, Reward: -1223.462 [   0.000], Avg: -1230.607 (1.000) <0-00:02:06> ({'r_t': -6280.4877, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  328000, Reward: -1228.721 [   0.000], Avg: -1230.601 (1.000) <0-00:02:06> ({'r_t': -6164.1459, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  329000, Reward: -1466.896 [   0.000], Avg: -1231.317 (1.000) <0-00:02:06> ({'r_t': -6146.3441, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  330000, Reward: -1273.347 [   0.000], Avg: -1231.444 (1.000) <0-00:02:07> ({'r_t': -6257.3675, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  331000, Reward: -1493.090 [   0.000], Avg: -1232.232 (1.000) <0-00:02:07> ({'r_t': -6069.6358, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  332000, Reward: -1337.958 [   0.000], Avg: -1232.550 (1.000) <0-00:02:08> ({'r_t': -6152.1987, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  333000, Reward: -1400.298 [   0.000], Avg: -1233.052 (1.000) <0-00:02:08> ({'r_t': -6059.9237, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  334000, Reward: -1034.577 [   0.000], Avg: -1232.459 (1.000) <0-00:02:08> ({'r_t': -6075.1578, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  335000, Reward: -1182.236 [   0.000], Avg: -1232.310 (1.000) <0-00:02:09> ({'r_t': -6568.0653, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  336000, Reward: -1139.659 [   0.000], Avg: -1232.035 (1.000) <0-00:02:09> ({'r_t': -5898.5797, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  337000, Reward: -1245.519 [   0.000], Avg: -1232.075 (1.000) <0-00:02:09> ({'r_t': -5892.6764, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  338000, Reward: -1221.957 [   0.000], Avg: -1232.045 (1.000) <0-00:02:10> ({'r_t': -5716.3109, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  339000, Reward: -1219.101 [   0.000], Avg: -1232.007 (1.000) <0-00:02:10> ({'r_t': -5971.0646, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  340000, Reward: -1387.872 [   0.000], Avg: -1232.464 (1.000) <0-00:02:11> ({'r_t': -6712.3601, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  341000, Reward: -1042.942 [   0.000], Avg: -1231.910 (1.000) <0-00:02:11> ({'r_t': -6136.5108, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  342000, Reward: -1218.197 [   0.000], Avg: -1231.870 (1.000) <0-00:02:11> ({'r_t': -6484.2043, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  343000, Reward: -1374.549 [   0.000], Avg: -1232.285 (1.000) <0-00:02:12> ({'r_t': -6245.8753, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  344000, Reward: -1134.257 [   0.000], Avg: -1232.001 (1.000) <0-00:02:12> ({'r_t': -6303.7770, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  345000, Reward: -1134.929 [   0.000], Avg: -1231.720 (1.000) <0-00:02:13> ({'r_t': -5873.5876, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  346000, Reward: -1203.881 [   0.000], Avg: -1231.640 (1.000) <0-00:02:13> ({'r_t': -6289.7418, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  347000, Reward: -1118.906 [   0.000], Avg: -1231.316 (1.000) <0-00:02:13> ({'r_t': -5814.1330, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  348000, Reward: -1220.368 [   0.000], Avg: -1231.284 (1.000) <0-00:02:14> ({'r_t': -5376.3184, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  349000, Reward: -1126.268 [   0.000], Avg: -1230.984 (1.000) <0-00:02:14> ({'r_t': -5657.0295, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  350000, Reward: -1123.622 [   0.000], Avg: -1230.679 (1.000) <0-00:02:14> ({'r_t': -6872.4682, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  351000, Reward: -1250.293 [   0.000], Avg: -1230.734 (1.000) <0-00:02:15> ({'r_t': -5852.0357, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  352000, Reward: -1434.919 [   0.000], Avg: -1231.313 (1.000) <0-00:02:15> ({'r_t': -6339.6719, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  353000, Reward: -1149.558 [   0.000], Avg: -1231.082 (1.000) <0-00:02:15> ({'r_t': -6557.8443, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  354000, Reward: -1159.763 [   0.000], Avg: -1230.881 (1.000) <0-00:02:16> ({'r_t': -5952.7580, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  355000, Reward: -1330.378 [   0.000], Avg: -1231.160 (1.000) <0-00:02:16> ({'r_t': -6815.3029, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  356000, Reward: -1098.349 [   0.000], Avg: -1230.788 (1.000) <0-00:02:17> ({'r_t': -6247.1954, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  357000, Reward: -1433.225 [   0.000], Avg: -1231.354 (1.000) <0-00:02:17> ({'r_t': -6423.7220, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  358000, Reward: -1295.333 [   0.000], Avg: -1231.532 (1.000) <0-00:02:17> ({'r_t': -6086.6496, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  359000, Reward: -1520.744 [   0.000], Avg: -1232.335 (1.000) <0-00:02:18> ({'r_t': -6052.1492, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  360000, Reward: -1358.961 [   0.000], Avg: -1232.686 (1.000) <0-00:02:18> ({'r_t': -6145.9961, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  361000, Reward: -1163.092 [   0.000], Avg: -1232.494 (1.000) <0-00:02:18> ({'r_t': -6389.5730, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  362000, Reward: -1099.829 [   0.000], Avg: -1232.128 (1.000) <0-00:02:19> ({'r_t': -6251.4253, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  363000, Reward: -1233.855 [   0.000], Avg: -1232.133 (1.000) <0-00:02:19> ({'r_t': -5764.3488, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  364000, Reward: -1214.332 [   0.000], Avg: -1232.084 (1.000) <0-00:02:20> ({'r_t': -5980.4155, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  365000, Reward: -1485.236 [   0.000], Avg: -1232.776 (1.000) <0-00:02:20> ({'r_t': -6191.7022, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  366000, Reward: -1214.998 [   0.000], Avg: -1232.728 (1.000) <0-00:02:20> ({'r_t': -5889.0548, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  367000, Reward: -1291.963 [   0.000], Avg: -1232.889 (1.000) <0-00:02:21> ({'r_t': -6604.9176, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  368000, Reward: -1175.832 [   0.000], Avg: -1232.734 (1.000) <0-00:02:21> ({'r_t': -6539.6740, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  369000, Reward: -1127.927 [   0.000], Avg: -1232.451 (1.000) <0-00:02:21> ({'r_t': -5614.2868, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  370000, Reward: -1229.748 [   0.000], Avg: -1232.443 (1.000) <0-00:02:22> ({'r_t': -6238.7957, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  371000, Reward: -1237.298 [   0.000], Avg: -1232.456 (1.000) <0-00:02:22> ({'r_t': -6518.2203, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  372000, Reward: -1107.964 [   0.000], Avg: -1232.123 (1.000) <0-00:02:23> ({'r_t': -6059.0841, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  373000, Reward: -1455.994 [   0.000], Avg: -1232.721 (1.000) <0-00:02:23> ({'r_t': -6320.7387, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  374000, Reward: -1284.847 [   0.000], Avg: -1232.860 (1.000) <0-00:02:23> ({'r_t': -6424.8963, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  375000, Reward: -1264.117 [   0.000], Avg: -1232.943 (1.000) <0-00:02:24> ({'r_t': -5516.4252, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  376000, Reward: -1274.600 [   0.000], Avg: -1233.054 (1.000) <0-00:02:24> ({'r_t': -6459.3207, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  377000, Reward: -1083.098 [   0.000], Avg: -1232.657 (1.000) <0-00:02:24> ({'r_t': -6456.8203, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  378000, Reward: -1297.464 [   0.000], Avg: -1232.828 (1.000) <0-00:02:25> ({'r_t': -5833.7752, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  379000, Reward: -1569.920 [   0.000], Avg: -1233.715 (1.000) <0-00:02:25> ({'r_t': -6203.9650, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  380000, Reward:  -974.087 [   0.000], Avg: -1233.034 (1.000) <0-00:02:26> ({'r_t': -6343.0570, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  381000, Reward: -1219.417 [   0.000], Avg: -1232.998 (1.000) <0-00:02:26> ({'r_t': -5691.9907, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  382000, Reward: -1479.477 [   0.000], Avg: -1233.642 (1.000) <0-00:02:26> ({'r_t': -5757.6259, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  383000, Reward: -1085.261 [   0.000], Avg: -1233.255 (1.000) <0-00:02:27> ({'r_t': -6122.3585, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  384000, Reward: -1306.554 [   0.000], Avg: -1233.446 (1.000) <0-00:02:27> ({'r_t': -6389.6866, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  385000, Reward: -1132.608 [   0.000], Avg: -1233.184 (1.000) <0-00:02:27> ({'r_t': -6179.4629, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  386000, Reward: -1232.567 [   0.000], Avg: -1233.183 (1.000) <0-00:02:28> ({'r_t': -6291.4139, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  387000, Reward:  -986.138 [   0.000], Avg: -1232.546 (1.000) <0-00:02:28> ({'r_t': -6226.3793, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  388000, Reward: -1442.103 [   0.000], Avg: -1233.085 (1.000) <0-00:02:29> ({'r_t': -5976.7317, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  389000, Reward: -1075.731 [   0.000], Avg: -1232.681 (1.000) <0-00:02:29> ({'r_t': -6832.8301, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  390000, Reward: -1239.521 [   0.000], Avg: -1232.699 (1.000) <0-00:02:29> ({'r_t': -6359.1187, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  391000, Reward: -1203.571 [   0.000], Avg: -1232.625 (1.000) <0-00:02:30> ({'r_t': -6570.5966, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  392000, Reward: -1181.691 [   0.000], Avg: -1232.495 (1.000) <0-00:02:30> ({'r_t': -6153.8974, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  393000, Reward: -1175.897 [   0.000], Avg: -1232.351 (1.000) <0-00:02:30> ({'r_t': -5680.8310, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  394000, Reward: -1064.184 [   0.000], Avg: -1231.926 (1.000) <0-00:02:31> ({'r_t': -6301.4421, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  395000, Reward: -1615.136 [   0.000], Avg: -1232.893 (1.000) <0-00:02:31> ({'r_t': -5591.6736, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  396000, Reward: -1111.493 [   0.000], Avg: -1232.588 (1.000) <0-00:02:32> ({'r_t': -5917.5924, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  397000, Reward: -1359.041 [   0.000], Avg: -1232.905 (1.000) <0-00:02:32> ({'r_t': -6260.9697, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  398000, Reward: -1312.799 [   0.000], Avg: -1233.105 (1.000) <0-00:02:32> ({'r_t': -5620.3640, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  399000, Reward: -1259.854 [   0.000], Avg: -1233.172 (1.000) <0-00:02:33> ({'r_t': -5948.3694, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  400000, Reward: -1006.288 [   0.000], Avg: -1232.607 (1.000) <0-00:02:33> ({'r_t': -6177.6561, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  401000, Reward: -1186.704 [   0.000], Avg: -1232.492 (1.000) <0-00:02:33> ({'r_t': -5706.2356, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  402000, Reward: -1010.354 [   0.000], Avg: -1231.941 (1.000) <0-00:02:34> ({'r_t': -5714.9124, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  403000, Reward: -1443.937 [   0.000], Avg: -1232.466 (1.000) <0-00:02:34> ({'r_t': -5877.2347, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  404000, Reward: -1173.135 [   0.000], Avg: -1232.319 (1.000) <0-00:02:35> ({'r_t': -6421.9233, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  405000, Reward: -1215.073 [   0.000], Avg: -1232.277 (1.000) <0-00:02:35> ({'r_t': -6262.9167, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  406000, Reward: -1467.069 [   0.000], Avg: -1232.854 (1.000) <0-00:02:35> ({'r_t': -6191.5085, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  407000, Reward: -1299.217 [   0.000], Avg: -1233.016 (1.000) <0-00:02:36> ({'r_t': -5787.4161, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  408000, Reward: -1098.973 [   0.000], Avg: -1232.689 (1.000) <0-00:02:36> ({'r_t': -6779.2350, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  409000, Reward: -1067.996 [   0.000], Avg: -1232.287 (1.000) <0-00:02:36> ({'r_t': -6284.0402, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  410000, Reward: -1089.740 [   0.000], Avg: -1231.940 (1.000) <0-00:02:37> ({'r_t': -6521.6375, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  411000, Reward: -1174.340 [   0.000], Avg: -1231.800 (1.000) <0-00:02:37> ({'r_t': -5839.5828, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  412000, Reward: -1407.537 [   0.000], Avg: -1232.226 (1.000) <0-00:02:38> ({'r_t': -5984.8608, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  413000, Reward: -1129.610 [   0.000], Avg: -1231.978 (1.000) <0-00:02:38> ({'r_t': -6245.4102, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  414000, Reward: -1403.766 [   0.000], Avg: -1232.392 (1.000) <0-00:02:38> ({'r_t': -6450.9253, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  415000, Reward: -1217.203 [   0.000], Avg: -1232.355 (1.000) <0-00:02:39> ({'r_t': -6623.5158, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  416000, Reward: -1486.267 [   0.000], Avg: -1232.964 (1.000) <0-00:02:39> ({'r_t': -6543.6064, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  417000, Reward: -1373.326 [   0.000], Avg: -1233.300 (1.000) <0-00:02:39> ({'r_t': -6058.0313, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  418000, Reward: -1129.685 [   0.000], Avg: -1233.053 (1.000) <0-00:02:40> ({'r_t': -5888.3134, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  419000, Reward: -1269.294 [   0.000], Avg: -1233.139 (1.000) <0-00:02:40> ({'r_t': -6040.8656, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  420000, Reward: -1036.093 [   0.000], Avg: -1232.671 (1.000) <0-00:02:41> ({'r_t': -5768.5741, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  421000, Reward: -1258.580 [   0.000], Avg: -1232.733 (1.000) <0-00:02:41> ({'r_t': -6727.7076, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  422000, Reward: -1118.839 [   0.000], Avg: -1232.463 (1.000) <0-00:02:41> ({'r_t': -6765.0019, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  423000, Reward: -1283.475 [   0.000], Avg: -1232.584 (1.000) <0-00:02:42> ({'r_t': -5973.1474, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  424000, Reward: -1181.047 [   0.000], Avg: -1232.462 (1.000) <0-00:02:42> ({'r_t': -6197.2860, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  425000, Reward: -1040.301 [   0.000], Avg: -1232.011 (1.000) <0-00:02:42> ({'r_t': -5759.3622, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  426000, Reward: -1270.279 [   0.000], Avg: -1232.101 (1.000) <0-00:02:43> ({'r_t': -5962.3606, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  427000, Reward: -1121.021 [   0.000], Avg: -1231.841 (1.000) <0-00:02:43> ({'r_t': -5402.0635, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  428000, Reward: -1631.135 [   0.000], Avg: -1232.772 (1.000) <0-00:02:44> ({'r_t': -6348.0725, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  429000, Reward: -1071.756 [   0.000], Avg: -1232.398 (1.000) <0-00:02:44> ({'r_t': -6218.6395, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  430000, Reward: -1171.785 [   0.000], Avg: -1232.257 (1.000) <0-00:02:44> ({'r_t': -6261.2161, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  431000, Reward: -1245.715 [   0.000], Avg: -1232.288 (1.000) <0-00:02:45> ({'r_t': -6009.5385, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  432000, Reward: -1270.613 [   0.000], Avg: -1232.377 (1.000) <0-00:02:45> ({'r_t': -6605.5203, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  433000, Reward: -1264.243 [   0.000], Avg: -1232.450 (1.000) <0-00:02:45> ({'r_t': -6706.4147, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  434000, Reward: -1111.664 [   0.000], Avg: -1232.172 (1.000) <0-00:02:46> ({'r_t': -5776.9192, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  435000, Reward: -1086.366 [   0.000], Avg: -1231.838 (1.000) <0-00:02:46> ({'r_t': -5896.5288, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  436000, Reward: -1247.499 [   0.000], Avg: -1231.874 (1.000) <0-00:02:47> ({'r_t': -6412.1167, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  437000, Reward: -1086.271 [   0.000], Avg: -1231.541 (1.000) <0-00:02:47> ({'r_t': -5739.1577, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  438000, Reward: -1143.499 [   0.000], Avg: -1231.341 (1.000) <0-00:02:47> ({'r_t': -5949.0451, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  439000, Reward: -1195.269 [   0.000], Avg: -1231.259 (1.000) <0-00:02:48> ({'r_t': -6418.8211, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  440000, Reward: -1256.597 [   0.000], Avg: -1231.316 (1.000) <0-00:02:48> ({'r_t': -5420.2572, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  441000, Reward: -1224.846 [   0.000], Avg: -1231.302 (1.000) <0-00:02:48> ({'r_t': -6124.6965, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  442000, Reward: -1379.822 [   0.000], Avg: -1231.637 (1.000) <0-00:02:49> ({'r_t': -6556.1122, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  443000, Reward:  -965.433 [   0.000], Avg: -1231.037 (1.000) <0-00:02:49> ({'r_t': -6239.6240, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  444000, Reward: -1355.082 [   0.000], Avg: -1231.316 (1.000) <0-00:02:50> ({'r_t': -6346.7741, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  445000, Reward: -1167.606 [   0.000], Avg: -1231.173 (1.000) <0-00:02:50> ({'r_t': -5689.4136, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  446000, Reward: -1295.224 [   0.000], Avg: -1231.317 (1.000) <0-00:02:50> ({'r_t': -6280.4450, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  447000, Reward: -1181.677 [   0.000], Avg: -1231.206 (1.000) <0-00:02:51> ({'r_t': -6751.5255, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  448000, Reward: -1036.801 [   0.000], Avg: -1230.773 (1.000) <0-00:02:51> ({'r_t': -6413.4306, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  449000, Reward: -1334.603 [   0.000], Avg: -1231.004 (1.000) <0-00:02:51> ({'r_t': -5857.1871, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  450000, Reward: -1526.385 [   0.000], Avg: -1231.658 (1.000) <0-00:02:52> ({'r_t': -5728.8363, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  451000, Reward: -1256.486 [   0.000], Avg: -1231.713 (1.000) <0-00:02:52> ({'r_t': -6446.9050, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  452000, Reward: -1210.864 [   0.000], Avg: -1231.667 (1.000) <0-00:02:53> ({'r_t': -6717.7502, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  453000, Reward: -1561.317 [   0.000], Avg: -1232.393 (1.000) <0-00:02:53> ({'r_t': -5924.4643, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  454000, Reward:  -983.300 [   0.000], Avg: -1231.846 (1.000) <0-00:02:53> ({'r_t': -6144.8261, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  455000, Reward: -1205.027 [   0.000], Avg: -1231.787 (1.000) <0-00:02:54> ({'r_t': -5505.3536, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  456000, Reward: -1224.661 [   0.000], Avg: -1231.772 (1.000) <0-00:02:54> ({'r_t': -6229.6096, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  457000, Reward: -1307.924 [   0.000], Avg: -1231.938 (1.000) <0-00:02:54> ({'r_t': -5894.7840, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  458000, Reward: -1039.958 [   0.000], Avg: -1231.520 (1.000) <0-00:02:55> ({'r_t': -6027.6066, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  459000, Reward: -1148.178 [   0.000], Avg: -1231.338 (1.000) <0-00:02:55> ({'r_t': -5618.4167, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  460000, Reward: -1315.543 [   0.000], Avg: -1231.521 (1.000) <0-00:02:55> ({'r_t': -6063.4293, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  461000, Reward: -1280.718 [   0.000], Avg: -1231.628 (1.000) <0-00:02:56> ({'r_t': -6285.3379, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  462000, Reward: -1354.850 [   0.000], Avg: -1231.894 (1.000) <0-00:02:56> ({'r_t': -6131.6400, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  463000, Reward: -1232.409 [   0.000], Avg: -1231.895 (1.000) <0-00:02:57> ({'r_t': -6310.3382, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  464000, Reward: -1513.596 [   0.000], Avg: -1232.501 (1.000) <0-00:02:57> ({'r_t': -6410.0334, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  465000, Reward: -1121.767 [   0.000], Avg: -1232.263 (1.000) <0-00:02:57> ({'r_t': -6529.7090, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  466000, Reward: -1062.862 [   0.000], Avg: -1231.900 (1.000) <0-00:02:58> ({'r_t': -6362.0273, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  467000, Reward: -1477.040 [   0.000], Avg: -1232.424 (1.000) <0-00:02:58> ({'r_t': -6432.8872, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  468000, Reward: -1559.540 [   0.000], Avg: -1233.122 (1.000) <0-00:02:58> ({'r_t': -6022.1632, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  469000, Reward: -1148.518 [   0.000], Avg: -1232.942 (1.000) <0-00:02:59> ({'r_t': -6617.3831, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  470000, Reward: -1487.060 [   0.000], Avg: -1233.481 (1.000) <0-00:02:59> ({'r_t': -5649.3640, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  471000, Reward: -1229.845 [   0.000], Avg: -1233.473 (1.000) <0-00:03:00> ({'r_t': -6096.1484, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  472000, Reward: -1303.949 [   0.000], Avg: -1233.622 (1.000) <0-00:03:00> ({'r_t': -5898.9402, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  473000, Reward: -1196.070 [   0.000], Avg: -1233.543 (1.000) <0-00:03:00> ({'r_t': -5691.3037, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  474000, Reward: -1455.315 [   0.000], Avg: -1234.010 (1.000) <0-00:03:01> ({'r_t': -6386.8575, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  475000, Reward: -1249.245 [   0.000], Avg: -1234.042 (1.000) <0-00:03:01> ({'r_t': -5804.2099, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  476000, Reward: -1123.035 [   0.000], Avg: -1233.809 (1.000) <0-00:03:01> ({'r_t': -6479.3124, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  477000, Reward:  -947.016 [   0.000], Avg: -1233.209 (1.000) <0-00:03:02> ({'r_t': -6145.2406, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  478000, Reward: -1306.046 [   0.000], Avg: -1233.361 (1.000) <0-00:03:02> ({'r_t': -5727.3548, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  479000, Reward: -1279.029 [   0.000], Avg: -1233.457 (1.000) <0-00:03:03> ({'r_t': -6209.7356, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  480000, Reward: -1222.569 [   0.000], Avg: -1233.434 (1.000) <0-00:03:03> ({'r_t': -6367.0961, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  481000, Reward: -1265.223 [   0.000], Avg: -1233.500 (1.000) <0-00:03:03> ({'r_t': -6953.2943, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  482000, Reward: -1006.338 [   0.000], Avg: -1233.030 (1.000) <0-00:03:04> ({'r_t': -6476.2243, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  483000, Reward: -1163.997 [   0.000], Avg: -1232.887 (1.000) <0-00:03:04> ({'r_t': -6821.5625, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  484000, Reward: -1110.685 [   0.000], Avg: -1232.635 (1.000) <0-00:03:04> ({'r_t': -6486.9445, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  485000, Reward:  -988.036 [   0.000], Avg: -1232.132 (1.000) <0-00:03:05> ({'r_t': -6593.4922, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  486000, Reward: -1208.731 [   0.000], Avg: -1232.084 (1.000) <0-00:03:05> ({'r_t': -6163.7675, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  487000, Reward: -1135.564 [   0.000], Avg: -1231.886 (1.000) <0-00:03:06> ({'r_t': -5754.7085, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  488000, Reward: -1139.419 [   0.000], Avg: -1231.697 (1.000) <0-00:03:06> ({'r_t': -6221.9318, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  489000, Reward: -1165.655 [   0.000], Avg: -1231.562 (1.000) <0-00:03:06> ({'r_t': -6080.0380, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  490000, Reward: -1201.584 [   0.000], Avg: -1231.501 (1.000) <0-00:03:07> ({'r_t': -5773.9901, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  491000, Reward: -1174.329 [   0.000], Avg: -1231.385 (1.000) <0-00:03:07> ({'r_t': -5943.5433, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  492000, Reward: -1326.640 [   0.000], Avg: -1231.578 (1.000) <0-00:03:07> ({'r_t': -5976.6172, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  493000, Reward: -1211.781 [   0.000], Avg: -1231.538 (1.000) <0-00:03:08> ({'r_t': -6365.5664, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  494000, Reward: -1144.462 [   0.000], Avg: -1231.362 (1.000) <0-00:03:08> ({'r_t': -6100.8319, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  495000, Reward: -1173.221 [   0.000], Avg: -1231.245 (1.000) <0-00:03:09> ({'r_t': -6798.1852, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  496000, Reward: -1389.708 [   0.000], Avg: -1231.564 (1.000) <0-00:03:09> ({'r_t': -6193.1142, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  497000, Reward: -1184.310 [   0.000], Avg: -1231.469 (1.000) <0-00:03:09> ({'r_t': -6135.8035, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  498000, Reward: -1259.841 [   0.000], Avg: -1231.526 (1.000) <0-00:03:10> ({'r_t': -6210.9744, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  499000, Reward: -1244.450 [   0.000], Avg: -1231.551 (1.000) <0-00:03:10> ({'r_t': -6361.3923, 'eps':     1.0000, 'eps_e':     1.0000})
Step:  500000, Reward: -1240.380 [   0.000], Avg: -1231.569 (1.000) <0-00:03:10> ({'r_t': -6234.8428, 'eps':     1.0000, 'eps_e':     1.0000})
